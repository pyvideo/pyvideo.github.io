<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Pavithra Eswaramoorthy</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_pavithra-eswaramoorthy.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2025-05-16T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Data of an Unusual Size: A practical guide to analysis and interactive visualization of massive datasets</title><link href="https://pyvideo.org/pycon-us-2023/data-of-an-unusual-size-a-practical-guide-to-analysis-and-interactive-visualization-of-massive-datasets.html" rel="alternate"></link><published>2023-04-19T00:00:00+00:00</published><updated>2023-04-19T00:00:00+00:00</updated><author><name>Pavithra Eswaramoorthy</name></author><id>tag:pyvideo.org,2023-04-19:/pycon-us-2023/data-of-an-unusual-size-a-practical-guide-to-analysis-and-interactive-visualization-of-massive-datasets.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While most folks aren't at the scale of cloud giants or black hole
research teams that analyze Petabytes of data every day, you can easily
fall into a situation where your laptop doesn't have quite enough power
to do the analytics you need.&lt;/p&gt;
&lt;p&gt;&amp;quot;Big data&amp;quot; refers to any data …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While most folks aren't at the scale of cloud giants or black hole
research teams that analyze Petabytes of data every day, you can easily
fall into a situation where your laptop doesn't have quite enough power
to do the analytics you need.&lt;/p&gt;
&lt;p&gt;&amp;quot;Big data&amp;quot; refers to any data that is too large to handle comfortably
with your current tools and infrastructure. As the leading language for
data science, Python has many mature options that allow you to work with
datasets that are orders of magnitudes larger than what can fit into a
typical laptop's memory.&lt;/p&gt;
&lt;p&gt;In this hands-on tutorial, you will learn the fundamentals of analyzing
massive datasets with real-world examples on actual powerful machines on
a public cloud – starting from how the data is stored and read, to how
it is processed and visualized.&lt;/p&gt;
&lt;p&gt;You will understand how large-scale analysis differs from local
workflows, the unique challenges associated with scale, and some best
practices to work productively with your data. By the end, you will be
able to answer:&lt;/p&gt;
&lt;p&gt;What makes some data formats more efficient at scale? Why, how, and when
(and when not) to leverage parallel and distributed computation
(primarily with Dask) for your work? How to manage cloud storage,
resources, and costs effectively? How interactive visualization can make
large and complex data more understandable (primarily with hvPlot)? How
to comfortably collaborate on data science projects with your entire
team?&lt;/p&gt;
&lt;p&gt;The tutorial focuses on the reasoning, intuition, and best practices
around big data workflows, while covering the practical details of
Python libraries like Dask and hvPlot that are great at handling large
data. It includes plenty of exercises to help you build a foundational
understanding within three hours.&lt;/p&gt;
</content><category term="PyCon US 2023"></category></entry><entry><title>From RAGs to riches: Build an AI document inquiry web-app</title><link href="https://pyvideo.org/pycon-us-2024/from-rags-to-riches-build-an-ai-document-inquiry-web-app.html" rel="alternate"></link><published>2024-05-16T00:00:00+00:00</published><updated>2024-05-16T00:00:00+00:00</updated><author><name>Pavithra Eswaramoorthy</name></author><id>tag:pyvideo.org,2024-05-16:/pycon-us-2024/from-rags-to-riches-build-an-ai-document-inquiry-web-app.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As we descend from the peak of the hype cycle around Large Language
Models (LLMs), chat-based document interrogation systems have emerged as
a high value practical use case. The ability to ask natural language
questions and get relevant and accurate answers from a large corpus of
documents can fundamentally …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As we descend from the peak of the hype cycle around Large Language
Models (LLMs), chat-based document interrogation systems have emerged as
a high value practical use case. The ability to ask natural language
questions and get relevant and accurate answers from a large corpus of
documents can fundamentally transform organizations and make
institutional knowledge accessible. Foundational LLM models like
OpenAI’s GPT4 provide powerful capabilities, but using them directly to
answer questions about a collection of documents presents
accuracy-related limitations. Retrieval-augmented generation (RAG) is
the leading approach to enhancing the capabilities and usability of
Large Language Models, especially for personal or company-level
chat-based document interrogation systems.&lt;/p&gt;
&lt;p&gt;RAG is a technique to share relevant context and external information
(retrieved from vector storage) to LLMs, thus making them more powerful
and accurate. In this tutorial, we’ll dive into RAG by creating a
personal chat application that accurately answers questions about your
selected documents. We’ll use a new &lt;a class="reference external" href="https://ragna.chat/en/latest/"&gt;OSS project called
Ragna&lt;/a&gt; that provides a friendly Python
and REST API, designed for this particular case. For our example, we’ll
test the effectiveness of different LLMs and vector databases. We'll
then develop a web application that leverages the REST API, built with
&lt;a class="reference external" href="https://panel.holoviz.org"&gt;Panel–a powerful OSS Python application development
framework&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;By the end of this tutorial, you will have an understanding of the
fundamental components that form a RAG model, and practical knowledge of
open source tools that can help you or your organization explore and
build on your own applications. This tutorial is designed to enable
enthusiasts in our community to explore an interesting topic using some
beginner-friendly Python libraries.&lt;/p&gt;
</content><category term="PyCon US 2024"></category></entry><entry><title>Inclusive Data for 1.3 Billion: Designing Accessible Visualizations</title><link href="https://pyvideo.org/pycon-us-2025/inclusive-data-for-13-billion-designing-accessible-visualizations.html" rel="alternate"></link><published>2025-05-16T00:00:00+00:00</published><updated>2025-05-16T00:00:00+00:00</updated><author><name>Pavithra Eswaramoorthy</name></author><id>tag:pyvideo.org,2025-05-16:/pycon-us-2025/inclusive-data-for-13-billion-designing-accessible-visualizations.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;According to the World Health Organization (WHO), an estimated 1.3 billion people (1 in 6 individuals) experience a disability, and nearly 2.2 billion people (1 in 5 individuals) have vision impairment. Improving the accessibility of visualizations will enable more people to participate in and engage with our …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;According to the World Health Organization (WHO), an estimated 1.3 billion people (1 in 6 individuals) experience a disability, and nearly 2.2 billion people (1 in 5 individuals) have vision impairment. Improving the accessibility of visualizations will enable more people to participate in and engage with our data analyses.&lt;/p&gt;
&lt;p&gt;In this talk, we’ll discuss some principles and best practices for creating more accessible data visualizations. It will include tips for individuals who create visualizations, as well as guidelines for the developers of visualization software to help ensure your tools can help downstream designers and developers create more accessible visualizations.&lt;/p&gt;
&lt;p&gt;Specifically, we will cover:&lt;/p&gt;
&lt;p&gt;What makes data visualizations inaccessible? We will cover accessibility fundamentals like color contrast, alternative text descriptions, keyboard navigation support, screen reader compatibility, and more, with specific examples and demonstrations.
Are Python data visualization tools accessible? We will teach how to analyze the visualization landscape and discuss how tool developers can begin and prioritize improvements.
How accessible is my visualization? We will demonstrate how to conduct accessibility audits for data visualization tools by performing and documenting two accessibility evaluation tests live.&lt;/p&gt;
&lt;p&gt;This talk will use examples from our ongoing work to improve the accessibility of Bokeh, a Python library for creating interactive data visualizations for web browsers. We hope this talk enables you to take the first few steps in making your next data visualization and your visualization tools, more accessible.&lt;/p&gt;
</content><category term="PyCon US 2025"></category></entry><entry><title>Collaboration Infrastructure in Data Science: Tools, Challenges, and Best Practices</title><link href="https://pyvideo.org/pyladiescon-2023/collaboration-infrastructure-in-data-science-tools-challenges-and-best-practices.html" rel="alternate"></link><published>2023-02-12T00:00:00+00:00</published><updated>2023-02-12T00:00:00+00:00</updated><author><name>Pavithra Eswaramoorthy</name></author><id>tag:pyvideo.org,2023-02-12:/pyladiescon-2023/collaboration-infrastructure-in-data-science-tools-challenges-and-best-practices.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We have mature collaboration tools in the PyData ecosystem like JupyterHub for shared infrastructure, conda for package &amp;amp; environment management, and Dask for distributed computing. However, the process for setting-up and using a platform with all these tools requires in-depth knowledge of these tools. This talk hopes to discuss some …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We have mature collaboration tools in the PyData ecosystem like JupyterHub for shared infrastructure, conda for package &amp;amp; environment management, and Dask for distributed computing. However, the process for setting-up and using a platform with all these tools requires in-depth knowledge of these tools. This talk hopes to discuss some friendly solutions for collaborative practices like:&lt;/p&gt;
&lt;p&gt;Sharing ongoing work, visualizations, and dashboards with reproducible environments
Designing for scalability (distributed compute) and productionization
Monitoring and managing team resources to minimize cloud costs&lt;/p&gt;
&lt;p&gt;Pre-requisites: A basic understanding of Python-based data science tools (NumPy, pandas, matplotlib, etc.) and workflows (exploratory analysis, visualization, etc.) is required – if you have used Jupyter Notebooks, created environments using the conda package manager, and performed a &lt;cite&gt;groupby&lt;/cite&gt; operation in pandas, you should be able to follow along with the talk comfortably. While not necessary, experiential knowledge of data workflows, previous experience working in a team, and familiarity with distributed computing principles will help you get the most value out of this talk.&lt;/p&gt;
</content><category term="PyLadiesCon 2023"></category></entry></feed>