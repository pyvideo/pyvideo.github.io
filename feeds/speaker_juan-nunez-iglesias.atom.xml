<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_juan-nunez-iglesias.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-07-13T00:00:00+00:00</updated><entry><title>Real World Numba: Creating a Skeleton Analysis Library</title><link href="https://pyvideo.org/scipy-2019/real-world-numba-creating-a-skeleton-analysis-library.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Juan Nunez-Iglesias</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/real-world-numba-creating-a-skeleton-analysis-library.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;kan is a Python library to analyze skeleton images, such as images of branching neurons, or of the molecular skeleton of a cell. It is written using NumPy, SciPy, and pandas, with key functions compiled by Numba for speed. I'll briefly describe the library and application, but then spend most of the time discussing Skan's gritty innards, including: how to write n-dimensional image analysis code instead of baking in 2D- or 3D-only logic; examples of using Numba to speed up real-world array-based code; why you should know about memory layout; and the versatility of SciPy's sparse matrix formats.&lt;/p&gt;
</summary></entry><entry><title>Image Analysis in Python with SciPy and Scikit Image</title><link href="https://pyvideo.org/scipy-2019/image-analysis-in-python-with-scipy-and-scikit-image.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Juan Nunez-Iglesias</name></author><id>tag:pyvideo.org,2019-07-10:scipy-2019/image-analysis-in-python-with-scipy-and-scikit-image.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;From telescopes to satellite cameras to electron microscopes, scientists are producing more images than they can manually inspect. This tutorial will introduce image analysis using the idea that &amp;quot;images are just NumPy arrays&amp;quot;. Then we will run through various fundamental image analysis operations (filters, morphology, segmentation), and finally we will demonstrate one or two advanced real-world examples. This tutorial is aimed at people who are familiar with NumPy, SciPy, and Matplotlib, but it does not require any previous knowledge of image analysis or image processing.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Advanced NumPy</title><link href="https://pyvideo.org/scipy-japan-2019/advanced-numpy.html" rel="alternate"></link><published>2019-04-23T00:00:00+00:00</published><updated>2019-04-23T00:00:00+00:00</updated><author><name>Juan Nuñez-Iglesias</name></author><id>tag:pyvideo.org,2019-04-23:scipy-japan-2019/advanced-numpy.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A hands on tutorial covering broadcasting rules, strides / stride tricks and advanced indexing.
​
Prerequisites: Comfortable with Python syntax, and some familiarity with NumPy / array computing.
​
Bio: Juan Nunez-Iglesias is a Research Fellow and CZI Imaging Software Fellow at Monash University in Melbourne, Australia. He is a core developer of scikit-image and has taught scientific Python at SciPy, EuroSciPy, the G-Node Summer School, and at other workshops. He is the co-author of the O'Reilly title &amp;quot;Elegant SciPy&amp;quot;.&lt;/p&gt;
&lt;div class="section" id="connect-with-us"&gt;
&lt;h4&gt;Connect with us!&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="https://twitter.com/enthought"&gt;https://twitter.com/enthought&lt;/a&gt;
&lt;a class="reference external" href="https://www.facebook.com/Enthought/"&gt;https://www.facebook.com/Enthought/&lt;/a&gt;
&lt;a class="reference external" href="https://www.linkedin.com/company/enthought"&gt;https://www.linkedin.com/company/enthought&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</summary><category term="tutorial"></category></entry><entry><title>Image Analysis in Python with SciPy and scikit-image</title><link href="https://pyvideo.org/scipy-2018/image-analysis-in-python-with-scipy-and-scikit-image.html" rel="alternate"></link><published>2018-07-09T00:00:00+00:00</published><updated>2018-07-09T00:00:00+00:00</updated><author><name>Stéfan van der Walt</name></author><id>tag:pyvideo.org,2018-07-09:scipy-2018/image-analysis-in-python-with-scipy-and-scikit-image.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;From telescopes to satellite cameras to electron microscopes, scientists
are producing more images than they can manually inspect. This tutorial
will introduce automated image analysis using the idea that &amp;quot;images are
just numpy arrays&amp;quot;. Then we will run through various fundamental image
analysis operations(filters, morphology, segmentation), and finally we
will demonstrate one or two advanced real-world examples. This tutorial
is aimed at people who are familiar with NumPy, SciPy, and Matplotlib,
but it does not require any previous knowledge of image analysis or
image processing.Presenter(s): Speaker: Stéfan van der Walt, University
of California, Berkeley Speaker: Juan Nunez-Iglesias, University of
Melbourne Speaker: Joshua Warner, Core Developer, Scikit
Image/University of Arizona&lt;/p&gt;
</summary></entry><entry><title>Python's Bright Future in Science</title><link href="https://pyvideo.org/pycon-au-2016/pythons-bright-future-in-science.html" rel="alternate"></link><published>2016-08-15T00:00:00+00:00</published><updated>2016-08-15T00:00:00+00:00</updated><author><name>Juan Nunez-Iglesias</name></author><id>tag:pyvideo.org,2016-08-15:pycon-au-2016/pythons-bright-future-in-science.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Juan Nunez-Iglesias
&lt;a class="reference external" href="https://2016.pycon-au.org/schedule/200/view_talk"&gt;https://2016.pycon-au.org/schedule/200/view_talk&lt;/a&gt;
Over the past five years, Python has skyrocketed in popularity in the scientific world, pushing out proprietary languages such as IDL and Matlab. This rise was powered by simple syntax and efficient numerical libraries. But many operations in Python are still slow, and upstart languages, such as Julia and Go, promise simplicity &lt;em&gt;and&lt;/em&gt; speed. Can Python cement its place in scientific computing?&lt;/p&gt;
</summary><category term="datascience"></category></entry><entry><title>Image Processing with Scikit Image</title><link href="https://pyvideo.org/euroscipy-2015/image-processing-with-scikit-image.html" rel="alternate"></link><published>2015-10-07T00:00:00+00:00</published><updated>2015-10-07T00:00:00+00:00</updated><author><name>Emmanuelle Gouillart</name></author><id>tag:pyvideo.org,2015-10-07:euroscipy-2015/image-processing-with-scikit-image.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;From telescopes to satellite cameras to electron microscopes, scientists are producing large datasets of images to be processed and analyzed. This tutorial will introduce image processing using the &amp;quot;images as numpy arrays&amp;quot; abstraction, run through various fundamental image analysis operations (filters, morphology, segmentation), and finally complete one or two more advanced real-world examples.&lt;/p&gt;
&lt;p&gt;Access materials here:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/jni/skimage-tutorials/blob/euroscipy2015/2015-euroscipy/index.ipynb"&gt;https://github.com/jni/skimage-tutorials/blob/euroscipy2015/2015-euroscipy/index.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/jni/skimage-tutorials/blob/a7ab20a6da21222c4006537cba2c6ca85c7b9d33/lectures/00_images_are_arrays.ipynb"&gt;https://github.com/jni/skimage-tutorials/blob/a7ab20a6da21222c4006537cba2c6ca85c7b9d33/lectures/00_images_are_arrays.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/jni/skimage-tutorials/blob/a7ab20a6da21222c4006537cba2c6ca85c7b9d33/lectures/1_image_filters.ipynb"&gt;https://github.com/jni/skimage-tutorials/blob/a7ab20a6da21222c4006537cba2c6ca85c7b9d33/lectures/1_image_filters.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</summary></entry><entry><title>Big Data in Little Laptop: A Streaming Story in Python</title><link href="https://pyvideo.org/euroscipy-2015/big-data-in-little-laptop-a-streaming-story-in-python.html" rel="alternate"></link><published>2015-10-05T00:00:00+00:00</published><updated>2015-10-05T00:00:00+00:00</updated><author><name>Juan Nunez-Iglesias</name></author><id>tag:pyvideo.org,2015-10-05:euroscipy-2015/big-data-in-little-laptop-a-streaming-story-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python contains nice primitives for streaming data processing. &amp;#64;mrocklin's Toolz library extends them to enable gorgeous, concise, memory-frugal code. I'll present an intuitive approach to streaming analysis in Python, starting with a &amp;quot;hello world&amp;quot;-level example, moving through image correction and streaming sklearn classifiers, and finally analysing a complete genome in a few minutes.&lt;/p&gt;
</summary></entry><entry><title>nD image segmentation using learned region agglomeration with the Ray Python library</title><link href="https://pyvideo.org/scipy-2012/nd-image-segmentation-using-learned-region-agglom.html" rel="alternate"></link><published>2012-07-19T00:00:00+00:00</published><updated>2012-07-19T00:00:00+00:00</updated><author><name>Juan Nunez-Iglesias</name></author><id>tag:pyvideo.org,2012-07-19:scipy-2012/nd-image-segmentation-using-learned-region-agglom.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;One of the principal goals of the Janelia Farm Research Campus is the
reconstruction of complete neuronal circuits. This involves 3D electron-
microscopy (EM) volumes many microns across with better than 10nm
resolution, resulting in gigavoxel scale images. From these, individual
neurons must be segmented out. Although image segmentation is a
well-studied problem, these data present unique challenges in addition
to scale: neurons have an elongated, irregular branching structure, with
processes up to 50nm thin but hundreds of micrometers long); one neuron
looks much like the next, with only a thin cellular boundary separating
densely packed neurons; and internal neuronal structures can look
similar to the cellular boundary. The first problem in particular means
that small errors in segment boundary predictions can lead to large
errors in neuron shape and neuronal network connectivity.&lt;/p&gt;
&lt;p&gt;Our segmentation workflow has three main steps: a voxelwise edge
classification, a fine-grained segmentation into supervoxels (which can
reasonably be assumed to be atomic groups of voxels), and hierarchical
region agglomeration.&lt;/p&gt;
&lt;p&gt;For the first step, we use Ilastik, a pixel-level interactive learning
program. Ilastik uses the output of various image filters as features to
classify voxels as labeled by the user. We then use the watershed
algorithm on the resulting edge probability map to obtain supervoxels.
For the last step, we developed a new machine learning algorithm
(Nunez-Iglesias et al, in preparation).&lt;/p&gt;
&lt;p&gt;Prior work has used the mean voxel-level edge-probability along the
boundaries between regions to agglomerate them. This strategy works
extremely well because boundaries get longer as agglomeration proceeds,
resulting in ever- improving estimates of the mean probability. We
hypothesized that we could improve agglomeration accuracy by using a
classifier (which can use many more features than the mean). However, a
classifier can perform poorly because throughout agglomeration we may
visit a part of the feature space that has not yet been sampled. In our
approach, we use active learning to ensure that we have examples from
all parts of the space we are likely to encounter.&lt;/p&gt;
&lt;p&gt;We implemented our algorithm in arbitrary dimensions in an open-source,
MIT- licensed Python library, Ray (&lt;a class="reference external" href="https://github.com/jni/ray"&gt;https://github.com/jni/ray&lt;/a&gt;). Ray
combines leading scientific computing Python libraries, including NumPy,
SciPy, NetworkX, and scikits-learn to deliver state of the art
segmentation accuracy in Python.&lt;/p&gt;
</summary><category term="General"></category></entry><entry><title>Clustering of high content images to discover off target phenotypes</title><link href="https://pyvideo.org/scipy-2014/clustering-of-high-content-images-to-discover-off.html" rel="alternate"></link><published>2014-07-10T00:00:00+00:00</published><updated>2014-07-10T00:00:00+00:00</updated><author><name>Juan Nunez-Iglesias</name></author><id>tag:pyvideo.org,2014-07-10:scipy-2014/clustering-of-high-content-images-to-discover-off.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;In high content imaging screens, cells are subjected to various
treatments (usually shutting down specific genes) in high throughput,
imaged, and a phenotype of interest measured. We argue that there is a
wealth of information to be found in off-target phenotypes, and present
an image clustering approach to discover these and infer gene function.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the decade between 1999 and 2008, more newly-approved, first-in-class
drugs were found by phenotypic screens than by molecular target-based
approaches. This is despite far more resources being invested in the
latter, and highlights the rising importance of screens in biomedical
research. (&lt;a class="reference external" href="http://www.nature.com/nrd/journal/v10/n7/full/nrd3480.html"&gt;Swinney and Anthony, Nat Rev Drug Discov,
2011&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Despite this success, the data from phenotypic screens is vastly
underutilized. A typical analysis takes millions of images, obtained at
a cost of, say, $250,000, and reduces each to a single number, a
quantification of the phenotype of interest. The images are then ranked
by that value and the top-ranked images are flagged for further
investigation. (&lt;a class="reference external" href="https://www.cell.com/trends/biotechnology/abstract/S0167-7799(10)00035-1"&gt;Zanella et al, Trends Biotech,
2010&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;The images, however, contain a lot more information than just a single
phenotypic number. For one, usually only the mean phenotype of all the
cells in the image is reported, with no information about variability,
even though the distribution of cell shapes in a single image is highly
informative (&lt;a class="reference external" href="http://www.nature.com/ncb/journal/v15/n7/full/ncb2764.html"&gt;Yin et al, Nat Cell Biol,
2013&lt;/a&gt;).
Additionally, cells display a variety of off-target phenotypes,
independently of the target, that can provide biological insight and new
research avenues.&lt;/p&gt;
&lt;p&gt;We are developing an unsupervised clustering pipeline, tentatively named
high-content-screen unsupervised sample clustering
(&lt;a class="reference external" href="http://github.com/jni/husc"&gt;HUSC&lt;/a&gt;), that leverages the scientific
Python stack, particularly &lt;tt class="docutils literal"&gt;scipy.stats&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;pandas&lt;/tt&gt;,
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;scikit-image&lt;/span&gt;&lt;/tt&gt;, and &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;scikit-learn&lt;/span&gt;&lt;/tt&gt;, to summarize images with feature
vectors, cluster them, and infer the functions of genes corresponding to
each cluster. The library includes functions for preprocessing images,
computing an array of features designed specifically for microscopy
images, and accessing a MongoDB database containing sample data. Its API
allows easy extensibility by placing screen-specific functions under the
&lt;tt class="docutils literal"&gt;screens&lt;/tt&gt; sub-package. An example IPython notebook with a preliminary
analysis can be found
&lt;a class="reference external" href="http://jni.github.io/notebooks/hcs_nb.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We plan to use this library to develop a flexible web interface for
flexible and extensible analysis of high-content screens, and relish the
opportunity to enlist the help and expertise of the SciPy crowd.&lt;/p&gt;
</summary></entry><entry><title>Image analysis in Python with scipy and scikit image 4</title><link href="https://pyvideo.org/scipy-2014/image-analysis-in-python-with-scipy-and-scikit-im.html" rel="alternate"></link><published>2014-07-09T00:00:00+00:00</published><updated>2014-07-09T00:00:00+00:00</updated><author><name>Juan Nunez-Iglesias</name></author><id>tag:pyvideo.org,2014-07-09:scipy-2014/image-analysis-in-python-with-scipy-and-scikit-im.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;From telescopes to satellite cameras to electron microscopes, scientists
are producing more images than they can manually inspect. This tutorial
will introduce automated image analysis using the &amp;quot;images as numpy
arrays&amp;quot; abstraction, run through various fundamental image analysis
operations (filters, morphology, segmentation), and finally complete one
or two more advanced real-world examples.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Image analysis is central to a boggling number of scientific endeavors.
Google needs it for their self-driving cars and to match satellite
imagery and mapping data. Neuroscientists need it to understand the
brain. NASA needs it to &lt;a class="reference external" href="http://www.bbc.co.uk/news/technology-26528516"&gt;map
asteroids&lt;/a&gt; and save
the human race. It is, however, a relatively underdeveloped area of
scientific computing. Attendees will leave this tutorial confident of
their ability to extract information from their images in Python.&lt;/p&gt;
&lt;p&gt;Attendees will need a working knowledge of numpy arrays, but no further
knowledge of images or voxels or other doodads. After a brief
introduction to the idea that images are just arrays and vice versa, we
will introduce fundamental image analysis operations: filters, which can
be used to extract features such as edges, corners, and spots in an
image; morphology, inferring shape properties by modifying the image
through local operations; and segmentation, the division of an image
into meaningful regions.&lt;/p&gt;
&lt;p&gt;We will then combine all these concepts and apply them to several
real-world examples of scientific image analysis: given an image of a
pothole, measure its size in pixels compare the fluorescence intensity
of a protein of interest in the centromeres vs the rest of the
chromosome. observe the distribution of cells invading a wound site&lt;/p&gt;
&lt;p&gt;Attendees will also be encouraged to bring their own image analysis
problems to the session for guidance, and, if time allows, we will cover
more advanced topics such as image registration and stitching.&lt;/p&gt;
&lt;p&gt;The entire tutorial will be coordinated with the IPython notebook, with
various code cells left blank for attendees to fill in as exercises.&lt;/p&gt;
</summary><category term="scikit"></category></entry><entry><title>Image analysis in Python with scipy and scikit image, Part 1</title><link href="https://pyvideo.org/scipy-2014/image-analysis-with-scikit-image-part-1.html" rel="alternate"></link><published>2014-07-09T00:00:00+00:00</published><updated>2014-07-09T00:00:00+00:00</updated><author><name>Juan Nunez-Iglesias</name></author><id>tag:pyvideo.org,2014-07-09:scipy-2014/image-analysis-with-scikit-image-part-1.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;From telescopes to satellite cameras to electron microscopes, scientists
are producing more images than they can manually inspect. This tutorial
will introduce automated image analysis using the &amp;quot;images as numpy
arrays&amp;quot; abstraction, run through various fundamental image analysis
operations (filters, morphology, segmentation), and finally complete one
or two more advanced real-world examples.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Image analysis is central to a boggling number of scientific endeavors.
Google needs it for their self-driving cars and to match satellite
imagery and mapping data. Neuroscientists need it to understand the
brain. NASA needs it to &lt;a class="reference external" href="http://www.bbc.co.uk/news/technology-26528516"&gt;map
asteroids&lt;/a&gt; and save
the human race. It is, however, a relatively underdeveloped area of
scientific computing. Attendees will leave this tutorial confident of
their ability to extract information from their images in Python.&lt;/p&gt;
&lt;p&gt;Attendees will need a working knowledge of numpy arrays, but no further
knowledge of images or voxels or other doodads. After a brief
introduction to the idea that images are just arrays and vice versa, we
will introduce fundamental image analysis operations: filters, which can
be used to extract features such as edges, corners, and spots in an
image; morphology, inferring shape properties by modifying the image
through local operations; and segmentation, the division of an image
into meaningful regions.&lt;/p&gt;
&lt;p&gt;We will then combine all these concepts and apply them to several
real-world examples of scientific image analysis: given an image of a
pothole, measure its size in pixels compare the fluorescence intensity
of a protein of interest in the centromeres vs the rest of the
chromosome. observe the distribution of cells invading a wound site&lt;/p&gt;
&lt;p&gt;Attendees will also be encouraged to bring their own image analysis
problems to the session for guidance, and, if time allows, we will cover
more advanced topics such as image registration and stitching.&lt;/p&gt;
&lt;p&gt;The entire tutorial will be coordinated with the IPython notebook, with
various code cells left blank for attendees to fill in as exercises.&lt;/p&gt;
</summary><category term="scikit"></category></entry><entry><title>Image analysis in Python with scipy and scikit image, Part 2</title><link href="https://pyvideo.org/scipy-2014/image-analysis-with-scikit-image-part-2.html" rel="alternate"></link><published>2014-07-09T00:00:00+00:00</published><updated>2014-07-09T00:00:00+00:00</updated><author><name>Juan Nunez-Iglesias</name></author><id>tag:pyvideo.org,2014-07-09:scipy-2014/image-analysis-with-scikit-image-part-2.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;From telescopes to satellite cameras to electron microscopes, scientists
are producing more images than they can manually inspect. This tutorial
will introduce automated image analysis using the &amp;quot;images as numpy
arrays&amp;quot; abstraction, run through various fundamental image analysis
operations (filters, morphology, segmentation), and finally complete one
or two more advanced real-world examples.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Image analysis is central to a boggling number of scientific endeavors.
Google needs it for their self-driving cars and to match satellite
imagery and mapping data. Neuroscientists need it to understand the
brain. NASA needs it to &lt;a class="reference external" href="http://www.bbc.co.uk/news/technology-26528516"&gt;map
asteroids&lt;/a&gt; and save
the human race. It is, however, a relatively underdeveloped area of
scientific computing. Attendees will leave this tutorial confident of
their ability to extract information from their images in Python.&lt;/p&gt;
&lt;p&gt;Attendees will need a working knowledge of numpy arrays, but no further
knowledge of images or voxels or other doodads. After a brief
introduction to the idea that images are just arrays and vice versa, we
will introduce fundamental image analysis operations: filters, which can
be used to extract features such as edges, corners, and spots in an
image; morphology, inferring shape properties by modifying the image
through local operations; and segmentation, the division of an image
into meaningful regions.&lt;/p&gt;
&lt;p&gt;We will then combine all these concepts and apply them to several
real-world examples of scientific image analysis: given an image of a
pothole, measure its size in pixels compare the fluorescence intensity
of a protein of interest in the centromeres vs the rest of the
chromosome. observe the distribution of cells invading a wound site&lt;/p&gt;
&lt;p&gt;Attendees will also be encouraged to bring their own image analysis
problems to the session for guidance, and, if time allows, we will cover
more advanced topics such as image registration and stitching.&lt;/p&gt;
&lt;p&gt;The entire tutorial will be coordinated with the IPython notebook, with
various code cells left blank for attendees to fill in as exercises.&lt;/p&gt;
</summary><category term="scikit"></category></entry><entry><title>Image analysis in Python with scipy and scikit image, Part 3</title><link href="https://pyvideo.org/scipy-2014/image-analysis-with-scikit-image-part-3.html" rel="alternate"></link><published>2014-07-09T00:00:00+00:00</published><updated>2014-07-09T00:00:00+00:00</updated><author><name>Juan Nunez-Iglesias</name></author><id>tag:pyvideo.org,2014-07-09:scipy-2014/image-analysis-with-scikit-image-part-3.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;From telescopes to satellite cameras to electron microscopes, scientists
are producing more images than they can manually inspect. This tutorial
will introduce automated image analysis using the &amp;quot;images as numpy
arrays&amp;quot; abstraction, run through various fundamental image analysis
operations (filters, morphology, segmentation), and finally complete one
or two more advanced real-world examples.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Image analysis is central to a boggling number of scientific endeavors.
Google needs it for their self-driving cars and to match satellite
imagery and mapping data. Neuroscientists need it to understand the
brain. NASA needs it to &lt;a class="reference external" href="http://www.bbc.co.uk/news/technology-26528516"&gt;map
asteroids&lt;/a&gt; and save
the human race. It is, however, a relatively underdeveloped area of
scientific computing. Attendees will leave this tutorial confident of
their ability to extract information from their images in Python.&lt;/p&gt;
&lt;p&gt;Attendees will need a working knowledge of numpy arrays, but no further
knowledge of images or voxels or other doodads. After a brief
introduction to the idea that images are just arrays and vice versa, we
will introduce fundamental image analysis operations: filters, which can
be used to extract features such as edges, corners, and spots in an
image; morphology, inferring shape properties by modifying the image
through local operations; and segmentation, the division of an image
into meaningful regions.&lt;/p&gt;
&lt;p&gt;We will then combine all these concepts and apply them to several
real-world examples of scientific image analysis: given an image of a
pothole, measure its size in pixels compare the fluorescence intensity
of a protein of interest in the centromeres vs the rest of the
chromosome. observe the distribution of cells invading a wound site&lt;/p&gt;
&lt;p&gt;Attendees will also be encouraged to bring their own image analysis
problems to the session for guidance, and, if time allows, we will cover
more advanced topics such as image registration and stitching.&lt;/p&gt;
&lt;p&gt;The entire tutorial will be coordinated with the IPython notebook, with
various code cells left blank for attendees to fill in as exercises.&lt;/p&gt;
</summary><category term="scikit"></category></entry><entry><title>Clustering of high-content screen images to discover off-target phenotypes by Juan Nunez-Iglesias</title><link href="https://pyvideo.org/pycon-au-2014/clustering-of-high-content-screen-images-to-disco.html" rel="alternate"></link><published>2014-08-11T00:00:00+00:00</published><updated>2014-08-11T00:00:00+00:00</updated><author><name>Juan Nunez-Iglesias</name></author><id>tag:pyvideo.org,2014-08-11:pycon-au-2014/clustering-of-high-content-screen-images-to-disco.html</id><summary type="html"></summary></entry></feed>