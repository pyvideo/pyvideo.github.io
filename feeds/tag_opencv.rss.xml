<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 12 Jul 2019 00:00:00 +0000</lastBuildDate><item><title>Astro Pi: Python on the International Space Station</title><link>https://pyvideo.org/europython-2019/astro-pi-python-on-the-international-space-station.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A collaboration between the Raspberry Pi Foundation and the European
Space Agency put two Raspberry Pi computers augmented with sensor boards
and camera modules on the International Space Station in 2015. Every
year we run a series of competitions for kids in schools around Europe
to design science experiments using the available sensors.&lt;/p&gt;
&lt;p&gt;Mission Zero is a low-barrier challenge where students can run a 1
minute Python program in space to display a message to the astronauts.
They have access to the sensors for conditional logic but cannot record
data or take photos.&lt;/p&gt;
&lt;p&gt;Mission Space Lab is a more involved challenge, including planning an
experiment, writing and testing code which will run for 3 hours in
space, either studying life in space or life on earth (which includes
taking photos of Earth out of the ISS window). MSL teams get to keep the
data and photo they record in their experiment and are to write a report
analysing their findings.&lt;/p&gt;
&lt;p&gt;A small tech team at the Raspberry Pi Foundation maintain the operating
system used in flight and work in collaboration with ESA and partners to
keep the operation of the Pis running smoothly on the ISS LAN.&lt;/p&gt;
&lt;p&gt;As well as sharing details of the OS maintenance and devops for the
Astro Pis, I'll share photos taken from space and show findings from
student experiments using opencv, tensorflow, scikit-learn, ephem and
more.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ben Nuttall</dc:creator><pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-12:europython-2019/astro-pi-python-on-the-international-space-station.html</guid><category>Data</category><category>Education</category><category>Linux</category><category>OpenCV</category><category>Raspberry PI</category></item><item><title>Machine learning approaches for road scene video analysis</title><link>https://pyvideo.org/pycon-italia-2019/machine-learning-approaches-for-road-scene-video-analysis.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dashboard cameras (dashcams), inward or front-facing cameras installed
in personal or commercial vehicles, are becoming increasingly popular
due to the pervasiveness of their applications: driver safety,
autonomous driving, fleet management systems, insurance, theft detection
are some examples. Focusing on safety, one of the main problems is to
analyze videos and automatically detect dangerous situations occurring
in them, such as the risk of a near crash with another vehicle or
pedestrian. In this talk, we show how we tackle this real- world problem
at Verizon Connect, using a mix of state-of-the-art deep learning
methods and traditional computer vision / machine learning techniques,
leveraging libraries such as scikit-learn, scipy/numpy, pandas, openCV,
and keras/tensorflow. We also describe how we use AWS and docker to
deploy, serve and scale the application to customers all over the world.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1603"&gt;https://python.it/feedback-1603&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 11:15 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrea Benericetti</dc:creator><pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-03:pycon-italia-2019/machine-learning-approaches-for-road-scene-video-analysis.html</guid><category>ComputerVision</category><category>analytics</category><category>scikit-learn</category><category>opencv</category><category>video</category><category>machine-learning</category><category>optical-flow</category><category>pandas</category></item><item><title>Applying serverless architecture pattern to distributed data processing</title><link>https://pyvideo.org/pycon-italia-2018/applying-serverless-architecture-pattern-to-distributed-data-processing.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Serverless architectures refer to applications that significantly depend
on “cloud” services (knows as Backend as a Service) or on custom code
that’s run in ephemeral runtime (Function as a Service or “FaaS&amp;quot;).&lt;/p&gt;
&lt;p&gt;To application developers, “serverless” mean app where some certain
logic of it is still written by the developer but unlike traditional
architectures or microservices is run in stateless compute runtime that
is event-triggered, may only last for one invocation, and fully managed
by a cloud. Serverless helps developers to transfer responsibility for
keeping their apps up and running as well as scaling out their workload
capacity without involving DevOps/ops as we got used to.&lt;/p&gt;
&lt;p&gt;In this talk we will go through whole “serverless” thing: from
decomposing app and its logic to microservices and further to smaller
bits, i.e. functions to defining data flow through functions and
building their fault-tolerant pipeline. Moreover, we will go through a
demo that highlights key takeaways:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;what are functions, what it could and could not be&lt;/li&gt;
&lt;li&gt;how to design scalable architecture without getting into troubles by
hitting concrete bottlenecks&lt;/li&gt;
&lt;li&gt;how serverless can help scaling in/out compute capacity for data
processing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The demo itself will include examples of applying serverless
architecture pattern to emotion recognition app based on TensorFlow and
OpenCV 3.3&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 20 April&lt;/strong&gt; at 15:15 &lt;a class="reference external" href="/en/sprints/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Denis Makogon</dc:creator><pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-20:pycon-italia-2018/applying-serverless-architecture-pattern-to-distributed-data-processing.html</guid><category>serverless</category><category>image-processing</category><category>data-exploration</category><category>emotion-recognition</category><category>Deep-Learning</category><category>opencv</category><category>tensorflow</category><category>python3</category></item><item><title>Facial Analysis Techniques for Pythonista (and beyond!)</title><link>https://pyvideo.org/pycon-italia-2017/facial-analysis-techniques-for-pythonista-and-beyond.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The ability to detect, track, and analyze faces opens up a wide range of
interesting use cases, ranging from interactive smart applications and
real- time video processing, all the way to biometric security and
augmented reality.&lt;/p&gt;
&lt;p&gt;This talk will showcase the available &lt;strong&gt;tools built by the Python
community&lt;/strong&gt; and their corresponding pros &amp;amp; cons, limitations, and
complexity. While discussing the possible scenarios and what is actually
required to &lt;strong&gt;DIY with Python&lt;/strong&gt;, I will compare such handmade solutions
with &lt;strong&gt;Cloud-based products and APIs&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;: basic understanding of Python’s data science stack
(especially numpy).&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alex Casalboni</dc:creator><pubDate>Sun, 09 Apr 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-04-09:pycon-italia-2017/facial-analysis-techniques-for-pythonista-and-beyond.html</guid><category>CloudComputing</category><category>aws</category><category>scikit-learn</category><category>scikit-image</category><category>google-cloud</category><category>Deep-Learning</category><category>opencv</category><category>scikits</category><category>cv</category><category>Machine Learning</category><category>Facial-Analysis</category><category>dlib</category><category>Artificial Intelligence</category></item><item><title>OpenCV el ojo de la serpiente que todo lo ve</title><link>https://pyvideo.org/pycon-es-2017/opencv-el-ojo-de-la-serpiente-que-todo-lo-ve.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;En esta charla vamos a ver las nociones básicas de OpenCV, conectaremos una webcam y veremos como en tiempo real se puede obtener información del entorno que nos rodea.
Se explicará un poco de código sencillo con resultados sorprendentes y se mostrarán algunos ejemplos mas elaborados.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Juan Francisco Huete Verdejo</dc:creator><pubDate>Sun, 24 Sep 2017 14:00:00 +0200</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-09-24:pycon-es-2017/opencv-el-ojo-de-la-serpiente-que-todo-lo-ve.html</guid><category>opencv</category></item><item><title>Corrigiendo 1000 exámenes con un pelín de OpenCV</title><link>https://pyvideo.org/pycon-es-2017/corrigiendo-1000-examenes-con-un-pelin-de-opencv.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;El objetivo de la charla es hacer una pequeña demostración del uso de algunas de las bibliotecas más icónicas, hiladas a través del objetivo final de analizar fácilmente un examen tipo test.&lt;/p&gt;
&lt;p&gt;Numpy y Matplotlib son dos de las bibliotecas más importantes en el Python científico, usadas para trabajar con arrays y representaciones gráficas respectivamente.&lt;/p&gt;
&lt;p&gt;Como una imagen en escala de grises en el fondo no es más que una matriz, usaremos unas pocas manipulaciones básicas con imágenes para mostrar cómo trabajar con funciones de Numpy, hacer slicings, etc.&lt;/p&gt;
&lt;p&gt;La interfaz de Matplotlib más sencilla, Pyplot, es muy útil para realizar muchos gráficos sin hacer un gran esfuerzo. Podemos mostrar un ejemplo sencillo de estas capacidades representando los contornos que detectemos sobre la imagen original.&lt;/p&gt;
&lt;p&gt;También se presentarán algunas de las funciones más básicas de OpenCV, uno de los paquetes de software más importantes de visión artificial. Usaremos las funciones de desenfoque, umbral y detección de contornos.&lt;/p&gt;
&lt;p&gt;Si el tiempo fuera suficiente, echaremos también un vistazo a la librería openpyxl, que nos permitirá importar y exportar datos de tablas de Excel.&lt;/p&gt;
&lt;p&gt;Puede ser importante resaltar explícitamente que debido a las limitaciones de tiempo, las librerías no pueden ser mostradas en profundidad, y que probablemente no habrá nada o casi nada de live coding. Sin embargo, todo el código usado, incluso para las imágenes intermedias, será publicado en forma de Notebook de Jupyter a través de Github.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Siro Moreno</dc:creator><pubDate>Sat, 23 Sep 2017 16:30:00 +0200</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-09-23:pycon-es-2017/corrigiendo-1000-examenes-con-un-pelin-de-opencv.html</guid><category>opencv</category></item><item><title>OpenCV con Python</title><link>https://pyvideo.org/pyday-galicia-2017/opencv-con-python.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ricardo Samaniego</dc:creator><pubDate>Sat, 10 Jun 2017 10:05:00 +0200</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-06-10:pyday-galicia-2017/opencv-con-python.html</guid><category>pyday</category><category>Galicia</category><category>opencv</category></item><item><title>How to Build Your Own Self Driving Toy Car</title><link>https://pyvideo.org/pydata-dc-2016/how-to-build-your-own-self-driving-toy-car.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;I’ve spent the past 6 months building a self-driving toy car using a Raspberry Pi, OpenCV, and TensorFlow. If you’ve ever thought about building your own self-driving toy car, this presentation will help you avoid common pitfalls and shed light on important tradeoffs that you’ll have to weigh along the way. I’ll cover things like how to parse images, how to effectively tune machine learning neural&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ryan Zotti</dc:creator><pubDate>Fri, 07 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-07:pydata-dc-2016/how-to-build-your-own-self-driving-toy-car.html</guid><category>opencv</category><category>tensorflow</category></item><item><title>Building a live face recognition system in the blink of a very slow eye</title><link>https://pyvideo.org/pydata-amsterdam-2016/building-a-live-face-recognition-system-in-the-blink-of-a-very-slow-eye.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2016&lt;/p&gt;
&lt;p&gt;Description&lt;/p&gt;
&lt;p&gt;In this tutorial we will create a face recognition application from scratch, it will provide you hands-on experience on the basics of Face Recognition. We will use the OpenCV library which makes the tutorial accessible to beginners. Together, we'll go from building our face dataset to recognizing faces in a live video. If time permits we will use this face recognition system to classify banking da&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;Building a live face recognition system in the blink of a very slow eye&lt;/p&gt;
&lt;p&gt;In this hands-on tutorial we will build a live face recognition system from scratch with the use of the OpenCV methods. Since face recognition is the main goal of this tutorial we will form teams of 2-3 people and recognize the faces in a live feed. We will make use of the OpenCV computer vision and machine learning library. OpenCV includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rodrigo Agundez</dc:creator><pubDate>Sat, 26 Mar 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-03-26:pydata-amsterdam-2016/building-a-live-face-recognition-system-in-the-blink-of-a-very-slow-eye.html</guid><category>tutorial</category><category>opencv</category></item><item><title>Using OpenCV with Python and ROS</title><link>https://pyvideo.org/chipy/using-opencv-with-python-and-ros.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Bill Mania and Eric Kinzle A brief presentation of using the OpenCV
computer vision toolset with Python and ROS. Included at the end will be
a demonstration of tracking a colored object using a camera with
servo-driven pan and tilt capability.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bill Mania</dc:creator><pubDate>Thu, 09 Jun 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-06-09:chipy/using-opencv-with-python-and-ros.html</guid><category>billmania</category><category>camera</category><category>chipy</category><category>image</category><category>opencv</category><category>robot</category><category>ros</category></item></channel></rss>