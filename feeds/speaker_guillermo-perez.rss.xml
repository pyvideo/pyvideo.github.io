<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Guillermo Perez</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 03 Aug 2020 00:00:00 +0000</lastBuildDate><item><title>Python as a configuration language</title><link>https://pyvideo.org/pycon-us-2016/guillermo-perez-python-as-a-configuration-language-pycon-2016.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Speaker: Guillermo Pérez&lt;/p&gt;
&lt;p&gt;The enormous size of Facebook's infrastructure and its &amp;quot;&amp;quot;Move Fast&amp;quot;&amp;quot; culture pose a challenge for the configuration framework, requiring a safe, fast and usable system to deploy settings to hundreds of thousands of servers.&lt;/p&gt;
&lt;p&gt;Python plays a special role in this framework, being the tool for generating the configuration, paired with thrift for enhanced schema validation and type-safety.&lt;/p&gt;
&lt;p&gt;Slides can be found at: &lt;a class="reference external" href="https://speakerdeck.com/pycon2016"&gt;https://speakerdeck.com/pycon2016&lt;/a&gt; and &lt;a class="reference external" href="https://github.com/PyCon/2016-slides"&gt;https://github.com/PyCon/2016-slides&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Pérez</dc:creator><pubDate>Mon, 30 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-05-30:/pycon-us-2016/guillermo-perez-python-as-a-configuration-language-pycon-2016.html</guid><category>PyCon US 2016</category></item><item><title>Finite-Memory Near-Optimal Learning for Markov Decision Processes with Long-Run Average Reward</title><link>https://pyvideo.org/uai-2020/finite-memory-near-optimal-learning-for-markov-decision-processes-with-long-run-average-reward.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Finite-Memory Near-Optimal Learning for Markov Decision Processes with Long-Run Average Reward&lt;/p&gt;
&lt;p&gt;Jan Kretinsky (TU Munich)*; Fabian Michel (TU Munich); Lukas Michel (TU Munich); Guillermo Perez (UAntwerpen)&lt;/p&gt;
&lt;p&gt;We consider learning policies online in Markov decision processes with the long-run average reward (a.k.a. mean payoff). To ensure implementability of the policies, we focus on policies with finite memory. Firstly, we show that near optimality can be achieved almost surely, using an unintuitive gadget we call forgetfulness. Secondly, we extend the approach to a setting with partial knowledge of the system topology, introducing two optimality measures and providing near-optimal algorithms also for these cases.&amp;quot;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jan Kretinsky</dc:creator><pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-08-03:/uai-2020/finite-memory-near-optimal-learning-for-markov-decision-processes-with-long-run-average-reward.html</guid><category>UAI 2020</category></item></channel></rss>