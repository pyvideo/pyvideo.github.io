<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - ASYNC / Concurreny</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Thu, 23 Jul 2020 00:00:00 +0000</lastBuildDate><item><title>An ASGI Server from scratch</title><link>https://pyvideo.org/europython-2020/an-asgi-server-from-scratch.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Echo server to a basic ASGI server in a talk&lt;/p&gt;
&lt;p&gt;I intend for this to be a fairly advanced talk that shows the steps required to go from a TCP echo server to a basic HTTP/1 ASGI server using asyncio for the IO. This is aimed at people who've read about asyncio, coroutines, etc and want to see them used in practice.&lt;/p&gt;
&lt;p&gt;This is a tutorial on how to build a HTTP/1 ASGI server using asyncio. I plan to start by building a TCP echo server and then add HTTP parsing and ASGI compliance.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Philip Jones</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/an-asgi-server-from-scratch.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>ASYNC / Concurreny</category><category>Web</category><category>Web Protocols</category><category>Web Servers and MicroFWs (Flask/Tornado/Nginx/...)</category></item><item><title>Ensuring data integrity with asynchronous programming in a cloud IoT core</title><link>https://pyvideo.org/europython-2020/ensuring-data-integrity-with-asynchronous-programming-in-a-cloud-iot-core.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python3.6, AsyncIO, Flask, RabbitMQ. A simple and powerful combination for IoT data integrity.&lt;/p&gt;
&lt;p&gt;Undoubtedly this will be the decade of low-cost and high-performance cloud IoT core development.
All cloud IoT solutions will have to meet the same two fundamental requirements: Performance and Data Integrity. Having said that,  AsyncIO comes to mind.
While researching similar topics on cloud IoT solutions, we noticed that the vast majority of such solutions primarily includes performance. In this discussion we would like to demonstrate how you can ensure that a low-cost, fast developed cloud IoT core can ensure that its data is not corrupted and is accurate  for the user.
Technically speaking, it is very interesting to analyze how a bucket of async/await tasks can handle (consume or even produce) messages from or to message queues, interact with other (even non pythonic) modules inside the core, manage socket connections and many other functionalities that make Python3.6+ the heart of any IoT core. Note that it is equally important to check imported data with periodic tasks, acquire statistics from devices and sanitize database data in order to ensure data integrity.
Our goal: Firstly, to encourage new developers to get involved with cloud IoT cores and use Python and AsyncIO as the heart of their core. Secondly, as new developers we would like to show our logic and our prefered python libraries and techniques in order to receive feedback from more experienced developers.
We are a team of software engineers located in Athens, Greece working for a fast growing startup in San Francisco (&lt;a class="reference external" href="https://www.veturilo.io"&gt;https://www.veturilo.io&lt;/a&gt;). We have developed our own cloud IoT core for a vehicle fleet management SaaS.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Theofanis Petkos</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/ensuring-data-integrity-with-asynchronous-programming-in-a-cloud-iot-core.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>ASYNC / Concurreny</category><category>Internet of Things (IoT)</category><category>Python 3</category><category>Software Design</category><category>Use Case</category></item><item><title>Flasync Await</title><link>https://pyvideo.org/europython-2020/flasync-await.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Async is all the rage, mostly because it simplifies waiting for an operation that takes some time to finish. Python went all in on asyncio by changing the language to support it (async/await) iIn this microservices era where many of the applications we develop consume several 3rd party API services, async is the fast track to success. In this talk, I’ll demonstrate the benefits of going async for a web application, justify choosing Sanic over other web frameworks like aiohttp. I’ll do so by transforming a Flask backed application to a Sanic backed application. Finally, I’ll provide tips &amp;amp; tricks from my experience on measuring, monitoring and testing async code.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">David Bordeynik</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/flasync-await.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>ASYNC / Concurreny</category><category>Abstractions</category><category>Best Practice</category><category>Web</category></item><item><title>gRPC Python, C Extensions, and AsyncIO</title><link>https://pyvideo.org/europython-2020/grpc-python-c-extensions-and-asyncio.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;How to make AsyncIO work with the gRPC Core&lt;/p&gt;
&lt;p&gt;Goal - Encourage Python developers to understand C extensions by sharing gRPC Python’s practice, and advocate the adoption of AsyncIO.&lt;/p&gt;
&lt;p&gt;Prerequisite
- Understand thread vs. process;
- Interested in asynchronous programming.&lt;/p&gt;
&lt;p&gt;gRPC Brief
- What’s gRPC Core? And what is gRPC Python?&lt;/p&gt;
&lt;p&gt;Cython To The Rescue
- Why we picked Cython among all other available tools (e.g., pybind11, ctypes)
- Debuggability: pdb &amp;amp; gdb&lt;/p&gt;
&lt;p&gt;The GIL Friction
- How to delegate work to C extension
- How to make multithreading work&lt;/p&gt;
&lt;p&gt;AsyncIO Topic
- Not blocking the loop, the main headache.
- Non-blocking I/O solution 1: replacing C libraries’ I/O operations
- Non-blocking I/O solution 2: dedicated background poller thread
- Performance improvement (10k -&amp;gt; 20k for client, 4k -&amp;gt; 16k for server)&lt;/p&gt;
&lt;p&gt;Migration to AsyncIO
- Tolerate multithreading and AsyncIO in the same application
- Make both API co-existable in the same application&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lidi Zheng</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/grpc-python-c-extensions-and-asyncio.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>ASYNC / Concurreny</category><category>CPython</category><category>Cython</category><category>Performance</category></item><item><title>Real Time Stream Processing for Machine Learning at Massive Scale</title><link>https://pyvideo.org/europython-2020/real-time-stream-processing-for-machine-learning-at-massive-scale.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Processing Massively Parallel Stream of Data with Python (+ Kafka, SKlearn, SpaCy and Seldon)&lt;/p&gt;
&lt;p&gt;This talk will provide a practical insight on how to build scalable data streaming machine learning pipelines to process large datasets in real time using Python and popular frameworks such as Kafka, SpaCy and Seldon.&lt;/p&gt;
&lt;p&gt;We will be covering a case study performing automated content moderation on Reddit comments in real time. Our dataset will consist of 200k reddit comments from /r/science, 50,000 of which have been removed by moderators. We will be handling the stream data in a Kubernetes cluster, and the stream processing will be handled using the stream processing library Kafka. We will be running the end-to-end pipeline in Kubernetes with various components legeraging SKLearn, SpaCy and Seldon.&lt;/p&gt;
&lt;p&gt;We will then dive into fundamental concepts on stream processing such as windows, watermarking and checkponting, and we will show how to use each of these frameworks to build complex data streaming pipelines that can perform real time processing at scale by building, deploying and monitoring a machine learning model which will process production incoming data..&lt;/p&gt;
&lt;p&gt;Finally we will show best practices when using these frameworks, as well as a high level overview of tools that can be used for monitoring in-depth.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alejandro Saucedo</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/real-time-stream-processing-for-machine-learning-at-massive-scale.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>ASYNC / Concurreny</category><category>Best Practice</category><category>Big Data</category><category>Distributed Systems</category><category>Scientific Libraries (Numpy/Pandas/SciKit/...)</category></item><item><title>Speed Up Your Data Processing</title><link>https://pyvideo.org/europython-2020/speed-up-your-data-processing.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Parallel and Asynchronous Programming in Data Science&lt;/p&gt;
&lt;p&gt;In a data science project, one of the biggest bottlenecks (in terms of time) is the constant wait for the data processing code to finish executing. Slow code, as well as connectivity issues, affect every step of a typical data science workflow — be it for network I/O operations or computation-driven workloads. In this talk, I will be sharing about common bottlenecks in data processing within a typical data science workflow, and exploring the use of parallel and asynchronous programming using concurrent.futures module in Python to speed up your data processing pipelines so that you could focus more on getting value out of your data. Through real-life analogies, you will learn about:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Sequential vs parallel processing,&lt;/li&gt;
&lt;li&gt;Synchronous vs asynchronous execution,&lt;/li&gt;
&lt;li&gt;Network I/O operations vs computation-driven workloads in a data science workflow,&lt;/li&gt;
&lt;li&gt;When is parallelism and asynchronous programming a good idea,&lt;/li&gt;
&lt;li&gt;How to implement parallel and asynchronous programming using concurrent.futures module to speed up your data processing pipelines&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This talk assumes basic understanding of data pipelines and data science workflows. While the main target audience are data scientists and engineers building data pipelines, the talk is designed such that anyone with a basic understanding of the Python language would be able to understand the illustrated concepts and use cases.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Chin Hwee Ong</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/speed-up-your-data-processing.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>ASYNC / Concurreny</category><category>Data</category><category>Data Science</category><category>Multi-Processing</category><category>Multi-Threading</category></item></channel></rss>