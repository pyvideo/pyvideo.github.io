<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_mapreduce.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2013-10-17T00:00:00+00:00</updated><entry><title>The Disco MapReduce Framework</title><link href="https://pyvideo.org/pydata/the-disco-mapreduce-framework.html" rel="alternate"></link><published>2012-03-02T00:00:00+00:00</published><updated>2012-03-02T00:00:00+00:00</updated><author><name>Chris Mueller</name></author><id>tag:pyvideo.org,2012-03-02:pydata/the-disco-mapreduce-framework.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Chris Mueller from Life Technologies introduces us to Disco, a MapReduce
framework built in Python and Erlang.&lt;/p&gt;
&lt;p&gt;Showing that Hadoop is not alone in the MapReduce world, Chris reviews
the basic MapReduce paradigm, dataflow, file and job distribution, and
goes on to explain the Disco Distributed Filesystem (DDFS) before going
into some use- case scenarios in next generation genomic sequencing.&lt;/p&gt;
</summary><category term="disco"></category><category term="mapreduce"></category></entry><entry><title>Programmazione MapReduce in Python con Pydoop</title><link href="https://pyvideo.org/europython-2011/programmazione-mapreduce-in-python-con-pydoop.html" rel="alternate"></link><published>2011-07-13T00:00:00+00:00</published><updated>2011-07-13T00:00:00+00:00</updated><author><name>Simone Leo</name></author><id>tag:pyvideo.org,2011-07-13:europython-2011/programmazione-mapreduce-in-python-con-pydoop.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Simone Leo - 23 June 2011 in &amp;quot;Track Italiana Big Mac &amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Hadoop è la principale implementazione open source di MapReduce, il
paradigma di calcolo distribuito su larga scala di Google. L'API nativa
di Hadoop è in Java e le opzioni built-in per la programmazione in
Python - Streaming e Jython - presentano diversi inconvenienti: la prima
consente di accedere solo a un piccolo sottoinsieme delle funzionalità
di Hadoop, mentre la seconda ha tutte le limitazioni di Jython rispetto
a CPython.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://pydoop.sourceforge.net"&gt;Pydoop&lt;/a&gt; è un'API per Hadoop che rende
disponibile buona parte delle funzionalità di Hadoop al programmatore
Python, consentendo lo sviluppo in CPython. I suoi moduli di base sono
wrapper Boost.Python per l'interfaccia C/C++ di Hadoop.&lt;/p&gt;
&lt;p&gt;Il talk consiste in un tutorial su MapReduce/Hadoop e in una
presentazione dell'API Pydoop, con l'obiettivo principale di avvicinare
le community di Hadoop e Python. Può essere utile, anche se non
strettamente necessaria, una conoscenza di base della programmazione
distribuita.&lt;/p&gt;
</summary><category term="community"></category><category term="hadoop"></category><category term="java"></category><category term="jython"></category><category term="mapreduce"></category><category term="python,"></category><category term="tutorial"></category></entry><entry><title>Python MapReduce Programming with Pydoop</title><link href="https://pyvideo.org/europython-2011/python-mapreduce-programming-with-pydoop.html" rel="alternate"></link><published>2011-07-13T00:00:00+00:00</published><updated>2011-07-13T00:00:00+00:00</updated><author><name>Simone Leo</name></author><id>tag:pyvideo.org,2011-07-13:europython-2011/python-mapreduce-programming-with-pydoop.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Simone Leo - 24 June 2011 in &amp;quot;Track Lasagne&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Hadoop is the leading open source implementation of MapReduce, Google's
large scale distributed computing paradigm. Hadoop's native API is in
Java, and its built-in options for Python programming - Streaming and
Jython - have several drawbacks: the former allows to access only a
small subset of Hadoop's features, while the latter carries with it all
of the limitations of Jython with respect to CPython.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://pydoop.sourceforge.net"&gt;Pydoop&lt;/a&gt; is an API for Hadoop that
makes most of its features available to Python programmers while
allowing CPython development. Its core consists of Boost.Python wrappers
for Hadoop's C/C++ interface.&lt;/p&gt;
&lt;p&gt;The talk consists of a MapReduce/Hadoop tutorial and a presentation of
the Pydoop API, with the main goal of bridging the gap between the
Hadoop and Python communities. A basic knowledge of distributed
programming is helpful but not strictly required.&lt;/p&gt;
</summary><category term="api"></category><category term="cpython"></category><category term="distributed"></category><category term="hadoop"></category><category term="jython"></category><category term="mapreduce"></category><category term="tutorial"></category></entry><entry><title>MapReduce mit Disco</title><link href="https://pyvideo.org/pycon-de-2013/mapreduce-mit-disco.html" rel="alternate"></link><published>2013-10-17T00:00:00+00:00</published><updated>2013-10-17T00:00:00+00:00</updated><author><name>Dr. Jan Morlock</name></author><id>tag:pyvideo.org,2013-10-17:pycon-de-2013/mapreduce-mit-disco.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Mit dem MapReduce-Verfahren können massive Datenmengen auf einem
Rechencluster verarbeitet werden. Namensgeber und wichtige Bestandteile
sind eine Map- und eine Reduce-Phase. Diese werden jeweils
parallelisiert ausgeführt und ermöglichen somit eine optimale Auslastung
der vorhandenen Ressourcen. Im Vergleich zu einer entsprechenden
sequentiellen Implementierung können dadurch große Zeiteinsparungen
erreicht werden.&lt;/p&gt;
&lt;p&gt;Mit dem freien Disco-Framework können MapReduce-Aufgaben leicht in
Python erstellt werden. Beim Zugriff auf die Eingabedaten werden
verschiedene Protokolle unterstützt. Während der Ausführung kann der
Zustand des Rechenclusters sowie der Fortschritt der einzelnen Aufgaben
mit Hilfe einer Weboberfläche überwacht werden. Ein verteiltes
Dateisystem, das Disco Distributed Filesystem (DDFS), wird zur
Speicherung der Zwischen- und Endergebnisse verwendet.&lt;/p&gt;
</summary><category term="big data"></category><category term="disco"></category><category term="mapreduce"></category><category term="parallelisierung"></category></entry></feed>