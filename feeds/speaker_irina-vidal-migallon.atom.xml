<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_irina-vidal-migallon.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-10-10T00:00:00+00:00</updated><entry><title>Using adversarial samples to break and robustify your...</title><link href="https://pyvideo.org/pydata-berlin-2019/using-adversarial-samples-to-break-and-robustify-your.html" rel="alternate"></link><published>2019-10-10T00:00:00+00:00</published><updated>2019-10-10T00:00:00+00:00</updated><author><name>Irina Vidal Migallón</name></author><id>tag:pyvideo.org,2019-10-10:pydata-berlin-2019/using-adversarial-samples-to-break-and-robustify-your.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Speaker: Irina Vidal Migallón&lt;/p&gt;
&lt;p&gt;Track:PyData
We will cover several techniques to expose weaknesses and robustify neural network models for computer vision, from basic precautions to more advanced adversarial training.&lt;/p&gt;
&lt;p&gt;Recorded at the PyConDE &amp;amp; PyData Berlin 2019 conference.
&lt;a class="reference external" href="https://pycon.de"&gt;https://pycon.de&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More details at the conference page: &lt;a class="reference external" href="https://de.pycon.org/program/GKHSBP"&gt;https://de.pycon.org/program/GKHSBP&lt;/a&gt;
Twitter:  &lt;a class="reference external" href="https://twitter.com/pydataberlin"&gt;https://twitter.com/pydataberlin&lt;/a&gt;
Twitter:  &lt;a class="reference external" href="https://twitter.com/pyconde"&gt;https://twitter.com/pyconde&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>When to go deep in Computer Vision... and how</title><link href="https://pyvideo.org/pydata-berlin-2018/when-to-go-deep-in-computer-vision-and-how.html" rel="alternate"></link><published>2018-07-08T00:00:00+00:00</published><updated>2018-07-08T00:00:00+00:00</updated><author><name>Irina Vidal Migallón</name></author><id>tag:pyvideo.org,2018-07-08:pydata-berlin-2018/when-to-go-deep-in-computer-vision-and-how.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We're in a transitional time where it is not always clear whether (Deep)
Neural Networks are the best way to solve a given problem - even in
Computer Vision. This talk discusses practical steps, tools and
practices that can help you make that decision and follow through.&lt;/p&gt;
</summary></entry><entry><title>Deep Learning for detection on a phone</title><link href="https://pyvideo.org/pydata-berlin-2017/deep-learning-for-detection-on-a-phone.html" rel="alternate"></link><published>2017-06-30T00:00:00+00:00</published><updated>2017-06-30T00:00:00+00:00</updated><author><name>Irina Vidal Migallon</name></author><id>tag:pyvideo.org,2017-06-30:pydata-berlin-2017/deep-learning-for-detection-on-a-phone.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deploying a deep model on a mobile device to be used for real-time detection is not quite trivial yet. Defining your Deep Learning architecture, gathering the right data, designing your training process, evaluating your models and turning this into a pipeline that keeps everyone on the team (somewhat) sane - these all have their pitfalls.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Deep Learning has gone through the hype phase where it seemed like a skeleton key, followed by a phase of despair for many who found the building blocks to be too esoteric and the training code and process too unreliable. Deploying on a device with strong hardware limitations adds that extra spice to the mix.&lt;/p&gt;
&lt;p&gt;This talk addresses a very specific use case: preparing a Deep Neural Network to be used for detection in real time in a mobile phone app. It is meant for hands-on engineers and data scientists who live in that area where writing scalable and testable code is every bit as important (and troublesome!) as understanding your loss function.&lt;/p&gt;
&lt;p&gt;We will cover different steps of the process, such as:&lt;/p&gt;
&lt;p&gt;Defining a good model for you:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Your device: it is what it is.&lt;/li&gt;
&lt;li&gt;Cargo cult or what is this layer doing and do we need it?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Gathering the right training data: who, where and how will be using your app?&lt;/p&gt;
&lt;p&gt;Training:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Transfer learning as a small company's best friend.&lt;/li&gt;
&lt;li&gt;Integrating different sources in your data pipeline. Evaluating earlier rather than later.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Depending on time and interest, we may also go over data augmentation and/or model persistence.&lt;/p&gt;
</summary></entry></feed>