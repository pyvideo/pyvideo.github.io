<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 07 Dec 2019 00:00:00 +0000</lastBuildDate><item><title>Introducción a pandas (español)</title><link>https://pyvideo.org/pydata-cordoba-2019/introduccion-a-pandas-espanol.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marc Garcia</dc:creator><pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-09-27:pydata-cordoba-2019/introduccion-a-pandas-espanol.html</guid><category>pandas</category></item><item><title>Hyperrest: A new Apache Arrow API For High Performance Data Access in Pandas</title><link>https://pyvideo.org/pydata-austin-2019/hyperrest-a-new-apache-arrow-api-for-high-performance-data-access-in-pandas.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas is one of the most popular data analytics frameworks for Python, and is widely used in machine learning applications. Pandas provides access to many data formats through a relatively slow ODBC interface. We will review performance benchmarks using Arrow with Pandas, and demonstrate a new API for Arrow called Hyperrest implemented in Dremio, a new open source project for Data Fabric.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sudheesh Katkam</dc:creator><pubDate>Sat, 07 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-07:pydata-austin-2019/hyperrest-a-new-apache-arrow-api-for-high-performance-data-access-in-pandas.html</guid><category>pandas</category><category>hyperrest</category><category>apache arrow</category></item><item><title>Python for Public Transport</title><link>https://pyvideo.org/kiwi-pycon-2019/python-for-public-transport.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;I'll show you how to analyse public transport data with Python.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alex Raichev</dc:creator><pubDate>Sat, 24 Aug 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-08-24:kiwi-pycon-2019/python-for-public-transport.html</guid><category>GTFSTK</category><category>pandas</category><category>Shapely</category></item><item><title>You don't need n dimensions when you have pandas</title><link>https://pyvideo.org/pycon-italia-2019/you-dont-need-n-dimensions-when-you-have-pandas.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;a class="reference external" href="https://pietrobattiston.it/wiki/python:pycon#talk_you_don_t_need_n_dimensions_when_you_have_pandas"&gt;Click here for slides and material
used&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;After a (very) quick general introduction to &lt;tt class="docutils literal"&gt;pandas&lt;/tt&gt;, and in
particular to pandas &lt;strong&gt;indexes&lt;/strong&gt; , this talk will focus on particular
types of indexes, &lt;tt class="docutils literal"&gt;MultiIndex&lt;/tt&gt;es, and on the many &lt;tt class="docutils literal"&gt;pandas&lt;/tt&gt;
features allowing us to use them to store and analyze multidimensional
data.&lt;/p&gt;
&lt;p&gt;We will discover together &lt;em&gt;why&lt;/em&gt; &lt;tt class="docutils literal"&gt;pandas&lt;/tt&gt; does not have (any more) data
structures with more than 2 dimensions, and why we should not regret
them. We will then look at further ways to “restructure” data, including
&lt;tt class="docutils literal"&gt;groupby&lt;/tt&gt; e &lt;tt class="docutils literal"&gt;window&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1771"&gt;https://python.it/feedback-1771&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Sunday 5 May&lt;/strong&gt; at 11:45 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Pietro Battiston</dc:creator><pubDate>Sun, 05 May 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-05:pycon-italia-2019/you-dont-need-n-dimensions-when-you-have-pandas.html</guid><category>data-structures</category><category>numpy</category><category>pandas</category><category>data-analysis</category><category>pydata</category></item><item><title>Predicting Human Activity using Time Series Analysis</title><link>https://pyvideo.org/pycon-italia-2019/predicting-human-activity-using-time-series-analysis.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Time series is referred to as sequence of data points measured over
successive intervals of time. Time series analysis is performed to
extract meaningful statistics and characteristics of the data. For
example, this analysis can be used to predict future based on the past
events. Such use cases of this analysis are stock market prediction,
weather prediction and web traffic prediction.&lt;/p&gt;
&lt;p&gt;In this talk, we’ll be understanding the basics and how to perform time
series analysis and machine learning for a given dataset. For this talk,
we’ll be using the UCI Human Activity Recognition (HAR) Data Set to
classify a given activity performed by the human as one of the following
activities: Walking, Sitting, Standing or Laying.&lt;/p&gt;
&lt;p&gt;The talk would be intermediate level and basics of Python and Pandas are
required. Understanding of Machine Learning algorithms and signal
processing would be helpful.&lt;/p&gt;
&lt;p&gt;Feedback form: &lt;a class="reference external" href="https://python.it/feedback-1576"&gt;https://python.it/feedback-1576&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Saturday 4 May&lt;/strong&gt; at 18:00 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Akul Mehra</dc:creator><pubDate>Sat, 04 May 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-04:pycon-italia-2019/predicting-human-activity-using-time-series-analysis.html</guid><category>TimeSeriesAnalysis</category><category>data-science</category><category>machine-language</category><category>Python</category><category>data-exploration</category><category>Data-Scientist</category><category>MachineLearning</category><category>TimeSeries</category><category>pandas</category><category>DataEngineering</category></item><item><title>Machine learning approaches for road scene video analysis</title><link>https://pyvideo.org/pycon-italia-2019/machine-learning-approaches-for-road-scene-video-analysis.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dashboard cameras (dashcams), inward or front-facing cameras installed
in personal or commercial vehicles, are becoming increasingly popular
due to the pervasiveness of their applications: driver safety,
autonomous driving, fleet management systems, insurance, theft detection
are some examples. Focusing on safety, one of the main problems is to
analyze videos and automatically detect dangerous situations occurring
in them, such as the risk of a near crash with another vehicle or
pedestrian. In this talk, we show how we tackle this real- world problem
at Verizon Connect, using a mix of state-of-the-art deep learning
methods and traditional computer vision / machine learning techniques,
leveraging libraries such as scikit-learn, scipy/numpy, pandas, openCV,
and keras/tensorflow. We also describe how we use AWS and docker to
deploy, serve and scale the application to customers all over the world.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1603"&gt;https://python.it/feedback-1603&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 11:15 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrea Benericetti</dc:creator><pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-03:pycon-italia-2019/machine-learning-approaches-for-road-scene-video-analysis.html</guid><category>ComputerVision</category><category>analytics</category><category>scikit-learn</category><category>opencv</category><category>video</category><category>machine-learning</category><category>optical-flow</category><category>pandas</category></item><item><title>Meet dask and distributed: the unsung heroes of Python scientific data ecosystem.</title><link>https://pyvideo.org/pycon-italia-2019/meet-dask-and-distributed-the-unsung-heroes-of-python-scientific-data-ecosystem.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Thanks to its world-class data tools and libraries, like Numpy, Pandas,
Jupyter, Matplotlib and xarray, Python is becoming the language of
choice in many scientific communities from Physics to Climate Science,
from Earth Observation to Economy.&lt;/p&gt;
&lt;p&gt;A turn-key but less-know component of the scientific ecosystem is the
dask library that enable seamless parallel, distributed and GPU
computing in most cases without code changes.&lt;/p&gt;
&lt;p&gt;We will use climate science as an typical example of a discipline where
simple tasks become easily big data problems and where mastering xarray,
dask and dask.distributed is the key to turn them back into simple
tasks, possibly on a large cluster of VMs (that you can easily provision
from your preferred cloud provider).&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://gitpitch.com/alexamici/talks/master?p=PyConX-2019"&gt;https://gitpitch.com/alexamici/talks/master?p=PyConX-2019&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1704"&gt;https://python.it/feedback-1704&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 17:15 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alessandro Amici</dc:creator><pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-03:pycon-italia-2019/meet-dask-and-distributed-the-unsung-heroes-of-python-scientific-data-ecosystem.html</guid><category>Jupyter</category><category>dask.distributed</category><category>Big-Data</category><category>xarray</category><category>dask</category><category>climate-change</category><category>earth-obeservation</category><category>pandas</category></item><item><title>Pandas ecosystem 2019</title><link>https://pyvideo.org/pycon-italia-2019/pandas-ecosystem-2019.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;pandas is more than 10 years old now. In this time, it became almost a
standard for building data pipelines and perform data analysis in
Python. As the popularity of the project grows, it also grows the number
of projects that depend or interact with pandas.&lt;/p&gt;
&lt;p&gt;This talk will cover this ecosystem of projects around pandas, mainly in
the prespective of scalability and performance. Discussing for example
how projects like Arrow are key for the future of pandas, or how Dask is
overcoming pandas limitations.&lt;/p&gt;
&lt;p&gt;In a first part, the talk will focus on pandas itself, its components,
and its architecture. This will give the required context for a second
part, that will explain related projects, how they interact with pandas,
and what the whole ecosystem can offer to users.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1613"&gt;https://python.it/feedback-1613&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 12:00 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marc Garcia</dc:creator><pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-03:pycon-italia-2019/pandas-ecosystem-2019.html</guid><category>pydata</category><category>analytics</category><category>data-analysis</category><category>Data Mining</category><category>data</category><category>pandas</category></item><item><title>Visualisation in Python</title><link>https://pyvideo.org/pycon-ireland-2018/visualisation-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The ability to explore and grasp data structures through quick and intuitive visualisation is a key skill of any data scientist. Different tools in the Python ecosystem required varying levels of mental-gymnastics to manipulate and visualise information during a data exploration session. The array of Python libraries, each with their own idiosyncrasies, available can be daunting for newcomers and data scientists-in-training. In this talk, we will examine the core data visualisation libraries compatible with the popular Pandas data wrangling library. We'll look at the base-level Matplotlib library first, and then show the benefits of the higher-level Pandas visualisation toolkit and the popular Seaborne library. By the end of the talk, you'll be bar plotting, scatter plotting, and line plotting (never pie charting) your way to data visualisation bliss.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Shane Lynn</dc:creator><pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-11-10:pycon-ireland-2018/visualisation-in-python.html</guid><category>data visualization</category><category>seaborn</category><category>matplotlib</category><category>pandas</category></item><item><title>Business Intelligence con Genropy</title><link>https://pyvideo.org/pycon-italia-2018/business-intelligence-con-genropy.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Genropy è ormai un framework maturo col quale sono stati scritti molti
gestionali che funzionano con piena soddisfazione di clienti e utenti.
Nel corso degli ultimi due anni è stato realizzato in particolare il
gestionale ERPY che usato con successo per gli adempimenti fiscali ma
anche per fornire alla direzione strumenti di analisi e di controllo
facilmente consultabili.&lt;/p&gt;
&lt;p&gt;A tal fine sono state implementate direttamente come funzionalità base
del framework strumenti di interrogazione e di business intelligence che
sono a disposizione di qualsiasi gestionale scritto in genropy.&lt;/p&gt;
&lt;p&gt;Nel corso del talk verranno mostrate le funzionalità base di Genropy con
particolare attenzione alle nuove funzionalità introdotte tra cui:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Integrazione con Pandas per creare in pochi minuti viste e grafici
dei dati aziendali con la possibilità di salvarli e di essere
eseguiti in momenti successivi e/o programmati.&lt;/li&gt;
&lt;li&gt;Costruzione di dashboard per mostrare in forma grafica e tabellare i
vari aspetti della realtà aziendale.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;in __on &lt;strong&gt;venerdì 20 aprile&lt;/strong&gt; at 11:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Francesco Porcari</dc:creator><pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-20:pycon-italia-2018/business-intelligence-con-genropy.html</guid><category>Erpy</category><category>genropy</category><category>business-intelligence</category><category>ERP</category><category>pandas</category></item><item><title>Unveiling the potential of graph databases with Python and Neo4j</title><link>https://pyvideo.org/pycon-italia-2018/unveiling-the-potential-of-graph-databases-with-python-and-neo4j.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Every time we are dealing with data coming from the real world, big and
not so big, you know that usually 80% of the time is needed to clean,
prepare and arrange them. We can then spend the other 20% of the time
enjoying our beloved data analysis.&lt;/p&gt;
&lt;p&gt;The thing that you may know less is that in the last years, the Neo4j
graph database went into the light of being the “right” place to store
data, thanks to its capacity of direct modelling relations among data,
its high availability and its easy, fast and clean query language
Cypher.&lt;/p&gt;
&lt;p&gt;In this talk I’m going to show you some tips to set up in the right way
your data using Pandas, in order to proper model and import them into
Neo4j. A Neo4j Python driver is available to easily import Cypher
queries embedded in Python code. Still, the py2neo package allows
building and querying your database right within your favourite snake
command line.&lt;/p&gt;
&lt;p&gt;Forget about “tall as teen” SQL queries here; thanks to Pandas, Python
and Cypher modelling, loading and query your database is going to be
really straightforward. After this talk, you’ll can’t wait to give Neo4j
a try!&lt;/p&gt;
&lt;p&gt;Prerequisite: a little knowledge of Pandas.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;venerdì 20 aprile&lt;/strong&gt; at 11:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Fabio Lamanna</dc:creator><pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-20:pycon-italia-2018/unveiling-the-potential-of-graph-databases-with-python-and-neo4j.html</guid><category>database</category><category>graph</category><category>storage</category><category>neo4j</category><category>data</category><category>pandas</category></item><item><title>Demystifying pandas internals</title><link>https://pyvideo.org/pydata-london-2018/demystifying-pandas-internals.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;pandas high-level API makes it easy for newcomers to do data wrangling
and analysis, without having to know much about data structures or low
level computing. But this initial easiness of use can become a problem
when performing complex operations, or when facing performance problems
when dealing with large volumes of data. In this talk, the essentials of
data structures and pandas will be covered&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marc Garcia</dc:creator><pubDate>Sat, 28 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-28:pydata-london-2018/demystifying-pandas-internals.html</guid><category>pandas</category></item><item><title>Using pandas for Better (and Worse) Data Science</title><link>https://pyvideo.org/pycon-us-2018/using-pandas-for-better-and-worse-data-science.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The pandas library is a powerful tool for multiple phases of the data science workflow, including data cleaning, visualization, and exploratory data analysis. However, proper data science requires careful coding, and pandas will not stop you from creating misleading plots, drawing incorrect conclusions, ignoring relevant data, including misleading data, or executing incorrect calculations.&lt;/p&gt;
&lt;p&gt;In this tutorial, you'll perform a variety of data science tasks on a handful of real-world datasets using pandas. With each task, you'll learn how to avoid either a pandas pitfall or a data science pitfall. By the end of the tutorial, you'll be more confident that you're using pandas for good rather than evil!&lt;/p&gt;
&lt;p&gt;Participants should have a working knowledge of pandas and an interest in data science, but are not required to have any experience with the data science workflow. Datasets will be provided by the instructor.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-05-10:pycon-us-2018/using-pandas-for-better-and-worse-data-science.html</guid><category>pandas</category></item><item><title>Faster data processing in Python</title><link>https://pyvideo.org/pycon-singapore-2015/faster-data-processing-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will covers ways that help process and analyse visualise data faster in Python. The primary focus is on the technique (should you optimise? what to optimise? how to optimise?) while covering libraries that help with this (line_profiler, Pandas, Numba, etc.)&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Anand S</dc:creator><pubDate>Fri, 19 Jun 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-06-19:pycon-singapore-2015/faster-data-processing-in-python.html</guid><category>pandas</category></item><item><title>Connecting PyData to other Big Data Landscapes using Arrow and Parquet</title><link>https://pyvideo.org/pycon-de-2017/connecting-pydata-to-other-big-data-landscapes-using-arrow-and-parquet.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Uwe L. Korn&lt;/strong&gt; (&amp;#64;xhochy)&lt;/p&gt;
&lt;p&gt;Uwe Korn is a Data Scientist at the Karlsruhe-based RetailTec company Blue Yonder. His expertise is on building architectures for machine learning services that are scalably usable for multiple customers aiming at high service availability as well as rapid prototyping of solutions to evaluate the feasibility of his design decisions. As part of his work to provide an efficient data interchange he became a core committer to the Apache Parquet and Apache Arrow projects.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While Python itself hosts a wide range of machine learning and data tools, other ecosystems like the Hadoop world also provide beneficial tools that can be either connected via Apache Parquet files or in memory using Arrow. This talks shows recent developments that allow interoperation at speed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Python has a vast amount of libraries and tools in its machine learning and data analysis ecosystem. Although it is clearly in competition with R here about the leadership, the world that has sprung out of the Hadoop ecosystem has established itself in the space of data engineering and also tries to provide tools for distributed machine learning. As these stacks run in different environments and are mostly developed by distinct groups of people, using them together has been a pain. While Apache Parquet has already proven itself as the gold standard for the exchange of DataFrames serialized to files, Apache Arrow recently got traction as the in-memory format for DataFrame exchange between different ecosystems.&lt;/p&gt;
&lt;p&gt;This talk will outline how Apache Parquet files can be used in Python and how they are structured to provide efficient DataFrame exchange. In addition to small code sample, this also includes an explanation of some interesting details of the file format. Additionally, the idea of Apache Arrow will be presented and taking Apache Spark (2.3) as an example to showcase how performance increases once DataFrames can be efficiently shared between Python and JVM processes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Uwe L. Korn</dc:creator><pubDate>Wed, 25 Oct 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-10-25:pycon-de-2017/connecting-pydata-to-other-big-data-landscapes-using-arrow-and-parquet.html</guid><category>data-science</category><category>hadoop</category><category>apache</category><category>arrow</category><category>parquet</category><category>pandas</category><category>pydata</category></item><item><title>Getting Scikit-Learn To Run On Top Of Pandas</title><link>https://pyvideo.org/pycon-de-2017/getting-scikit-learn-to-run-on-top-of-pandas.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Ami Tavory&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Ami is a data scientist at Facebook Research's Core Data Science group. He previously worked as a machine learning researcher in the fields of bioinformatics and algorithmic trading. In 2010 he received a Ph.D in Electrical Engineering from Tel Aviv University, in the field of financial information theory. His bachelor's and master's are from Tel Aviv University too.&lt;/p&gt;
&lt;p&gt;Ami uses Python and C++ for data analysis. He contributed to various open source projects, and is the author of a libstd C++ extension shipped with g++ (pb_ds: policy-based data structures).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Scikit-Learn is built directly over numpy, Python's numerical array library. Pandas adds to numpy metadata and higher-level munging capabilities. This talk describes how to intelligently auto-wrap Scikit-Learn for creating a version that can leverage pandas's added features.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Scikit-Learn is the de-facto standard Python library for general-purpose machine learning. It operates over NumPy, an efficient, but low-level, homogeneic array library. Pandas adds to NumPy metadata, heterogeneity, and higher-leve munging capabilities.&lt;/p&gt;
&lt;p&gt;In the field of visualization, newer generation libraries, e.g., Seaborn and Bokeh, are providing safer, more readable, and higher-level functionality, by operating over Pandas data structures. Some of these are implemented using Matplotlib, a lower-level NumPy-based plotting library.&lt;/p&gt;
&lt;p&gt;This talk describes a library for a Pandas-based version of sickit-learn. Here, too, giving a Pandas interface to a machine-learning library, provides code which is safer to use, more readable, and allows direct integration with Pandas's higher-level munging capabilities.&lt;/p&gt;
&lt;p&gt;Due to the large-scale, and evolving nature, of sicikit-learn's codebase, it is infeasible to manually wrap it. Except for a small number of intentional deviations from sickit-learn, the library wraps Scikit-Learn modules lazily through module and class introspection, and dynamic module loading.&lt;/p&gt;
&lt;p&gt;Following a short review of the relevant points of Pandas and Scikit-Learn, the talk is roughly divided into two aspects:     Scikit-Learn And Pandas User Perspective     Safety Advantages Of Pandas-Based Estimators     Using Metadata For Inter-Instance Aggregated Features And Cross-Validation     Using Metadata For Advanced Meta-Algorithms: Stacking, Nested Labeled And Stratified Cross-Valdiation     Python Develop Perspective     Unique Challenges Of Scikit-Learn Introspection And Decoration     Two Approaches For Wrapping Scikit-Learn Estimators     Lazy Dynamic Module Loading&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ami Tavory</dc:creator><pubDate>Wed, 25 Oct 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-10-25:pycon-de-2017/getting-scikit-learn-to-run-on-top-of-pandas.html</guid><category>code-introspection</category><category>scikit-learn</category><category>pandas</category><category>data-science</category><category>python</category><category>machine learning</category></item><item><title>Master 2.5 GB of unstructured specification documents with ease</title><link>https://pyvideo.org/pycon-de-2017/master-25-gb-of-unstructured-specification-documents-with-ease.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Dr. Andreas Schilling&lt;/strong&gt; is Senior Software Engineer at eXXcellent solutions. In his job, he helps customers to develop software solutions from the early stage of defining the particular requirements to developing information systems which meet their needs.&lt;/p&gt;
&lt;p&gt;Before working at eXXcellent solutions Andreas Schilling studied Information Systems at the University of Bamberg focusing on distributed systems and information management. Thereafter, he pursued his PhD and studied collaboration dynamics in open source projects.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;How Do you kick start a project which is based on 2.5 GB files of unstructured specification documents? To answer this question, we present our lessons learned from developing a Python based knowledge management tool which provides a lightweight and intuitive browser frontend.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this talk, we present lessons learned from and practical advice on how to deal with a large body of specification documents in your next project. We introduce our approach as well as code excerpts from our powerful toolset to transform a large set of unstructured and partially corrupt specification documents into structured JSON Files. Finally, we showcase a simple, yet powerful Javascript frontend which requires no additional infrastructure to present the compiled artefacts in an intuitive and responsive user interface.&lt;/p&gt;
&lt;p&gt;In particular this talk covers the following topics:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;How to make use of pywin32 to access layout and content information from partially corrupt .doc and .docx files and create simple JSON files with UTF-8 encoding.&lt;/li&gt;
&lt;li&gt;Identify and categorize signal words in your specification.&lt;/li&gt;
&lt;li&gt;Use pandas to compile content based recommender functionality&lt;/li&gt;
&lt;li&gt;Use networkx and py2cytoscape to visualize call sequences and semantic relationships in your specification.&lt;/li&gt;
&lt;li&gt;Present the compiled artefacts and identified relationships in an easy-to-use and lightweight Javascript browser interface without any additional infrastructure (i.e. no webserver and no database server).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andreas Schilling</dc:creator><pubDate>Wed, 25 Oct 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-10-25:pycon-de-2017/master-25-gb-of-unstructured-specification-documents-with-ease.html</guid><category>networkx</category><category>pandas</category><category>visualization</category><category>knowledge-management</category><category>analytics</category><category>use-case</category><category>python</category><category>business</category></item><item><title>Digital Analytics Data Aggregation: un case study dal mondo reale utilizzando SQL, NoSQL e Pandas</title><link>https://pyvideo.org/pycon-italia-2017/digital-analytics-data-aggregation-un-case-study-dal-mondo-reale-utilizzando-sql-nosql-e-pandas.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;I clienti enterprise si trovano sempre più spesso ad avere difficoltà
nel recuperare informazioni essenziali per capire nel complesso dove il
brand sta funzionando e dove invece serve un intervento tempestivo,
perchè sono inondati di dati di dettaglio che spesso non sono facilmente
aggregabili e visualizzabili insieme con frequenza giornaliera.&lt;/p&gt;
&lt;p&gt;Per rispondere a questa esigenza, in azienda, nel nostro reparto R&amp;amp;D,
abbiamo sviluppato una dashboard che permette a clienti con diversi
brand e properties (siti) di aggregare i principali KPI da monitorare
(sia KPI standard che KPI personalizzati). I KPI sono i key performance
indicators, ovvero metriche che aiutano a valutare le performance).&lt;/p&gt;
&lt;p&gt;Ma i dati da visualizzare e aggregare, provenienti da diverse fonti
(Google Analytics, Adobe Analytics, tools SEO), hanno strutture diverse
e non è possibile a priori prevedere quali sono le strutture
disponibili.&lt;/p&gt;
&lt;p&gt;Perciò, in questo talk vedremo insieme come abbiamo gestito questo caso
reale attraverso un mix di tecnologie SQL (MySQL attraverso Django) e
NoSQL (MongoDb), utilizzando i dataframe di Pandas come layer intermedio
attraverso il quale lavorare il dato velocemente.&lt;/p&gt;
&lt;p&gt;La soluzione realizzata ci ha permesso di integrare rapidamente nuove
fonti e nuovi KPI, e di gestire volumi elevati di dati (attualmente 200+
siti contemporaneamente) con ottime performance.&lt;/p&gt;
&lt;p&gt;Vedremo poi (se rimane tempo) come questi dati vengono forniti
attraverso API Rest (grazie a Django Rest Framework) e consumati
attraverso AngularJS sul client.&lt;/p&gt;
&lt;p&gt;Vorremmo infine coinvolgervi chiedendovi come avreste gestito questa
difficoltà - non è assolutamente detto che la nostra soluzione sia per
forza quella ottimale!&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alessandro Pelliciari</dc:creator><pubDate>Sat, 08 Apr 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-04-08:pycon-italia-2017/digital-analytics-data-aggregation-un-case-study-dal-mondo-reale-utilizzando-sql-nosql-e-pandas.html</guid><category>django-rest-framework</category><category>mongodb</category><category>django</category><category>API Design</category><category>web-development</category><category>angularjs</category><category>mysql</category><category>google-analytics</category><category>pandas</category></item><item><title>How to use pandas the wrong way</title><link>https://pyvideo.org/pycon-italia-2017/how-to-use-pandas-the-wrong-way.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The &lt;strong&gt;pandas&lt;/strong&gt; library represents a very efficient and convenient tool
for data manipulation, but sometimes hides unexpected pitfalls which can
arise in various and sometimes unintelligible ways.&lt;/p&gt;
&lt;p&gt;By briefly referring to some aspects of the internals, I will review
specific situations in which a change of approach can, for instance,
make a difference in terms of performance.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UPDATE (April 12, 2017) - SLIDES:&lt;/strong&gt; the talk had very few slides;
still, you can find those few, together with the notebooks I used live,
&lt;a class="reference external" href="https://pietrobattiston.it/python:pycon"&gt;here&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Pietro Battiston</dc:creator><pubDate>Sat, 08 Apr 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-04-08:pycon-italia-2017/how-to-use-pandas-the-wrong-way.html</guid><category>data-science</category><category>pandas</category><category>pydata</category></item><item><title>Analisi dati e grafici con Genropy e Pandas</title><link>https://pyvideo.org/pycon-italia-2017/analisi-dati-e-grafici-con-genropy-e-pandas.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Genropy è un framework per la creazione di Single Page Applications che
offre ad utenti e sviluppatori un ambiente di lavoro molto comodo per il
caricamento e la gestione dei dati. In questo talk parleremo degli
strumenti messi a disposizione per l’analisi dei dati e la
rappresentazione grafica, tabellare e in dashboard. Parleremo in
particolare dell’integrazione con Pandas e di come sia facile anche per
un utente non particolarmente esperto generare pivot table, e creare
colonne calcolate e mostrare i risultati come grafici.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Francesco Porcari</dc:creator><pubDate>Fri, 07 Apr 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-04-07:pycon-italia-2017/analisi-dati-e-grafici-con-genropy-e-pandas.html</guid><category>genropy</category><category>webapp</category><category>pandas</category><category>web-development</category><category>graph</category></item><item><title>How to hug Pandas</title><link>https://pyvideo.org/pycon-es-2017/how-to-hug-pandas.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Una breve introducción al tratamiento de datos con Pandas. Hablaremos de: Cómo cargar datos para su procesado, tipos de datos básicos (DataFrame, Series...), información estadística sobre los datos, indexación de los datos, consulta a los datos: Slicing y filtering, operaciones vectoriales, agrupación y agregación de datos.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Eyad Tomeh</dc:creator><pubDate>Sun, 24 Sep 2017 14:30:00 +0200</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-09-24:pycon-es-2017/how-to-hug-pandas.html</guid><category>pandas</category></item><item><title>Pandas</title><link>https://pyvideo.org/euroscipy-2017/pandas.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas is nowadays the library of choice for manipulating and analysing structured data, providing high-performance, easy-to-use data structures and data analysis tools.&lt;/p&gt;
&lt;p&gt;This hands-on tutorial will give a basic introduction to pandas, guide you through the different data structures and its manipulation, explaining the the key concepts and defining features. No prior knowledge about pandas is required.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joris Van den Bossche</dc:creator><pubDate>Thu, 31 Aug 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-08-31:euroscipy-2017/pandas.html</guid><category>tutorial</category><category>pandas</category></item><item><title>Gotchas of Pandas</title><link>https://pyvideo.org/pycon-israel-2017/gotchas-of-pandas.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas is one of the first libraries someone deals with while learning data science with python. While being one of the best libraries for data analysis and data cleaning, pandas is full of bugs and gotchas. This talk will look inside those gotchas with detailed explanations and will provide the solutions for some of them. this talk will cover the common and rare pandas gotchas like:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;NaN problems Errors due to Numpy and core python libraries&lt;/li&gt;
&lt;li&gt;Reindexing gotchas&lt;/li&gt;
&lt;li&gt;Boolean Gotchas&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Prabhant Singh</dc:creator><pubDate>Mon, 12 Jun 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-06-12:pycon-israel-2017/gotchas-of-pandas.html</guid><category>pandas</category></item><item><title>Data Science &amp; Data Visualization in Python. How to harness power of Python for social good?</title><link>https://pyvideo.org/pydata-berlin-2017/data-science-data-visualization-in-python-how-to-harness-power-of-python-for-social-good.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python as an Open Data Science tool offers many libraries for data visualization and I will show you how to use and combine the best. I strongly believe that power of data is not only in the information &amp;amp; insight that data can provide us, Data is and can be really beautiful and can not only transform our perception but also the world that we all live in.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In my talk I will primarily focus on answering/offer the answer to these questions:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Why we need data science and why more and more people should be really interested in analyzing data and data visualization? (motivation)&lt;/li&gt;
&lt;li&gt;What is data science and how to start doing it in Python? (introduction of procedures, tools, most popular IDE-s for Python, etc.)&lt;/li&gt;
&lt;li&gt;What tools for data analysis and data visualization Python offers? (in each stage of analysis the best libraries will be shown for the specific purpose; as for data visualization we will focus particularly on Bokeh, Seaborn, Plotly and use of Jupyter Notebook and Plotly)&lt;/li&gt;
&lt;li&gt;How to 'unlock' the insight hidden in data through Python and how to use it to transform not only public administration or business, but ultimately the transformation of the whole society and economy towards the insight &amp;amp; knowledge based? (potential of data science)&lt;/li&gt;
&lt;li&gt;Open Data, Open Government Partnership, Open Public Administration &amp;amp; all the advantages of Open Data Science &amp;amp; Python. Data-Driven Approach. Everywhere. Now. (the end of talk +vision)&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Radovan Kavicky</dc:creator><pubDate>Fri, 30 Jun 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-06-30:pydata-berlin-2017/data-science-data-visualization-in-python-how-to-harness-power-of-python-for-social-good.html</guid><category>python</category><category>data-science</category><category>data-visualization</category><category>analytics</category><category>PyData</category><category>PyDataBLN</category><category>PyDataBerlin</category><category>PyDataBA</category><category>PyDataBratislava</category><category>talk</category><category>Data</category><category>Bokeh</category><category>Social Good</category><category>datascience</category><category>jupyter</category><category>open science</category><category>open data science</category><category>DataVisualization</category><category>data-analysis</category><category>analysis</category><category>matplotlib</category><category>numpy</category><category>data wrangling</category><category>jupyter notebook</category><category>pandas</category><category>machine learning</category><category>deep learning</category><category>Open Data</category><category>Citizen Data Science</category></item><item><title>Marketing Data Science</title><link>https://pyvideo.org/pydata-barcelona-2017/marketing-data-science.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Marketing Data Science: how digital marketing needs data science to survive.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Digital Marketing is changing the way corporations and brands communicates with customers. The investments in Digital Marketing are skyrocketing around the world in a multi-billion industry.&lt;/p&gt;
&lt;p&gt;But consumers and customers (specially millenials) does not trust advertising. Different approaches are being made by corporations like Inbound Marketing Strategies. My presentation is about how Digital Marketing needs Data Science in order to better understand the customer needs and generate new niches of interest for companies. Companies investing in Digital Marketing should take a close look at Data Science Platforms like Python in order to better gather inisghts, create segments and personalice a customer experience.&lt;/p&gt;
&lt;p&gt;I will provide some short examples about how we are using python jupyter notebook environment in order to gain inisghts from customers using IBM Watson API, generating new segmentation and customer experiences.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joaquin Pais</dc:creator><pubDate>Sun, 21 May 2017 15:45:00 +0200</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-05-21:pydata-barcelona-2017/marketing-data-science.html</guid><category>marketing</category><category>data science</category><category>pandas</category></item><item><title>The Secret Life Of Rolling Pandas</title><link>https://pyvideo.org/pydata-barcelona-2017/the-secret-life-of-rolling-pandas.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas provides a powerful set of functions to compute statistics on rolling windows. We will go beyond the convenient interface, and peek at the algorithmic gems that implement these operations efficiently: summed area tables, Welford's method, skip lists, ring buffers, deques... will all get their minute of fame, and attendees may learn a thing or two they can use in their everyday coding.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The talk will cover:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;A quick overview of the Rolling and Expanding objects in pandas. Why straightforward implementations, even clever ones using advanced NumPy tricks, are inefficient.&lt;/li&gt;
&lt;li&gt;How is Series.rolling().sum() implemented. How the same idea can be extended to higher dimensions with the help of the inclusion-exclusion principle to yield summed area tables.&lt;/li&gt;
&lt;li&gt;How are Series.rolling().var() and friends implemented. The importance of numerically stable algorithms: why Welford's method is the better choice, even if it's a little slower. How can the same ideas be generalized to higher order moments, and used to parallelize computations.&lt;/li&gt;
&lt;li&gt;How are Series.rolling().max() and .min() implemented. The beauty of clever algorithms. The use of specialized data structures: a ring buffer as a deque.&lt;/li&gt;
&lt;li&gt;How are Series.rolling().median() and .quantile() implemented. More specialized data structures: the skip list, or why randomization can be your friend.&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jaime Fernandez del Rio</dc:creator><pubDate>Sat, 20 May 2017 15:45:00 +0200</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-05-20:pydata-barcelona-2017/the-secret-life-of-rolling-pandas.html</guid><category>pandas</category></item><item><title>Pandas for Data Analysis</title><link>https://pyvideo.org/scipy-2017/pandas-for-data-analysis.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There are audio issues with this video that cannot be fixed. We recommend listening to the tutorial without headphones to minimize the buzzing sound.&lt;/p&gt;
&lt;p&gt;Tutorial information may be found at &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Data Science and Machine learning have been synonymous with languages like Python. Libraries like numpy and Pandas have become the de facto standard when working with data.
The DataFrame object provided by Pandas gives us the ability to work with heterogeneous unstructured data that is commonly used in &amp;quot;real world&amp;quot; data.&lt;/p&gt;
&lt;p&gt;New learners are often drawn to Python and Pandas because of all the different and exciting types of models and insights the language can do and provide, but are awestruck when faced with the initial learning curve.&lt;/p&gt;
&lt;p&gt;This tutorial aims to guide the learner from using spreadsheets to using the Pandas DataFrame.
Not only does moving to a programming language allow the user to have a more reproducible workflow, but as datasets get larger, some cannot even be opened in a spreadsheet program. The goal is to have an absolute beginner proficient enough with Pandas that they can start working with data in Python.&lt;/p&gt;
&lt;p&gt;We will cover how to load and view our data. Then, some basic methods to do quick visualizations of our data for exploratory data analysis. We will then work on combining and working multiple datasets (concatenating and merging), and introduce what Dr. Hadley Wickham has coined &amp;quot;tidy data&amp;quot;. Tidy data is an important concept because the process of tidying data will fix a host of data problems that are needed to perform analysis. We then cover functions and applying methods to our data with a focus on data cleaning, and how we can use the concept of split-apply-combine (groupby) to summarize or reduce our data.&lt;/p&gt;
&lt;p&gt;Finally, we cover the basics of string manipulation and how to use it to clean data before briefly covering the role of Pandas in analysis packages such as scikit learn. The tutorial will with a fitted model.&lt;/p&gt;
&lt;p&gt;The goal is to get people familiar with Python and Pandas so they can learn and explore many other parts of the Python ecosystem.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Daniel Chen</dc:creator><pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-08-05:scipy-2017/pandas-for-data-analysis.html</guid><category>pandas</category></item><item><title>Pandas from the Inside</title><link>https://pyvideo.org/pydata-dc-2016/pandas-from-the-inside.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Pandas is great for data analysis in Python: intuitive DataFrames from R; fast numpy arrays under the hood; groupby like in SQL. But this familiarity is deceptive: pandas users often get stuck on things they feel should be simple. This talk look inside pandas to see how DataFrames actually work when building, indexing and grouping tables. You will learn how to write fast, efficient pandas code.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Stephen Simmons</dc:creator><pubDate>Fri, 07 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-07:pydata-dc-2016/pandas-from-the-inside.html</guid><category>pandas</category></item><item><title>Mind the Gap! Bridging the pandas - scikit learn dtype divide</title><link>https://pyvideo.org/pydata-chicago-2016/mind-the-gap-bridging-the-pandas-scikit-learn-dtype-divide.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/TomAugspurger/mtg/blob/master/MTG.pdf"&gt;https://github.com/TomAugspurger/mtg/blob/master/MTG.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This talk briefly introduces the two different data models used by Scikit-Learn (NumPy arrays) and pandas DataFrames. We see why this can cause problems for users of these libraries. Finally, we discuss strategies for managing the differences.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tom Augspurger</dc:creator><pubDate>Sat, 27 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-27:pydata-chicago-2016/mind-the-gap-bridging-the-pandas-scikit-learn-dtype-divide.html</guid><category>pandas</category><category>scikit</category></item><item><title>How do I apply a function to a pandas Series or DataFrame?</title><link>https://pyvideo.org/data-school/pandas-30-apply-function.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever struggled to figure out the differences between apply, map, and applymap? In this video, I'll explain when you should use each of these methods and demonstrate a few common use cases. Watch the end of the video for three important announcements!&lt;/p&gt;
&lt;p&gt;This is video 30 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 23 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-23:data-school/pandas-30-apply-function.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>NumPy</category></item><item><title>How do I create a pandas DataFrame from another object?</title><link>https://pyvideo.org/data-school/pandas-29-dummy-dataframe.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever needed to create a DataFrame of &amp;quot;dummy&amp;quot; data, but without reading from a file? In this video, I'll demonstrate how to create a DataFrame from a dictionary, a list, and a NumPy array. I'll also show you how to create a new Series and attach it to the DataFrame.&lt;/p&gt;
&lt;p&gt;This is video 29 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 16 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-16:data-school/pandas-29-dummy-dataframe.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>NumPy</category></item><item><title>How do I change display options in pandas?</title><link>https://pyvideo.org/data-school/pandas-28-customize-display.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever wanted to change the way your DataFrame is displayed? Perhaps you needed to see more rows or columns, or modify the formatting of numbers? In this video, I'll demonstrate how to change the settings for five common display options in pandas.&lt;/p&gt;
&lt;p&gt;This is video 28 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 09 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-09:data-school/pandas-28-customize-display.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>How do I avoid a SettingWithCopyWarning in pandas?</title><link>https://pyvideo.org/data-school/pandas-27-setting-with-copy-warning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you've been using pandas for a while, you've likely encountered a SettingWithCopyWarning. The proper response is to modify your code appropriately, not to turn off the warning! In this video, I'll show you two common scenarios in which this warning arises, explain why it's occurring, and then demonstrate how to address it.&lt;/p&gt;
&lt;p&gt;This is video 27 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 02 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-02:data-school/pandas-27-setting-with-copy-warning.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>missing data</category></item><item><title>How do I find and remove duplicate rows in pandas?</title><link>https://pyvideo.org/data-school/pandas-26-duplicate-data.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;During the data cleaning process, you will often need to figure out whether you have duplicate data, and if so, how to deal with it. In this video, I'll demonstrate the two key methods for finding and removing duplicate rows, as well as how to modify their behavior to suit your specific needs.&lt;/p&gt;
&lt;p&gt;This is video 26 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 26 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-26:data-school/pandas-26-duplicate-data.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>duplicate data</category></item><item><title>How do I work with dates and times in pandas?</title><link>https://pyvideo.org/data-school/pandas-25-dates-and-times.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Let's say that you have dates and times in your DataFrame and you want to analyze your data by minute, month, or year. What should you do? In this video, I'll demonstrate how you can convert your data to &amp;quot;datetime&amp;quot; format, enabling you to access a ton of convenient attributes and perform datetime comparisons and mathematical operations.&lt;/p&gt;
&lt;p&gt;This is video 25 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 19 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-19:data-school/pandas-25-dates-and-times.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>data visualization</category></item><item><title>How do I create dummy variables in pandas?</title><link>https://pyvideo.org/data-school/pandas-24-dummy-variables.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you want to include a categorical feature in your machine learning model, one common solution is to create dummy variables. In this video, I'll demonstrate three different ways you can create dummy variables from your existing DataFrame columns. I'll also show you a trick for simplifying your code that was introduced in pandas 0.18.&lt;/p&gt;
&lt;p&gt;This is video 24 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 12 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-12:data-school/pandas-24-dummy-variables.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>machine learning</category></item><item><title>More of your pandas questions answered!</title><link>https://pyvideo.org/data-school/pandas-23-viewer-questions.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, I'm answering a few of the pandas questions I've received in the YouTube comments: Could you explain how to read the pandas documentation? What is the difference between ufo.isnull() and pd.isnull(ufo)? Why are DataFrame slices inclusive when using .loc, but exclusive when using .iloc? How do I randomly sample rows from a DataFrame?&lt;/p&gt;
&lt;p&gt;This is video 23 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 05 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-05:data-school/pandas-23-viewer-questions.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>reproducibility</category></item><item><title>How do I use pandas with scikit-learn to create Kaggle submissions?</title><link>https://pyvideo.org/data-school/pandas-22-prepare-for-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you been using scikit-learn for machine learning, and wondering whether pandas could help you to prepare your data and export your predictions? In this video, I'll demonstrate the simplest way to integrate pandas into your machine learning workflow, and will create a submission for Kaggle's Titanic competition in just a few lines of code!&lt;/p&gt;
&lt;p&gt;This is video 22 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 28 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-06-28:data-school/pandas-22-prepare-for-machine-learning.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>scikit-learn</category><category>machine learning</category></item><item><title>How do I make my pandas DataFrame smaller and faster?</title><link>https://pyvideo.org/data-school/pandas-21-reduce-dataframe-size.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Are you working with a large dataset in pandas, and wondering if you can reduce its memory footprint or improve its efficiency? In this video, I'll show you how to do exactly that in one line of code using the &amp;quot;category&amp;quot; data type, introduced in pandas 0.15. I'll explain how it works, and how to know when you shouldn't use it.&lt;/p&gt;
&lt;p&gt;This is video 21 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 21 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-06-21:data-school/pandas-21-reduce-dataframe-size.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>When should I use the "inplace" parameter in pandas?</title><link>https://pyvideo.org/data-school/pandas-20-inplace-parameter.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We've used the &amp;quot;inplace&amp;quot; parameter many times during this video series, but what exactly does it do, and when should you use it? In this video, I'll explain how &amp;quot;inplace&amp;quot; affects methods such as &amp;quot;drop&amp;quot; and &amp;quot;dropna&amp;quot;, and why it is always False by default.&lt;/p&gt;
&lt;p&gt;This is video 20 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 14 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-06-14:data-school/pandas-20-inplace-parameter.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>missing data</category></item><item><title>How do I select multiple rows and columns from a pandas DataFrame?</title><link>https://pyvideo.org/data-school/pandas-19-select-dataframe-rows-and-columns.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever been confused about the &amp;quot;right&amp;quot; way to select rows and columns from a DataFrame? pandas gives you an incredible number of options for doing so, but in this video, I'll outline the current best practices for row and column selection using the loc, iloc, and ix methods.&lt;/p&gt;
&lt;p&gt;This is video 19 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 07 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-06-07:data-school/pandas-19-select-dataframe-rows-and-columns.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>What do I need to know about the pandas index? (Part 2)</title><link>https://pyvideo.org/data-school/pandas-18-index-part-2.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In part two of our discussion of the index, we'll switch our focus from the DataFrame index to the Series index. After discussing index-based selection and sorting, I'll demonstrate how automatic index alignment during mathematical operations and concatenation enables us to easily work with incomplete data in pandas.&lt;/p&gt;
&lt;p&gt;This is video 18 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Thu, 02 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-06-02:data-school/pandas-18-index-part-2.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>missing data</category></item><item><title>What do I need to know about the pandas index? (Part 1)</title><link>https://pyvideo.org/data-school/pandas-17-index-part-1.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The DataFrame index is core to the functionality of pandas, yet it's confusing to many users. In this video, I'll explain what the index is used for and why you might want to store your data in the index. I'll also demonstrate how to set and reset the index, and show how that affects the DataFrame's shape and contents.&lt;/p&gt;
&lt;p&gt;This is video 17 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 31 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-05-31:data-school/pandas-17-index-part-1.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>How do I handle missing values in pandas?</title><link>https://pyvideo.org/data-school/pandas-16-missing-values.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Most datasets contain &amp;quot;missing values&amp;quot;, meaning that the data is incomplete. Deciding how to handle missing values can be challenging! In this video, I'll cover all of the basics: how missing values are represented in pandas, how to locate them, and options for how to drop them or fill them in.&lt;/p&gt;
&lt;p&gt;This is video 16 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Thu, 26 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-05-26:data-school/pandas-16-missing-values.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>missing data</category></item><item><title>How do I explore a pandas Series?</title><link>https://pyvideo.org/data-school/pandas-15-explore-series.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When you start working with a new dataset, how should you go about exploring it? In this video, I'll demonstrate some of the basic tools in pandas for exploring both numeric and non-numeric data. I'll also show you how to create simple visualizations in a single line of code!&lt;/p&gt;
&lt;p&gt;This is video 15 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 24 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-05-24:data-school/pandas-15-explore-series.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>data visualization</category></item><item><title>When should I use a "groupby" in pandas?</title><link>https://pyvideo.org/data-school/pandas-14-analyze-data-by-category.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The pandas &amp;quot;groupby&amp;quot; method allows you to split a DataFrame into groups, apply a function to each group independently, and then combine the results back together. This is called the &amp;quot;split-apply-combine&amp;quot; pattern, and is a powerful tool for analyzing data across different categories. In this video, I'll explain when you should use a groupby and then demonstrate its flexibility using four different examples.&lt;/p&gt;
&lt;p&gt;This is video 14 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Thu, 19 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-05-19:data-school/pandas-14-analyze-data-by-category.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>data visualization</category></item><item><title>How do I change the data type of a pandas Series?</title><link>https://pyvideo.org/data-school/pandas-13-change-data-type-of-series.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever tried to do math with a pandas Series that you thought was numeric, but it turned out that your numbers were stored as strings? In this video, I'll demonstrate two different ways to change the data type of a Series so that you can fix incorrect data types. I'll also show you the easiest way to convert a boolean Series to integers, which is useful for creating dummy/indicator variables for machine learning.&lt;/p&gt;
&lt;p&gt;This is video 13 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 17 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-05-17:data-school/pandas-13-change-data-type-of-series.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>How do I use string methods in pandas?</title><link>https://pyvideo.org/data-school/pandas-12-string-methods.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;pandas includes powerful string manipulation capabilities that you can easily apply to any Series of strings. In this video, I'll show you how to access string methods in pandas (along with a few examples), and then end with two bonus tips to help you maximize your efficiency.&lt;/p&gt;
&lt;p&gt;This is video 12 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Thu, 12 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-05-12:data-school/pandas-12-string-methods.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>regular expressions</category><category>string processing</category></item><item><title>How do I use the "axis" parameter in pandas?</title><link>https://pyvideo.org/data-school/pandas-11-dataframe-axis.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When performing operations on a pandas DataFrame, such as dropping columns or calculating row means, it is often necessary to specify the &amp;quot;axis&amp;quot;. But what exactly is an axis? In this video, I'll help you to build a mental model for understanding the axis parameter so that you will know when and how to use it.&lt;/p&gt;
&lt;p&gt;This is video 11 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 10 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-05-10:data-school/pandas-11-dataframe-axis.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>Your pandas questions answered!</title><link>https://pyvideo.org/data-school/pandas-10-viewer-questions.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, I'm answering a few of the pandas questions I've received in the YouTube comments: When reading from a file, how do I read in only a subset of the columns or rows? How do I iterate through a Series or a DataFrame? How do I drop all non-numeric columns from a DataFrame? How do I know whether I should pass an argument as a string or a list?&lt;/p&gt;
&lt;p&gt;This is video 10 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Thu, 05 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-05-05:data-school/pandas-10-viewer-questions.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>How do I apply multiple filter criteria to a pandas DataFrame?</title><link>https://pyvideo.org/data-school/pandas-09-multiple-filter-criteria.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Let's say that you want to filter the rows of a DataFrame by multiple conditions. In this video, I'll demonstrate how to do this using two different logical operators. I'll also explain the special rules in pandas for combining filter criteria, and end with a trick for simplifying chained conditions!&lt;/p&gt;
&lt;p&gt;This is video 9 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 03 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-05-03:data-school/pandas-09-multiple-filter-criteria.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>How do I filter rows of a pandas DataFrame by column value?</title><link>https://pyvideo.org/data-school/pandas-08-filter-dataframe-rows.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Let's say that you only want to display the rows of a DataFrame which have a certain column value. How would you do it? pandas makes it easy, but the notation can be confusing and thus difficult to remember. In this video, I'll work up to the solution step-by-step using regular Python code so that you can truly understand the logic behind pandas filtering notation.&lt;/p&gt;
&lt;p&gt;This is video 8 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Thu, 28 Apr 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-04-28:data-school/pandas-08-filter-dataframe-rows.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>How do I sort a pandas DataFrame or a Series?</title><link>https://pyvideo.org/data-school/pandas-07-sort-dataframe-or-series.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;pandas allows you to sort a DataFrame by one of its columns (known as a &amp;quot;Series&amp;quot;), and also allows you to sort a Series alone. The sorting API changed in pandas version 0.17, so in this video, I'll demonstrate both the &amp;quot;old way&amp;quot; and the &amp;quot;new way&amp;quot; to sort. I'll also show you how to sort a DataFrame by multiple columns at once!&lt;/p&gt;
&lt;p&gt;This is video 7 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 26 Apr 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-04-26:data-school/pandas-07-sort-dataframe-or-series.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>How do I remove columns from a pandas DataFrame?</title><link>https://pyvideo.org/data-school/pandas-06-remove-dataframe-column.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you have DataFrame columns that you're never going to use, you may want to remove them entirely in order to focus on the columns that you do use. In this video, I'll show you how to remove columns (and rows), and will briefly explain the meaning of the &amp;quot;axis&amp;quot; and &amp;quot;inplace&amp;quot; parameters.&lt;/p&gt;
&lt;p&gt;This is video 6 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Thu, 21 Apr 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-04-21:data-school/pandas-06-remove-dataframe-column.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>How do I rename columns in a pandas DataFrame?</title><link>https://pyvideo.org/data-school/pandas-05-rename-dataframe-column.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;You will often want to rename the columns of a DataFrame so that their names are descriptive, easy to type, and don't contain any spaces. In this video, I'll demonstrate three different strategies for renaming columns so that you can choose the best strategy to fit your particular situation.&lt;/p&gt;
&lt;p&gt;This is video 5 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 19 Apr 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-04-19:data-school/pandas-05-rename-dataframe-column.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>Why do some pandas commands end with parentheses (and others don't)?</title><link>https://pyvideo.org/data-school/pandas-04-methods-and-attributes.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;To access most of the functionality in pandas, you have to call the methods and attributes of DataFrame and Series objects. In this video, I'll discuss some common methods and attributes, and show you how to tell the difference between them. (Hint: It's all about the parentheses!)&lt;/p&gt;
&lt;p&gt;This is video 4 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Thu, 14 Apr 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-04-14:data-school/pandas-04-methods-and-attributes.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>How do I select a pandas Series from a DataFrame?</title><link>https://pyvideo.org/data-school/pandas-03-select-series-from-dataframe.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;DataFrames and Series are the two main object types in pandas for data storage: a DataFrame is like a table, and each column of the table is called a Series. You will often select a Series in order to analyze or manipulate it. In this video, I'll show you how to select a Series using &amp;quot;bracket notation&amp;quot; and &amp;quot;dot notation&amp;quot;, and will discuss the limitations of dot notation. I'll also demonstrate how to create a new Series in a DataFrame.&lt;/p&gt;
&lt;p&gt;This is video 3 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 12 Apr 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-04-12:data-school/pandas-03-select-series-from-dataframe.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>What is pandas? (Introduction to the Q&amp;A series)</title><link>https://pyvideo.org/data-school/pandas-01-introduction.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;pandas is a full-featured Python library for data analysis, manipulation, and visualization. This video series is for anyone who wants to work with data in Python, regardless of whether you are brand new to pandas or have some experience.&lt;/p&gt;
&lt;p&gt;This is video 1 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Thu, 07 Apr 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-04-07:data-school/pandas-01-introduction.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category></item><item><title>How do I read a tabular data file into pandas?</title><link>https://pyvideo.org/data-school/pandas-02-read-tabular-data-file.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Tabular data&amp;quot; is just data that has been formatted as a table, with rows and columns (like a spreadsheet). You can easily read a tabular data file into pandas, even directly from a URL! In this video, I'll walk you through how to do that, including how to modify some of the default arguments of the read_table function to solve common problems.&lt;/p&gt;
&lt;p&gt;This is video 2 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Thu, 07 Apr 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-04-07:data-school/pandas-02-read-tabular-data-file.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>csv</category></item><item><title>Data science in Python: pandas, seaborn, scikit-learn</title><link>https://pyvideo.org/data-school/scikit-learn-06-data-science-pipeline.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, we'll cover the data science pipeline from data ingestion (with pandas) to data visualization (with seaborn) to machine learning (with scikit-learn). We'll learn how to train and interpret a linear regression model, and then compare three possible evaluation metrics for regression problems. Finally, we'll apply the train/test split procedure to decide which features to include in our model.&lt;/p&gt;
&lt;p&gt;This is the sixth video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Thu, 28 May 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-05-28:data-school/scikit-learn-06-data-science-pipeline.html</guid><category>machine learning</category><category>data science</category><category>scikit-learn</category><category>tutorial</category><category>Data School</category><category>pandas</category><category>seaborn</category><category>linear regression</category><category>model evaluation</category><category>feature selection</category><category>visualization</category></item><item><title>pandasによる時系列データ処理</title><link>https://pyvideo.org/pycon-japan-2016/pandasniyorushi-xi-lie-detachu-li.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;データ分析ライブラリであるpandasを利用して、時系列データのグループ化や集計、サンプリングなどの処理を簡単・高速に行う方法を説明します。また、統計解析パッケージであるstatsmodelsを用いて簡単な時系列モデリングを行います。&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;データ分析では売上データやログデータなどの時系列での傾向を分析したいことがあります。こういった時系列のデータについて、データ分析ライブラリであるpandasを利用してグループ化や集計、サンプリングなどの処理を簡単・高速に行う方法を説明します。pandasでは以下のような処理を少ないコード量で直感的に記述することができます。&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;日時文字列のパース処理&lt;/li&gt;
&lt;li&gt;適当な日時単位(年月, 四半期...)でのグループ化、集計&lt;/li&gt;
&lt;li&gt;サンプリング、フィルタ (移動平均など)&lt;/li&gt;
&lt;li&gt;タイムゾーン&lt;/li&gt;
&lt;li&gt;可視化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;また、API上の利便性と処理のパフォーマンスを両立するために行っているデータの内部表現と内部処理についてもご説明します。&lt;/p&gt;
&lt;p&gt;最後に、統計解析パッケージであるstatsmodelsを用いて簡単な時系列モデリングを行い、 時系列中のトレンドや季節性を抽出するとともに、将来の予測を行います。&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Masaaki Horikoshi</dc:creator><pubDate>Thu, 22 Sep 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-09-22:pycon-japan-2016/pandasniyorushi-xi-lie-detachu-li.html</guid><category>pandas</category></item><item><title>Build Data Apps by Deploying ML Models as API Services</title><link>https://pyvideo.org/pydata-san-francisco-2016/build-data-apps-by-deploying-ml-models-as-api-services.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData SF 2016
Ramesh Sampath | Build Data Apps by Deploying ML Models as API Services&lt;/p&gt;
&lt;p&gt;As data scientists, we love building models using IPython Notebooks / Scikit-Learn / Pandas eco-system. But integrating these models with an web app can be a challenge. In this tutorial, we will take our machine learning models and make them available as APIs for use by Web and Mobile Apps. We will also build a simple webapp that uses our prediction service.&lt;/p&gt;
&lt;p&gt;Deploy your ML Models as a Service&lt;/p&gt;
&lt;p&gt;In this talk, we will learn one way to take our Machine Learning models and make them available as a Prediction Service. We will work through the following steps.&lt;/p&gt;
&lt;p&gt;Create a Simple Machine learning Model using Scikit-Learn / Pandas
Pickle the model
Using Tornado Web App, Make this model available as an API Service
Build an Web App that uses this deployed Model
Add Authentication to our Prediction API
Optionally, add Redis to Cache Prediction Results
Deploy the model in the Cloud (AWS)
Please have Anaconda or Miniconda installed on your local machine. I will mostly be using Python 3.5, but Python 2.7 should be fine as well.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ramesh Sampath</dc:creator><pubDate>Wed, 24 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-24:pydata-san-francisco-2016/build-data-apps-by-deploying-ml-models-as-api-services.html</guid><category>tutorial</category><category>machine learning</category><category>scikit-learn</category><category>pandas</category><category>tornado</category></item><item><title>Pandas, Data Wrangling &amp; Data Science</title><link>https://pyvideo.org/pydata-san-francisco-2016/pandas-data-wrangling-data-science.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData SF 2016
Krishna Sankar | Pandas, Data Wrangling &amp;amp; Data Science&lt;/p&gt;
&lt;p&gt;Let us explore Pandas from a Data Science perspective, mainly data exploration &amp;amp; feature extraction. In the process we will also ponder Data Science pragmas. We start with Pandas fundamentals and then move on to analyzing datasets. If you want to follow along, have a working iPython, download the notebooks at &lt;a class="reference external" href="https://github.com/xsankar/cautious-octo-waffle"&gt;https://github.com/xsankar/cautious-octo-waffle&lt;/a&gt; and the data. Run PreFlightCheck.ipynb.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Data Wrangling &amp;amp; Data Science Pipeline&lt;/li&gt;
&lt;li&gt;Pandas – APIs &amp;amp; Namespaces&lt;/li&gt;
&lt;li&gt;Pandas – Basic Maneuvers&lt;/li&gt;
&lt;li&gt;Hands-on : Titanic Dataset&lt;/li&gt;
&lt;li&gt;Pandas – Data Wrangling – Transformations, Aggregations &amp;amp; Join&lt;/li&gt;
&lt;li&gt;Hands-on : NW Dataset, State Of The Union Speeches &amp;amp; Debates, Recsys-2015 Data&lt;/li&gt;
&lt;li&gt;Q &amp;amp; A&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Krishna Sankar</dc:creator><pubDate>Wed, 24 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-24:pydata-san-francisco-2016/pandas-data-wrangling-data-science.html</guid><category>pandas</category></item><item><title>Networks meet Finance in Python</title><link>https://pyvideo.org/pydata-amsterdam-2016/networks-meet-finance-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2016&lt;/p&gt;
&lt;p&gt;Description&lt;/p&gt;
&lt;p&gt;I will talk about network models in finance, and walk through real data and very visual examples using the pydata toolset - pandas, bokeh, pandas, networkx, ipywidgets. Special focus will be given to correlation networks, with applications to market characterization and portfolio risk management (as done in Pozzi 2013) using the latest available market data.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;In the course of the 2008 Lehman and the subsequent European debt crisis, it became clear that both financial industry and regulators had underestimated the degree of interconnectedness and interdependency across financial assets and institutions. This type of information is especially well represented by network models, which had first gained popularity in computer science, biology and social sciences.&lt;/p&gt;
&lt;p&gt;The study of network models in finance is already providing insight into the structure of the financial world and the economy. Network models are proving to be useful tools for providing early-warning signals of systemic risk (e.g. Squartini 2013), measuring liquidity and concentration risk, identifying sectors from time-series correlations (e.g. Fenn 2011) as well as insights into finding diversified baskets of assets in the classical investment framework (e.g. Pozzi 2013).&lt;/p&gt;
&lt;p&gt;I will provide an overview of some of the aforementioned work, and walk through (real data) examples using the pydata toolset. Special focus will be given to the study of correlation networks, with applications to portfolio risk management as in (Pozzi 2013) using the latest available market data. The examples make heavy use of pandas, bokeh, pandas, networkx, ipywidgets.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Miguel Vaz</dc:creator><pubDate>Sat, 26 Mar 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-03-26:pydata-amsterdam-2016/networks-meet-finance-in-python.html</guid><category>pandas</category><category>bokeh</category><category>networkx</category><category>ipywidgets</category></item><item><title>Pandas: from bdate_range to wide_to_long</title><link>https://pyvideo.org/pydata-amsterdam-2016/pandas-from-bdate_range-to-wide_to_long.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2016&lt;/p&gt;
&lt;p&gt;The notebook can be found at &lt;a class="reference external" href="http://s.lanzani.nl/pydataamsterdam"&gt;http://s.lanzani.nl/pydataamsterdam&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Description&lt;/p&gt;
&lt;p&gt;In this tutorial we will walk through the most useful pandas features with examples and exercises. The tutorial will assume some basic Python knowledge.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;In this tutorial we will walk through the most useful pandas features with examples and exercises. We will take a look at:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Series&lt;/li&gt;
&lt;li&gt;Dataframes&lt;/li&gt;
&lt;li&gt;(Re)Indexing&lt;/li&gt;
&lt;li&gt;Dropping data&lt;/li&gt;
&lt;li&gt;Adding data&lt;/li&gt;
&lt;li&gt;Filtering&lt;/li&gt;
&lt;li&gt;Apply functions to dataframes&lt;/li&gt;
&lt;li&gt;Missing data&lt;/li&gt;
&lt;li&gt;Merge and combine&lt;/li&gt;
&lt;li&gt;Stacking and unstacking&lt;/li&gt;
&lt;li&gt;Replacing values&lt;/li&gt;
&lt;li&gt;Binary decomposition&lt;/li&gt;
&lt;li&gt;Plotting&lt;/li&gt;
&lt;li&gt;Data aggregation&lt;/li&gt;
&lt;li&gt;Quantile bucket analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;During the tutorial we will decide how many exercises to fit. The students will get the notebook if time won't be enough to cover everything.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Giovanni Lanzani</dc:creator><pubDate>Sat, 26 Mar 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-03-26:pydata-amsterdam-2016/pandas-from-bdate_range-to-wide_to_long.html</guid><category>pandas</category></item><item><title>¡Eureka! (Python y ciencia)</title><link>https://pyvideo.org/pyday-galicia-2016/eureka-python-y-ciencia.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;En esta charla se plantea una pregunta de física básica que se resolverá científicamente con ingenio, mátemáticas y python, aprovechando para (de una manera amena) ver librerías habituales en el entorno científico como sympy, numpy, scipy, matplotlib, bokeh, numba, pandas y sklearn.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Miguel Sánchez de León Peque</dc:creator><pubDate>Sat, 17 Sep 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-09-17:pyday-galicia-2016/eureka-python-y-ciencia.html</guid><category>pyday</category><category>sympy</category><category>numpy</category><category>scipy</category><category>matplotlib</category><category>bokeh</category><category>numba</category><category>pandas</category><category>sklearn</category></item><item><title>Usando contenedores para Big Data</title><link>https://pyvideo.org/pycon-es-2015/usando-contenedores-para-big-data.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;En la actualidad existe una variedad bastante grande de contenedores de datos para almacenar grandes cantidades de datos en Python, tanto en memoria como en disco. En mi taller pasaremos revista a unos cuantos de los más útiles, empezando por los más básicos y generales (listas, diccionarios, NumPy/ndarray, pandas/DataFrames) a los más especializados (RDBMS, PyTables/Table/HDF5, bcolz/carray/ctable). Durante el camino se darán pistas de cuando usar unos u otros dependiendo del caso de uso.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Francesc Alted</dc:creator><pubDate>Tue, 02 Feb 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-02-02:pycon-es-2015/usando-contenedores-para-big-data.html</guid><category>workshop</category><category>big data</category><category>numpy</category><category>pandas</category><category>pytables</category><category>bcolz</category></item><item><title>A proof of concept Python toolkit for effective landscape fuel hazard management</title><link>https://pyvideo.org/pycon-au-2016/a-proof-of-concept-python-toolkit-for-effective-landscape-fuel-hazard-management.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Henry Walshaw
&lt;a class="reference external" href="https://2016.pycon-au.org/schedule/136/view_talk"&gt;https://2016.pycon-au.org/schedule/136/view_talk&lt;/a&gt;
Since the 2009 Victorian Bushfires there has been a major funding increase to allow fuel reduction burns in national parks in NSW. The first recommendation (Review of performance targets for bushfire fuel management on public land 2015) is that the government moves towards a risk reduction target rather than the current hectarue target. An evidentiary method of proposing burns based on ISO 31000 Risk management - principles and guidelines (2009) was built into a manual workflow using Esri's ArcGIS suite. The next step was to automate the process as much as possible. To do this we built a suite of tools using Python in ArcGIS and in Pandas. This meant that we could spend more time making sure our calculations were correct and we understood the data rather than spending time re-creating ways to read tables and perform calculations.&lt;/p&gt;
&lt;p&gt;In this talk we'll cover the suite of tools we built and a workflow for a user, and what this means for environmental policy in the department and NSW. We'll talk about ways we step between automation and using tools like Excel which our Environmental managers are very familiar with, but which don't always lend themselves to consistent input. And we'll talk about how building this suite not only does the calculations for us, but also records the metadata at every step along the trail, so we can provide evidence of how we made our decisions.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Henry Walshaw</dc:creator><pubDate>Mon, 15 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-15:pycon-au-2016/a-proof-of-concept-python-toolkit-for-effective-landscape-fuel-hazard-management.html</guid><category>ArcGIS</category><category>Pandas</category></item><item><title>Python at the Intersection of Data Science, Machine Learning &amp; Cyber Anomaly Detection</title><link>https://pyvideo.org/scipy-2016/python-at-the-intersection-of-data-science-machine-learning-cyber-anomaly-detection-scipy-2016.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will focus on the use of Python, scikit-learn, NumPy, SciPy, and pandas in Data Science and machine learning with a focus on cyber anomaly detection. The presentation will focus on how Python facilitates all stages of such analysis including data gathering, analytics, and scaling to large data sets.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Randy Paffenroth</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/python-at-the-intersection-of-data-science-machine-learning-cyber-anomaly-detection-scipy-2016.html</guid><category>scikit-learn</category><category>numpy</category><category>scipy</category><category>pandas</category></item><item><title>PyData: Data Analysis in Python with Pandas</title><link>https://pyvideo.org/pydata/pydata-data-analysis-in-python-with-pandas.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Coming from the 2012 PyData Workshop, Wes McKinney, CTO and cofounder of
Lambda Foundry, gives us a tour of Pandas, a rich data manipulation tool
built on top of NumPy. Frustrated with working in R, Wes started
building Pandas in 2008 with a focus on fast, intuitive data structures
and data manipulation capabilities. The Pandas project has seen huge
growth in the last few years, and aims to be the ultimate data tool for
Python.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Wes McKinney</dc:creator><pubDate>Fri, 30 Mar 2012 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2012-03-30:pydata/pydata-data-analysis-in-python-with-pandas.html</guid><category>numpy</category><category>pandas</category></item><item><title>PyGotham 2011: Powerful Pythonic data analysis using pandas</title><link>https://pyvideo.org/pygotham-2011/pygotham-2011--powerful-pythonic-data-analysis-us.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;In this talk I will give an overview on the pandas data analysis package
for Python, its features, and plans for future development. I'll use
various interesting data sets to illustrate the features and give
motivation for how the tools can be applied in a diverse set of fields.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Wes McKinney</dc:creator><pubDate>Fri, 16 Sep 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-09-16:pygotham-2011/pygotham-2011--powerful-pythonic-data-analysis-us.html</guid><category>dataanalysis</category><category>pandas</category><category>pygotham</category><category>pygotham2011</category></item><item><title>Beginner's Guide to Machine Learning Competitions</title><link>https://pyvideo.org/pytexas-2015/beginners-guide-to-machine-learning-competitions.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This tutorial will offer a hands-on introduction to machine learning and
the process of applying these concepts in a Kaggle competition. We will
introduce attendees to machine learning concepts, examples and flows,
while building up their skills to solve an actual problem. At the end of
the tutorial attendees will be familiar with a real data science flow:
feature preparation, modeling, optimization and validation.&lt;/p&gt;
&lt;p&gt;Packages used in the tutorial will include: IPython notebook,
scikit-learn, pandas and NLTK. We’ll use IPython notebook for
interactive exploration and visualization, in order to gain a basic
understanding of what’s in the data. From there, we’ll extract features
and train a model using scikit-learn. This will bring us to our first
submission. We’ll then learn how to structure the problem for offline
evaluation and use scikit-learn’s clean model API to train many models
simultaneously and perform feature selection and hyperparameter
optimization.&lt;/p&gt;
&lt;p&gt;At the end of session, attendees will have time to work on their own to
improve their models and make multiple submissions to get to the top of
the leaderboard, just like in a real competition. Hopefully attendees
will not only leave the tutorial having learned the core data science
concepts and flow, but also having had a great time doing it.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Christine Doig</dc:creator><pubDate>Fri, 09 Oct 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-10-09:pytexas-2015/beginners-guide-to-machine-learning-competitions.html</guid><category>tutorial</category><category>machine learning</category><category>nltk</category><category>pandas</category><category>scikit-learn</category><category>ipython</category></item><item><title>The Wonderful World of Scientific Computing with Python</title><link>https://pyvideo.org/scipy-2014/the-wonderful-world-of-scientific-computing-with.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;We will give an overview of the basics of the scientific computing
ecosystem with Python: what does each of the fundamental packages
(numpy, matplotlib, scipy, sympy and pandas) do, and how does it work?
We will use the IPython Notebook in our quest to enter this wonderful
world.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Starting out with scientific computing in Python can be daunting: Where
do I start? What are the basic packages, and what is the use case for
each of them? What are the fundamental ideas I need to understand each
package and how it works?&lt;/p&gt;
&lt;p&gt;In this tutorial, we will use examples of scientific questions and
calculations which lead directly to the need for certain computational
tools as a gateway to understand the basic structure of the scientific
computing ecosystem. The specific packages we will touch on are
&lt;tt class="docutils literal"&gt;numpy&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;matplotlib&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;scipy&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;sympy&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;pandas&lt;/tt&gt;, all
viewed through the wonderful lens of the IPython Notebook.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">David P. Sanders</dc:creator><pubDate>Wed, 09 Jul 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2014-07-09:scipy-2014/the-wonderful-world-of-scientific-computing-with.html</guid><category>matplotlib</category><category>numpy</category><category>pandas</category><category>scipy</category><category>sympy</category></item><item><title>Effiziente Datenanalyse mit pandas</title><link>https://pyvideo.org/pycon-de-2012/effiziente-datenanalyse-mit-pandas.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Datenanalyse ist eine der Kernaufgaben moderner Technologie. pandas
(vgl. &lt;a class="reference external" href="http://pandas.pydata.org"&gt;http://pandas.pydata.org&lt;/a&gt;) ist eine leistungsstarke
Python-Bibliothek, die die Möglichkeiten zur Datenanalyse mit
Python/NumPy/SciPy in viele Richtungen erweitert. Der Fokus liegt dabei
auf Convenience und Performance.&lt;/p&gt;
&lt;p&gt;Python in Kombination mit pandas macht Datenanalyse im Unternehmens- und
Forscheralltag effizient und kann z.T. sogar komplexe und
kostenintensive Business Intelligence-Lösungen ersetzen. Besondere
Stärken zeigen sich im Zeitreihenmanagement, was für viele Branchen und
Unternehmen eine immer höhere Bedeutung erlangt (z.B. Finanzbranche,
Energieversorger).&lt;/p&gt;
&lt;p&gt;Mit pandas werden die guten Datenanalysefähigkeiten von einer typischen
Python-Installation mit NumPy, SciPy etc. in vielerlei Hinsicht
erweitert, indem z.B. viele Eigenschaften und Features der statistischen
Sprache R in die Python-Welt portiert werden. Es ist dabei kein Ersatz
für Standard- Bibliotheken wie NumPy, sondern eine nützliche Erweiterung
mit viel &amp;quot;eingebauter Intelligenz&amp;quot; für die Datenanalyse.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dr. Yves J. Hilpisch</dc:creator><pubDate>Tue, 30 Oct 2012 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2012-10-30:pycon-de-2012/effiziente-datenanalyse-mit-pandas.html</guid><category>datenanalyse</category><category>pandas</category><category>zeitreihen</category></item><item><title>Python in quantitative finance (#158)</title><link>https://pyvideo.org/pycon-us-2010/python-in-quantitative-finance-158.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python in quantitative finance&lt;/p&gt;
&lt;p&gt;Presented by Wes McKinney (AQR Capital Management, LLC)&lt;/p&gt;
&lt;p&gt;This talk will show how Python and libraries such as NumPy were
instrumental at AQR for building a robust research platform for
prototyping and implementing quantitative trading models. We will
discuss many different tools, including pandas, a new open source
library designed for analyzing common financial and economic data sets.&lt;/p&gt;
&lt;p&gt;A variety of examples will be presented to explore Python's current
status as a replacement for other statistical computing environments (as
compared with R, MATLAB, or other commercial and open-source statistical
products).&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Wes McKinney</dc:creator><pubDate>Fri, 19 Feb 2010 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2010-02-19:pycon-us-2010/python-in-quantitative-finance-158.html</guid><category>numpy</category><category>pandas</category><category>pycon</category><category>pycon2010</category></item></channel></rss>