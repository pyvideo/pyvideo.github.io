<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Wed, 09 Oct 2019 00:00:00 +0000</lastBuildDate><item><title>Fighting fraud: finding duplicates at scale</title><link>https://pyvideo.org/pydata-berlin-2019/fighting-fraud-finding-duplicates-at-scale.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Speaker: Alexey Grigorev&lt;/p&gt;
&lt;p&gt;Track:PyData
We present a duplicate detection system that we use to fight fraud in online classifieds. The system uses machine learning to analyze both text and images of 10 million ads daily and stop fraudulent listings before they do any harm.&lt;/p&gt;
&lt;p&gt;Recorded at the PyConDE &amp;amp; PyData Berlin 2019 conference.
&lt;a class="reference external" href="https://pycon.de"&gt;https://pycon.de&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More details at the conference page: &lt;a class="reference external" href="https://de.pycon.org/program/7PHMWA"&gt;https://de.pycon.org/program/7PHMWA&lt;/a&gt;
Twitter:  &lt;a class="reference external" href="https://twitter.com/pydataberlin"&gt;https://twitter.com/pydataberlin&lt;/a&gt;
Twitter:  &lt;a class="reference external" href="https://twitter.com/pyconde"&gt;https://twitter.com/pyconde&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexey Grigorev</dc:creator><pubDate>Wed, 09 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-09:pydata-berlin-2019/fighting-fraud-finding-duplicates-at-scale.html</guid></item><item><title>Large Scale Vandalism Detection in Knowledge Bases</title><link>https://pyvideo.org/pydata-berlin-2017/large-scale-vandalism-detection-in-knowledge-bases.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Wikidata is a Knowledge Base where anybody can add new information. Unfortunately, it is targeted by vandals, who put inaccurate or offensive information there. To fight them, Wikidata employs moderators, who manually inspect each suggested edit. In this talk we will look into how we can use Machine Learning to automatically detect vandalic revisions and help the moderators.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Knowledge bases are an important source of information for many AI system: they rely on the bases for enriching the information they process to make better user experience. Obtaining such Knowledge Bases is difficult, and which is why this process is crowd-sourced. One of such bases is Wikidata: they allow everybody on the Internet to edit the content and add new information.&lt;/p&gt;
&lt;p&gt;Unfortunately, Wikidata is often targeted by vandals, who misuse the system and put false or offensive information there. This may lead to incorrect behaviour of the AI systems. To keep the base clean, Wikidata employs moderators who manually inspect each revision and revert vandalic ones.&lt;/p&gt;
&lt;p&gt;To help moderators fight vandals, the organizers of WSDM Cup 2017 challenged the participants to build a Machine Learning model which automatically detects if an edit should be rolled back. In this talk we will discuss the second place solution to the Cup: how to process half of terabyte of revisions, extract meaningful features and create a production ready model that scales to a large number of testing examples.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexey Grigorev</dc:creator><pubDate>Fri, 30 Jun 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-06-30:pydata-berlin-2017/large-scale-vandalism-detection-in-knowledge-bases.html</guid></item></channel></rss>