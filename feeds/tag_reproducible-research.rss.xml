<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Wed, 09 Jul 2014 00:00:00 +0000</lastBuildDate><item><title>A Common Scientific Compute Environment for Research and Education</title><link>https://pyvideo.org/scipy-2014/a-common-scientific-compute-environment-for-resea.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;I provide an overview of the challenges we’ve tackled at UC Berkeley
deploying scientific compute environments in both educational and
research contexts. After a discussion of how these needs can be served
by devops tools like Docker and Ansible, I argue that a coherent,
easy-to-understand philosophy around reproducible compute environments
is fundamental.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As the line between developer and researcher becomes ever more blurred,
the challenge of sharing your compute environment with students and
colleagues becomes ever more complex. Large, private organizations have
been grappling with this issue for a while, spawning a great deal of
enthusiasm around tools like Docker, Puppet, Vagrant, and Packer. And
let’s not forget notable python-based upstarts, Ansible and Salt! These
tools can generate immense enthusiasm, followed by the question, “Why
are we doing this?”&lt;/p&gt;
&lt;p&gt;The problem is that researcher / developers can become overwhelmed by
the complexity and variety inherent in devops tools - all the while
losing sight of the real reason for using these tools: a philosophy of
documenting your research compute environments in a reproducible
fashion, with a focus on scripting as much as is reasonable.&lt;/p&gt;
&lt;p&gt;At UC Berkeley, members of the D-Lab, the Statistical Compute Facility,
Computer Science and Research IT have organized a project to develop the
Berkeley Common Environment (BCE). I’ll provide an overview of the
challenges we’ve tackled in both educational and research contexts, and
the needs served by the above-mentioned devops tools. In the end, I
argue that a coherent, easy-to-understand philosophy around scientific
compute environments is fundamental - the tools are just a way to make
your collaboration architecture a little easier for the people building
these environments a few times a year. What we should focus on, though,
is end-user experience and research community buy-in.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dav Clark</dc:creator><pubDate>Wed, 09 Jul 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2014-07-09:scipy-2014/a-common-scientific-compute-environment-for-resea.html</guid><category>devops</category><category>reproducible research</category></item><item><title>Reproducible, Relocatable, Customizable Builds and Packaging with HashDist Part1</title><link>https://pyvideo.org/scipy-2014/reproducible-relocatable-customizable-builds-an.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;This talk introduces HashDist, a critical component of the scientific
software development workflow. HashDist enables highly customizable,
source-driven, and reproducible builds for scientific software stacks.
HashDist builds can be made relocatable, allowing the easy
redistribution of binaries on all three major operating systems as well
as cloud and supercomputing platforms.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Developing scientific software is a continuous balance between not
reinventing the wheel and getting fragile codes to interoperate with one
another. Binary software distributions such as Anaconda provide a robust
starting point for many scientific software packages, but this solution
alone is insufficient for many scientific software developers. HashDist
provides a critical component of the development workflow, enabling
highly customizable, source-driven, and reproducible builds for
scientific software stacks, available from both the IPython Notebook and
the command line.&lt;/p&gt;
&lt;p&gt;To address these issues, the Coastal and Hydraulics Laboratory at the US
Army Engineer Research and Development Center has funded the development
of HashDist in collaboration with Simula Research Laboratories and the
University of Texas at Austin. HashDist is motivated by a functional
approach to package build management, and features intelligent caching
of sources and builds, parametrized build specifications, and the
ability to interoperate with system compilers and packages. HashDist
enables the easy specification of &amp;quot;software stacks&amp;quot;, which allow both
the novice user to install a default environment and the advanced user
to configure every aspect of their build in a modular fashion. As an
advanced feature, HashDist builds can be made relocatable, allowing the
easy redistribution of binaries on all three major operating systems as
well as cloud, and supercomputing platforms. As a final benefit, all
HashDist builds are reproducible, with a build hash specifying exactly
how each component of the software stack was installed.&lt;/p&gt;
&lt;p&gt;This talk will feature an introduction to the problem of packaging
Python-based scientific software, a discussion of the basic tools
available to scientific Python developers, and a detailed discussion and
demonstration of the HashDist package build manager.&lt;/p&gt;
&lt;p&gt;The HashDist documentation is available from:
&lt;a class="reference external" href="http://hashdist.readthedocs.org/en/latest/"&gt;http://hashdist.readthedocs.org/en/latest/&lt;/a&gt; HashDist is currently hosted
at: &lt;a class="reference external" href="https://github.com/hashdist/hashdist"&gt;https://github.com/hashdist/hashdist&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andy Terrel</dc:creator><pubDate>Wed, 09 Jul 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2014-07-09:scipy-2014/reproducible-relocatable-customizable-builds-an.html</guid><category>packaging</category><category>reproducible research</category></item><item><title>Reproducible Science: Walking the Walk Part 1</title><link>https://pyvideo.org/scipy-2014/reproducible-science-walking-the-walk-part-1.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;This tutorial will train reproducible research warriors on the practices
and tools that make experimental verification possible with an
end-to-end data analysis workflow. &amp;nbsp;The tutorial will expose attendees
to open science methods during data gathering, storage, analysis up to
publication into a reproducible article. &amp;nbsp;Attendees are expected to have
basic familiarity with scientific Python and Git.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The tutorial will cover four hours with the following topics&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Introduction (10min)&lt;/li&gt;
&lt;li&gt;History of scientific societies and publications&lt;ul&gt;
&lt;li&gt;Leeuwenhoek was the Man !&lt;/li&gt;
&lt;li&gt;The Invisible College&lt;/li&gt;
&lt;li&gt;Nullius in Verba&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Replication of the early microscope experiments by Leeuwenhoek[a][b]&lt;/li&gt;
&lt;li&gt;Image Acquisition (15 min)&lt;ul&gt;
&lt;li&gt;Hands on: Cell camera phone microscope&lt;ul&gt;
&lt;li&gt;With drop of water&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hands on: Each pair acquires images&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data Sharing (45min)&lt;ul&gt;
&lt;li&gt;Image gathering, storage, and sharing (15min)&lt;ul&gt;
&lt;li&gt;GitHub (www.github.com)&lt;/li&gt;
&lt;li&gt;Figshare (www.figshare.com)&lt;/li&gt;
&lt;li&gt;Midas (www.midasplatform.com)&lt;/li&gt;
&lt;li&gt;Hands on: Upload the images&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Metadata Identifiers (15 min)&lt;ul&gt;
&lt;li&gt;Citable&lt;/li&gt;
&lt;li&gt;Machine Readable&lt;/li&gt;
&lt;li&gt;Hands on: Create data citation and machine readable metadata&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hands on: Download data via RESTful API (15min)&lt;ul&gt;
&lt;li&gt;Provenance and&lt;/li&gt;
&lt;li&gt;Python scripts&lt;/li&gt;
&lt;li&gt;Hands on: Download the data via HTTP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Break (10min)&lt;/li&gt;
&lt;li&gt;Local processing (60min)&lt;ul&gt;
&lt;li&gt;Replication Enablement (20min)&lt;ul&gt;
&lt;li&gt;Package versioning&lt;/li&gt;
&lt;li&gt;Virtual Machines&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;Cloud services&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Create a virtualenv&lt;/li&gt;
&lt;li&gt;Run our tutorial package verification script&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Revision Control with Git (20min)&lt;ul&gt;
&lt;li&gt;Keeping track of changes&lt;/li&gt;
&lt;li&gt;Unique hashes&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Forking a repository in GitHub&lt;/li&gt;
&lt;li&gt;Cloning a repository&lt;/li&gt;
&lt;li&gt;Creating a branch&lt;/li&gt;
&lt;li&gt;Making a commit&lt;/li&gt;
&lt;li&gt;Pushing a branch&lt;/li&gt;
&lt;li&gt;Diffing&lt;/li&gt;
&lt;li&gt;Merging&lt;/li&gt;
&lt;li&gt;Pushing again&lt;/li&gt;
&lt;li&gt;Create pull request&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Python scripts (20min)&lt;ul&gt;
&lt;li&gt;Data analysis, particle counting.&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Run scripts on new data&lt;/li&gt;
&lt;li&gt;Generate histogram for the data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Testing (30min)&lt;ul&gt;
&lt;li&gt;Unit testing with known data&lt;/li&gt;
&lt;li&gt;Regression testing with known data&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Run tests&lt;/li&gt;
&lt;li&gt;Add coverage for another method to the unit tests&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Break (10min)&lt;/li&gt;
&lt;li&gt;Publication Tools (30min)&lt;ul&gt;
&lt;li&gt;Article generation&lt;/li&gt;
&lt;li&gt;RST to HTML&lt;/li&gt;
&lt;li&gt;GitHub replication and sharing&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Run dexy to generate the document&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reproducibility Verification (30min)&lt;ul&gt;
&lt;li&gt;Reproducing Works&lt;/li&gt;
&lt;li&gt;Publication of Positive and Negative results&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Create Open Science Framework (OSF) project&lt;/li&gt;
&lt;li&gt;Connect Figshare and Github to OSF project&lt;/li&gt;
&lt;li&gt;Fork or link another group’s project in the OSF to run dexy on
their work&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Infrastructure:&lt;/p&gt;
&lt;p&gt;Attendees will use software installed in their laptops to gather and
process data, then publish and share a reproducible report.&lt;/p&gt;
&lt;p&gt;They will access repositories in GitHub, upload data to a repository and
publish materials necessary to replicate their data analysis.&lt;/p&gt;
&lt;p&gt;We expect that wireless network will be have moderate bandwidth to allow
all attendees to move data, source code and publications between their
laptops and hosting servers.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aashish Chaudhary</dc:creator><pubDate>Wed, 09 Jul 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2014-07-09:scipy-2014/reproducible-science-walking-the-walk-part-1.html</guid><category>open science</category><category>reproducible research</category><category>tutorial</category></item><item><title>Reproducible Science: Walking the Walk Part 2</title><link>https://pyvideo.org/scipy-2014/reproducible-science-walking-the-walk-part-2.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;This tutorial will train reproducible research warriors on the practices
and tools that make experimental verification possible with an
end-to-end data analysis workflow. &amp;nbsp;The tutorial will expose attendees
to open science methods during data gathering, storage, analysis up to
publication into a reproducible article. &amp;nbsp;Attendees are expected to have
basic familiarity with scientific Python and Git.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The tutorial will cover four hours with the following topics&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Introduction (10min)&lt;/li&gt;
&lt;li&gt;History of scientific societies and publications&lt;ul&gt;
&lt;li&gt;Leeuwenhoek was the Man !&lt;/li&gt;
&lt;li&gt;The Invisible College&lt;/li&gt;
&lt;li&gt;Nullius in Verba&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Replication of the early microscope experiments by Leeuwenhoek[a][b]&lt;/li&gt;
&lt;li&gt;Image Acquisition (15 min)&lt;ul&gt;
&lt;li&gt;Hands on: Cell camera phone microscope&lt;ul&gt;
&lt;li&gt;With drop of water&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hands on: Each pair acquires images&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data Sharing (45min)&lt;ul&gt;
&lt;li&gt;Image gathering, storage, and sharing (15min)&lt;ul&gt;
&lt;li&gt;GitHub (www.github.com)&lt;/li&gt;
&lt;li&gt;Figshare (www.figshare.com)&lt;/li&gt;
&lt;li&gt;Midas (www.midasplatform.com)&lt;/li&gt;
&lt;li&gt;Hands on: Upload the images&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Metadata Identifiers (15 min)&lt;ul&gt;
&lt;li&gt;Citable&lt;/li&gt;
&lt;li&gt;Machine Readable&lt;/li&gt;
&lt;li&gt;Hands on: Create data citation and machine readable metadata&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hands on: Download data via RESTful API (15min)&lt;ul&gt;
&lt;li&gt;Provenance and&lt;/li&gt;
&lt;li&gt;Python scripts&lt;/li&gt;
&lt;li&gt;Hands on: Download the data via HTTP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Break (10min)&lt;/li&gt;
&lt;li&gt;Local processing (60min)&lt;ul&gt;
&lt;li&gt;Replication Enablement (20min)&lt;ul&gt;
&lt;li&gt;Package versioning&lt;/li&gt;
&lt;li&gt;Virtual Machines&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;Cloud services&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Create a virtualenv&lt;/li&gt;
&lt;li&gt;Run our tutorial package verification script&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Revision Control with Git (20min)&lt;ul&gt;
&lt;li&gt;Keeping track of changes&lt;/li&gt;
&lt;li&gt;Unique hashes&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Forking a repository in GitHub&lt;/li&gt;
&lt;li&gt;Cloning a repository&lt;/li&gt;
&lt;li&gt;Creating a branch&lt;/li&gt;
&lt;li&gt;Making a commit&lt;/li&gt;
&lt;li&gt;Pushing a branch&lt;/li&gt;
&lt;li&gt;Diffing&lt;/li&gt;
&lt;li&gt;Merging&lt;/li&gt;
&lt;li&gt;Pushing again&lt;/li&gt;
&lt;li&gt;Create pull request&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Python scripts (20min)&lt;ul&gt;
&lt;li&gt;Data analysis, particle counting.&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Run scripts on new data&lt;/li&gt;
&lt;li&gt;Generate histogram for the data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Testing (30min)&lt;ul&gt;
&lt;li&gt;Unit testing with known data&lt;/li&gt;
&lt;li&gt;Regression testing with known data&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Run tests&lt;/li&gt;
&lt;li&gt;Add coverage for another method to the unit tests&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Break (10min)&lt;/li&gt;
&lt;li&gt;Publication Tools (30min)&lt;ul&gt;
&lt;li&gt;Article generation&lt;/li&gt;
&lt;li&gt;RST to HTML&lt;/li&gt;
&lt;li&gt;GitHub replication and sharing&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Run dexy to generate the document&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reproducibility Verification (30min)&lt;ul&gt;
&lt;li&gt;Reproducing Works&lt;/li&gt;
&lt;li&gt;Publication of Positive and Negative results&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Create Open Science Framework (OSF) project&lt;/li&gt;
&lt;li&gt;Connect Figshare and Github to OSF project&lt;/li&gt;
&lt;li&gt;Fork or link another group’s project in the OSF to run dexy on
their work&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Infrastructure:&lt;/p&gt;
&lt;p&gt;Attendees will use software installed in their laptops to gather and
process data, then publish and share a reproducible report.&lt;/p&gt;
&lt;p&gt;They will access repositories in GitHub, upload data to a repository and
publish materials necessary to replicate their data analysis.&lt;/p&gt;
&lt;p&gt;We expect that wireless network will be have moderate bandwidth to allow
all attendees to move data, source code and publications between their
laptops and hosting servers.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aashish Chaudhary</dc:creator><pubDate>Wed, 09 Jul 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2014-07-09:scipy-2014/reproducible-science-walking-the-walk-part-2.html</guid><category>open science</category><category>reproducible research</category><category>tutorial</category></item></channel></rss>