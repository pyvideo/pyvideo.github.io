<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Shandian Zhe</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_shandian-zhe.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-08-03T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Streaming Nonlinear Bayesian Tensor Decomposition</title><link href="https://pyvideo.org/uai-2020/streaming-nonlinear-bayesian-tensor-decomposition.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Zhimeng Pan</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/streaming-nonlinear-bayesian-tensor-decomposition.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Streaming Nonlinear Bayesian Tensor Decomposition&lt;/p&gt;
&lt;p&gt;Zhimeng Pan (University of Utah)*; Zheng Wang (University of Utah); Shandian Zhe (University of Utah)&lt;/p&gt;
&lt;p&gt;Despite the success of the recent nonlinear tensor decomposition models based on Gaussian processes (GPs), they lack an effective way to deal with streaming data, which are important for â€¦&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Streaming Nonlinear Bayesian Tensor Decomposition&lt;/p&gt;
&lt;p&gt;Zhimeng Pan (University of Utah)*; Zheng Wang (University of Utah); Shandian Zhe (University of Utah)&lt;/p&gt;
&lt;p&gt;Despite the success of the recent nonlinear tensor decomposition models based on Gaussian processes (GPs), they lack an effective way to deal with streaming data, which are important for many applications. Using the standard streaming variational Bayes framework or the recent streaming sparse GP approximations will lead to intractable model evidence lower bounds; although we can use stochastic gradient descent for incremental updates, they are unreliable and often yield poor estimations. To address this problem, we propose Streaming Nonlinear Bayesian Tensor Decomposition (SNBTD) that can conduct high-quality, closed-form and iteration-free updates upon receiving new tensor entries. Specifically, we use random Fourier features to build a sparse spectrum GP decomposition model to dispense with complex kernel/matrix operations and to ease posterior inference. We then extend the assumed-density-filtering framework by approximating all the data likelihoods in a streaming batch with a single factor to perform one-shot updates. We use conditional moment matching and Taylor approximations to fulfill efficient, analytical factor calculation. We show the advantage of our method on four real-world applications.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry></feed>