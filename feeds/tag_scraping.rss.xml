<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 11 May 2018 00:00:00 +0000</lastBuildDate><item><title>Scaping the web with Scrapy</title><link>https://pyvideo.org/python-frederick/scaping-the-web-with-scrapy.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At the November 2017 Python Frederick presentation, Micah showed the group how to get data from web pages using Scrapy. He explained the core pieces needed to work with Scrapy and demonstrated the tool by building a project that scraped content from a sample website.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Micah Nordland</dc:creator><pubDate>Thu, 09 Nov 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-11-09:python-frederick/scaping-the-web-with-scrapy.html</guid><category>scrapy</category><category>scraping</category></item><item><title>Beyond scraping: how to use machine learning when you're not sure where to start</title><link>https://pyvideo.org/pycon-us-2018/beyond-scraping-how-to-use-machine-learning-when-youre-not-sure-where-to-start.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Scraping one web site for information is easy, scraping 10000 different sites is hard. Beyond page-specific scraping, how do you build a program than can extract the publication date of (almost) any news article online, no matter the web site?&lt;/p&gt;
&lt;p&gt;We’ll cover when to use machine learning vs. humans or heuristics for data extraction, the different steps of how to phrase the problem in terms of machine learning, including feature selection on HTML documents, and issues that arise when turning research into production code.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Julie Lavoie</dc:creator><pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-05-11:pycon-us-2018/beyond-scraping-how-to-use-machine-learning-when-youre-not-sure-where-to-start.html</guid><category>scraping</category><category>machine learning</category></item><item><title>Open Data Dashboards &amp; Python Web Scraping</title><link>https://pyvideo.org/pydata-dc-2016/open-data-dashboards-python-web-scraping.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Distilling a world of data down to a few key indicators can be an effective way of keeping an audience informed, and this concept is at the heart of a good dashboard. This talk will cover a few methods of scraping and reshaping open data for dashboard visualization, to automate the boring stuff so you have more time and energy to focus on the analysis and content.&lt;/p&gt;
&lt;p&gt;This talk will cover a basic scenario of curating open data into visualizations for an audience. The main goal is to automate data scraping/downloading and reshaping. I use python to automate data gathering, and Tableau and D3 as visualization tools -- but the process can be applied to numerous analytical/visualization suites.&lt;/p&gt;
&lt;p&gt;I'll discuss situations where a dashboard makes sense (and when one doesn't). I will make a case also that automation makes for a more seamless data gathering and updating process, but not always for smarter data analysis.&lt;/p&gt;
&lt;p&gt;Some python packages I'll cover for web scraping and downloading/reshaping open data include: openpyxl, pandas, xlsxwriter, and BeautifulSoup. I'll also touch on APIs.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marie Whittaker</dc:creator><pubDate>Sun, 09 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-09:pydata-dc-2016/open-data-dashboards-python-web-scraping.html</guid><category>Data</category><category>scraping</category><category>web</category></item><item><title>Introduction to Web Scraping using Scrapy</title><link>https://pyvideo.org/pygotham-2016/introduction-to-web-scraping-using-scrapy.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you wanted to grab data from websites and automatically categorize it into a formatted list? Or maybe you want to opt out of registering for API keys and want data straight out of a web page? This is an introduction to web scraping and we will cover building bots through Scrapy to crawl a few sample web pages and have it extract information that we want. Prior knowledge not required; we’ll break down the steps in creating your own bot, and before you know it you'll be scraping the web.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kaira Villanueva</dc:creator><pubDate>Sun, 17 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-17:pygotham-2016/introduction-to-web-scraping-using-scrapy.html</guid><category>scraping</category><category>scrapy</category></item><item><title>Webscraping by Example: An introduction to BeautifulSoup</title><link>https://pyvideo.org/pygotham-2016/webscraping-by-example-an-introduction-to-beautifulsoup.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This is a basic tutorial on the various features of the popular html parser BeautifulSoup.  In this tutorial, we will cover the basic functions and data structures that make up the BeautifulSoup package.  We will utilize this knowledge as we automate some data extraction tasks on the Buildings Information System (BIS) published by the New York City Department of Buildings.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Stevie Slotterback</dc:creator><pubDate>Sat, 16 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-16:pygotham-2016/webscraping-by-example-an-introduction-to-beautifulsoup.html</guid><category>Scraping</category><category>BeautifulSoup</category></item><item><title>How Soon is Now: extracting publication dates with machine learning</title><link>https://pyvideo.org/pydata-san-francisco-2016/how-soon-is-now-extracting-publication-dates-with-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData SF 2016&lt;/p&gt;
&lt;p&gt;Scraping New York Times articles for publication dates is easy, scraping 10 000 different sites is hard. Beyond page-specific scraping, how do you build a parser than can extract the publication date of (almost) any news article online, no matter what the site is? We implemented a research paper in machine learning to solve this problem, and talk about the challenges we faced.&lt;/p&gt;
&lt;p&gt;We’ll cover when to use machine learning vs. humans or heuristics for data extraction, the different steps of how to phrase the problem in terms of machine learning, including feature selection on HTML documents, and issues that arise when turning research into production code. Data scientists and developers will leave knowing how to extract information from the web using new and more sophisticated techniques than simply writing a scraper.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Julie Lavoie</dc:creator><pubDate>Wed, 24 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-24:pydata-san-francisco-2016/how-soon-is-now-extracting-publication-dates-with-machine-learning.html</guid><category>scraping</category></item><item><title>Scraping from the Web: An Overview That Does Not Contain Too Much Cussing</title><link>https://pyvideo.org/chipy/scraping-with-python.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;A high level overview of how we did scraping at EveryBlock.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Feihong Hsu</dc:creator><pubDate>Fri, 15 Feb 2013 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2013-02-15:chipy/scraping-with-python.html</guid><category>scraping</category></item><item><title>Y'all Wanna Scrape with Us? Content Ain't a Thing : Web Scraping With Our Favorite Python Libraries</title><link>https://pyvideo.org/djangocon-us-2011/djangocon-2011--y--39-all-wanna-scrape-with-us--c.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Y'all Wanna Scrape with Us? Content Ain't a Thing: Web Scraping With Our
Favorite Python Libraries&lt;/p&gt;
&lt;p&gt;Presented by Katharine Jarmul&lt;/p&gt;
&lt;p&gt;Love or hate them, the top python scraping libraries have some hidden
gems and tricks that you can use to enhance, update and diversify your
Django models. This talk will teach you more advanced techniques to
aggregate content from RSS feeds, Twitter, Tumblr and normal old web
sites for your Django projects.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Katharine Jarmul</dc:creator><pubDate>Mon, 05 Sep 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-09-05:djangocon-us-2011/djangocon-2011--y--39-all-wanna-scrape-with-us--c.html</guid><category>djangocon</category><category>djangocon2011</category><category>lxml</category><category>scraping</category><category>web</category></item><item><title>Scraping Techniques to Extract Advertisements from Web Pages</title><link>https://pyvideo.org/europython-2011/scraping-techniques-to-extract-advertisements-fro.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Mirko Urru,Stefano Cotta Ramusino - 24 June 2011 in
&amp;quot;Track Tagliatelle &amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Online Advertising is an emerging research field, at the intersection of
Information Retrieval, Machine Learning, Optimization, and
Microeconomics. Its main goal is to choose the right ads to present to a
user engaged in a given task, such as Sponsored Search Advertising or
Contextual Advertising. The former puts ads on the page returned from a
Web search engine following a query. The latter puts ads within the
content of a generic, third party, Web page. The ads themselves are
selected and served by automated systems based on the content displayed
to the user.&lt;/p&gt;
&lt;p&gt;Web scraping is the set of techniques used to automatically get some
information from a website instead of manually copying it. In
particular, we're interested in studying and adopting scraping
techniques for: i. accessing tags as object members ii. finding out tags
whose name, contents or attributes match selection criteria iii.
accessing tag attributes by using a dictionary-like syntax.&lt;/p&gt;
&lt;p&gt;In this talk, we focus on the adoption of scraping techniques in the
contextual advertising field. In particular, we present a system aimed
at finding the most relevant ads for a generic web page p. Starting from
p, the system selects a set of its inlinks (i.e., the pages that link p)
and extracts the ads contained into them. Selection is performed
querying the Google search engine, whereas extraction is made by using
suitable scraping techniques.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mirko Urru</dc:creator><pubDate>Sun, 24 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-24:europython-2011/scraping-techniques-to-extract-advertisements-fro.html</guid><category>google</category><category>scraping</category><category>search</category><category>web</category></item><item><title>Robert Coup - /me wants it. Scraping sites to get data.</title><link>https://pyvideo.org/kiwi-pycon-2009/robert-coup----me-wants-it--scraping-sites-to-get.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;/me wants it. Scraping sites to get data.&lt;/p&gt;
&lt;p&gt;Presented by Robert Coup&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;Building scrapers for grabbing data from websites. Tools, techniques,
and tips.&lt;/p&gt;
&lt;p&gt;Outline&lt;/p&gt;
&lt;p&gt;Life would be so much easier if the data contained in websites was
available raw via APIs. Alas, until that mythical day comes we either
need to deal with unhelpful people via email and phone, or just get it
ourselves. Python has some great tools available to help with building
scrapers and for parsing and formatting the data we get. Starting off
with the basics - tracking what needs to be done, making web requests,
parsing HTML, following links, and extricating data from Excel and PDF
documents. Our scraper needs to be resilient against too-clever content
management systems, Frontpage-era HTML, and plain dodgy data. We may
need to pass through logins and other messiness. There are some
techniques and tips for approaching the problems and keeping your
solution flexible and as simple as possible. We'll discuss some scrapers
built for New Zealand data, and introduce a new project from the NZ open
government data group to provide a RESTful interface to scrapers -
effectively creating a nice API where there isn't one.&lt;/p&gt;
&lt;p&gt;Slides:
&lt;a class="reference external" href="http://www.slideshare.net/rcoup/me-wants-it-scraping-sites-to-get-data"&gt;http://www.slideshare.net/rcoup/me-wants-it-scraping-sites-to-get-
data&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[VIDEO HAS ISSUES: Sound and video are poor. Slides are hard to read.]&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Robert Coup</dc:creator><pubDate>Sat, 07 Nov 2009 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2009-11-07:kiwi-pycon-2009/robert-coup----me-wants-it--scraping-sites-to-get.html</guid><category>api</category><category>html</category><category>kiwipycon</category><category>kiwipycon2009</category><category>rest</category><category>scraping</category><category>web</category></item><item><title>PyCon 2009: Scrape the Web: Strategies for programming websites that don't expect it (Part 1 of 3)</title><link>https://pyvideo.org/pycon-us-2009/pycon-2009--scrape-the-web--strategies-for-progr0.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[VIDEO HAS ISSUES: Speaker walked away from the mic most of the time.]
Do you find yourself faced with websites that have data you need to
extract? Would your life be simpler if you could programmatically input
data into web applications, even those tuned to resist interaction by
bots? We'll discuss the basics of web scraping, and then dive into the
details of different methods and where they are most applicable. You'll
leave with an understanding of when to apply different tools, and learn
about a &amp;quot;heavy hammer&amp;quot; for screen scraping that I picked up at a project
for the Electronic Frontier Foundation. Atendees should bring a laptop,
if possible, to try the examples we discuss and optionally take notes.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Unknown</dc:creator><pubDate>Tue, 17 Feb 2009 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2009-02-17:pycon-us-2009/pycon-2009--scrape-the-web--strategies-for-progr0.html</guid><category>pycon</category><category>pycon2009</category><category>scraping</category></item><item><title>PyCon 2009: Scrape the Web: Strategies for programming websites that don't expect it (Part 3 of 3)</title><link>https://pyvideo.org/pycon-us-2009/pycon-2009--scrape-the-web--strategies-for-progr1.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[VIDEO HAS ISSUES: Speaker walked away from the mic most of the time.]
Do you find yourself faced with websites that have data you need to
extract? Would your life be simpler if you could programmatically input
data into web applications, even those tuned to resist interaction by
bots? We'll discuss the basics of web scraping, and then dive into the
details of different methods and where they are most applicable. You'll
leave with an understanding of when to apply different tools, and learn
about a &amp;quot;heavy hammer&amp;quot; for screen scraping that I picked up at a project
for the Electronic Frontier Foundation. Atendees should bring a laptop,
if possible, to try the examples we discuss and optionally take notes.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Unknown</dc:creator><pubDate>Tue, 17 Feb 2009 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2009-02-17:pycon-us-2009/pycon-2009--scrape-the-web--strategies-for-progr1.html</guid><category>pycon</category><category>pycon2009</category><category>scraping</category></item><item><title>PyCon 2009: Scrape the Web: Strategies for programming websites that don't expect it (Part 2 of 3)</title><link>https://pyvideo.org/pycon-us-2009/pycon-2009--scrape-the-web--strategies-for-progra.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[VIDEO HAS ISSUES: Speaker walked away from the mic most of the time.]
Do you find yourself faced with websites that have data you need to
extract? Would your life be simpler if you could programmatically input
data into web applications, even those tuned to resist interaction by
bots? We'll discuss the basics of web scraping, and then dive into the
details of different methods and where they are most applicable. You'll
leave with an understanding of when to apply different tools, and learn
about a &amp;quot;heavy hammer&amp;quot; for screen scraping that I picked up at a project
for the Electronic Frontier Foundation. Atendees should bring a laptop,
if possible, to try the examples we discuss and optionally take notes.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Unknown</dc:creator><pubDate>Tue, 17 Feb 2009 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2009-02-17:pycon-us-2009/pycon-2009--scrape-the-web--strategies-for-progra.html</guid><category>pycon</category><category>pycon2009</category><category>scraping</category></item><item><title>Dealing with unsightly data in the real world. (#156)</title><link>https://pyvideo.org/pycon-us-2010/pycon-2010--dealing-with-unsightly-data-in-the-re.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dealing with unsightly data in the real world&lt;/p&gt;
&lt;p&gt;Presented by Alexander Dutton&lt;/p&gt;
&lt;p&gt;Drawing on experiences writing &lt;a class="reference external" href="http://m.ox.ac.uk/"&gt;http://m.ox.ac.uk/&lt;/a&gt;, we'll explore the art
of getting data out of unhelpful systems. We'll start with working out
how to interact with a system, move on to techniques for parsing the
data it gives you, and round off by implementing a shinier interface
over the top.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexander Dutton</dc:creator><pubDate>Fri, 19 Feb 2010 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2010-02-19:pycon-us-2010/pycon-2010--dealing-with-unsightly-data-in-the-re.html</guid><category>pycon</category><category>pycon2010</category><category>scraping</category><category>web</category></item><item><title>Scrape the Web: Strategies for programming websites that don't expect it</title><link>https://pyvideo.org/pycon-us-2010/pycon-2010--scrape-the-web--strategies-for-progra.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;We'll discuss the basics of web scraping, and then dive into the details
of different methods and where they are most applicable. You'll leave
with an understanding of when to apply different tools, and learn about
automating a full web browser, a &amp;quot;heavy hammer&amp;quot; that I picked up at a
project for the Electronic Frontier Foundation.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Scrape the Web: Strategies for programming websites that don't expect it&lt;/p&gt;
&lt;p&gt;Presented by Asheesh Laroia&lt;/p&gt;
&lt;p&gt;Do you find yourself faced with websites that have data you need to
extract? Would your life be simpler if you could programmatically input
data into web applications, even those tuned to resist interaction by
bots?&lt;/p&gt;
&lt;p&gt;Year by year, the web is becoming a stronger force. Learn how to get the
best of it.&lt;/p&gt;
&lt;p&gt;We'll discuss the basics of web scraping, and then dive into the details
of different methods and where they are most applicable. You'll leave
with an understanding of when to apply different tools, and learn about
automating a full web browser, a &amp;quot;heavy hammer&amp;quot; that I picked up at a
project for the Electronic Frontier Foundation.&lt;/p&gt;
&lt;p&gt;Atendees should bring a laptop, if possible, to try the examples we
discuss and optionally take notes. Code samples will be made available
after class with no restrictions. Intended Audience&lt;/p&gt;
&lt;p&gt;Intermediate (or better) Python programmers, probably without extensive
web testing experience&lt;/p&gt;
&lt;p&gt;Class Outline&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;My motto: &amp;quot;The website is the API.&amp;quot;&lt;/li&gt;
&lt;li&gt;Choosing a parser: BeautifulSoup, lxml, HTMLParse, and html5lib.&lt;/li&gt;
&lt;li&gt;Extracting information, even in the face of bad HTML: Regular
expressions, BeautifulSoup, SAX, and XPath.&lt;/li&gt;
&lt;li&gt;Automatic template reverse-engineering tools.&lt;/li&gt;
&lt;li&gt;Submitting to forms.&lt;/li&gt;
&lt;li&gt;Playing with XML-RPC&lt;/li&gt;
&lt;li&gt;DO NOT BECOME AN EVIL COMMENT SPAMMER.&lt;/li&gt;
&lt;li&gt;Countermeasures, and circumventing them:&lt;ul&gt;
&lt;li&gt;IP address limits&lt;/li&gt;
&lt;li&gt;Hidden form fields&lt;/li&gt;
&lt;li&gt;User-agent detection&lt;/li&gt;
&lt;li&gt;JavaScript&lt;/li&gt;
&lt;li&gt;CAPTCHAs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Plenty of full source code to working examples:&lt;ul&gt;
&lt;li&gt;Submitting to forms for text-to-speech.&lt;/li&gt;
&lt;li&gt;Downloading music from web stores.&lt;/li&gt;
&lt;li&gt;Automating Firefox with Selenium RC to navigate a pure-JavaScript
service.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Q&amp;amp;A; and workshopping&lt;/li&gt;
&lt;li&gt;Use your power for good, not evil.&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Asheesh Laroia</dc:creator><pubDate>Fri, 19 Feb 2010 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2010-02-19:pycon-us-2010/pycon-2010--scrape-the-web--strategies-for-progra.html</guid><category>pycon</category><category>pycon2010</category><category>scraping</category><category>web</category></item></channel></rss>