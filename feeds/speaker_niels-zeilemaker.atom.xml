<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_niels-zeilemaker.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-05-26T00:00:00+00:00</updated><entry><title>Super Donkey Cars</title><link href="https://pyvideo.org/pydata-amsterdam-2018/super-donkey-cars.html" rel="alternate"></link><published>2018-05-26T00:00:00+00:00</published><updated>2018-05-26T00:00:00+00:00</updated><author><name>Niels Zeilemaker</name></author><id>tag:pyvideo.org,2018-05-26:pydata-amsterdam-2018/super-donkey-cars.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A Donkey car is an open source DIY self driving platform powered by a Raspberry Pi running a Deep Learning network. In this talk we'll go into how we modified the platform to retrain the Deep Learning network on a AWS GPU instance.&lt;/p&gt;
</summary></entry><entry><title>Deploying Python models to production</title><link href="https://pyvideo.org/pydata-amsterdam-2017/deploying-python-models-to-production.html" rel="alternate"></link><published>2017-04-09T00:00:00+00:00</published><updated>2017-04-09T00:00:00+00:00</updated><author><name>Niels Zeilemaker</name></author><id>tag:pyvideo.org,2017-04-09:pydata-amsterdam-2017/deploying-python-models-to-production.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2017&lt;/p&gt;
&lt;p&gt;Deploying models to production can sometimes be more difficult than developing the model itself. In this talk we'll explain how we deploy our Pandas/Scikit machine learning models to production using Flask, Docker, and Kubernetes. Moreover, we'll describe the CI process which automated away all the manual steps which were required.&lt;/p&gt;
&lt;p&gt;By using an internally developed framework, we allowed Data Scientists to develop models which can easily be deployed to production. The framework exposes models either over HTTP (REST) or binds them to a Kafka topic. Additionally, the framework packages the model and its dependencies in a Docker container, and generates all deployment templates required for deploying to Kubernetes. Finally, we'll describe our Jenkins jobs which automated away all the manual steps.&lt;/p&gt;
</summary></entry><entry><title>Embarrassingly parallel database calls with Python</title><link href="https://pyvideo.org/pydata-paris-2015/embarrassingly-parallel-database-calls-with-pytho.html" rel="alternate"></link><published>2015-04-14T00:00:00+00:00</published><updated>2015-04-14T00:00:00+00:00</updated><author><name>Niels Zeilemaker</name></author><id>tag:pyvideo.org,2015-04-14:pydata-paris-2015/embarrassingly-parallel-database-calls-with-pytho.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever squeezed you SQL queries to the last millisecond, but
still found yourself with not enough speed in your data­driven Python
applications? Then this talk is for you. We’ll look at how to shard your
data, which design changes should happen and how to use the Python
threading module to bring in the data as quickly as possible by making
parallel database calls.&lt;/p&gt;
&lt;p&gt;Expected audience: Python developers building real­time applications
needing increase their response time.&lt;/p&gt;
</summary></entry></feed>