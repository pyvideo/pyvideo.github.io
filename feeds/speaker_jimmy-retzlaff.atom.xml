<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_jimmy-retzlaff.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2011-03-11T00:00:00+00:00</updated><entry><title>mrjob: Distributed Computing for Everyone</title><link href="https://pyvideo.org/pycon-us-2011/pycon-2011--mrjob--distributed-computing-for-ever.html" rel="alternate"></link><published>2011-03-11T00:00:00+00:00</published><updated>2011-03-11T00:00:00+00:00</updated><author><name>Jimmy Retzlaff</name></author><id>tag:pyvideo.org,2011-03-11:pycon-us-2011/pycon-2011--mrjob--distributed-computing-for-ever.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;mrjob: Distributed Computing for Everyone&lt;/p&gt;
&lt;p&gt;Presented by Jimmy Retzlaff&lt;/p&gt;
&lt;p&gt;Have tons of data that needs analysis? Now it's as easy as 1-2-3! 1)
Sign up for an Amazon Web Services account. 2) Install Yelp's mrjob. 3)
Write as few as a dozen lines of Python code. This talk will show you
how to use mrjob and Amazon's Elastic MapReduce to easily process lots
of data in parallel on a potentially large cluster of computers that you
can rent for a dime per computer per hour.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;In their 2004 paper, Google outlined MapReduce - one of the programming
models they use to process large data sets. MapReduce is a relatively
simple model to develop for that allows the underlying framework to
automatically parallelize the job, add fault tolerance, and scale the
job to many commodity computers.&lt;/p&gt;
&lt;p&gt;In 2009, Amazon Web Services introduced their Elastic MapReduce (EMR)
product. It layers the Hadoop open source package on top of their
Elastic Compute Cloud (EC2) to allow anyone to rent a cluster of
computers by the hour, starting at about a dime per computer per hour,
in order to run MapReduce jobs.&lt;/p&gt;
&lt;p&gt;Some of the significant issues with Amazon's solution involve starting
up machine instances, replicating your code and its dependancies to EMR,
running and monitoring the job, and gathering the results.&lt;/p&gt;
&lt;p&gt;So Yelp developed mrjob, which takes care of these details and lets the
developer focus on working with their data. Yelp uses mrjob to power
many internal jobs that work with its very large log files, for example:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;People Who Viewed This Also Viewed...&lt;/li&gt;
&lt;li&gt;A user clicked an ad over and over, but we only want to charge the
advertiser once&lt;/li&gt;
&lt;li&gt;We're thinking of a change, but want to simulate how that will affect
ad revenue&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now you can use that same power with just a few lines of Python.&lt;/p&gt;
&lt;p&gt;Useful links:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Install mrjob: sudo easy_install mrjob&lt;/li&gt;
&lt;li&gt;Documentation: &lt;a class="reference external" href="http://packages.python.org/mrjob/"&gt;http://packages.python.org/mrjob/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;PyPI: &lt;a class="reference external" href="http://pypi.python.org/pypi/mrjob"&gt;http://pypi.python.org/pypi/mrjob&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Development is hosted at github: &lt;a class="reference external" href="http://github.com/Yelp/mrjob"&gt;http://github.com/Yelp/mrjob&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="distributed"></category><category term="distributedcomputing"></category><category term="mrjob"></category><category term="pycon"></category><category term="pycon2011"></category></entry></feed>