<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_stephanie-kim.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-05-11T00:00:00+00:00</updated><entry><title>Exploring Deep Learning Framework PyTorch</title><link href="https://pyvideo.org/pycon-us-2018/exploring-deep-learning-framework-pytorch.html" rel="alternate"></link><published>2018-05-11T00:00:00+00:00</published><updated>2018-05-11T00:00:00+00:00</updated><author><name>Stephanie Kim</name></author><id>tag:pyvideo.org,2018-05-11:pycon-us-2018/exploring-deep-learning-framework-pytorch.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Anyone who is interested in deep learning has gotten their hands dirty playing around with Tensorflow, Google's open source deep learning framework. Tensorflow has its benefits like wide scale adoption, deployment on mobile, and support for distributed computing, but it also has a somewhat challenging learning curve, is difficult to debug, and hard to deploy in production. PyTorch is a new deep learning framework that solves a lot of those problems.&lt;/p&gt;
&lt;p&gt;PyTorch is only in beta, but users are rapidly adopting this modular deep learning framework. PyTorch supports tensor computation and dynamic computation graphs that allow you to change how the network behaves on the fly unlike static graphs that are used in frameworks such as Tensorflow. PyTorch offers modularity which enhances the ability to debug or see within the network and for many, is more intuitive to learn than Tensorflow.&lt;/p&gt;
&lt;p&gt;This talk will objectively look at PyTorch and why it might be the best fit for your deep learning use case and we'll look at use cases that will showcase why you might want consider using Tensorflow instead.&lt;/p&gt;
</summary><category term="pytorch"></category></entry><entry><title>Racial Bias in Facial Recognition Software</title><link href="https://pyvideo.org/pycascades-2018/racial-bias-in-facial-recognition-software.html" rel="alternate"></link><published>2018-01-22T00:00:00+00:00</published><updated>2018-01-22T00:00:00+00:00</updated><author><name>Stephanie Kim</name></author><id>tag:pyvideo.org,2018-01-22:pycascades-2018/racial-bias-in-facial-recognition-software.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will cover the basics of facial recognition and the importance of having diverse datasets when building out a model. We’ll explore racial bias in datasets using real world examples and cover a use case for developing an OpenFace model for a celebrity look-a-like app.&lt;/p&gt;
</summary></entry><entry><title>How to be a 10x Data Scientist</title><link href="https://pyvideo.org/pydata-seattle-2017/how-to-be-a-10x-data-scientist.html" rel="alternate"></link><published>2017-07-06T00:00:00+00:00</published><updated>2017-07-06T00:00:00+00:00</updated><author><name>Stephanie Kim</name></author><id>tag:pyvideo.org,2017-07-06:pydata-seattle-2017/how-to-be-a-10x-data-scientist.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Knowing the difference between your logistic and linear regression models or knowing how to train a model using a CNN won't make you a 10x data scientist, but there are other tips and tricks to becoming an even greater commodity to your employer than you already are. Bringing ideas from the developer community, I'll cover what you can do to increase productivity and level up your career.&lt;/p&gt;
&lt;p&gt;Using basic principles from the world of software development, this talk will cover ideas on how to become a more productive data scientist. This includes common principles such as not reinventing the wheel by using API's and libraries instead of writing your own code, writing tests to future-proof your code and be your own QA, how to make your models available to team members regardless of what language they use, how to write your code for production, versioning and automation.&lt;/p&gt;
&lt;p&gt;Data scientists will take away how they can become a 10x developer and increase their value and write better code by leveraging software developers common best practices.&lt;/p&gt;
</summary></entry><entry><title>Investigating User Experience with Natural Language Analysis</title><link href="https://pyvideo.org/pydata-seattle-2015/investigating-user-experience-with-natural-language-analysis.html" rel="alternate"></link><published>2015-07-25T00:00:00+00:00</published><updated>2015-07-25T00:00:00+00:00</updated><author><name>Stephanie Kim</name></author><id>tag:pyvideo.org,2015-07-25:pydata-seattle-2015/investigating-user-experience-with-natural-language-analysis.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk focuses on the methodology and intent of studying feedback form data using Python tools and libraries for natural language processing and machine learning analysis. I will discuss potential trouble areas of starting such a project from scratch from a developer’s perspective. This will include the type of analysis that might be helpful in discerning user experience and what analysis that you run, but might end up tossing out at the end due to lack of insight on your data. For instance, what is the value of running a K-Means cluster analysis and does it offer substantial actionable insights for textual content? And how much data do you need to pre-label for a training set for a Naïve Bayes Classification in order for it to be accurate? My intent is that people will walk away learning the basics of textual analysis and become motivated to help their users succeed in whatever tasks they are trying to accomplish through finding potential points of friction and even issues that spring up from changes in the design. This talk will be for developers or marketers who don’t have a lot or any experience in data analysis or machine learning.&lt;/p&gt;
</summary></entry><entry><title>Triaging Feedback Form Data</title><link href="https://pyvideo.org/pydata-dc-2016/triaging-feedback-form-data.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Stephanie Kim</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/triaging-feedback-form-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;This talk will cover how to use predictive modeling on unstructured text data including feedback form, social media or chat message data to triage issues in order to prevent future problems with a service, platform or user interface using NLP techniques in Python and R.&lt;/p&gt;
&lt;p&gt;Companies gain useful insights about their users from feedback form and other unstructured text data including live chat messages. Even though they are read and responded to, often such data is ignored when thinking about larger scale trend analysis and this can result in missed insight about how users react to a product or service. Sometimes analysis is being done by looking at changes in user sentiment or other heuristics, however it could be taken a step further by applying predictive modeling in attempt to recognize areas that need more attention and support. While you can use predictive modeling on network and log data, that is looking at how the hardware is handling your users requests, not how it's being perceived by users. By predicting areas where users are having difficulty whether it's with the UI or with the platform's response time you can triage these areas of concern to prevent future cases of negative perception. This talk will cover how to utilize common NLP tools used to gather and process the features in Python then will use R to perform trend analysis and predictive modeling then use the results to triage what areas should be focused on in the future.&lt;/p&gt;
</summary><category term="Data"></category></entry></feed>