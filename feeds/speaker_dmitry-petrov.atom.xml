<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_dmitry-petrov.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-12-05T00:00:00+00:00</updated><entry><title>Datasets and machine learning models versioning using open source tools</title><link href="https://pyvideo.org/pydata-la-2019/datasets-and-machine-learning-models-versioning-using-open-source-tools.html" rel="alternate"></link><published>2019-12-05T00:00:00+00:00</published><updated>2019-12-05T00:00:00+00:00</updated><author><name>Dmitry Petrov</name></author><id>tag:pyvideo.org,2019-12-05:pydata-la-2019/datasets-and-machine-learning-models-versioning-using-open-source-tools.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;AI and ML are becoming an essential part of software engineering. Open
source tools like Git, Git-LFS, MlFlow can increase ML teams
productivity by introducing best practices. However, large datasets
management and versioning are not covered by these tools. We will show
how to overcome the limitations of the tools by using DVC.org - an
open-source project for ML models and datasets versioning.&lt;/p&gt;
&lt;p&gt;AI and ML are becoming an essential part of software engineering. The
traditional engineering toolset does not fully cover machine learning
team's needs. The teams need new tools for data versioning, ML pipeline
versioning, ML model versioning, experiments metrics tracking, and
others.&lt;/p&gt;
&lt;p&gt;ML workflow is data-centric while software engineering workflow is
centered around source code. We will discuss the current practices of
organizing ML projects using open-source tools like Git, Git-LFS, MlFlow
as well as their limitations. Thereby motivation for developing new ML
specific data versioning systems will be explained.&lt;/p&gt;
&lt;p&gt;Data Version Control or DVC.ORG is an open-source command-line tool. We
will show how to version ML models and multi-gigabyte datasets, how to
use your favorite cloud storage (S3, Google Cloud Storage, or bare metal
SSH server) as a data file backend, how to apply the best engineering
practices to your ML projects and how to combine the different tools in
the same project.&lt;/p&gt;
</summary></entry><entry><title>Machine learning model and dataset versioning practices</title><link href="https://pyvideo.org/pycon-us-2019/machine-learning-model-and-dataset-versioning-practices.html" rel="alternate"></link><published>2019-05-04T10:50:00+00:00</published><updated>2019-05-04T10:50:00+00:00</updated><author><name>Dmitry Petrov</name></author><id>tag:pyvideo.org,2019-05-04:pycon-us-2019/machine-learning-model-and-dataset-versioning-practices.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python is a prevalent programming language in machine learning (ML)
community. A lot of Python engineers and data scientists feel the lack
of engineering practices like versioning large datasets and ML models,
and the lack of reproducibility. This lack is particularly acute for
engineers who just moved to ML space.&lt;/p&gt;
&lt;p&gt;We will discuss the current practices of organizing ML projects using
traditional open-source toolset like Git and Git-LFS as well as this
toolset limitation. Thereby motivation for developing new ML specific
version control systems will be explained.&lt;/p&gt;
&lt;p&gt;Data Version Control or &lt;a class="reference external" href="http://dvc.org"&gt;DVC.ORG&lt;/a&gt; is an &lt;a class="reference external" href="https://github.com/iterative/dvc"&gt;open
source&lt;/a&gt;, command-line tool written
in Python. We will show how to version datasets with dozens of gigabytes
of data and version ML models, how to use your favorite cloud storage
(S3, GCS, or bare metal SSH server) as a data file backend and how to
embrace the best engineering practices in your ML projects.&lt;/p&gt;
</summary><category term="talk"></category></entry><entry><title>Data versioning in machine learning projects</title><link href="https://pyvideo.org/pydata-berlin-2018/data-versioning-in-machine-learning-projects.html" rel="alternate"></link><published>2018-07-08T00:00:00+00:00</published><updated>2018-07-08T00:00:00+00:00</updated><author><name>Dmitry Petrov</name></author><id>tag:pyvideo.org,2018-07-08:pydata-berlin-2018/data-versioning-in-machine-learning-projects.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In machine learning projects it is easy to get lost in many versions of
your data files. Data Version Control or DVC is an open source tool for
data science projects that was created to solve the issue of discrepancy
between code and data files. It works on top of Git and helps you switch
between Git branches and extracts not only source code but a right
version of data files.&lt;/p&gt;
</summary></entry><entry><title>Reskit — A Library for Creating and Curating Reproducible Pipelines for Scientific Machine Learning</title><link href="https://pyvideo.org/scipy-2017/reskit-a-library-for-creating-and-curating-reproducible-pipelines-for-scientific-machine-learning.html" rel="alternate"></link><published>2017-07-17T00:00:00+00:00</published><updated>2017-07-17T00:00:00+00:00</updated><author><name>Dmitry Petrov</name></author><id>tag:pyvideo.org,2017-07-17:scipy-2017/reskit-a-library-for-creating-and-curating-reproducible-pipelines-for-scientific-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this work we introduce Reskit (researcher’s kit), a library for creating and curating reproducible pipelines for scientific machine learning. A natural extension of the Scikit Pipelines to general classes of pipelines, Reskit allows for the efficient and transparent optimization of each pipeline step. Its main features include data caching, compatibility with most of the scikit-learn objects, optimization constraints such as forbidden combinations, and table generation for quality metrics. Reskit’s design will be especially useful for researchers requiring pipeline versioning and reproducibility, while running large volumes of experiments.&lt;/p&gt;
&lt;p&gt;Link: &lt;a class="reference external" href="https://github.com/neuro-ml/reskit"&gt;https://github.com/neuro-ml/reskit&lt;/a&gt;&lt;/p&gt;
</summary><category term="reskit"></category><category term="machine learning"></category></entry></feed>