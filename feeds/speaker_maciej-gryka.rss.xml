<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Thu, 13 Jul 2017 00:00:00 +0000</lastBuildDate><item><title>Despicable machines: how computers can be assholes</title><link>https://pyvideo.org/europython-2017/despicable-machines-how-computers-can-be-assholes.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When working on a new ML solution to solve a given problem, do you
think that you are simply using objective reality to infer a set of
unbiased rules that will allow you to predict the future? Do you
think that worrying about the morality of your work is something
other people should do? If so, this talk is for you.&lt;/p&gt;
&lt;p&gt;In this brief time, I will try to convince you that you hold great
power over how the future world will look like and that you should
incorporate thinking about morality into the set of ML tools you use
every day. We will take a short journey through several problems,
which surfaced over the last few years, as ML and AI generally,
became more widely used. We will look at bias present in training
data, at some real-world consequences of not considering it
(including one or two hair-raising stories) and cutting-edge research
on how to counteract this.&lt;/p&gt;
&lt;p&gt;The outline of the talk is:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Intro the problem: ML algos can be biased!&lt;/li&gt;
&lt;li&gt;Two concrete examples.&lt;/li&gt;
&lt;li&gt;What's been done so far (i.e. techniques from recently-published papers).&lt;/li&gt;
&lt;li&gt;What to do next: unanswered questions.&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Maciej Gryka</dc:creator><pubDate>Thu, 13 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-13:europython-2017/despicable-machines-how-computers-can-be-assholes.html</guid></item><item><title>Removing Soft Shadows with Hard Data</title><link>https://pyvideo.org/pydata-berlin-2016/removing-soft-shadows-with-hard-data.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Description&lt;/p&gt;
&lt;p&gt;Find out how we used recent advances in photorealistic rendering and machine learning to teach a Random Forest how soft shadows look like. See how this model can then be used to to remove and modify shadows in RGB photographs with minimal user input.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;Manipulated images lose believability if the user's edits fail to account for shadows. We propose a method that makes removal and editing of soft shadows easy. Soft shadows are ubiquitous, but remain notoriously difficult to extract and manipulate. We posit that soft shadows can be segmented, and therefore edited, by learning a mapping function for image patches that generates shadow mattes. We validate this premise by removing soft shadows from photographs with only a small amount of user input.&lt;/p&gt;
&lt;p&gt;Given only broad user brush strokes that indicate the region to be processed, our new supervised regression algorithm automatically unshadows an image, removing the umbra and penumbra. The resulting lit image is frequently perceived as a believable shadow-free version of the scene. We tested the approach on a large set of soft shadow images, and performed a user study that compared our method to the state of the art and to real lit scenes. Our results are more difficult to identify as being altered, and are perceived as preferable compared to prior work.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Maciej Gryka</dc:creator><pubDate>Mon, 06 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-06-06:pydata-berlin-2016/removing-soft-shadows-with-hard-data.html</guid></item><item><title>Gotta catch'em all: recognizing sloppy work in crowdsourcing tasks</title><link>https://pyvideo.org/pydata-amsterdam-2016/gotta-catchem-all-recognizing-sloppy-work-in-crowdsourcing-tasks.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2016&lt;/p&gt;
&lt;p&gt;Description&lt;/p&gt;
&lt;p&gt;If you have ever used crowdsourcing, you know that dealing with sloppy workers is a major part of the effort. Come see this talk if you want to learn about how to solve this problem using machine learning and some elbow grease. As a bonus, you will also find out how to properly persist your ML models and use them to serve predictions through an HTTP API.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;In 2016 nobody needs convincing that crowdsourced work is a solution to many problems from data labeling, to gathering subjective opinions, to producing transcripts etc. Turns out it can also work really well for functional software testing - but it's not easy to get right.&lt;/p&gt;
&lt;p&gt;One well-known problem with crowdsourcing is sloppy work - where people perform only the absolute minimum actions allowing them to get paid, without actually fulfilling the intended tasks. In many scenarios this can be counteracted by asking multiple workers to complete the same task, but that dramatically increases cost and can still be error-prone. Detecting lazy work is another way to increase quality of gathered data and we have found a way to do this reliably for quite a large variety of tasks.&lt;/p&gt;
&lt;p&gt;In this talk I will describe how we have trained a machine learning model to discriminate between good and sloppy work. The outline is as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;describe the specific problem we had (5m)&lt;/li&gt;
&lt;li&gt;overview of the solution (2m)&lt;/li&gt;
&lt;li&gt;ML model details (10m)&lt;/li&gt;
&lt;li&gt;data capture&lt;/li&gt;
&lt;li&gt;labelling&lt;/li&gt;
&lt;li&gt;balancing the dataset&lt;/li&gt;
&lt;li&gt;feature engineering&lt;/li&gt;
&lt;li&gt;training, retraining&lt;/li&gt;
&lt;li&gt;model itself&lt;/li&gt;
&lt;li&gt;model persistence (10m)&lt;/li&gt;
&lt;li&gt;productizing the result by putting it behind an HTTP API (3m)&lt;/li&gt;
&lt;li&gt;limitations, trade-offs, what could we do better (3m)&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Maciej Gryka</dc:creator><pubDate>Sat, 26 Mar 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-03-26:pydata-amsterdam-2016/gotta-catchem-all-recognizing-sloppy-work-in-crowdsourcing-tasks.html</guid></item><item><title>Gotta catch'em all recognizing sloppy work in crowdsourcing tasks</title><link>https://pyvideo.org/pydata-london-2016/maciej-gryka-gotta-catchem-all-recognizing-sloppy-work-in-crowdsourcing-tasks.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData London 2016&lt;/p&gt;
&lt;p&gt;If you have ever used crowdsourcing, you know that dealing with sloppy workers is a major part of the effort. Come see this talk if you want to learn about how to solve this problem using machine learning and some elbow grease. As a bonus, you will also find out how to properly persist your ML models and use them to serve predictions through an HTTP API.&lt;/p&gt;
&lt;p&gt;In 2016 nobody needs convincing that crowdsourced work is a solution to many problems from data labeling, to gathering subjective opinions, to producing transcripts etc. Turns out it can also work really well for functional software testing - but it's not easy to get right.&lt;/p&gt;
&lt;p&gt;One well-known problem with crowdsourcing is sloppy work - where people perform only the absolute minimum actions allowing them to get paid, without actually fulfilling the intended tasks. In many scenarios this can be counteracted by asking multiple workers to complete the same task, but that dramatically increases cost and can still be error-prone. Detecting lazy work is another way to increase quality of gathered data and we have found a way to do this reliably for quite a large variety of tasks.&lt;/p&gt;
&lt;p&gt;In this talk I will describe how we have trained a machine learning model to discriminate between good and sloppy work. The outline is as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;describe the specific problem we had 5m&lt;/li&gt;
&lt;li&gt;overview of the solution 2m&lt;/li&gt;
&lt;li&gt;ML model details 10m&lt;/li&gt;
&lt;li&gt;data capture&lt;/li&gt;
&lt;li&gt;labelling&lt;/li&gt;
&lt;li&gt;balancing the dataset&lt;/li&gt;
&lt;li&gt;feature engineering&lt;/li&gt;
&lt;li&gt;training, retraining&lt;/li&gt;
&lt;li&gt;model itself&lt;/li&gt;
&lt;li&gt;model persistence 10m&lt;/li&gt;
&lt;li&gt;productizing the result by putting it behind an HTTP API 3m&lt;/li&gt;
&lt;li&gt;limitations, trade-offs, what could we do better 3m&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Slides available here: &lt;a class="reference external" href="https://docs.google.com/presentation/d/1ZY-VFCOh54LGfE5LVz4cIFpvizwdrqomb4-suNTKSZo/edit?usp=sharing"&gt;https://docs.google.com/presentation/d/1ZY-VFCOh54LGfE5LVz4cIFpvizwdrqomb4-suNTKSZo/edit?usp=sharing&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GitHub Repo: &lt;a class="reference external" href="https://github.com/rainforestapp/destimator"&gt;https://github.com/rainforestapp/destimator&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Maciej Gryka</dc:creator><pubDate>Wed, 11 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-05-11:pydata-london-2016/maciej-gryka-gotta-catchem-all-recognizing-sloppy-work-in-crowdsourcing-tasks.html</guid></item></channel></rss>