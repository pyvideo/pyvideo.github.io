<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Adonai Vera</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_adonai-vera.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2024-05-17T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Hackeando el Pensamiento: Traduciendo Señales Eléctricas del Cerebro en Acciones a través de Modelos LLM.</title><link href="https://pyvideo.org/pycon-us-2024/hackeando-el-pensamiento-traduciendo-senales-electricas-del-cerebro-en-acciones-a-traves-de-modelos-llm.html" rel="alternate"></link><published>2024-05-17T00:00:00+00:00</published><updated>2024-05-17T00:00:00+00:00</updated><author><name>Adonai Vera</name></author><id>tag:pyvideo.org,2024-05-17:/pycon-us-2024/hackeando-el-pensamiento-traduciendo-senales-electricas-del-cerebro-en-acciones-a-traves-de-modelos-llm.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;En esta charla única, demostraremos la increíble capacidad de &amp;quot;hackear&amp;quot;
el cerebro humano para interactuar con tecnologías avanzadas. Usando el
dispositivo Neurosity, capturaremos señales eléctricas cerebrales, que
luego serán interpretadas en Python para realizar acciones específicas.&lt;/p&gt;
&lt;p&gt;Este proceso comienza con la lectura de ondas cerebrales, utilizando un
clasificador para …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;En esta charla única, demostraremos la increíble capacidad de &amp;quot;hackear&amp;quot;
el cerebro humano para interactuar con tecnologías avanzadas. Usando el
dispositivo Neurosity, capturaremos señales eléctricas cerebrales, que
luego serán interpretadas en Python para realizar acciones específicas.&lt;/p&gt;
&lt;p&gt;Este proceso comienza con la lectura de ondas cerebrales, utilizando un
clasificador para convertirlas en comandos digitales. Por ejemplo,
mostraremos cómo estas señales pueden transformarse en la acción de
pedir una pizza. Esta demostración práctica resalta el potencial de
combinar neurotecnología con aplicaciones cotidianas.&lt;/p&gt;
&lt;p&gt;Luego, incorporaremos tecnología de voz a texto para convertir un
diálogo sobre pedir una pizza en una llamada telefónica real. Esta
integración multifacética ilustra la eficacia de Python en la unión de
distintas tecnologías en un flujo de trabajo coherente.&lt;/p&gt;
&lt;p&gt;Además, compartiremos insights y recomendaciones basadas en nuestra
experiencia en la implementación de estas tecnologías. Los participantes
obtendrán una comprensión detallada de cómo la interpretación de señales
cerebrales puede aplicarse en situaciones reales, abriendo nuevas
posibilidades en la interacción humano-máquina.&lt;/p&gt;
&lt;p&gt;Esta presentación es una ventana al futuro de la interacción
humano-computadora, destacando el poder transformador de la
neurotecnología y la inteligencia artificial en la vida diaria.&lt;/p&gt;
</content><category term="PyCon US 2024"></category></entry></feed>