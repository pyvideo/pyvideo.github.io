<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - scaling</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 03 Jun 2022 00:00:00 +0000</lastBuildDate><item><title>Scaling Django Web Applications</title><link>https://pyvideo.org/djangocon-us-2009/djangocon-2009--scaling-django-web-applications.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mike Malone</dc:creator><pubDate>Thu, 10 Sep 2009 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2009-09-10:/djangocon-us-2009/djangocon-2009--scaling-django-web-applications.html</guid><category>DjangoCon US 2009</category><category>djangocon</category><category>djangocon2009</category><category>scaling</category></item><item><title>Alice in Performanceland -- Down the Rabbit Hole with Frank Wiles</title><link>https://pyvideo.org/djangocon-us-2010/djangocon-2010--alice-in-performanceland----down-.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While pre-optimization is often the root of all evil, knowing how to
think about performance and scalability are important skills for any
geek. Learn about all the knobs you didn't know you could or should
tweak.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;Code profiling and dealing with your database aren't the only places to
find performance gains. Performance and scalability are holistic
endeavors.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Frank Wiles</dc:creator><pubDate>Thu, 09 Sep 2010 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2010-09-09:/djangocon-us-2010/djangocon-2010--alice-in-performanceland----down-.html</guid><category>DjangoCon US 2010</category><category>djangocon</category><category>djangocon2010</category><category>optimization</category><category>performance</category><category>scaling</category></item><item><title>Best Practices for Python in the Cloud</title><link>https://pyvideo.org/europython-2011/best-practices-for-python-in-the-cloud.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Gisle Aas - 21 June 2011 in &amp;quot;Track Lasagne&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Abstract: Whether you’re an independent developer or development manager
in a large company, “the cloud” is on everyone’s mind. But just because
it’s in the cloud, doesn’t mean development and deployment is
effortless. The cloud presents infrastructure and development challenges
in a new way.&lt;/p&gt;
&lt;p&gt;In this presentation, ActiveState's Gisle Aas will share best practices
in building and deploying a Python-centric LAMP stack(s) on the cloud
for a range of web-based applications from simple Django site to HPC GPU
Clusters.&lt;/p&gt;
&lt;p&gt;Based on ActiveState’s experiences, Gisle will discuss the challenges
faced and lessons learned in building an infrastructure to deploy web
applications to the cloud with Python.&lt;/p&gt;
&lt;p&gt;You will learn about:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Which packages are critical for a secure, Python-centric LAMP stack
(and what it takes to build them)!&lt;/li&gt;
&lt;li&gt;Tips for developing, deploying, and scaling Python applicaitons in
the cloud&lt;/li&gt;
&lt;li&gt;How to use Python to connect and build infrastructure to support and
manage your deployment&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Gisle Aas</dc:creator><pubDate>Mon, 18 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-18:/europython-2011/best-practices-for-python-in-the-cloud.html</guid><category>EuroPython 2011</category><category>cloud</category><category>deploy</category><category>deployment</category><category>django</category><category>gpu</category><category>hpc</category><category>infrastructure</category><category>lamp</category><category>packages</category><category>scaling</category><category>web</category></item><item><title>Building Data Workflows with Luigi and Kubernetes</title><link>https://pyvideo.org/europython-2019/building-data-workflows-with-luigi-and-kubernetes.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will focus on how one can build complex data pipelines in
Python. I will introduce Luigi and show how it solves problems while
running multiple chain of batch jobs like dependency resolution,
workflow management, visualisation, failure handling etc.&lt;/p&gt;
&lt;p&gt;After that, I will present how to package Luigi pipelines as Docker
image for easier testing and deployment. Finally, I will go through way
to deploy them on Kubernetes cluster, thus making it possible to scale
Big Data pipelines on- demand and reduce infrastructure costs. I will
also give tips and tricks to make Luigi Scheduler play well with
Kubernetes batch execution feature.&lt;/p&gt;
&lt;p&gt;This talk will be accompanied by demo project. It will be very
beneficial for audience who have some experience in running batch jobs
(not necessarily in Python), typically people who work in Big Data
sphere like data scientists, data engineers, BI devs and software
developers. Familiarity with Python is helpful but not needed.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Nar Kumar Chhantyal</dc:creator><pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-11:/europython-2019/building-data-workflows-with-luigi-and-kubernetes.html</guid><category>EuroPython 2019</category><category>Architecture</category><category>Big Data</category><category>Data</category><category>Distributed Systems</category><category>Scaling</category></item><item><title>Deploy Python to the cloud faster with Azure Serverless</title><link>https://pyvideo.org/europython-2019/deploy-python-to-the-cloud-faster-with-azure-serverless.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Bringing your Python scripts or apps and running them in the cloud is
easier than ever with serverless computing. In this talk, we’ll show how
you can use Azure Functions to easily deploy and scale your Python
workloads without having to manage any servers or pay for unused compute
resources. We’ll also show how deep integration with Visual Studio Code
offers a great local development experience with full support for
debugging and testing your app, and allows you to seamlessly deploy your
serverless code to the cloud.&lt;/p&gt;
&lt;p&gt;We’ll start by giving a brief overview of the value of serverless
computing. Next, we'll create a brand new Python app in Visual Studio
Code, and start to add in business logic and ML capabilities. Once we
get the app running debugged locally, we’ll publish it to the cloud as a
serverless function, and demonstrate the serverless scalability.
Finally, we’ll walk you through the tools and capabilities you can
leverage around monitoring and management of your Python Azure
Functions.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jeff Hollan</dc:creator><pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-11:/europython-2019/deploy-python-to-the-cloud-faster-with-azure-serverless.html</guid><category>EuroPython 2019</category><category>APIs</category><category>Development</category><category>Microservices</category><category>Scaling</category><category>Tooling</category></item><item><title>Is it me, or the GIL?</title><link>https://pyvideo.org/europython-2019/is-it-me-or-the-gil.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python's Global Interpreter Lock is a friend and rival at the same time.
We, as developers, can focus on the design and implementation of
applications without the hassle of memory management. On the other side,
we complain about the GIL as the limiting factor of performance
sensitive applications. Therefore, it is common to refactor parts of
systems when the system doesn't perform or scale enough anymore. The
refactoring often includes the switch of the used concurrency paradigms
like replacing multithreading with multiprocessing or asyncio. Another
option is moving logic of CPU-bound workload into C extensions or a full
rewrite in a &amp;quot;GIL-free&amp;quot; language. But how do you know that the GIL is
the actual performance bottleneck?&lt;/p&gt;
&lt;p&gt;While scaling and developing performance sensitive components in Python,
my colleagues and I often also assumed the GIL as cause of our
performance problems because it is a common and simple answer for this
usually complex and varied problems. Instead of starting a rewrite or
major refactoring, we took a step back and tried to prove our
assumption. With the result that analyzing the impact of the GIL
contention on the overall performance is a very interesting problem
without common practices or easy usable set of tools that support Python
developers. Within this talk, I will share and explain the methods and
tools, which we use to analyze the relevance of the GIL on our
application performance and how it helped us to stay focused on the
actual problematic areas of our applications that required improvements
to meet our performance goals.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Christoph Heer</dc:creator><pubDate>Wed, 10 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-10:/europython-2019/is-it-me-or-the-gil.html</guid><category>EuroPython 2019</category><category>ASYNC / Concurrency</category><category>Multi-Threading</category><category>Performance</category><category>Scaling</category><category>Tooling</category></item><item><title>A deep dive and comparison of Python drivers for Cassandra and Scylla</title><link>https://pyvideo.org/europython-2020/a-deep-dive-and-comparison-of-python-drivers-for-cassandra-and-scylla.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will explain the thread-per-core data architecture of Scylla and
detail how we implemented &amp;quot;shard-awareness&amp;quot; in the Cassandra Python driver
which allows to route queries down to the right CPU!&lt;/p&gt;
&lt;p&gt;Cassandra's and Scylla's architecture and topology rely on the usage of
a consistent token ring to distribute their data evenly on the cluster.&lt;/p&gt;
&lt;p&gt;The cassandra-python driver is used widely to interact with those NoSQL
databases. It implements connection pools and token awareness allowing the
driver to route queries to the right node based on its knowledge of where the
data is.&lt;/p&gt;
&lt;p&gt;But Scylla goes one step further as it also dedicates CPUs to a smaller portion
of the data on each node (called shards). This means that &lt;strong&gt;we can route CQL
queries not only to the right node but to the right CPU&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;This talk will give implementation details on how we have done it.&lt;/p&gt;
&lt;p&gt;Talk audience requirements: having a minimal knowledge of what Cassandra and
a consistent hash ring are.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexys Jacob</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/a-deep-dive-and-comparison-of-python-drivers-for-cassandra-and-scylla.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>Databases</category><category>NoSQL</category><category>Python 3</category><category>Scaling</category></item><item><title>Efficient ML pipelines using Parquet and PyArrow</title><link>https://pyvideo.org/pycon-italia-2022/efficient-ml-pipelines-using-parquet-and-pyarrow.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Efficient ML pipelines using Parquet and PyArrow - PyCon Italia 2022&lt;/p&gt;
&lt;p&gt;Parquet is an high-performance columnar data format that has become the
de facto standard in the ML world. By leveraging the powerful PyArrow
API, I’ll show how to manage parquet datasets, ranging from a single
local file to a partitioned cloud-based dataset updated in real time.
Advanced analytics and Machine Learning (ML) are increasingly used to
drive business decisions or provide real-time services for end-users in
virtually every industry. Tabular data is the most ubiquitous type of
data. Therefore, efficient processing of handle tabular datasets is a
critical requirement to deliver performant products or services.&lt;/p&gt;
&lt;p&gt;In a proto-typical production ML workflow, an “ingestion pipeline” needs
to store large datasets on the cloud and continuously update them as new
data becomes available. An “analytics pipeline” usually needs to process
the entire dataset by reading it in batches, because the full dataset
would be too large to fit in RAM. An “inference pipeline” provides
real-time results (i.e.&amp;nbsp;model predictions or other online statistics)
and needs to process small batches of data in quasi-realtime. Finally,
the presentation of analytics results requires not only to show the
output from the models but also to provide context through “historical
data” for an arbitrary set of features. Therefore, low-latency access to
a small group of columns from a large dataset represents an additional
requirement.&lt;/p&gt;
&lt;p&gt;In the Python ecosystem, we can leverage tools such as Parquet and
PyArrow to address such complex workflow.&lt;/p&gt;
&lt;p&gt;Apache Parquet is a columnar storage format initially created to address
similar storage challenges in the Hadoop ecosystem. It has since become
a standard for efficient storage of large datasets in all the major
languages, including Python.&lt;/p&gt;
&lt;p&gt;The Apache Arrow project provides a cross-language in-memory
representation and query engine for tabular datasets and has a
performant IO interface for Parquet datasets. Its Python interface,
PyArrow, allows to query and process large partitioned datasets
distributed across multiple files and folders on local and cloud
storage.&lt;/p&gt;
&lt;p&gt;In this talk, combining PyArrow and Parquet datasets, we will explore
several techniques to address the use-cases of the typical production ML
workflows delineated above.&lt;/p&gt;
&lt;p&gt;Speaker: Ingargiola&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ingargiola</dc:creator><pubDate>Fri, 03 Jun 2022 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2022-06-03:/pycon-italia-2022/efficient-ml-pipelines-using-parquet-and-pyarrow.html</guid><category>PyCon Italia 2022</category><category>aws</category><category>best practice</category><category>infrastructure</category><category>machine learning</category><category>pandas</category><category>performance</category><category>scaling</category></item><item><title>Managing large-scale ML pipelines with MLflow and serverless computing.</title><link>https://pyvideo.org/pycon-italia-2022/managing-large-scale-ml-pipelines-with-mlflow-and-serverless-computing.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Managing large-scale Machine Learning pipelines with MLflow and
serverless computing. - PyCon Italia 2022&lt;/p&gt;
&lt;p&gt;MLOps aims to manage the machine learning (ML) lifecycle including
experimentation, reproducibility, deployment, and model registry. Come
to discover how in Vedrai - one of the top AI startups in Europe - we
enhance and maintain ML pipelines models in production reliably and
efficiently using MLOps. Problem:&lt;/p&gt;
&lt;p&gt;One difficulty of employing Machine Learning (ML) within organizations
is managing the model’s lifecycle. Moving from experimenting to
deployment in production environments is operated by different steps:
Preparing and Analysing Data, Training, Deployment, Monitoring, and
Governance of ML models. So, it is crucial to possess a platform to
manage and organize the ML lifecycle.&lt;/p&gt;
&lt;p&gt;Solution:&lt;/p&gt;
&lt;p&gt;In Vedrai, we combined the strength of the MLflow framework and the
resilience of AWS serverless services to manage, deploy, and scale our
ML models in production. MLflow is an open-source framework for tracking
the entire ML lifecycle from training to deployment. Among the
functions, it offers model tracking, packaging, and serving. Whereas,
deploying ML applications is an infrastructure affair that needs to be
scalable with minimum server management, which makes AWS serverless
services a great choice.&lt;/p&gt;
&lt;p&gt;Value:&lt;/p&gt;
&lt;p&gt;MLflow enforces the model’s reproducibility and robustness at the same
time allowing more centralized experimentation. AWS serverless services
allow training and inferencing pipelines to run without provisioning or
managing servers while only paying for the time it takes to run.&lt;/p&gt;
&lt;p&gt;Summary:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;State of the art of MLOps.&lt;/li&gt;
&lt;li&gt;Record and query experiments with MLflow Tracking.&lt;/li&gt;
&lt;li&gt;Package data science code with MLflow Projects.&lt;/li&gt;
&lt;li&gt;Store ML models with MLflow Models Registry.&lt;/li&gt;
&lt;li&gt;Deploy ML models in the AWS environment.&lt;/li&gt;
&lt;li&gt;Future MLOps challenges.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Speaker: ilyas chaoua&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">ilyas chaoua</dc:creator><pubDate>Fri, 03 Jun 2022 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2022-06-03:/pycon-italia-2022/managing-large-scale-ml-pipelines-with-mlflow-and-serverless-computing.html</guid><category>PyCon Italia 2022</category><category>architecture</category><category>aws</category><category>best practice</category><category>deep learning</category><category>devops</category><category>docker</category><category>infrastructure</category><category>machine learning</category><category>open source</category><category>operations</category><category>packaging</category><category>performance</category><category>scaling</category></item><item><title>What do you want to be known for?</title><link>https://pyvideo.org/pycon-italia-2022/what-do-you-want-to-be-known-for.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;What do you want to be known for? - PyCon Italia 2022&lt;/p&gt;
&lt;p&gt;If you feel professionally unsatisfied, struggle to make decisions, or
have a burning desire to leave behind an epic legacy – this session is
for you!&lt;/p&gt;
&lt;p&gt;In this fun + interactive session you’ll discover your Top 2 Personal
Values that are the secret to creating impact through your work. You
work hard. You are great at your job.&lt;/p&gt;
&lt;p&gt;But hard work is not what creates FULFILLMENT.&lt;/p&gt;
&lt;p&gt;If you feel professionally unsatisfied, struggle to make decisions, want
to feel more creative, or desire to leave behind an epic legacy – this
session is for you!&lt;/p&gt;
&lt;p&gt;In this fun + interactive session you’ll discover the secret to creating
impact through your work.&lt;/p&gt;
&lt;p&gt;When you get clear about what you value – finding your purpose, choosing
a direction, and making important career decisions becomes easy.&lt;/p&gt;
&lt;p&gt;In this session you’ll discover: - Your top two personal values - How to
quickly make career decisions that feel right - How to use creativity to
get clarity - Who you are now by modernizing your value system&lt;/p&gt;
&lt;p&gt;Join certified coach, master workshop facilitator, community creator,
and international entrepreneur Angela Parker for this unique session
that will help you get clear and inspire you to take action.&lt;/p&gt;
&lt;p&gt;Although Angela is American she lives half the year in Trentino Italy
and is a big supporter of the Python Community.&lt;/p&gt;
&lt;p&gt;Official Bio: Angela Parker is an international entrepreneur, CPCC
Certified Coach, ICF Coach Member, and AJ&amp;amp;Smart Master Workshop
Facilitator who teaches deep-feeling leaders &amp;amp; entrepreneurs how to use
creativity, values, self-compassion, and radical self-care – to create
deeply fulfilling work.&lt;/p&gt;
&lt;p&gt;Angela designs and facilitates impactful in-person and on-line
workshops, masterminds, and experiences for leaders and teams.&lt;/p&gt;
&lt;p&gt;Angela founded the largest and longest running outdoor fitness program
in Santa Monica CA. After her exit in 2018 she began coaching and
offering workshop facilitation. She’s known for her empathy, intuition,
directness, humor, and ability to thread the most impactful details into
all her sessions.&lt;/p&gt;
&lt;p&gt;Angela and her work has been featured on CBS, The LA Times, ESPN, MTV,
ABC, The Hallmark Channel, Carson Magazine, and Self Magazine.&lt;/p&gt;
&lt;p&gt;When Covid possible, Angela splits her time between the Italian Alps,
Los Angeles, Chicago, and Japan.&lt;/p&gt;
&lt;p&gt;Speaker: Angela Parker&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Angela Parker</dc:creator><pubDate>Fri, 03 Jun 2022 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2022-06-03:/pycon-italia-2022/what-do-you-want-to-be-known-for.html</guid><category>PyCon Italia 2022</category><category>communication</category><category>community</category><category>education</category><category>scaling</category><category>teaching</category></item><item><title>When gRPC Met Python</title><link>https://pyvideo.org/pycon-italia-2022/when-grpc-met-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When gRPC Met Python - PyCon Italia 2022&lt;/p&gt;
&lt;p&gt;What if we can have a tool that helps us to do intelligent load
balancing or What if we can do selective compression of the data and
extremely fast and light weight transfer of data? Then let me introduce
gRPC, the technology that helps us to do all of this and how can we
integrate gRPC with Python. gRPC is one of the most new breakthroughs in
the world of client server interaction. Using gRPC our client can
directly make a call to a server on a different machine as if it were a
local object. gRPC has low latency, high scalability and supports
multiple use cases for distributed system. We can even build mobile
clients which can communicate to a cloud server. gRPC uses Protocol
Buffers which is an open source mechanism for serialising structured
data, which makes payloads faster, smaller and simpler. In this talk we
will try to understand how can we get started with gRPC in Python.
grpcio package of python will be used for the demonstration of the
examples and we will cover basics of gRPC as well. We will build a basic
gRPC service and define protocol buffers for it. Demonstration of how a
client and a server can be made through gRPC and how can they
communicate.&lt;/p&gt;
&lt;p&gt;Speaker: Sanket Singh&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sanket Singh</dc:creator><pubDate>Fri, 03 Jun 2022 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2022-06-03:/pycon-italia-2022/when-grpc-met-python.html</guid><category>PyCon Italia 2022</category><category>distributed systems</category><category>scaling</category></item><item><title>Actors: What, Why, and How (#161)</title><link>https://pyvideo.org/pycon-us-2010/pycon-2010--actors--what--why--and-how---161.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Actors: What, Why and How&lt;/p&gt;
&lt;p&gt;Presented by Donovan Preston&lt;/p&gt;
&lt;p&gt;Since the dawn of concurrency research, there have been two camps:
shared everything, and shared nothing. Most modern applications use
threads for concurrency, a shared everything architecture.&lt;/p&gt;
&lt;p&gt;Actors, however, use a shared nothing architecture where lightweight
processes communicate with each other using message passing. Actors can
change their state, create a new Actor, send a message to any Actor it
has the Address of, and wait for a specific kind of message to arrive in
it's mailbox.&lt;/p&gt;
&lt;p&gt;We will discuss the benefits of using the Actor architecture and
strategies for implementing an Actor system in Python.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://bitbucket.org/fzzzy/python-%20actors/"&gt;http://bitbucket.org/fzzzy/python-actors/&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Donovan Preston</dc:creator><pubDate>Fri, 19 Feb 2010 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2010-02-19:/pycon-us-2010/pycon-2010--actors--what--why--and-how---161.html</guid><category>PyCon US 2010</category><category>concurrency</category><category>eventlet</category><category>infrastructure</category><category>pycon</category><category>pycon2010</category><category>rest</category><category>scaling</category><category>wsgi</category></item><item><title>Designing to Scale: The Story of ShootQ (#5)</title><link>https://pyvideo.org/pycon-us-2010/pycon-2010--designing-to-scale--the-story-of-shoo.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Designing to Scale: The story of ShootQ&lt;/p&gt;
&lt;p&gt;Jonathan LaCour (ShootQ)&lt;/p&gt;
&lt;p&gt;ShootQ is a web-based studio management solution for professional
photography studios, designed to automate and simplify the task of
running a small business. In this talk, Jonathan LaCour, the CTO of
ShootQ, hopes to share his experience designing a web application that
can scale up to meet the demands of a rapidly growing customer base. The
talk will cover a variety of topics including TurboGears 2.0, WSGI,
horizontal and vertical scaling, database replication, load balancing,
deployment, and more.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Unknown</dc:creator><pubDate>Fri, 19 Feb 2010 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2010-02-19:/pycon-us-2010/pycon-2010--designing-to-scale--the-story-of-shoo.html</guid><category>PyCon US 2010</category><category>deployment</category><category>loadbalancing</category><category>pycon</category><category>pycon2010</category><category>replication</category><category>scaling</category><category>turbogears</category><category>wsgi</category></item><item><title>Scaling your Python application on EC2 (#191)</title><link>https://pyvideo.org/pycon-us-2010/pycon-2010--scaling-your-python-application-on-ec.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Scaling Your Python Application on EC2&lt;/p&gt;
&lt;p&gt;Presented by Jeremy Edberg&lt;/p&gt;
&lt;p&gt;Come hear about the trials and tribulations of moving reddit's Python
application from physical hardware to EC2's cloud infrastructure, and
how they have scaled since moving. Will include general discussion of
their learnings about scaling as well cloud specific issues.&lt;/p&gt;
&lt;p&gt;[VIDEO HAS ISSUES: Missing audio first few seconds]&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jeremy Edberg</dc:creator><pubDate>Fri, 19 Feb 2010 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2010-02-19:/pycon-us-2010/pycon-2010--scaling-your-python-application-on-ec.html</guid><category>PyCon US 2010</category><category>pycon</category><category>pycon2010</category><category>reddit</category><category>scaling</category><category>web</category></item><item><title>What every developer should know about database scalability (#21)</title><link>https://pyvideo.org/pycon-us-2010/pycon-2010--what-every-developer-should-know-abou.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;What every developer should know about database scalability&lt;/p&gt;
&lt;p&gt;Presented by Jonathan Ellis&lt;/p&gt;
&lt;p&gt;Caching, replication, partitioning, and distributed databases: how these
can (and can't!) help you scale your data.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jonathan Ellis</dc:creator><pubDate>Fri, 19 Feb 2010 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2010-02-19:/pycon-us-2010/pycon-2010--what-every-developer-should-know-abou.html</guid><category>PyCon US 2010</category><category>caching</category><category>distributeddatabases</category><category>partitioning</category><category>pycon</category><category>pycon2010</category><category>replication</category><category>scaling</category></item><item><title>Scaling up to Big Data Devops for Data Science</title><link>https://pyvideo.org/pydata-dc-2016/scaling-up-to-big-data-devops-for-data-science.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Scaling up R/Python from a single machine to a cluster environment can be tricky. While there are many tools available that make the launching of a cluster relatively easy, they are not focused or optimized to the specific use case of analytics but mostly on operations. Come and learn about devops tips and tricks to optimize your transition into the big data world as a data scientist.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marck Vaisman</dc:creator><pubDate>Sat, 08 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-08:/pydata-dc-2016/scaling-up-to-big-data-devops-for-data-science.html</guid><category>PyData DC 2016</category><category>big data</category><category>Data</category><category>data science</category><category>devops</category><category>scaling</category><category>science</category></item></channel></rss>