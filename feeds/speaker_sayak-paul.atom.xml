<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Sayak Paul</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_sayak-paul.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-10-30T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Demystifying Self-Supervised Learning for Visual Recognition</title><link href="https://pyvideo.org/scipy-japan-2020/demystifying-self-supervised-learning-for-visual-recognition.html" rel="alternate"></link><published>2020-10-30T00:00:00+00:00</published><updated>2020-10-30T00:00:00+00:00</updated><author><name>Sayak Paul</name></author><id>tag:pyvideo.org,2020-10-30:/scipy-japan-2020/demystifying-self-supervised-learning-for-visual-recognition.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deep learning models are powered by data, the abundance of it. Most of the deep learning models that empower many critical applications in our day-to-day lives depend on labeled data. Affording humongous amounts of labeled datasets is not always possible for a number of different factors like budget, human …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deep learning models are powered by data, the abundance of it. Most of the deep learning models that empower many critical applications in our day-to-day lives depend on labeled data. Affording humongous amounts of labeled datasets is not always possible for a number of different factors like budget, human resources, lack of expert annotators, and so on. The internet is practically an infinite source of unlabeled data. So, at this point, an important question that gets raised is - how can we effectively utilize this large pool of unlabeled data for developing better deep learning models? Self-supervised learning can be helpful here to answer questions like this.&lt;/p&gt;
&lt;p&gt;ディープラーニングモデルは、豊富なデータを動力源としています。私たちの日常生活における多くの重要なアプリケーションに力を与えているディープラーニングモデルのほとんどは、ラベル付きデータに依存しています。膨大な量のラベル付きデータセットを提供することは、予算、人的資源、専門家のアノテータの不足など、さまざまな要因により常に可能とは限りません。インターネットには、事実上、ラベル付けされていないデータが無限に存在します。そこで、この時点で重要な疑問が浮かび上がってきます-どのようにして、より良いディープラーニングモデルを開発するために、この大規模な非ラベルデータのプールを効果的に利用することができるのでしょうか？自己教師付き学習は、このような疑問に答えるのに役立ちます。&lt;/p&gt;
</content><category term="Scipy Japan 2020"></category></entry></feed>