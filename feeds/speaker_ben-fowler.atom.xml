<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_ben-fowler.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-12-04T00:00:00+00:00</updated><entry><title>Evaluation of Traditional and Novel Feature Selection Approaches</title><link href="https://pyvideo.org/pydata-la-2019/evaluation-of-traditional-and-novel-feature-selection-approaches.html" rel="alternate"></link><published>2019-12-04T00:00:00+00:00</published><updated>2019-12-04T00:00:00+00:00</updated><author><name>Ben Fowler</name></author><id>tag:pyvideo.org,2019-12-04:pydata-la-2019/evaluation-of-traditional-and-novel-feature-selection-approaches.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Selecting the optimal set of features is a key step in the ML modeling
process. This talk will present research conducted that tested five
approaches for feature selection. The approaches included current widely
used methods, along with novel approaches for feature selection using
open-source libraries, building a classification model using the Lending
Club dataset.&lt;/p&gt;
&lt;p&gt;A central component to the Machine Learning process is feature
selection. Selecting the optimal set of features is important to
generate a best fit model which generalizes to unseen data. A widely
used approach for feature selection involves calculating Gini Importance
(Gain) to identify the best set of features. However, recent work from
Scott Lundberg has found challenges with the consistency of the Gain
attribution method. This talk will present results of model metrics on
the Lending Club dataset, testing five different feature selection
approaches. The approaches tested involved widely used approaches
combined with novel approaches for feature selection.&lt;/p&gt;
&lt;p&gt;Through the experimental design of the five feature selection approaches
that were tested; attendees will gain clarity on the impact of:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Data splitting method&lt;/li&gt;
&lt;li&gt;Including relevant two-way and three-way interactions (xgbfir
library)&lt;/li&gt;
&lt;li&gt;Backwards stepwise feature selection as opposed to a singular feature
selection step&lt;/li&gt;
&lt;li&gt;Backwards stepwise feature selection using Shapley values (shap
library).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The knowledge from this research can provide added predictive power and
velocity to the feature selection process for Data Scientists.&lt;/p&gt;
</summary></entry></feed>