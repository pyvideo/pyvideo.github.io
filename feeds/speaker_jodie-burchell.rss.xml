<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Jodie Burchell</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 08 Jul 2024 00:00:00 +0000</lastBuildDate><item><title>Q&amp;A panel for data science newbies</title><link>https://pyvideo.org/europython-2023/qa-panel-for-data-science-newbies.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[EuroPython 2023 — Terrace 2B on 2023-07-19]&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://ep2023.europython.eu/session/qa-panel-for-data-science-newbies"&gt;https://ep2023.europython.eu/session/qa-panel-for-data-science-newbies&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Are you just getting started in the world of data science and feeling overwhelmed by the abundance of information on various packages, models, and techniques? Perhaps you're finding it challenging to decide which visualization package to use or which tools to begin with. Maybe you're puzzled by the distinctions between pip and Conda, or you're feeling bombarded by all the news about AI and large language models.&lt;/p&gt;
&lt;p&gt;Worry no more! Join us for this Q&amp;amp;A session, where a panel of data science experts will be there to address all of your pressing questions. This session is designed to create a relaxed and welcoming environment for complete beginners in the field, offering guidance on topics that might be causing confusion.&lt;/p&gt;
&lt;p&gt;This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License &lt;a class="reference external" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;http://creativecommons.org/licenses/by-nc-sa/4.0/&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Cheuk Ting Ho</dc:creator><pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-17:/europython-2023/qa-panel-for-data-science-newbies.html</guid><category>EuroPython 2023</category></item><item><title>Lies, damned lies and large language models</title><link>https://pyvideo.org/europython-2024/lies-damned-lies-and-large-language-models.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[EuroPython 2024 — Forum Hall on 2024-07-11]&lt;/p&gt;
&lt;p&gt;Lies, damned lies and large language models by Jodie Burchell&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://ep2024.europython.eu/session/lies-damned-lies-and-large-language-models"&gt;https://ep2024.europython.eu/session/lies-damned-lies-and-large-language-models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Would you like to use large language models (LLMs) in your own project, but are troubled by their tendency to frequently “hallucinate”, or produce incorrect information? Have you ever wondered if there was a way to easily measure an LLM’s hallucination rate, and compare this against other models? And would you like to learn how to help LLMs produce more accurate information?&lt;/p&gt;
&lt;p&gt;In this talk, we’ll have a look at some of the main reasons that hallucinations occur in LLMs, and then focus on how we can measure one specific type of hallucination: the tendency of models to regurgitate misinformation that they have learned from their training data. We’ll explore how we can easily measure this type of hallucination in LLMs using a dataset called TruthfulQA in conjunction with Python tooling including Hugging Face’s &lt;cite&gt;datasets&lt;/cite&gt; and &lt;cite&gt;transformers&lt;/cite&gt; packages, and the &lt;cite&gt;langchain&lt;/cite&gt; package.&lt;/p&gt;
&lt;p&gt;We’ll end by looking at recent initiatives to reduce hallucinations in LLMs, using a technique called retrieval augmented generation (RAG). We’ll look at how and why RAG makes LLMs less likely to hallucinate, and how this can help make these models more reliable and usable in a range of contexts.&lt;/p&gt;
&lt;p&gt;---&lt;/p&gt;
&lt;p&gt;This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License: &lt;a class="reference external" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;https://creativecommons.org/licenses/by-nc-sa/4.0/&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jodie Burchell</dc:creator><pubDate>Mon, 08 Jul 2024 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2024-07-08:/europython-2024/lies-damned-lies-and-large-language-models.html</guid><category>EuroPython 2024</category></item><item><title>Reproducible Research in Python</title><link>https://pyvideo.org/pycon-au-2016/reproducible-research-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jodie Burchell
&lt;a class="reference external" href="https://2016.pycon-au.org/schedule/127/view_talk"&gt;https://2016.pycon-au.org/schedule/127/view_talk&lt;/a&gt;
You’ve seen a great idea on someone’s blog that you think would really push that old analysis you did 6 months ago to the next level. You open up the Dropbox folder you have with all of your scripts, and … you’re lost. Which script did you start with? What does this random chunk of code do? Where is the original data file? You finally sort out your scripts, but then your code fails every second line because you don't even remember which packages you used before. Frustrated, you give up.&lt;/p&gt;
&lt;p&gt;What if I told you that there is a better way to keep track of your analyses, and that it is easier than you think to do so? In this talk I will show you how using a reproducible research approach to your analyses can save you hours of time when revisiting or updating old projects, and demonstrate some of the tools that Python has available to make this possible. This talk will cover how to manage your packages using virtualenvs, how to thoroughly document your analysis using Jupyter Notebook, how to keep track of any changes using source control systems like Git and how to collaborate effectively using GitHub. By the end you will wonder why you’ve ever done your analyses any other way, and will be happily maintaining and improving your projects for many years to come!&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jodie Burchell</dc:creator><pubDate>Mon, 15 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-15:/pycon-au-2016/reproducible-research-in-python.html</guid><category>PyCon AU 2016</category></item><item><title>Vectorise all the things! How basic linear algebra can speed up your data science code</title><link>https://pyvideo.org/pycon-uk-2022/vectorise-all-the-things-how-basic-linear-algebra-can-speed-up-your-data-science-code.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Do you feel like your data science code is horribly inefficient, but you don’t know how to make things faster? Fear not! In this talk, we’ll speed up some common operations using tricks from linear algebra - all within the comfort of the Python ecosystem.&lt;/p&gt;
&lt;p&gt;Have you found that your data science code works beautifully on a few dozen test rows, but leaves you wondering how to spend the next couple of hours after you start looping through your full data set? Are you only familiar with Python, and wish there was a way to speed things up without subjecting yourself to learning C? In this talk, I will show you some simple tricks, borrowed from linear algebra, which can give you significant performance gains in your Python data science code. I will gently take you through the basics of linear algebra, explaining core operations such as matrix addition, subtraction and multiplication, scalar multiplication and the dot product. I will then show you some examples of how you can easily utilise these concepts in your machine learning code to speed up common data science operations such as distance calculations, classification tasks and finding nearest neighbours.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jodie Burchell</dc:creator><pubDate>Sat, 17 Sep 2022 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2022-09-17:/pycon-uk-2022/vectorise-all-the-things-how-basic-linear-algebra-can-speed-up-your-data-science-code.html</guid><category>PyCon UK 2022</category></item><item><title>Vectorize all the things! Using linear algebra and NumPy to make your Python code lightning fast.</title><link>https://pyvideo.org/pycon-us-2023/vectorize-all-the-things-using-linear-algebra-and-numpy-to-make-your-python-code-lightning-fast.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you found that your code works beautifully on a few dozen examples,
but leaves you wondering how to spend the next couple of hours after you
start looping through all of your data? Are you only familiar with
Python, and wish there was a way to speed things up without subjecting
yourself to learning C?&lt;/p&gt;
&lt;p&gt;In this talk, you'll see some simple tricks, borrowed from linear
algebra, which can give you significant performance gains in your Python
code, and how you can implement these in NumPy. We'll start exploring an
inefficient implementation of an algorithm that relies heavily on loops
and lists. Throughout the talk, we'll iteratively replace bottlenecks
with NumPy vectorized operations.&lt;/p&gt;
&lt;p&gt;At each stage, you'll learn the linear algebra behind why these
operations are more efficient so that you'll be able to utilize these
concepts in your own code. You'll see how straightforward it can be to
make your code many times faster, all without losing readability or
needing to understand complex coding concepts.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jodie Burchell</dc:creator><pubDate>Sat, 22 Apr 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-04-22:/pycon-us-2023/vectorize-all-the-things-using-linear-algebra-and-numpy-to-make-your-python-code-lightning-fast.html</guid><category>PyCon US 2023</category></item><item><title>Lies, damned lies and large language models</title><link>https://pyvideo.org/pycon-us-2024/lies-damned-lies-and-large-language-models.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Would you like to use large language models (LLMs) in your own project,
but are troubled by their tendency to frequently “hallucinate”, or
produce incorrect information? Have you ever wondered if there was a way
to easily measure an LLM’s hallucination rate, and compare this against
other models? And would you like to learn how to help LLMs produce more
accurate information?&lt;/p&gt;
&lt;p&gt;In this talk, we’ll have a look at some of the main reasons that
hallucinations occur in LLMs, and then focus on how we can measure one
specific type of hallucination: the tendency of models to regurgitate
misinformation that they have learned from their training data. We’ll
explore how we can easily measure this type of hallucination in LLMs
using a dataset called &lt;em&gt;TruthfulQA&lt;/em&gt; in conjunction with Python tooling
including Hugging Face’s &lt;tt class="docutils literal"&gt;datasets&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;transformers&lt;/tt&gt; packages, and
the &lt;tt class="docutils literal"&gt;langchain&lt;/tt&gt; package.&lt;/p&gt;
&lt;p&gt;We’ll end by looking at recent initiatives to reduce hallucinations in
LLMs, using a technique called retrieval augmented generation (RAG).
We’ll look at how and why RAG makes LLMs less likely to hallucinate, and
how this can help make these models more reliable and usable in a range
of contexts.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jodie Burchell</dc:creator><pubDate>Sat, 18 May 2024 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2024-05-18:/pycon-us-2024/lies-damned-lies-and-large-language-models.html</guid><category>PyCon US 2024</category></item></channel></rss>