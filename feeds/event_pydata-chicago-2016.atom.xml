<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/event_pydata-chicago-2016.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2016-09-23T00:00:00+00:00</updated><entry><title>Embracing the Monolith in Small Teams</title><link href="https://pyvideo.org/pydata-chicago-2016/embracing-the-monolith-in-small-teams.html" rel="alternate"></link><published>2016-09-23T00:00:00+00:00</published><updated>2016-09-23T00:00:00+00:00</updated><author><name>Leon Sasson</name></author><id>tag:pyvideo.org,2016-09-23:pydata-chicago-2016/embracing-the-monolith-in-small-teams.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="http://www.slideshare.net/LeonSasson/embracing-the-monolith"&gt;http://www.slideshare.net/LeonSasson/embracing-the-monolith&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Its unlikely for small orgs to have resources to support the fanciest and shiny data tooling out there. Choosing the right tools and tightly coupling them, can can give small, cross-disciplinary teams the power of moving fast, without breaking things. This goes against a lot of common advice, but becomes powerful when applied with disciplines. I'll show you how with Django, IPython, and Postgres.&lt;/p&gt;
</summary></entry><entry><title>Evolutionary Algorithms Perfecting the Art of "Good Enough"</title><link href="https://pyvideo.org/pydata-chicago-2016/evolutionary-algorithms-perfecting-the-art-of-good-enough.html" rel="alternate"></link><published>2016-09-23T00:00:00+00:00</published><updated>2016-09-23T00:00:00+00:00</updated><author><name>Liz Sander</name></author><id>tag:pyvideo.org,2016-09-23:pydata-chicago-2016/evolutionary-algorithms-perfecting-the-art-of-good-enough.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="http://www.slideshare.net/secret/dvt9zZBUVz7b7X"&gt;http://www.slideshare.net/secret/dvt9zZBUVz7b7X&lt;/a&gt;
Github: &lt;a class="reference external" href="https://github.com/esander91"&gt;https://github.com/esander91&lt;/a&gt;
Code: &lt;a class="reference external" href="https://github.com/esander91/GoodEnoughAlgs"&gt;https://github.com/esander91/GoodEnoughAlgs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Evolutionary algorithms let us tackle all kinds of impossible problems. Want to design a short delivery route, but there are more possible solutions than atoms in the universe? Well, evolutionary algorithms can't promise to find the optimal solution, but can guarantee finding a pretty great one. I'll give an overview of these algorithms, and how you can use them for your own impossible problems.&lt;/p&gt;
</summary><category term="art"></category></entry><entry><title>A Year of Pyxley: My First Open Source Adventure</title><link href="https://pyvideo.org/pydata-chicago-2016/a-year-of-pyxley-my-first-open-source-adventure.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Nicholas Kridler</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/a-year-of-pyxley-my-first-open-source-adventure.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Last year, I created my first Flask-powered web application utilizing React.js and D3. I refactored it into reusable components and released it as Pyxley. In this talk, I’ll introduce the basics of Pyxley and discuss what has and hasn’t worked. More importantly, I’ll talk about what it’s like to maintain an open-source project for the first time.&lt;/p&gt;
</summary><category term="adventure"></category><category term="Open Source"></category></entry><entry><title>AutoDocish: Automated-ish Dataset Documentation</title><link href="https://pyvideo.org/pydata-chicago-2016/autodocish-automated-ish-dataset-documentation.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Elizabeth Wickes</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/autodocish-automated-ish-dataset-documentation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://figshare.com/articles/AutoDocish_Automated-ish_Dataset_Documentation/3759288/1"&gt;https://figshare.com/articles/AutoDocish_Automated-ish_Dataset_Documentation/3759288/1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;AutoDocish is a command line Python tool to semi-automate the dataset documentation process. Written with a framework for expansion and customization, it produces template files in MarkDown that contain a basic data dictionary structure. This talk explains dataset documentation practices and how this tool could fit into the data publishing workflow.&lt;/p&gt;
</summary><category term="documentation"></category></entry><entry><title>Creating a Contemporary Risk Management System Using Python</title><link href="https://pyvideo.org/pydata-chicago-2016/creating-a-contemporary-risk-management-system-using-python.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Piero Ferrante</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/creating-a-contemporary-risk-management-system-using-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Lending involves risk and in order to be a successful lender at scale that risk needs to be mitigated. We'll be discussing how C2FO has built a suite of risk management tools for underwriting and portfolio management using the PyData ecosystem, rpy2 (for integrating R), and Spyre (for building a simple web application).&lt;/p&gt;
</summary><category term="management"></category></entry><entry><title>Finding Driving Style Patterns in Caterpillar Machine Data</title><link href="https://pyvideo.org/pydata-chicago-2016/finding-driving-style-patterns-in-caterpillar-machine-data.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Benjamin Hodel</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/finding-driving-style-patterns-in-caterpillar-machine-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://cat.app.box.com/s/1c4mvt8eayb5o7g2wp8nsdwbguhgersm"&gt;https://cat.app.box.com/s/1c4mvt8eayb5o7g2wp8nsdwbguhgersm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Identifying predominant driving-style patterns in logged time series data of Caterpillar machines is daunting due to the nature and size of the data. However, insight gained from field data can deliver optimized powertrain control software and better machine performance. A solution for finding patterns was built using engineered features, dimensionality reduction, and unsupervised learning.&lt;/p&gt;
</summary><category term="Data"></category><category term="patterns"></category><category term="style"></category></entry><entry><title>Genotype Phenotype Modelling with Python and Machine Learning</title><link href="https://pyvideo.org/pydata-chicago-2016/genotype-phenotype-modelling-with-python-and-machine-learning.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Mat Kallada</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/genotype-phenotype-modelling-with-python-and-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Genotype-phenotype studies are done for predicting traits such as whether someone will go bald or have a particular disease given their only genome. We look at how Python libraries such as scikit-learn and keras have made it easier to develop these statistical models. We describe a pipeline to predict antimicrobial resistance in bacteria and elaborate on challenges when working with genomic data.&lt;/p&gt;
</summary><category term="learning"></category><category term="machine learning"></category></entry><entry><title>Implementing distributed grid search for deep learning using scikit learn and joblib</title><link href="https://pyvideo.org/pydata-chicago-2016/implementing-distributed-grid-search-for-deep-learning-using-scikit-learn-and-joblib.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Mike Heilman</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/implementing-distributed-grid-search-for-deep-learning-using-scikit-learn-and-joblib.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://mheilman.github.io/pydata_chicago_2016/#/"&gt;https://mheilman.github.io/pydata_chicago_2016/#/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Grid search over hyperparameters is an important but computationally expensive process in machine learning, particularly for deep learning and tree ensembles. In this talk, I will describe how one can use joblib's recently added custom backend functionality to do distributed grid search on Amazon EC2 for a TensorFlow deep text classifier that follows the scikit-learn estimator API.&lt;/p&gt;
</summary><category term="deep learning"></category><category term="distributed"></category><category term="learning"></category><category term="scikit"></category><category term="search"></category></entry><entry><title>Keynote: Built in Super Heroes</title><link href="https://pyvideo.org/pydata-chicago-2016/keynote-built-in-super-heroes.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>David Beazley</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/keynote-built-in-super-heroes.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
</summary></entry><entry><title>Keynote: Developing Communities to Develop Themselves</title><link href="https://pyvideo.org/pydata-chicago-2016/keynote-developing-communities-to-develop-themselves.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Matthew Turk</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/keynote-developing-communities-to-develop-themselves.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://docs.google.com/presentation/d/1EK7_ioemYMqrUW4M8vvF2usql4vjvQMS5I9xCUNvBso/edit#slide=id.p"&gt;https://docs.google.com/presentation/d/1EK7_ioemYMqrUW4M8vvF2usql4vjvQMS5I9xCUNvBso/edit#slide=id.p&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>Machine learning techniques for data cleaning</title><link href="https://pyvideo.org/pydata-chicago-2016/machine-learning-techniques-for-data-cleaning.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Cathy Deng</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/machine-learning-techniques-for-data-cleaning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://docs.google.com/presentation/d/1k42esoWoc_WezfPfQ5vxbHTsuFOvAshEusD-GFCElTQ/edit#slide=id.g166bf446d8_1_12"&gt;https://docs.google.com/presentation/d/1k42esoWoc_WezfPfQ5vxbHTsuFOvAshEusD-GFCElTQ/edit#slide=id.g166bf446d8_1_12&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Often, the most interesting datasets - data about people and organizations - are the messiest and most difficult to analyze. When data comes from multiple sources, or when data is entered manually, variation &amp;amp; ambiguity are inevitable. Learn about ways to infer structure and relationships in messy data, using open source Python libraries.&lt;/p&gt;
</summary><category term="Data"></category><category term="learning"></category><category term="machine learning"></category></entry><entry><title>Using Exploratory Data Analysis to Discover Patterns in Image and Document Collections</title><link href="https://pyvideo.org/pydata-chicago-2016/using-exploratory-data-analysis-to-discover-patterns-in-image-and-document-collections.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Mehrdad Yazdani</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/using-exploratory-data-analysis-to-discover-patterns-in-image-and-document-collections.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://docs.google.com/presentation/d/1StRN0-_0x4BPkFFQ79GusgQAqXgwvJ1Fc8Tlu68YO4E/edit"&gt;https://docs.google.com/presentation/d/1StRN0-_0x4BPkFFQ79GusgQAqXgwvJ1Fc8Tlu68YO4E/edit&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Exploratory Data Analysis (EDA) is one of the key sets of procedures for summarizing a dataset. In this talk we will develop an EDA procedure for large collections of documents and images (such as photo albums, emails, articles, etc). We will show features used from NLP and Deep Neural Nets and also introduce novel visualization techniques for large image collections using PyImagePlot.&lt;/p&gt;
</summary><category term="analysis"></category><category term="Data"></category><category term="data analysis"></category><category term="patterns"></category></entry><entry><title>Using Twitter's Breakout Detection Package</title><link href="https://pyvideo.org/pydata-chicago-2016/using-twitters-breakout-detection-package.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Eric Bunch</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/using-twitters-breakout-detection-package.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
</summary><category term="twitter"></category></entry><entry><title>When Worlds Collide: Productionalizing a Data Science Model</title><link href="https://pyvideo.org/pydata-chicago-2016/when-worlds-collide-productionalizing-a-data-science-model.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Tudor Radoaca</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/when-worlds-collide-productionalizing-a-data-science-model.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;On our first data science project at Shiftgig, the data science and engineering teams had to build software that was production-ready while maintaining the flexibility of a data science sandbox. Although these seem like irreconcilable goals, they forced us to improve inter-team communication and ultimately helped create a great product. We’ll walk through our process and the lessons we learned.&lt;/p&gt;
</summary><category term="Data"></category><category term="data science"></category><category term="model"></category><category term="science"></category></entry><entry><title>Adding Image and Voice Intelligence to Your Apps with Microsoft Cognitive Services</title><link href="https://pyvideo.org/pydata-chicago-2016/adding-image-and-voice-intelligence-to-your-apps-with-microsoft-cognitive-services.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>David Giard</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/adding-image-and-voice-intelligence-to-your-apps-with-microsoft-cognitive-services.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Cognitive Services is a set of APIs that use the power of Machine Learning to enhance your application. Using these APIs, you can quickly add image recognition and analysis; facial recognition, speech recognition, text-to-speech capabilities, and many other features to your application.&lt;/p&gt;
</summary><category term="image"></category></entry><entry><title>Data Engineering Architecture at Simple</title><link href="https://pyvideo.org/pydata-chicago-2016/data-engineering-architecture-at-simple.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>Rob Story</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/data-engineering-architecture-at-simple.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;A walk through Simple's Data Engineering stack, including lessons learned and why we chose certain tools and languages for different parts of our infrastructure.&lt;/p&gt;
</summary><category term="architecture"></category><category term="Data"></category><category term="engineering"></category></entry><entry><title>Deconstructing Feather</title><link href="https://pyvideo.org/pydata-chicago-2016/deconstructing-feather.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>Bill Lattner</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/deconstructing-feather.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/wlattner/PyData_Chi_2016"&gt;https://github.com/wlattner/PyData_Chi_2016&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Feather, Avro, Parquet, Arrow... all these new file formats, what's wrong with good old CSVs? In this talk, we will cover why CSV files are not always the optimal storage format for tabular data and what optimizations each of these formats make. We will do a deep dive on Feather, a cross-language format created by Wes McKinney and Hadley Wickham.&lt;/p&gt;
</summary></entry><entry><title>Deploying Machine Learning using sklearn pipelines</title><link href="https://pyvideo.org/pydata-chicago-2016/deploying-machine-learning-using-sklearn-pipelines.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>Kevin Goetsch</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/deploying-machine-learning-using-sklearn-pipelines.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Sklearn pipeline objects provide an framework that simplifies the lifecycle of data science models. This talk will cover the how and why of encoding feature engineering, estimators, and model ensembles in a single deployable object.&lt;/p&gt;
</summary><category term="deploying"></category><category term="learning"></category><category term="machine learning"></category><category term="sklearn"></category></entry><entry><title>Don't Live Patch Your CPython Interpreter</title><link href="https://pyvideo.org/pydata-chicago-2016/dont-live-patch-your-cpython-interpreter.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>James Powell</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/dont-live-patch-your-cpython-interpreter.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
</summary><category term="CPython"></category><category term="interpreter"></category></entry><entry><title>Fizz Buzz in Tensorflow</title><link href="https://pyvideo.org/pydata-chicago-2016/fizz-buzz-in-tensorflow.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>Joel Grus</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/fizz-buzz-in-tensorflow.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Fizz Buzz is a ubiquitous, nearly trivial problem used to weed out developer job applicants. Recently I wrote a joking-not-joking blog post about a fictional interviewee who solves it using neural networks. After the blog post went viral, I spent a lot of time thinking about Fizz Buzz as a machine learning problem. It turns out it's surprisingly interesting and subtle! I'll talk about how and why.&lt;/p&gt;
</summary><category term="tensorflow"></category></entry><entry><title>Forecasting with the Kalman Filter</title><link href="https://pyvideo.org/pydata-chicago-2016/forecasting-with-the-kalman-filter.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>Mike Mull</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/forecasting-with-the-kalman-filter.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/mikemull/Notebooks/blob/master/Kalman-Slides-PyDataChicago2016.ipynb"&gt;https://github.com/mikemull/Notebooks/blob/master/Kalman-Slides-PyDataChicago2016.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Kalman filter is a popular tool in control theory and time-series analysis, but it can be a little hard to grasp. This talk will serve as in introduction to the concept, using an example of forecasting an economic indicator with tools from the statsmodels library.&lt;/p&gt;
</summary><category term="Kalman Filter"></category></entry><entry><title>High Frequency Trading in MMORPG Markets using Luigi, Pandas, and Scikit learn</title><link href="https://pyvideo.org/pydata-chicago-2016/high-frequency-trading-in-mmorpg-markets-using-luigi-pandas-and-scikit-learn.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>J. Henry Hinnefeld</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/high-frequency-trading-in-mmorpg-markets-using-luigi-pandas-and-scikit-learn.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;In this talk I’ll describe the system I developed to implement a basic algorithmic trading strategy in the in-game market of an online, multi-player video game. Using this toy model, I’ll walk through the steps involved in setting up a data pipeline with Luigi, analyzing the resulting data with pandas, and identifying important factors and features with scikit-learn.&lt;/p&gt;
</summary><category term="scikit"></category></entry><entry><title>It's Not Magic: Explaining Classification Algorithms</title><link href="https://pyvideo.org/pydata-chicago-2016/its-not-magic-explaining-classification-algorithms.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>Brian Lange</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/its-not-magic-explaining-classification-algorithms.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;As organizations increasingly make use of data and machine learning methods, people must build a basic &amp;quot;data literacy&amp;quot;. Data scientist &amp;amp; instructor Brian Lange provides simple, visual &amp;amp; equation-free explanations for a variety of classification algorithms geared towards helping understand them. He shows how the concepts explained can be pulled off using Python library Scikit Learn in a few lines.&lt;/p&gt;
</summary><category term="classification"></category></entry><entry><title>Keynote</title><link href="https://pyvideo.org/pydata-chicago-2016/keynote.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>Katy Huff</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/keynote.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://katyhuff.github.io/2016-08-27-pydata/#/"&gt;https://katyhuff.github.io/2016-08-27-pydata/#/&lt;/a&gt;&lt;/p&gt;
</summary><category term="keynote"></category></entry><entry><title>Keynote: Using Data Science for Social Good: Examples, Opportunities, and Challenges</title><link href="https://pyvideo.org/pydata-chicago-2016/keynote-using-data-science-for-social-good-examples-opportunities-and-challenges.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>Rayid Ghani</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/keynote-using-data-science-for-social-good-examples-opportunities-and-challenges.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
</summary><category term="Data"></category><category term="data science"></category><category term="science"></category></entry><entry><title>Mind the Gap! Bridging the pandas - scikit learn dtype divide</title><link href="https://pyvideo.org/pydata-chicago-2016/mind-the-gap-bridging-the-pandas-scikit-learn-dtype-divide.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>Tom Augspurger</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/mind-the-gap-bridging-the-pandas-scikit-learn-dtype-divide.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/TomAugspurger/mtg/blob/master/MTG.pdf"&gt;https://github.com/TomAugspurger/mtg/blob/master/MTG.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This talk briefly introduces the two different data models used by Scikit-Learn (NumPy arrays) and pandas DataFrames. We see why this can cause problems for users of these libraries. Finally, we discuss strategies for managing the differences.&lt;/p&gt;
</summary><category term="pandas"></category><category term="scikit"></category></entry><entry><title>Pyglmnet: A Python package for elastic net regularized generalized linear model</title><link href="https://pyvideo.org/pydata-chicago-2016/pyglmnet-a-python-package-for-elastic-net-regularized-generalized-linear-model.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>Pavan Ramkumar</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/pyglmnet-a-python-package-for-elastic-net-regularized-generalized-linear-model.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/pavanramkumar/pydata-chicago-2016"&gt;https://github.com/pavanramkumar/pydata-chicago-2016&lt;/a&gt;
Additional Tutorials: &lt;a class="reference external" href="https://pavanramkumar.github.io/pydata-chicago-2016/#1"&gt;https://pavanramkumar.github.io/pydata-chicago-2016/#1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pyglmnet: &lt;a class="reference external" href="https://github.com/pavanramkumar/pyglmnet"&gt;https://github.com/pavanramkumar/pyglmnet&lt;/a&gt;
Documentation &lt;a class="reference external" href="http://pavanramkumar.github.io/pyglmnet/"&gt;http://pavanramkumar.github.io/pyglmnet/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the era of big data, and high performance computing, generalized linear models (GLMs) have come to be widely applied across the sciences, economics, business, and finance. Although a popular R package exists, there is no equivalent in Python. I developed pyglmnet to address this need. In this talk, I will give a theoretical overview of GLMs and demonstrate the package with examples.&lt;/p&gt;
</summary><category term="pyglmnet"></category></entry><entry><title>What Data Analysts Wish Application Developers Knew</title><link href="https://pyvideo.org/pydata-chicago-2016/what-data-analysts-wish-application-developers-knew.html" rel="alternate"></link><published>2016-08-27T00:00:00+00:00</published><updated>2016-08-27T00:00:00+00:00</updated><author><name>Alison Stanton</name></author><id>tag:pyvideo.org,2016-08-27:pydata-chicago-2016/what-data-analysts-wish-application-developers-knew.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://speakerdeck.com/alison985/what-data-analysts-wish-application-developers-knew"&gt;https://speakerdeck.com/alison985/what-data-analysts-wish-application-developers-knew&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Data analysts frequently do not get to participate in the app development process despite being some of its biggest stakeholders. This talk focuses on general guidelines and best practices for application developers on what they can do to optimize data content and quality available for analysis.&lt;/p&gt;
</summary><category term="Data"></category></entry><entry><title>A Quickstart Guide to PyMC3</title><link href="https://pyvideo.org/pydata-chicago-2016/a-quickstart-guide-to-pymc3.html" rel="alternate"></link><published>2016-08-26T00:00:00+00:00</published><updated>2016-08-26T00:00:00+00:00</updated><author><name>Nicole Carlson</name></author><id>tag:pyvideo.org,2016-08-26:pydata-chicago-2016/a-quickstart-guide-to-pymc3.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/parsing-science/pymc3_quickstart_guide"&gt;https://github.com/parsing-science/pymc3_quickstart_guide&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;PyMC3 is a powerful relatively new library for probabilistic models. The developers have given multiple talks describing probabilistic models, Bayesian statistics, and the features of the library. This tutorial aims to complement these talks by providing a practical guide to using PyMC3 with step-by-step implementations of some basic models and some issues you might encounter.&lt;/p&gt;
</summary></entry><entry><title>Building a Recommendation Engine with Neo4j and Python</title><link href="https://pyvideo.org/pydata-chicago-2016/building-a-recommendation-engine-with-neo4j-and-python.html" rel="alternate"></link><published>2016-08-26T00:00:00+00:00</published><updated>2016-08-26T00:00:00+00:00</updated><author><name>Kevin Van Gundy</name></author><id>tag:pyvideo.org,2016-08-26:pydata-chicago-2016/building-a-recommendation-engine-with-neo4j-and-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="http://www.slideshare.net/secret/DwbGswbtHTmYvy"&gt;http://www.slideshare.net/secret/DwbGswbtHTmYvy&lt;/a&gt;
Github: github.com/kevinvangundy&lt;/p&gt;
&lt;p&gt;In this session we will show how to build a meetup.com recommendation engine using Neo4j and Python. Our solution will be a hybrid approach which makes uses of both content based and collaborative filtering using Neo4j to glue all the data together, Cypher to query the dataset and Python to do analysis and pre/post processing of data.&lt;/p&gt;
</summary><category term="neo4j"></category></entry><entry><title>Intro to Julia</title><link href="https://pyvideo.org/pydata-chicago-2016/intro-to-julia.html" rel="alternate"></link><published>2016-08-26T00:00:00+00:00</published><updated>2016-08-26T00:00:00+00:00</updated><author><name>Huda Nassar</name></author><id>tag:pyvideo.org,2016-08-26:pydata-chicago-2016/intro-to-julia.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;The Julia language has been increasingly used in the research community specially in areas related to data science. This tutorial aims at introducing attendees to Julia in the context of data science. This includes familiarizing the audience with the basics of Julia and illustrating the major differences with Python; also, going over writing Julia wrappers for other programming languages including&lt;/p&gt;
</summary><category term="julia"></category></entry><entry><title>Learning scikit learn - An Introduction to Machine Learning in Python</title><link href="https://pyvideo.org/pydata-chicago-2016/learning-scikit-learn-an-introduction-to-machine-learning-in-python.html" rel="alternate"></link><published>2016-08-26T00:00:00+00:00</published><updated>2016-08-26T00:00:00+00:00</updated><author><name>Sebastian Raschka</name></author><id>tag:pyvideo.org,2016-08-26:pydata-chicago-2016/learning-scikit-learn-an-introduction-to-machine-learning-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;This tutorial provides you with a comprehensive introduction to machine learning in Python using the popular scikit-learn library. We will learn how to tackle common problems in predictive modeling and clustering analysis that can be used in real-world problems, in business and in research applications. And we will implement certain algorithms as scratch as well, to internalize the inner workings&lt;/p&gt;
&lt;p&gt;This tutorial will teach you the basics of scikit-learn. We will learn how to leverage powerful algorithms from the two main domains of machine learning: supervised and unsupervised learning. In this talk, I will give you a brief overview of the basic concepts of classification and regression analysis, how to build powerful predictive models from labeled data. Furthermore, we will go over the basics of clustering analysis to discover hidden structures in unlabeled data. Although it's not a requirement for attending this tutorial, I highly recommend you to check out the accompanying GitHub repository at &lt;a class="reference external" href="https://github.com/rasbt/pydata-chicago2016-ml-tutorial"&gt;https://github.com/rasbt/pydata-chicago2016-ml-tutorial&lt;/a&gt; 1-2 days before the tutorial. During the session, we will not only talk about scikit-learn, but we will also go over some live code examples and code simple machine-learning algorithms from scratch to get the knack of scikit-learn's API.&lt;/p&gt;
</summary><category term="learning"></category><category term="machine learning"></category><category term="scikit"></category></entry><entry><title>Luigi &amp; Data Pipelines</title><link href="https://pyvideo.org/pydata-chicago-2016/luigi-data-pipelines.html" rel="alternate"></link><published>2016-08-26T00:00:00+00:00</published><updated>2016-08-26T00:00:00+00:00</updated><author><name>Hunter Owens</name></author><id>tag:pyvideo.org,2016-08-26:pydata-chicago-2016/luigi-data-pipelines.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/hunterowens/data-pipelines"&gt;https://github.com/hunterowens/data-pipelines&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You need a data pipeline. This talk will discuss the lifecycle of projects using Jupyter notebooks &amp;amp; Luigi as a data pipeline management tool for a variety of projects, from greenfield to retrofitting complex systems. It will included a hands on demo.&lt;/p&gt;
</summary><category term="Data"></category></entry><entry><title>Pandas: .head() to .tail()</title><link href="https://pyvideo.org/pydata-chicago-2016/pandas-head-to-tail.html" rel="alternate"></link><published>2016-08-26T00:00:00+00:00</published><updated>2016-08-26T00:00:00+00:00</updated><author><name>Tom Augspurger</name></author><id>tag:pyvideo.org,2016-08-26:pydata-chicago-2016/pandas-head-to-tail.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/TomAugspurger/pydata-chi-h2t"&gt;https://github.com/TomAugspurger/pydata-chi-h2t&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;An introduction to using pandas for data analysis.  Please clone the repository and follow the setup before arriving.&lt;/p&gt;
</summary></entry><entry><title>Pomegranate: fast and flexible probabilistic models in python</title><link href="https://pyvideo.org/pydata-chicago-2016/pomegranate-fast-and-flexible-probabilistic-models-in-python.html" rel="alternate"></link><published>2016-08-26T00:00:00+00:00</published><updated>2016-08-26T00:00:00+00:00</updated><author><name>Jacob Schreiber</name></author><id>tag:pyvideo.org,2016-08-26:pydata-chicago-2016/pomegranate-fast-and-flexible-probabilistic-models-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="http://www.slideshare.net/secret/cxZTghInOlIeOs"&gt;http://www.slideshare.net/secret/cxZTghInOlIeOs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;pomegranate is a python module for probabilistic modelling focusing on both ease of use and speed, beating out competitors, including scikit-learn, in benchmarks. In this talk I will describe how to use pomegranate to simply create sophisticated hidden Markov models, Bayesian Networks, General Mixture Models (and more!) and benchmark their implementations to other python packages.&lt;/p&gt;
</summary><category term="models"></category></entry><entry><title>Popping Kernels: An Exploration of Kernel Development for Jupyter Notebooks</title><link href="https://pyvideo.org/pydata-chicago-2016/popping-kernels-an-exploration-of-kernel-development-for-jupyter-notebooks.html" rel="alternate"></link><published>2016-08-26T00:00:00+00:00</published><updated>2016-08-26T00:00:00+00:00</updated><author><name>Safia Abdalla</name></author><id>tag:pyvideo.org,2016-08-26:pydata-chicago-2016/popping-kernels-an-exploration-of-kernel-development-for-jupyter-notebooks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;This talk will give individuals with no kernel experience and some Python experience, a brief introduction to the concepts they need to understand in order to develop kernels. This talk will also be useful to individuals who are looking for fun projects that will allow them to strengthen their skills in a particular programming language.&lt;/p&gt;
</summary><category term="development"></category><category term="jupyter"></category><category term="jupyter notebook"></category></entry><entry><title>Using Dask for Parallel Computing in Python</title><link href="https://pyvideo.org/pydata-chicago-2016/using-dask-for-parallel-computing-in-python.html" rel="alternate"></link><published>2016-08-26T00:00:00+00:00</published><updated>2016-08-26T00:00:00+00:00</updated><author><name>Skipper Seabold</name></author><id>tag:pyvideo.org,2016-08-26:pydata-chicago-2016/using-dask-for-parallel-computing-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Dask is a relatively new library for parallel computing in Python. It builds around familiar data structures to users of the PyData stack and enables them to scale up their work on one or many machines. This tutorial will introduce users to the core concepts of dask by working through some example problems. The tutorial will be distributed via Jupyter Notebooks.&lt;/p&gt;
</summary><category term="dask"></category><category term="parallel"></category><category term="parallel computing"></category></entry></feed>