<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_catherine-holloway.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2017-10-07T00:00:00+00:00</updated><entry><title>Snooping on Digital Electronics with Machine Learning</title><link href="https://pyvideo.org/florida-pycon-2017/snooping-on-digital-electronics-with-machine-learning.html" rel="alternate"></link><published>2017-10-07T00:00:00+00:00</published><updated>2017-10-07T00:00:00+00:00</updated><author><name>Catherine Holloway</name></author><id>tag:pyvideo.org,2017-10-07:florida-pycon-2017/snooping-on-digital-electronics-with-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Ever wondered what the chips in your electronics are saying? I trained a
classifier that can decode signals based on their tapped-in oscilloscope
voltage traces. Assuming no knowledge of machine learning, I’ll cover
which classifiers worked and which didn’t, and demonstrate some
snooping.&lt;/p&gt;
</summary></entry><entry><title>Simplifying Computer Art in Python</title><link href="https://pyvideo.org/europython-2016/simplifying-computer-art-in-python.html" rel="alternate"></link><published>2016-08-04T00:00:00+00:00</published><updated>2016-08-04T00:00:00+00:00</updated><author><name>Catherine Holloway</name></author><id>tag:pyvideo.org,2016-08-04:europython-2016/simplifying-computer-art-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Catherine Holloway - Simplifying Computer Art in Python
[EuroPython 2016]
[21 July 2016]
[Bilbao, Euskadi, Spain]
(&lt;a class="reference external" href="https://ep2016.europython.eu//conference/talks/simplifying-computer-art-in-python"&gt;https://ep2016.europython.eu//conference/talks/simplifying-computer-art-in-python&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;The Processing project demonstrated that computer art can attract a
wider audience to programming. Python has a robust catalog of
libraries, including two interfaces to OpenGL. However, none of these
libraries replicate Processing’s simplicity when drawing to the
screen. I will present my solution to this problem: a re-
implementation of VPython’s visual module purely in python called
PygletHelper.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Processing is a programming language originally developed by the MIT
media lab with the goal of allowing artists, educators, and many
others develop striking computer generated or assisted projects
without requiring deep knowledge of software engineering or computer
graphics. Like Processing, Python has become a favourite language of
users from diverse backgrounds, such as web development, education,
and science. Unlike Processing, python lacks a simple and easy to use
library for drawing shapes. Python’s existing libraries for scientific
computing and data analysis could be made even more awesome when
combined with a simple drawing library.&lt;/p&gt;
&lt;p&gt;VPython contains a module called visual that established a simple API
and convention for drawing shapes, however it was written in C++,
prior to the development of pyglet, and thus is not entirely cross-
platform. In this talk, I will demonstrate my solution to this
problem: a re-implementation of visual purely in Python called
PygletHelper. Pyglet, an existing python library, provides a python
interface to OpenGL. PygletHelper is built on pyglet but obscures all
of the OpenGL calls, such that the user can draw simple geometric
shapes to the screen and animate them without needing to know about
computer graphics terminology, memory usage, or C data types.&lt;/p&gt;
&lt;p&gt;I will also show some need visualizations of science and music in my
talk, as well as the graphical glitches encountered implementing the
library.&lt;/p&gt;
</summary></entry><entry><title>3D Drawing in Python: Reviving Visual</title><link href="https://pyvideo.org/scipy-2016/3d-drawing-in-python-reviving-visual-scipy-2016-catherine-holloway.html" rel="alternate"></link><published>2016-07-15T00:00:00+00:00</published><updated>2016-07-15T00:00:00+00:00</updated><author><name>Catherine Holloway</name></author><id>tag:pyvideo.org,2016-07-15:scipy-2016/3d-drawing-in-python-reviving-visual-scipy-2016-catherine-holloway.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In 2000 David Scherer created Visual, a python package with a simple interface for drawing 3D objects to the screen. Visual abstracted away calls to OpenGL vertex drawing, textures, and transformations, and allowed primitive geometric objects to be placed on the screen in an intuitive manner. Visual was subsequently adopted by many researchers and university instructors, primarily in physics, to visualize scientific results and simulation assignments. The original Visual module used C++ to make OpenGL calls, and compatibility with Linux was never implemented. Python and OpenGL have come a long way in the past sixteen years, and now Visual can be made cross-platform by removing the C++ backend. I will present my attempt to re-implement Visual using pyglet, as well as demonstrate its API and usage in education and research visualization.&lt;/p&gt;
</summary><category term="SciPy 2016"></category></entry><entry><title>Data mining robots: using Seaborn and pandas with the Robot Operating System</title><link href="https://pyvideo.org/pycon-ca-2015/data-mining-robots-using-seaborn-and-pandas-with.html" rel="alternate"></link><published>2015-11-07T00:00:00+00:00</published><updated>2015-11-07T00:00:00+00:00</updated><author><name>Catherine Holloway</name></author><id>tag:pyvideo.org,2015-11-07:pycon-ca-2015/data-mining-robots-using-seaborn-and-pandas-with.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;PyCon Canada 2015:&lt;/p&gt;
&lt;p&gt;Talk Description:
The Robot Operating System (ROS) is an open-source project that facilitates communication between robotic components such as motors, cameras, and other sensors, and computational nodes such as movement commands and pose estimation. However, acquiring and analysing data from ROS can be a little tricky. In this talk, I will go over a few examples of loading data from saved files and live ROS processes using Python with the pandas and Seaborn libraries.&lt;/p&gt;
</summary></entry></feed>