<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Thu, 05 Dec 2019 00:00:00 +0000</lastBuildDate><item><title>Accelerate your NumPy Data Science Workloads and Deep Learning Applications</title><link>https://pyvideo.org/pydata-la-2019/accelerate-your-numpy-data-science-workloads-and-deep-learning-applications.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, we’ll cover creation of a multilayer perceptron model
using gluon and MXNet’s new NumPy-compatible functions, a port of the
classic NumPy with GPU accelerations and additional features for deep
learning.&lt;/p&gt;
&lt;p&gt;All the code snippets shown during the talk are available at
&lt;a class="reference external" href="https://github.com/haojin2/PyData-LA-Demo"&gt;https://github.com/haojin2/PyData-LA-Demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Diving into deep learning requires understanding bulky new frameworks,
which significantly increases the adoption curve for data scientists in
industry. In this talk, we’ll cover creation of a multilayer perceptron
model using gluon and MXNet’s new NumPy-compatible functions, a port of
the classic NumPy with GPU accelerations and additional features for
deep learning. These open source tools will give you a working
foundation for building out more complicated models for real
applications with faster performance and less hassle.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Hao Jin</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/accelerate-your-numpy-data-science-workloads-and-deep-learning-applications.html</guid></item><item><title>AI meets Fashion for product retrieval with multi-modally generated data</title><link>https://pyvideo.org/pydata-la-2019/ai-meets-fashion-for-product-retrieval-with-multi-modally-generated-data.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The talk will cover generative modeling for multimodal input (image and
text) in the context of product retrieval in fashion/e-commerce.&lt;/p&gt;
&lt;p&gt;The presentation will include examples of applying generative (GAN)
architectures for image generation with multimodal query using models
derived from Conditional GAN, StackGAN, AttnGAN and others.&lt;/p&gt;
&lt;p&gt;Retrieving products from large databases and finding items of particular
interest for the user is a topic of ongoing research. Moving further
from text search, tag based search and image search, there is still a
lot of ambiguity when visual and textual features need to be merged.
Text query might compliment an image (&amp;quot;I want sport shoes like these in
the image, produced by XXX, wide fit and comfortable&amp;quot;) or might
represent a difference from image query (&amp;quot;I want a dress like that in
the picture, only with shorter sleeves&amp;quot;).&lt;/p&gt;
&lt;p&gt;Talk outline:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Use cases in e-commerce and fashion&lt;/li&gt;
&lt;li&gt;Current methods for learning multimodal embedding (VSE, Multimodal
Siamese Networks)&lt;/li&gt;
&lt;li&gt;Intro to GAN architectures that take latent representation as an
input (we can influence what we generate, yeah!)&lt;/li&gt;
&lt;li&gt;How do you feed multimodal input into GAN&lt;/li&gt;
&lt;li&gt;Results and comparison&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ivona Tautkute</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/ai-meets-fashion-for-product-retrieval-with-multi-modally-generated-data.html</guid></item><item><title>Build an AI-powered Pet Detector in Visual Studio Code</title><link>https://pyvideo.org/pydata-la-2019/build-an-ai-powered-pet-detector-in-visual-studio-code.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Ever wondered what breed that dog or cat is? Let’s build a pet detector
service to recognize them in pictures!&lt;/p&gt;
&lt;p&gt;Ever wondered what breed that dog or cat is? Let’s build a pet detector
service to recognize them in pictures! In this talk, we will walk
through the training, optimizing, and deploying of a deep learning model
by using VS Code and the Azure Machine Learning service. We will use
transfer learning to recognize dog and cat breeds. Next, we’ll optimize
the model using Azure Machine Learning service to improve the model
accuracy. Putting on our developer hat, we'll then refactor the
notebooks into Python modules using VS Code. Finally, we will deploy the
model as a web service in Azure, all from the comforts of VS Code. Come
to see how Azure and VS Code makes AI and machine learning development
and deployment easy.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jeffrey Mew</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/build-an-ai-powered-pet-detector-in-visual-studio-code.html</guid></item><item><title>Building Named Entity Recognition Models Efficiently using NERDS</title><link>https://pyvideo.org/pydata-la-2019/building-named-entity-recognition-models-efficiently-using-nerds.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Named Entity Recognition (NER) is foundational for many downstream NLP
tasks. The Open Source NERDS toolkit provides algorithms that can be
used to quickly build and evaluate NER models from labeled data such as
IOB. New algorithms can be added with minimal effort. This presentation
will demonstrate how to create and evaluate new NER models using NERDS,
as well as add new NER algorithms to it.&lt;/p&gt;
&lt;p&gt;Named Entity Recognition (NER) is foundational for many downstream NLP
tasks such as Information Retrieval, Relation Extraction, Question
Answering, and Knowledge Base Construction. While many high-quality
pre-trained NER models exist, they usually cover a small subset of
popular entities such as people, organizations, and locations. But what
if we need to recognize domain specific entities such as proteins,
chemical names, diseases, etc? The Open Source Named Entity Recognition
for Data Scientists (NERDS) toolkit, from the Elsevier Data Science
team, was built to address this need.&lt;/p&gt;
&lt;p&gt;NERDS aims to speed up development and evaluation of NER models by
providing a set of NER algorithms that are callable through the familiar
scikit-learn style API. The uniform interface allows reuse of code for
data ingestion and evaluation, resulting in cleaner and more
maintainable NER pipelines. In addition, customizing NERDS by adding new
and more advanced NER models is also very easy, just a matter of
implementing a standard NER Model class.&lt;/p&gt;
&lt;p&gt;Our presentation will describe the main features of NERDS, then walk
through a demonstration of developing and evaluating NER models that
recognize biomedical entities. We will then describe a Neural Network
based NER algorithm (a Bi-LSTM seq2seq model written in Pytorch) that we
will then integrate into the NERDS NER pipeline.&lt;/p&gt;
&lt;p&gt;We believe NERDS addresses a real need for building domain specific NER
models quickly and efficiently. NER is an active field of research, and
the hope is that this presentation will spark interest and contributions
of new NER algorithms and Data Adapters from the community that can in
turn help to move the field forward.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sujit Pal</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/building-named-entity-recognition-models-efficiently-using-nerds.html</guid></item><item><title>Carol Willing: Keynote</title><link>https://pyvideo.org/pydata-la-2019/carol-willing-keynote.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;www.pydata.org&lt;/p&gt;
&lt;p&gt;PyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R.&lt;/p&gt;
&lt;p&gt;PyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Carol Willing</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/carol-willing-keynote.html</guid></item><item><title>Datasets and machine learning models versioning using open source tools</title><link>https://pyvideo.org/pydata-la-2019/datasets-and-machine-learning-models-versioning-using-open-source-tools.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;AI and ML are becoming an essential part of software engineering. Open
source tools like Git, Git-LFS, MlFlow can increase ML teams
productivity by introducing best practices. However, large datasets
management and versioning are not covered by these tools. We will show
how to overcome the limitations of the tools by using DVC.org - an
open-source project for ML models and datasets versioning.&lt;/p&gt;
&lt;p&gt;AI and ML are becoming an essential part of software engineering. The
traditional engineering toolset does not fully cover machine learning
team's needs. The teams need new tools for data versioning, ML pipeline
versioning, ML model versioning, experiments metrics tracking, and
others.&lt;/p&gt;
&lt;p&gt;ML workflow is data-centric while software engineering workflow is
centered around source code. We will discuss the current practices of
organizing ML projects using open-source tools like Git, Git-LFS, MlFlow
as well as their limitations. Thereby motivation for developing new ML
specific data versioning systems will be explained.&lt;/p&gt;
&lt;p&gt;Data Version Control or DVC.ORG is an open-source command-line tool. We
will show how to version ML models and multi-gigabyte datasets, how to
use your favorite cloud storage (S3, Google Cloud Storage, or bare metal
SSH server) as a data file backend, how to apply the best engineering
practices to your ML projects and how to combine the different tools in
the same project.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dmitry Petrov</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/datasets-and-machine-learning-models-versioning-using-open-source-tools.html</guid></item><item><title>Dynamic programming for machine learning: Hidden Markov Models</title><link>https://pyvideo.org/pydata-la-2019/dynamic-programming-for-machine-learning-hidden-markov-models.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dynamic programming turns up in many machine learning algorithms, maybe
because dynamic programming excels at solving problems involving
&amp;quot;non-local&amp;quot; information. I explore one technique used in machine
learning, Hidden Markov Models, and how dynamic programming is used when
applying this technique. Then, I'll show a few real-world examples where
Hidden Markov Models are used.&lt;/p&gt;
&lt;p&gt;A Hidden Markov Model deals with inferring the state of a system given
some unreliable or ambiguous observations from that system. One
important characteristic of this system is the state of the system
evolves over time, producing a sequence of observations along the way.
By incorporating some domain-specific knowledge, it’s possible to take
the observations and work backwards to a maximally plausible ground
truth.&lt;/p&gt;
&lt;p&gt;This talk explores Hidden Markov Models in three steps:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;First, I define Hidden Markov Models and how they apply to machine
learning problems.&lt;/li&gt;
&lt;li&gt;Next, I build up an understanding of the Viterbi algorithm, used to
infer the state of the system given a sequence of observations. This
involves some basic math, but the goal is to form an intuition for
the algorithm. Some sample Python code is presented to demonstrate
how simple the algorithm is.&lt;/li&gt;
&lt;li&gt;Finally, I introduce several real-world applications of Hidden Markov
Models in machine learning. In this section, real-world
considerations like feature extraction and training are discussed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Basic math knowledge is expected, just the ability to express concepts
as equations and an understanding of Big-O notation. Basic Python
knowledge is also expected, as code samples will be presented. The goal
is build up intuition.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://avikdas.com/2019/06/24/dynamic-programming-for-machine-%20learning-hidden-markov-models.html"&gt;The content of this talk is available as an article on my personal
blog.&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Avik Das</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/dynamic-programming-for-machine-learning-hidden-markov-models.html</guid></item><item><title>Fitting Many Dimensions into One: The Promise of Hierarchical Indices for Data Beyond Two Dimensions</title><link>https://pyvideo.org/pydata-la-2019/fitting-many-dimensions-into-one-the-promise-of-hierarchical-indices-for-data-beyond-two-dimensions.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Recent versions of Pandas have warned users of the imminent deprecation
of the Panel, Panda’s name-sake data structure for storing
three-dimensional data. This talk will examine the tradeoffs in
performance and interface between two types of Panel alternatives: using
hierarchical indices in Pandas and StaticFrame, or using true
n-dimensional arrays in NumPy or xarray.&lt;/p&gt;
&lt;p&gt;This talk will aid those working in data science and related fields by
examining the tradeoffs between working with data in true
multidimensional data structures (i.e., NumPy and xarray) versus working
with hierarchical index implementations on one- or two-dimensional data.&lt;/p&gt;
&lt;p&gt;The immediate point of departure is Pandas imminent deprecation of the
Panel: for Pandas users who have used the Panel, this talk will
illustrate how to transition away from the Panel and the tradeoffs in
Panel alternatives.&lt;/p&gt;
&lt;p&gt;This talk will explain how hierarchical indices work by comparing two
implementations: the Pandas MultiIndex and the StaticFrame
IndexHierarchy. The StaticFream IndexHierarchy offers a new, independent
implementation of hierarchical indices that deviates from Pandas in
significant ways: the index is literally composed of other index
objects, permitting usage of specialized index types (such as datetime
indices), efficient memory usage of shared immutable objects, and the
enforcement of a strict tree graph.&lt;/p&gt;
&lt;p&gt;After demonstrating how hierarchical indices can support higher
dimensional data in one or two-dimensional arrays, the power and
flexibility of selecting and slicing data with hierarchical indices will
be demonstrated.&lt;/p&gt;
&lt;p&gt;The talk will close with performance analysis, isolating the overhead of
using hierarchical indices over true multi-dimensional array
representations, and comparing the performance of selection, slicing,
grouping, and function application of hierarchical data in NumPy,
xarray, Pandas and StaticFrame.&lt;/p&gt;
&lt;p&gt;This talk is aimed at both beginners, new to hierarchical indices, and
more advanced users interested in interface design and performance
tradeoffs. Basic familiarity with NumPy and Pandas is expected. Audience
members will leave with a better understanding of how hierarchical
indices work, and what tradeoffs are made when using them.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Christopher Ariza</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/fitting-many-dimensions-into-one-the-promise-of-hierarchical-indices-for-data-beyond-two-dimensions.html</guid></item><item><title>IBM Code and Response: Open Sourcing Natural Disaster Preparedness and Relief</title><link>https://pyvideo.org/pydata-la-2019/ibm-code-and-response-open-sourcing-natural-disaster-preparedness-and-relief.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will provide an overview of the past few years of Call for
Code and introduce IBM Code and Response, IBM's effort to enable,
deploy, and create innovative solutions to reduce the impact of natural
disasters through open source.&lt;/p&gt;
&lt;p&gt;Natural disasters are among the world's greatest challenges, and have
devastating effects both locally, from the many fires that have occurred
in Southern and Northern California (over 17 million acres of land have
been lost to wildfire in the US in the last 2 years), and globally. IBM,
with help a large partnership group including the United Nations and
American Red Cross, developed Call for Code, a global contest
challenging developers to build technologies to aide those going through
adversity. This talk will provide an overview of the past few years of
Call for Code and introduce IBM Code and Response, IBM's effort to
enable, deploy, and create innovative solutions to reduce the impact of
natural disasters through open source. The talk will also highlight some
novel ways developers have used Python in order to accomplish these
goals.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Nick Acosta</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/ibm-code-and-response-open-sourcing-natural-disaster-preparedness-and-relief.html</guid></item><item><title>Machine Learning Model Evaluation Metrics</title><link>https://pyvideo.org/pydata-la-2019/machine-learning-model-evaluation-metrics.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Choosing the right evaluation metric for your machine learning project
is crucial, as it decides which model you’ll ultimately use. How do you
choose an appropriate metric? This talk will explore the important
evaluation metrics used in regression and classification tasks, their
pros and cons, and how to make a smart decision.&lt;/p&gt;
&lt;p&gt;In this talk, we'll go through evaluation metrics for regression tasks
(R squared, MAE, MSE, RMSE, and RMSLE) and classification tasks
(Classification accuracy, Precision, Recall, F1 Score, ROC/AUC,
Precision/Recall AUC, Matthews Correlation Coefficient, and ways to
extend some of these from binary to multiclass problems). I'll talk
about the differences between them, the trade- offs, and when some may
be more helpful than others.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Maria Khalusova</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/machine-learning-model-evaluation-metrics.html</guid></item><item><title>MAP all the things</title><link>https://pyvideo.org/pydata-la-2019/map-all-the-things.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Embedding techniques like word2vec and doc2vec are taking over the
world. An up and coming technique for embedding numeric data is UMAP.
How would you go about applying UMAP to real word data? How about text
data? What about malware? In this talk we’ll learn how to MAP all the
things!&lt;/p&gt;
&lt;p&gt;Embedding techniques are taking over the world. From word2vec to embed
words, all the way to Latent Dirichlet Allocation and doc2vec to embed
documents. All these techniques are really about turning non-numeric
data into vector space data suitable for either machine learning or
visualization. An up and coming technique for embedding numeric data is
&lt;a class="reference external" href="https://github.com/lmcinnes/umap"&gt;UMAP&lt;/a&gt;. How would you go about
applying UMAP to word data? How about text data? What about malware? In
this talk we’ll learn how to MAP all the things!&lt;/p&gt;
&lt;p&gt;We’ll introduce you to a new technique called WordMAP for generating
very low dimensional word embeddings by making use of UMAP. With this
technique in hand one can generalize to a document embedding algorithm
we're calling DocMAP. This approach ultimately only requires sequences
of tokens and thus can apply to much broader classes of problems. We’ll
demonstrate this by applying a variation of DocMAP to the problem of
mapping the space of malware based on it’s behaviour.&lt;/p&gt;
&lt;p&gt;While the math behind UMAP might be challenging to some this talk will
focus more on how to apply it in novel situations and take a more
practical approach to things. If you have problems that can fit in this
framework you should come and learn how to MAP all the things!&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">John Healy</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/map-all-the-things.html</guid></item><item><title>Modeling Search Term Revenue: Using Embedding Layers to Manage High Cardinality Categorical Data</title><link>https://pyvideo.org/pydata-la-2019/modeling-search-term-revenue-using-embedding-layers-to-manage-high-cardinality-categorical-data.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At System1, data scientists are faced with the task of predicting
revenue and cost per click across millions of unique keywords that drive
traffic to our sites or monetize on a pay per click basis. This talk
will show a variety of techniques we use to extract the most information
from categorical variables, especially anonymized, sparse, high
cardinality categorical variables, like search terms.&lt;/p&gt;
&lt;p&gt;Categorical variables are easily interpretable by data scientists and
non- technical people, but they can also be difficult to translate into
machine learning algorithms. Categorical variables need to be converted
to quantitative values to be used in machine learning models and can
very quickly explode the feature space of a model, add noise or
unintended signals to the data, or simply not include all the meaning
and predictive power that feature provides for the dependent variable.
There are many popular and effective libraries that abstract categorical
variable feature creation. However, if a model is sensitive from a
financial, data ethics, or some level of public visibility standpoint,
or simply prone to overfitting, it is vital to understand how the model
is capturing all features and how to tune model parameters or input
data. Furthermore, if dealing with personal or sensitive data, machines
need to be able to handle anonymized categories while still allowing a
human to interpret the source data. One of the problems we face at
System1 is that individual keywords can receive very little traffic,
sometimes less than a click per day; however, across millions of
keywords, these long- tail keywords comprise significant revenue.
Furthermore, data science models need to be proactive and adjust bids
and traffic based on seasonal components even if there is no data from
the prior season. This talk will present a variety of practical
techniques to extract and retain information and predictive power for
categorical variables. We will talk about model selection, feature
creation and techniques for converting categorical variables to
quantitative values for modeling. Finally, the talk will present an
interesting technique that utilizes embedding layers and transfer
learning in a neural network framework to predict cost per click values
on search terms.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Fletcher Riehl</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/modeling-search-term-revenue-using-embedding-layers-to-manage-high-cardinality-categorical-data.html</guid></item><item><title>Open Source is Better Together: GPU Python Libraries Unite</title><link>https://pyvideo.org/pydata-la-2019/open-source-is-better-together-gpu-python-libraries-unite.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Today, the computational limits of CPUs are being realized, and GPUs are
being utilized to satisfy the compute demands of users. In the past,
this has meant low level programming in C/C++, but today there is a rich
ecosystem of open source software with Python APIs and interfaces. This
talk will highlight the journey of developing open source software on
top of and integrating with this ecosystem.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;PyData Ecosystem&lt;ul&gt;
&lt;li&gt;Pandas, Numpy, SciPy, SKLearn, Dask, Cython, etc.&lt;/li&gt;
&lt;li&gt;Highly interoperable with everything standardizing around Numpy /
Pandas&lt;/li&gt;
&lt;li&gt;Highly productive&lt;/li&gt;
&lt;li&gt;Compute limited&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Apache Big Data Ecosystem&lt;ul&gt;
&lt;li&gt;Spark, Beam, Flink, Hive, Impala, etc.&lt;/li&gt;
&lt;li&gt;Semi interoperable but very technology dependent&lt;/li&gt;
&lt;li&gt;Semi productive&lt;/li&gt;
&lt;li&gt;Still compute limited&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GPUs&lt;ul&gt;
&lt;li&gt;Thrust, CUB, NCCL, OpenUCX, etc.&lt;/li&gt;
&lt;li&gt;Not very interoperable&lt;/li&gt;
&lt;li&gt;Not productive&lt;/li&gt;
&lt;li&gt;Not compute limited!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Apache Arrow&lt;ul&gt;
&lt;li&gt;Standards for memory layouts&lt;/li&gt;
&lt;li&gt;Cross language compatible&lt;/li&gt;
&lt;li&gt;Potential to bridge the PyData, Apache Big Data, and GPU
ecosystems!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RAPIDS&lt;ul&gt;
&lt;li&gt;Combining the compute of GPUs with the productivity of the PyData
ecosystem with the integration and interoperability of Apache
Arrow&lt;/li&gt;
&lt;li&gt;Built on top of OSS C/C++ GPU Ecosystem: Thrust, CUB, NCCL,
OpenUCX&lt;/li&gt;
&lt;li&gt;Integrated with OSS Python GPU Ecosystem: Numba, CuPy, PyTorch&lt;/li&gt;
&lt;li&gt;Built on top of and integrated with OSS PyData Ecosystem: Pandas,
Numpy, Dask, Cython&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ecosystem Interoperability&lt;ul&gt;
&lt;li&gt;Standards / Protocols&lt;/li&gt;
&lt;li&gt;Numpy &lt;tt class="docutils literal"&gt;__array_function__&lt;/tt&gt; protocol&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;__cuda_array_interface__&lt;/tt&gt; protocol&lt;/li&gt;
&lt;li&gt;DLPack&lt;/li&gt;
&lt;li&gt;User Experience&lt;/li&gt;
&lt;li&gt;Follow the same Python APIs that users are comfortable,
productive, and happy with&lt;/li&gt;
&lt;li&gt;Performance&lt;/li&gt;
&lt;li&gt;Deliver 10-1000x the performance with nearly zero code change&lt;/li&gt;
&lt;li&gt;Scaling&lt;/li&gt;
&lt;li&gt;Scale the same way as existing PyData ecosystem with Dask&lt;/li&gt;
&lt;li&gt;Improve Dask for everyone with lower level communication
acceleration&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Struggles&lt;ul&gt;
&lt;li&gt;CI&lt;/li&gt;
&lt;li&gt;Travis-CI doesn’t cut it for GPUs and no easy to use off the shelf
alternative&lt;/li&gt;
&lt;li&gt;Programming Paradigm Mindset&lt;/li&gt;
&lt;li&gt;Thinking in terms of vectorized operations instead of loops /
iterations&lt;/li&gt;
&lt;li&gt;Amdahl’s Law&lt;/li&gt;
&lt;li&gt;New bottlenecks that we didn’t previously worry about&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Conclusion&lt;/li&gt;
&lt;li&gt;Q/A&lt;/li&gt;
&lt;/ol&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dante Gama Dessavre</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/open-source-is-better-together-gpu-python-libraries-unite.html</guid></item><item><title>Preparing messy data for supervised learning with vtreat</title><link>https://pyvideo.org/pydata-la-2019/preparing-messy-data-for-supervised-learning-with-vtreat.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Cleaning messy data is a necessary component of data science projects.
The vtreat package automates common data preparation steps for
supervised machine learning. In this talk, we will introduce vtreat and
demonstrate its effective use with Pandas and xgboost on real-world
data.&lt;/p&gt;
&lt;p&gt;Data characterization, treatment, and cleaning are necessary (though not
always glamorous) components of machine learning and data science
projects. While there is no substitute for getting your hands dirty in
the data, there are many data issues that repeat from project to
project. In particular, there are pitfalls in properly dealing with
missing data values, previously unobserved categorical values, and
high-cardinality categorical variables.&lt;/p&gt;
&lt;p&gt;In this talk, we will discuss using the vtreat package to prepare data
for supervised machine learning. We will demonstrate vtreat on a
real-world data set, with xgboost and Pandas. Vtreat automates the
statistically sound treatment of common data problems, leaving the data
scientist free to concentrate on problem-specific data and modeling
issues.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">John Mount</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/preparing-messy-data-for-supervised-learning-with-vtreat.html</guid></item><item><title>RAPIDS: Open Source GPU Data Science</title><link>https://pyvideo.org/pydata-la-2019/rapids-open-source-gpu-data-science.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;See how RAPIDS and the open source ecosystem are advancing data science.
In this session, we will explore RAPIDS, the open source data science
platform from NVIDIA. Come learn how to get started leveraging these
open-source libraries for faster performance and easier development on
GPUs. See the latest engineering work and new release features,
including benchmarks and software development roadmap&lt;/p&gt;
&lt;p&gt;The RAPIDS suite of open source software libraries gives the data
scientist the freedom to execute end-to-end data science and analytics
pipelines on GPUs. RAPIDS is incubatedby NVIDIA based on years of
accelerated analytics experience. RAPIDS relies on NVIDIA CUDA
primitives for low-level compute optimization and exposes GPU
parallelism and high-bandwidth memory speed through user-friendly Python
interfaces. Through a familiar DataFrame API that integrates with a
variety of machine learning algorithms, RAPIDS facilitates common data
preparations tasks while removing typical serialization costs. RAPIDS
includes support for multi-GPU deployments, enabling vastly accelerated
processing and training on large dataset sizes.&lt;/p&gt;
&lt;p&gt;Join NVIDIA’s engineers as they walk through a collection of data
science problems that introduce components and features of RAPIDS,
including: feature engineering, data manipulation, statistical tasks,
machine learning, and graph analysis.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brad Rees</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/rapids-open-source-gpu-data-science.html</guid></item><item><title>Sameer Singh: Keynote | PyData LA 2019</title><link>https://pyvideo.org/pydata-la-2019/sameer-singh-keynote-pydata-la-2019.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;www.pydata.org&lt;/p&gt;
&lt;p&gt;PyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R.&lt;/p&gt;
&lt;p&gt;PyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sameer Singh</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/sameer-singh-keynote-pydata-la-2019.html</guid></item><item><title>Simplicity For Scale: Analyzing 15 Million DNA Samples With Python</title><link>https://pyvideo.org/pydata-la-2019/simplicity-for-scale-analyzing-15-million-dna-samples-with-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When confronted with large-scale data challenges, we often reach for
complex tools to help solve the problem. In the past 7 years, Ancestry
DNA has amassed the largest collection of consumer genomic data in the
world, creating a new scaling challenge in the genomics world. We'll
show how picking simple tools in the Python ecosystem helped us solve
massive scaling challenges in production.&lt;/p&gt;
&lt;p&gt;With data sets growing larger by the day, and the number of big-data
tools growing right along with them, it can be daunting to select the
right tool for the job. Sometimes, too, it's tempting to apply the
latest-and-greatest ones to the problems we're working on. But, more
often than not, the simplest tool is the right one and, fortunately for
us, that's where Python shines.&lt;/p&gt;
&lt;p&gt;In a short 7 years, Ancestry has collected nearly 15 million DNA
samples. Data of this magnitude has proved to be a massive scaling
challenge for the production pipeline that must analyze that data set to
produce customer results every single day. This talk will tell the story
of how that pipeline has evolved over the years, from a manual command
line process, to a scheduled Hadoop pipeline, and finally into the
Python-based, event-driven system we use today.&lt;/p&gt;
&lt;p&gt;The talk will give a basic overview of our DNA test and cover our core
relative detection and ethnicity algorithms at a high level. I'll then
dive into the constraints and specific challenges the pipeline presents,
and how we decided to leverage Python &amp;amp; Celery to solve those problems.
Lastly, I'll describe the benefits of switching to Python, demonstrating
the simplicity, performance, and reduction in code it provided.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tim Orme</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/simplicity-for-scale-analyzing-15-million-dna-samples-with-python.html</guid></item><item><title>Tackling Homelessness with Open Data</title><link>https://pyvideo.org/pydata-la-2019/tackling-homelessness-with-open-data.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Volunteer data scientists have converted 5 years of data about sheltered
homeless people in Downtown San Diego from hand-marked paper maps to a
detailed geographic dataset, using a combination of machine vision
tools, Python programs and manual work. This talk will review how we
created the dataset and how we are working with government and
universities to use the dataset to inform social policy.&lt;/p&gt;
&lt;p&gt;For the last 7 years, the &lt;a class="reference external" href="https://downtownsandiego.org/"&gt;Downtown San Diego
Partnership&lt;/a&gt; has been conducting
monthly counts of homeless in the Downtown neighborhood. The data is
recorded on paper maps, which are &lt;a class="reference external" href="https://downtownsandiego.org/wp-%20content/uploads/2019/02/January-2019-Unsheltered-Homeless-Sleep-Count-Web-%20Version-Final-003.pdf"&gt;compiled into a
spreadsheet.&lt;/a&gt;
This is a fantastic dataset which would be even more useful if the
hand-recorded paper maps were digitized. This project involves
collecting and digitizing 5 years of the monthly maps, to produce a
geographic dataset, whcih we will analyze for time trends and for the
association between homeess movements, geography and the built
environment.&lt;/p&gt;
&lt;p&gt;This talk is suitable for people with an interest in using data to solve
social issues any level of skill.&lt;/p&gt;
&lt;p&gt;This talk will:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Describe the scope of the homeless problem in San Diego and present
the opportunities for data science to inform homeless policy.&lt;/li&gt;
&lt;li&gt;Detail the process we used to convert the hand-marked maps, both the
manual process and use of machine vision&lt;/li&gt;
&lt;li&gt;Show the analysis of the final dataset, with specific emphasis on
geographic analysis using Geopandas and Jupyter.&lt;/li&gt;
&lt;li&gt;Demonstrate the data management process, using Metatab to package
data and publish it to Wordpress&lt;/li&gt;
&lt;li&gt;Present how we are training volunteer analysts in the PyData tools to
answer data questions posed by researchers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Attendees will learn important aspects of an important social problem
and how to use data to solve these problems using a range of Python
tools.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Eric Busboom</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/tackling-homelessness-with-open-data.html</guid></item><item><title>What You Got Is What You Got</title><link>https://pyvideo.org/pydata-la-2019/what-you-got-is-what-you-got.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Composition, inheritance, restricted computation domains, boxed versus
unboxed, and the search for a perfect proxy. But, folks, what you got is
what you got.&lt;/p&gt;
&lt;p&gt;Composition, inheritance, restricted computation domains, boxed versus
unboxed, and the search for a perfect proxy. But, folks, what you got is
what you got.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">James Powell</dc:creator><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-05:pydata-la-2019/what-you-got-is-what-you-got.html</guid></item><item><title>A Guide to Modern Hyperparameter Tuning Algorithms</title><link>https://pyvideo.org/pydata-la-2019/a-guide-to-modern-hyperparameter-tuning-algorithms.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Modern deep learning model performance is very dependent on the choice
of model hyperparameters, and the tuning process is a major bottleneck
in the machine learning pipeline. In this talk, we will overview modern
methods for hyperparameter tuning and demonstrate how to use Tune, a
scalable hyperparameter tuning library. Tune is completely open source
at &lt;a class="reference external" href="http://tune.io"&gt;http://tune.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This talk will target intermediate to advanced data scientists and
researchers familiar with deep learning. The talk will first motivate
the need for advancements in hyperparameter tuning methods. The talk
will then overview standard methods for hyperparameter tuning: grid
search, random search, and bayesian optimization. Then, we will motivate
and discuss cutting edge methods for hyperparameter tuning:
multi-fidelity bayesian optimization, successive halving algorithms
(HyperBand), and population-based training.&lt;/p&gt;
&lt;p&gt;The talk will then present a overview of Tune, a scalable hyperparameter
tuning system from the UC Berkeley RISELab, and demonstrate about how
users can leverage cutting edge hyperparameter tuning methods
implemented in Tune to quickly improve the performance of standard deep
learning models.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Richard Liaw</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/a-guide-to-modern-hyperparameter-tuning-algorithms.html</guid></item><item><title>A "Supremely" Light introduction to Quantum Computing</title><link>https://pyvideo.org/pydata-la-2019/a-supremely-light-introduction-to-quantum-computing.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Quantum Computing is here and now, and its uses for solving real-world
problems is getting nearer. This talk will give you the tools to
understand the main concepts of Quantum Information, and even perform
your first steps by running your own programs on real hardware using
Qiskit and Rigetti Forest.&lt;/p&gt;
&lt;p&gt;Quantum Computing is one of the most disruptive and fast-paced
disciplines of the present time.&lt;/p&gt;
&lt;p&gt;For Data Science practitioners, understanding the main elements of the
new paradigm (Superposition, measurement, entanglement, Qubits, etc) can
be a daunting task. In this talk, we will walk through all these
concepts and will use Python to understand and probe them.&lt;/p&gt;
&lt;p&gt;The talk will focus on direct and math-light examples, with accompanying
python code examples illustrating the differences between simulating the
quantum world ideally, an then observing introduced error of running
code in the noisy environment of real IBM and Rigetti's devices.&lt;/p&gt;
&lt;p&gt;The outline of the talk is as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The need for a new kind of computing&lt;/li&gt;
&lt;li&gt;Quantum phenomena and how it can be used for computing.&lt;/li&gt;
&lt;li&gt;Quantum circuits and algorithms: Manipulating quantum data.&lt;/li&gt;
&lt;li&gt;Simulating and real hardware running of Python-based examples
(Qiskit, Rigetti Forest SDK, Pennylane)&lt;/li&gt;
&lt;li&gt;Conclusion&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rodolfo Bonnin</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/a-supremely-light-introduction-to-quantum-computing.html</guid></item><item><title>A/B Testing in Python</title><link>https://pyvideo.org/pydata-la-2019/ab-testing-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python development has had a great emergence in development of
statistical packages, algorithms, and implementations. However, with the
development and ease of practicing statistics &amp;amp; algorithms, there are
still some rules and constraints one must follow to obtain quality
solutions. And that is especially true with AB Testing, a statistical
procedure to provide data- driven insights in uncertainty.&lt;/p&gt;
&lt;p&gt;This will be a breakout Session on frequentist AB Testing in python.&lt;/p&gt;
&lt;p&gt;We'll explore the jungle of application and statistical methodology and
practice with examples of Click Through Rates, the early metrics of
choice for AB Testing in production. That being said, compared to your
last statistics course you may have taken in the past, there are still
some rules and constraints one must follow to obtain quality solutions.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Raul Maldonado</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/ab-testing-in-python.html</guid></item><item><title>Ahead in the Clouds: How to get started with serverless on Google, Amazon &amp; Microsoft</title><link>https://pyvideo.org/pydata-la-2019/ahead-in-the-clouds-how-to-get-started-with-serverless-on-google-amazon-microsoft.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Serverless apps are everywhere these days, but how do you get started?
How do you decide which provider to go with? I have created the same
Python app with 3 services, AWS, Google Cloud &amp;amp; Microsoft Azure. I will
go over the highlights and lowlights, and how to judge what’s right for
your project.&lt;/p&gt;
&lt;p&gt;Serverless apps are everywhere these days, but how do you get started?
How do you decide which provider to go with? I have created the same
Python based app with 3 services, AWS, Google Cloud &amp;amp; Microsoft Azure. I
will go over the highlights and lowlights, and how to judge what’s right
for your project.&lt;/p&gt;
&lt;p&gt;My goal for creating this app was to answer these questions. What
services are available for which languages, but especially Python? How
fast can I get to coding? How do I programmatically define the
infrastructure? How do I test everything? How is their CI/CD pipeline?
How do I secure the app? How can I monitor what is going on?&lt;/p&gt;
&lt;p&gt;During my research I ran into a common problem. There are guides on how
to use the UI to create samples. There is technical documentation that
will give you the name of the flag you are looking for. There is rarely
a user story to help you go from nothing to a running application. My
user story is that I wanted an endpoint that allows you to add data to
persistent storage, get, edit and delete that data. Seems
straightforward, but there is a steep learning curve that had me tearing
my hair out. This talk is not just to give you a better understanding of
serverless offerings, but to keep you from getting discouraged at the
inevitable blockers. At the end of this talk you’ll walk out with the
confidence to create your first serverless microservice and smash any
walls you hit along the way.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Michelle Brenner</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/ahead-in-the-clouds-how-to-get-started-with-serverless-on-google-amazon-microsoft.html</guid></item><item><title>Bokeh Maps: Making an interactive map for your next web application</title><link>https://pyvideo.org/pydata-la-2019/bokeh-maps-making-an-interactive-map-for-your-next-web-application.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Data scientists, analysts, and developers are proficient in creating
static maps but what about interactive ones? An interactive map of Los
Angeles neighborhoods will be made via Python’s Bokeh library to show
how quickly one can be built.&lt;/p&gt;
&lt;p&gt;Maps are crucial for showing differences between regions. However, what
happens when users want to see regional changes over a range of time
periods for a variety of variables? One map may not be enough. Rather
than creating many maps for all your user’s needs, an interactive map
allows the viewer to choose the time period and variables of interest.
In order to get a better sense of the process of making an interactive
map, a map of Los Angeles neighborhoods will be built live using
Python’s Bokeh library.&lt;/p&gt;
&lt;p&gt;The presentation will cover how to add features and widgets such as a
hovertool, selection form, and mouse selection click to a map. We will
also go over the important modify_doc and update functions that are
crucial for an interactive map to be able to respond to input changes
from a viewer. We’ll deploy to a Google Cloud server, discuss when to
build an interactive map, and best practices for designing one.&lt;/p&gt;
&lt;p&gt;Knowledge of certain data visual python libraries such as matplotlib or
seaborn, in addition to basic python functionality, will be assumed.
This is a presentation geared for intermediate python users.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Chrzanowski</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/bokeh-maps-making-an-interactive-map-for-your-next-web-application.html</guid></item><item><title>Building a Data Driven Organization</title><link>https://pyvideo.org/pydata-la-2019/building-a-data-driven-organization.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Buckminster Fuller said, “If you want to teach people a new way of
thinking, don’t bother trying to teach them. Instead, give them a tool,
the use of which will lead to new ways of thinking.” This profound
insight shaped the way I build my organization. We will look at some
tools that enable us to think like a data-driven organization.&lt;/p&gt;
&lt;p&gt;Buckminster Fuller said, “If you want to teach people a new way of
thinking, don’t bother trying to teach them. Instead, give them a tool,
the use of which will lead to new ways of thinking.” This profound
insight shaped the way I build my organization. We will look at some of
the tools that enable us to think like a data-driven organization.&lt;/p&gt;
&lt;p&gt;Teams are built out of three things: * People * Processes * Resources&lt;/p&gt;
&lt;p&gt;There is a 3 step process we can deploy. We start by focusing on
resources, then processes, and lastly people. With each step we climb
the ladder of value.&lt;/p&gt;
&lt;p&gt;With resources, we have tools. By choosing specific tools, we can being
to shape our thinking. We can create mental pathways that intentionally
take us in a particular direction.&lt;/p&gt;
&lt;p&gt;After we establish the tools, we focus on our processes. These are our
workflows and in many ways, our philosophies. How we think things should
proceed. This could be kanban and how we move work from left to right
through the pipeline, and it can be kaizen and belief in small,
continuous improvement. Processes can be considered tools as much as
resources.&lt;/p&gt;
&lt;p&gt;Once we have resources and processes, we can free up bandwidth with our
people. People are most creative and dynamic at this stage once friction
is removed and adding business value can go from one-off fixes to
becoming part of the organization itself.&lt;/p&gt;
&lt;p&gt;Tools that facilitate a data-driven culture: * Mental models * Kanban
and Kaizen * Opinionated, structured data science like Kedro * OKRs *
KPIs&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Franklin Sarkett</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/building-a-data-driven-organization.html</guid></item><item><title>Data and ETL with Notebooks in Papermill</title><link>https://pyvideo.org/pydata-la-2019/data-and-etl-with-notebooks-in-papermill.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Notebooks have traditionally been a tool for drafting code and avoiding
repeated expensive computations while exploring solutions. However, with
new tools like nteract's papermill and scrapbook libraries, this
technology has been expanded to make a reusable and parameterizable
template for execution. We'll look at how to make use of this pattern
for Data and ETL processes.&lt;/p&gt;
&lt;div class="section" id="intro"&gt;
&lt;h4&gt;Intro&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Myself, Netflix, and Why I'm here&lt;/li&gt;
&lt;li&gt;What does a Data Platform Team do?&lt;/li&gt;
&lt;li&gt;Projects and Open Source tools discussed in presentation Papermill,
Jupyter, nteract, etc&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="notebooks"&gt;
&lt;h5&gt;Notebooks&lt;/h5&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="what-are-jupyter-notebooks"&gt;
&lt;h4&gt;What are Jupyter Notebooks?&lt;/h4&gt;
&lt;p&gt;We'll some visual examples and breakdowns of notebooks.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-notebook-work"&gt;
&lt;h4&gt;How Notebook Work&lt;/h4&gt;
&lt;p&gt;A guide through how a notebook executes and the model it uses to run
your code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="traditional-use-cases"&gt;
&lt;h4&gt;Traditional Use Cases&lt;/h4&gt;
&lt;p&gt;Around experimentation and code development.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="new-use-cases"&gt;
&lt;h4&gt;New Use Cases&lt;/h4&gt;
&lt;p&gt;For production data and operations without full rewrites of Notebook
code.&lt;/p&gt;
&lt;div class="section" id="papermill"&gt;
&lt;h5&gt;Papermill&lt;/h5&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="what-is-papermill"&gt;
&lt;h4&gt;What is papermill?&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="https://papermill.readthedocs.io/en/latest/"&gt;papermill&lt;/a&gt; is a library
for executing notebooks programmatically.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-do-you-use-it"&gt;
&lt;h4&gt;How do you use it?&lt;/h4&gt;
&lt;p&gt;You'll see some examples in Python and with it's provided CLI.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-does-it-fit-into-the-notebook-model"&gt;
&lt;h4&gt;How does it fit into the Notebook model?&lt;/h4&gt;
&lt;p&gt;We'll relate the execution back into original Notebook execution
diagrams.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-to-extend-papermill"&gt;
&lt;h4&gt;How to extend papermill&lt;/h4&gt;
&lt;p&gt;Quick pointer to the extensibility of the library and how to add new
functionality.&lt;/p&gt;
&lt;div class="section" id="using-papermill-in-production-data-pipelines"&gt;
&lt;h5&gt;Using papermill in production data pipelines&lt;/h5&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="operationalizing-notebooks"&gt;
&lt;h4&gt;Operationalizing Notebooks&lt;/h4&gt;
&lt;p&gt;Failure analysis, Productionalization, Sharing executions...&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="dags-of-notebooks"&gt;
&lt;h4&gt;Dags of Notebooks&lt;/h4&gt;
&lt;p&gt;Making a pipeline with Notebooks.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="integration-testing"&gt;
&lt;h4&gt;Integration Testing&lt;/h4&gt;
&lt;p&gt;Good practices Where unittesting doesn't fit&lt;/p&gt;
&lt;div class="section" id="netflix-usage"&gt;
&lt;h5&gt;&amp;#64; Netflix usage&lt;/h5&gt;
&lt;p&gt;Quick blip about adoption and usage at Netflix.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="related-libraries-time-pending"&gt;
&lt;h5&gt;Related libraries (time pending)&lt;/h5&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="scrapbook"&gt;
&lt;h4&gt;Scrapbook&lt;/h4&gt;
&lt;/div&gt;
&lt;div class="section" id="commuter-nbviewer"&gt;
&lt;h4&gt;Commuter / NBViewer&lt;/h4&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Matthew Seal</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/data-and-etl-with-notebooks-in-papermill.html</guid></item><item><title>Evaluation of Traditional and Novel Feature Selection Approaches</title><link>https://pyvideo.org/pydata-la-2019/evaluation-of-traditional-and-novel-feature-selection-approaches.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Selecting the optimal set of features is a key step in the ML modeling
process. This talk will present research conducted that tested five
approaches for feature selection. The approaches included current widely
used methods, along with novel approaches for feature selection using
open-source libraries, building a classification model using the Lending
Club dataset.&lt;/p&gt;
&lt;p&gt;A central component to the Machine Learning process is feature
selection. Selecting the optimal set of features is important to
generate a best fit model which generalizes to unseen data. A widely
used approach for feature selection involves calculating Gini Importance
(Gain) to identify the best set of features. However, recent work from
Scott Lundberg has found challenges with the consistency of the Gain
attribution method. This talk will present results of model metrics on
the Lending Club dataset, testing five different feature selection
approaches. The approaches tested involved widely used approaches
combined with novel approaches for feature selection.&lt;/p&gt;
&lt;p&gt;Through the experimental design of the five feature selection approaches
that were tested; attendees will gain clarity on the impact of:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Data splitting method&lt;/li&gt;
&lt;li&gt;Including relevant two-way and three-way interactions (xgbfir
library)&lt;/li&gt;
&lt;li&gt;Backwards stepwise feature selection as opposed to a singular feature
selection step&lt;/li&gt;
&lt;li&gt;Backwards stepwise feature selection using Shapley values (shap
library).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The knowledge from this research can provide added predictive power and
velocity to the feature selection process for Data Scientists.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ben Fowler</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/evaluation-of-traditional-and-novel-feature-selection-approaches.html</guid></item><item><title>Gradient Boosting for data with both numerical and text features</title><link>https://pyvideo.org/pydata-la-2019/gradient-boosting-for-data-with-both-numerical-and-text-features.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Some problems contain different types of data, including numerical,
categorical and text data. CatBoost is the first Gradient Boosting
library to have text features support out-of-the box. This talk will
walk you through main features of CatBoost library and explain how it
deals with text data.&lt;/p&gt;
&lt;p&gt;Gradient boosting is a powerful machine-learning technique that achieves
state-of-the-art results in a variety of practical tasks. For a number
of years, it has remained the primary method for learning problems with
heterogeneous features, noisy data, and complex dependencies: web
search, recommendation systems, weather forecasting, and many others.&lt;/p&gt;
&lt;p&gt;Some problems contain different types of data, including numerical,
categorical and text data. In this case the best solution is either
building new numerical features instead of text and categories and pass
it to gradient boosting, or using out-of-the box solutions for that.&lt;/p&gt;
&lt;p&gt;CatBoost (&lt;a class="reference external" href="https://catboost.ai/"&gt;https://catboost.ai/&lt;/a&gt;) is the first Gradient Boosting library
to have text features support out-of-the box.&lt;/p&gt;
&lt;p&gt;CatBoost is a popular open-source gradient boosting library with a whole
set of advantages:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;CatBoost is able to incorporate categorical features and text
features in your data with no additional preprocessing.&lt;/li&gt;
&lt;li&gt;CatBoost has the fastest GPU and multi GPU training implementations
of all the openly available gradient boosting libraries.&lt;/li&gt;
&lt;li&gt;CatBoost predictions are 20-60 times faster then in other open-source
gradient boosting libraries, which makes it possible to use CatBoost
for latency-critical tasks.&lt;/li&gt;
&lt;li&gt;CatBoost has a variety of tools to analyze your model.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This talk will walk you through main features of this library including
the way it works with texts.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Anna Veronika Dorogush</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/gradient-boosting-for-data-with-both-numerical-and-text-features.html</guid></item><item><title>Introducing Autoimpute: a Python Package for Grappling with Missing Data</title><link>https://pyvideo.org/pydata-la-2019/introducing-autoimpute-a-python-package-for-grappling-with-missing-data.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Real-world data is messy and missing, yet most statistical models
require it to be clean and complete. Analysts are often well versed in
modeling, but few are familiar with handling missingness. This talk
teaches data professionals best practices for dealing with missingness
and introduces Autoimpute, our Python package that helps users grapple
with missing data during statistical analysis.&lt;/p&gt;
&lt;p&gt;Most real-world datasets contain missing data, but many statistical
models expect input datasets to be complete. This disconnect requires
analysts to figure out what to do about missing data before they can
proceed with statistical analysis.&lt;/p&gt;
&lt;p&gt;Unfortunately, most aspiring data professionals spend the bulk of their
time studying statistical models themselves, not techniques to handle
missing data. As a result, individuals opt for simple methods such as
listwise deletion or mean imputation and underestimate the impact these
methods have on parameter inference of statistical models.&lt;/p&gt;
&lt;p&gt;This problem inspired us to create Autoimpute, a Python package that
offers a framework for properly handling missing data during end-to-end
analysis. In this talk, we focus on handling missing data during
regression analysis, and we demonstrate how to use Autoimpute to tackle
the problem methodologically.&lt;/p&gt;
&lt;p&gt;To start, we provide context to understand different types of missing
data, and we define terminology used in the remainder of the talk. We
then walk through examples that contain different types of missingness.
Each example use a four-step methodology we developed to perform
statistical analysis with missing data. We start by assessing the extent
of the missing data problem using descriptive and visual measures. We
end by measuring the impact of imputation on the bias and variance of
parameters derived from regression models built on imputed data.&lt;/p&gt;
&lt;p&gt;By the end of the talk, each listener should leave equipped with a
methodological approach to handling missing data during statistical
analysis. Additionally, the audience should feel comfortable using the
Autoimpute package as a tool in their Python data analysis ecosystem.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joseph Kearney</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/introducing-autoimpute-a-python-package-for-grappling-with-missing-data.html</guid></item><item><title>Kyle Polich: Keynote | PyData LA 2019</title><link>https://pyvideo.org/pydata-la-2019/kyle-polich-keynote-pydata-la-2019.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;www.pydata.org&lt;/p&gt;
&lt;p&gt;PyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R.&lt;/p&gt;
&lt;p&gt;PyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kyle Polich</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/kyle-polich-keynote-pydata-la-2019.html</guid></item><item><title>Learning Topology: Topological Techniques for Unsupervised Learning</title><link>https://pyvideo.org/pydata-la-2019/learning-topology-topological-techniques-for-unsupervised-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Many topics in unsupervised learning can be viewed as dealing with the
relative geometry of data. In mathematics, topology and homotopy theory
are the fields that deal with similar kinds of questions. Using ideas,
techniques, and language from topology can prove fruitful for
unsupervised learning. This talk will introduce you to the ideas and
intuitions for this, and provide meaningful examples.&lt;/p&gt;
&lt;p&gt;Many topics in unsupervised learning can be viewed as dealing with the
relative geometry of data. In mathematics, topology and homotopy theory
are the fields that deal with similar kinds of questions. Using ideas,
techniques, and language from topology can prove fruitful for
unsupervised learning. This talk will look at how topological approaches
can be brought to bear upon unsupervised learning problems as diverse as
dimension reduction, clustering, anomaly detection, word embedding, and
metric learning. Through the lens and language of topology and category
theory we can draw common threads through all these topics, pointing the
way toward new approaches to these problems. By focusing on broad ideas
and intuitions, and working with example uses, you don't need a
background in topology to understand the approach. I hope to convince
you that topological approaches offer a rich and growing field of
research for unsupervised learning.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Leland McInnes</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/learning-topology-topological-techniques-for-unsupervised-learning.html</guid></item><item><title>Lightning Talks | PyData LA 2019</title><link>https://pyvideo.org/pydata-la-2019/lightning-talks-pydata-la-2019.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;www.pydata.org&lt;/p&gt;
&lt;p&gt;PyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R.&lt;/p&gt;
&lt;p&gt;PyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Various speakers</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/lightning-talks-pydata-la-2019.html</guid></item><item><title>Making data relevant to business. Its harder than you think!</title><link>https://pyvideo.org/pydata-la-2019/making-data-relevant-to-business-its-harder-than-you-think.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Want to use your data skills to empower an organization and influence
your companies strategy? Unfortunately its not as easy as just starting
a jupyter notebook and importing Tensorflow. Making your analysis change
hearts and minds take more than math and code, and is more challenging
than just the algorithm. In this talk I'll share tips of how to make
your data work resonate across your org.&lt;/p&gt;
&lt;p&gt;Making data relevant to your company isn't just math and code. Business
skills are required as well. Many data folks, including myself in the
past, underestimate these &amp;quot;soft skills&amp;quot; and end up feeling frustrated
when your analyses don't have the recognition or impact that you expect.&lt;/p&gt;
&lt;p&gt;In this talk I'll focus on the soft skills of data, and connect these
skills to &amp;quot;hard data&amp;quot;. These include topics such as , story telling,
coalition building, empathizing with stakeholders, making subjective
calls, and negotiation.&lt;/p&gt;
&lt;p&gt;In particular I'll talk about my own failures and my most helpful
resources outside of the data &amp;quot;sphere&amp;quot; which have helped me pick up and
practice each of these topics. Ultimately by pairing these human skills
with your data skills you'll better be able to make your voice heard and
influence that change that you're looking for.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ravin Kumar</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/making-data-relevant-to-business-its-harder-than-you-think.html</guid></item><item><title>Milana Lewis: Keynote | PyData LA 2019</title><link>https://pyvideo.org/pydata-la-2019/milana-lewis-keynote-pydata-la-2019.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;www.pydata.org&lt;/p&gt;
&lt;p&gt;PyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R.&lt;/p&gt;
&lt;p&gt;PyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Milana Lewis</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/milana-lewis-keynote-pydata-la-2019.html</guid></item><item><title>To Production and Beyond: How to Manage the Machine Learning Lifecycle with MLflow</title><link>https://pyvideo.org/pydata-la-2019/to-production-and-beyond-how-to-manage-the-machine-learning-lifecycle-with-mlflow.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Building a machine learning model that runs locally on a laptop probably
isn't generating any value, you have to get that model into production.
This talk will focus on getting Data Scientist and Data Engineers more
comfortable with the Machine Learning Lifecycle, and how the open source
tool MLflow can help. Let's take our machine learning models to
production and beyond!&lt;/p&gt;
&lt;div class="section" id="introduction"&gt;
&lt;h4&gt;Introduction&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;What is the machine learning lifecycle?&lt;/li&gt;
&lt;li&gt;Why should I care about this?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="what-is-mlflow"&gt;
&lt;h4&gt;What is MLflow?&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;High-level overview of this open source Python project&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="what-is-model-tracking"&gt;
&lt;h4&gt;What is model tracking?&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Demo how MLflow can easily be used to track and record experiments&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="how-to-build-a-reproducible-project"&gt;
&lt;h4&gt;How to build a reproducible project?&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Demo how to use MLflow to be able to reproduce model building&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="how-to-create-models-that-can-be-run-anywhere"&gt;
&lt;h4&gt;How to create models that can be run anywhere?&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Demo building a model with Apache Spark and deploy on a non-Apache
Spark cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Amanda Moran</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/to-production-and-beyond-how-to-manage-the-machine-learning-lifecycle-with-mlflow.html</guid></item><item><title>What's Data Science Reporting?</title><link>https://pyvideo.org/pydata-la-2019/whats-data-science-reporting.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We do great things with data science models but often forget that it is
as important to advocate and maintain model health. Building data
science reports ahead of time can help. In this talk, let’s talk about
how to make useful data science reports for data scientists and business
stakeholders. You do not need to be an R user to follow along, but you
will see some useful R packages and tricks!&lt;/p&gt;
&lt;p&gt;In this talk, we will first walk through what data science reporting
means and how it is different from BI and general-purpose dashboards.
Next, we explore different options for producing data science reports in
a “loud” and clear way for data scientists and other technical and
non-technical business stakeholders. Throughout the talk, I will
introduce some useful R packages and tricks for building your own
reports, however, you do not need to be an R user because the same
principles apply. The talk is marked as intermediate but all levels are
welcome and should be able to follow along.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Amy Tzu-Yu Chen</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/whats-data-science-reporting.html</guid></item><item><title>Write the Docs!</title><link>https://pyvideo.org/pydata-la-2019/write-the-docs.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will provide an in-depth overview of Sphinx and how it can be
used to generate intelligent and readable documentation of your Python
code.&lt;/p&gt;
&lt;p&gt;Documenting code should be the easiest part, yet it is often cited as
the hardest part of developing a data science product. In this talk we
will introduce Sphinx, an open-source tool that allows you to template
documentation for any project. We will give an overview of how Sphinx
works, and walk through:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Examples of documentation generated with Sphinx&lt;/li&gt;
&lt;li&gt;reStructuredText vs Markdown&lt;/li&gt;
&lt;li&gt;How does Docutils work at the individual file level&lt;/li&gt;
&lt;li&gt;How does Sphinx tie it all together&lt;/li&gt;
&lt;li&gt;Best practices for setting up your documentation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This talk is for anyone who has ever wondered how all the Read the Docs
are generated!&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Hareem Naveed</dc:creator><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-04:pydata-la-2019/write-the-docs.html</guid></item><item><title>Analyzing genetic networks using neural networks</title><link>https://pyvideo.org/pydata-la-2019/analyzing-genetic-networks-using-neural-networks.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this tutorial, we'll delve into the depths of biological data
analysis. Using publicly available datasets, we'll use machine learning
to try to solve one of life's biggest mysteries: that of completing the
wiring diagrams of genetic regulatory networks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Genes that fire together wire together&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In every living cell, there are genetic regulatory networks that dictate
how genes are turned on and off. This networks have evolved to help the
cell to fine-tune the number and speed of the biomolecules that make up
the cell. Despite studying gene networks for more than 30 years in model
organisms, the community still faces some problems. The problem we're
going to address in this tutorial is to try to make guesses of the
&amp;quot;missing wires&amp;quot; of this gene networks.&lt;/p&gt;
&lt;p&gt;We'll be using the Keras API to build our neural nets and pandas / numpy
/ sci-kit learn to wrangle through this massive datasets. Using publicly
available RNAseq datasets, we'll train a neural network to predict the
biological module of some of the missing nodes in the network. We'll
also use the NetworkX library to work with the genetic networks.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Manu Flores</dc:creator><pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-03:pydata-la-2019/analyzing-genetic-networks-using-neural-networks.html</guid></item><item><title>Computer Vision with PyTorch</title><link>https://pyvideo.org/pydata-la-2019/computer-vision-with-pytorch.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Computer vision algorithms, which process video and image data, have
many applications. The development of convolutional neural networks,
alongside hardware improvements, have led to a proliferation of highly
accurate computer vision models. In this tutorial, you will learn how to
build new, and use existing, computer vision models using PyTorch.&lt;/p&gt;
&lt;p&gt;This tutorial is a practical, hands-on, introduction to computer vision
with PyTorch.&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;In this tutorial, you will learn about:&lt;/div&gt;
&lt;div class="line"&gt;- An overview of deep learning for computer vision&lt;/div&gt;
&lt;div class="line"&gt;- How to implement neural networks in PyTorch&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;You will gain hands-on experience with important computer vision
tasks:&lt;/div&gt;
&lt;div class="line"&gt;- Image classification&lt;/div&gt;
&lt;div class="line"&gt;- Object detection&lt;/div&gt;
&lt;div class="line"&gt;- Semantic segmentation&lt;/div&gt;
&lt;div class="line"&gt;- Generative models&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Tutorial materials are available on GitHub in Jupyter notebook format.&lt;/p&gt;
&lt;p&gt;Laptops are encouraged, but not required.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Daniel J. Brooks</dc:creator><pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-03:pydata-la-2019/computer-vision-with-pytorch.html</guid></item><item><title>Experimental Machine Learning with HoloViz and PyTorch in Jupyterlab</title><link>https://pyvideo.org/pydata-la-2019/experimental-machine-learning-with-holoviz-and-pytorch-in-jupyterlab.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;pre&gt;This tutorial introduces how to make your data exploration and neural
network training process more interactive and exploratory by using the
combination of JupyterLab, HoloViews, and PyTorch. I will first
introduce the basic concepts behind HoloViews, and walk through how to
embellish each step of your machine learning workflow with HoloVie to
emphasize the experimental nature of modeling.

**Update** : Please visit `this
repo &lt;https://github.com/cocoaaa/PyData-%20LA-2019&gt;`__ for tutorial
materials

-  Subtitle: A guide through multi-class road detection on satellite
   images with interactive visualization and explorative model building
-  Author: Hayley Song (`[email
   protected] &lt;/cdn-cgi/l/email-protection&gt;`__)
-  Category: step-by-step tutorial
-  Prereq:

   -  Basic understanding of visaulization with python (eg. previously
      have used matplotlib.pyplot library)
   -  | Basic understanding of neural network training process
      | I'll give a brief overview of the workflow, assuming audiences'
        previous experience with the following concepts

   -  mini-batch training
   -  forward-pass, backword-pass
   -  gradient, gradient descent algorithm
   -  classification, semantic segmentation
   -  image as numpy ndarray

-  Material distribution

   -  All materials needed to follow the tutorial will be shared in a
      self-containing GitHub repo, as well as a Binder environment
   -  **Update** : Please visit `this
      repo &lt;https://github.com/cocoaaa/PyData-LA-2019&gt;`__ for tutorial
      materials
   -  Links to extra resources will be provided as appropriate

Overview
--------

This tutorial introduces how to make your data exploration and model
building process more interactive and exploratory by using the
combination of JupyterLab, HoloViews, and PyTorch.
`HoloViews &lt;https://HoloViews.org/&gt;`__ is a set of Python libraries that
offers simple yet powerful visualization and GUI building tools which,
together with other data analysis libraries (eg. ``pandas``,
``geopandas``, ``numpy``) and machine learning framework (eg.
``PyTorch``, ``Tensorflow``) can make your modeling procedure more
interactive and exploratory. I will start by introducing four core
HoloViews libraries (Holoviews, GeoViews, Panel and Param) and
demonstrate basic examples on how we can essentially replace any
"Matplotlib.pyplot" calls with equivalents in ``HoloViews``. You will
see how this opens up the possibilities to directly interact with your
visualization by eg. hovering over the graph to inspect values, querying
RGB values of an image, or Lat/Lon values on your map.

Following the introduction of the HoloViews libraries, I will
demonstrate how to embellish each step of your machine learning workflow
with HoloViews. First, you will learn to easily turn your PyTorch codes
into a simple GUI that encaptulates the state of your model (or
alternatively, the state of your training session). This GUI explicitly
exposes your model parameters and training hyperparameters (eg. learning
rate, optimizer settings, batch size) as directly tunable parameters.
Compared to conventional ways of specifying the hyperparameter settings
with the help of 'argparse' library or config files, this GUI approach
focuses on the experimental nature of modeling and integrates seamlessly
with Jupyter notebooks. After training a neural network model using our
own GUI in the notebook, I will demonstrate how to understand the model
by visualizing the intermediate layers with HoloViews and test the model
with test images directly sampled from HoloViews visualization.

To illustrate these steps, I will focus on the problem of classfying
different types of roads on satellite images, defined as a multi-class
semantic segmentation problem. Starting from the data exploration to the
trained model understanding, you will learn different ways to explore
the data and models by easily building simple GUIs in a Jupyter
notebook.

In summary, by the end of the talk you will have learned: - how to make
your data exploration more intuitive and experimental using HoloViews
libraries - how to turn your model script into a simple GUI that allows
interactive hyperparameter tuning and model exploration - how to monitor
the training process in realtime - how to quickly build a GUI tool to
inspect the trained models in the same Jupyter notebook

The provided example codes will be a great starting point to experiment
these tools on your own datasets and tasks.

Outline
-------

This tutorial will consists of five main sections. I will first
introduce the basic concepts behind ``Holoviews/Geoviews`` and ``Panel``
which are the main libraries we are going to use to add interactive
exploration tools for data exploration and model training/evaluation,
all in a single Jupyter notebook. This will take ~15 minutes. The rest
of the tutorial will flow in the order of the general neural network
training workflow, while integrating these libraries at each step. I
will leave the last &lt;10 minutes for questions.

-  Step 0: Introduction to ``Holoviews``/``Geoviews`` and ``Panel``
   [15mins]
-  Step 1: Explore your dataset with ``Holoviews``/``Geoviews`` [15mins]
-  Step 2: Build an easily-configurable neural network model with
   ``param`` [15mins]
-  Step 3: Monitor your training process through an interactive GUI
   [15mins]
-  Step 4: Analyze your learned model on new images + Understand what
   your model has learned by looking at intermediate feature maps with
   ``Holoviews`` and ``Panel`` [15mins]
-  Q/A [5~10 mins]

Step 0: Introduction to ``HoloViews`` libraries
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In this introductory section, I will go over the basic concepts behind
the ``HoloViews`` libraries. I will provide simple examples that show
how we can replace any ``Matplotlib`` plot calls with equivalent calls
in ``Holoviews/Geoviews`` with no hassle, and build easy tools to
interact with your data.

Step 1: Explore your dataset
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The first step in building a machine learning model is to understand
your dataset. For the scope of this tutorial (ie.semantic segmentation
of road types from satellite images), we will use the SpaceNet datasets.
More details on how to get the data as well as how the data are
collected and annotated can be found
`here &lt;https://spacenetchallenge.github.io/datasets/datasetHomePage.html&gt;`__.
The original dataset is very large (&gt;100GB) and requires a lot of
preprocessing to be useful for training. For example, the RGB images are
16bits of size 1300x1300, and the "target" roads are vector lines (as
opposed to raster images), which means they need to be rasterized. I
have prepared a smaller sample dataset consisting of the RGB images
converted to 8bits and cropped to 520x520 size, as well as road buffers
as rasters which can be easily used as the target images. I will share
the dataset to accompany my tutorial. The shared dataset will consists
of input RGB images and target mask images. Each pixel of a target image
will contain one of the labels in {'highway', 'track', 'dirt', 'others'}
(as ``uint8``).

The focus of this section is to show how to build a GUI-like
visualization of a satellite dataset within a Jupyter notebook using
``Holoviews``/``Geoviews``. See Figure 1 (in the shared Google Drive)
for an example. Unlike a static plot (eg. one that is generated from
Matplotlib), one can hover over the ``Holoviews`` plot to inspect the
labels at each pixel of the mask image or to check the lat/lon
locations. Furthermore I will show how you can trigger more complicated
computations (eg. compute road length within a selected zone), while
interacting with the plot directly, eg. selecting a region by mouse
drag, clicking a lat/lon by mouse click.

The second example will show how this interactive plot can extended to
incorporate external information (eg. roadlines from OpenStreetMap) to
easily compare with your own dataset. See Figure 2 (in the shared Google
Drive) for a snapshot of such tool. In this example, as you select
different RGB filenames (of your dataset), you have an option to click
on the 'click to download OSM' to download the corresponding region's
OSM road data, and visualize it as an interactive map.

Step 2: Monitor the training process
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In this section, I will show how to wrap around a ``PyTorch``'s NN model
with ``param``'s \`Parametrized' class to expose its hyperparameters as
tunable parameters. Using the GUI representation of the NN model, we can
control the (hyper)parameter configurations more intuitively, and study
their effects. Its seamless integration into a Jupyter notebook
facilitates the experimental side of machine learning training pocess.

Step 3: Interactively test your trained model on the new data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Step 4: Understand what the model has learned
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

--------------

I will conclude the tutorial by summarzing the main takeaways and
providing pointers to useful resources:

-  General

   -  Github repo for this talk
   -  Link to HoloViews libraries
   -  more: DataShader
   -  PyTorch, torchvision

-  Geospatial Data

   -  remote sensing data: google-earth-engine
   -  libraries: xarray, dash, rasterio, geopandas
&lt;/pre&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Hayley Song</dc:creator><pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-03:pydata-la-2019/experimental-machine-learning-with-holoviz-and-pytorch-in-jupyterlab.html</guid></item><item><title>Git-ting along with others</title><link>https://pyvideo.org/pydata-la-2019/git-ting-along-with-others.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you emailed snippets of code with your colleagues, only to get
stuck trying to find which email has the right code? In this tutorial, I
will demonstrate how to collaborate on code with others using Git. We
will cover branching, opening pull requests, doing code reviews,
resolving code conflicts, and undoing any mistakes you may make along
the way. This talk assumes basic Git knowledge.&lt;/p&gt;
&lt;div class="section" id="prerequisites"&gt;
&lt;h4&gt;Prerequisites&lt;/h4&gt;
&lt;p&gt;This tutorial will assume that participants have basic Git knowledge,
though anyone who is interested is welcome to attend. If you are
unfamiliar with Git, I recommend &lt;a class="reference external" href="https://swcarpentry.github.io/git-%20novice/"&gt;Software Carpentry's
tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We will be doing some Git work together, so participants should have
&lt;a class="reference external" href="https://git-scm.com/"&gt;Git installed&lt;/a&gt; and should have a personal
&lt;a class="reference external" href="https://github.com/"&gt;GitHub account&lt;/a&gt;. If participants would prefer
to use a graphical interface, I recommend using
&lt;a class="reference external" href="https://www.sourcetreeapp.com/"&gt;SourceTree&lt;/a&gt;. Note that to install
SourceTree, you will need to create a personal BitBucket account.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="material"&gt;
&lt;h4&gt;Material&lt;/h4&gt;
&lt;div class="section" id="collaboration"&gt;
&lt;h5&gt;Collaboration&lt;/h5&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;What happens when multiple people try to commit code at once?&lt;/li&gt;
&lt;li&gt;Using branches and merges&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="pull-requests"&gt;
&lt;h5&gt;Pull requests&lt;/h5&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Opening issues in GitHub&lt;/li&gt;
&lt;li&gt;Creating a pull request&lt;/li&gt;
&lt;li&gt;Doing code reviews&lt;/li&gt;
&lt;li&gt;Fixing conflicts&lt;/li&gt;
&lt;li&gt;Merging your code back in&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="fixing-mistakes-as-time-permits"&gt;
&lt;h5&gt;Fixing mistakes (as time permits)&lt;/h5&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Reverts and resets&lt;/li&gt;
&lt;li&gt;Cherry-picking&lt;/li&gt;
&lt;li&gt;Whoops, I just committed my password...&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Paul Anzel</dc:creator><pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-03:pydata-la-2019/git-ting-along-with-others.html</guid></item><item><title>Introduction to Data Analysis with Python datatable</title><link>https://pyvideo.org/pydata-la-2019/introduction-to-data-analysis-with-python-datatable.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this tutorial, an introduction of Data Analysis with Python
datatable, one would learn about data wrangling with datatable via a
banking loan scenario using a subset of the Fannie Mae and Freddie Mac
datasets. We would show how to munge loan-level data, obtain basic
insights, exploratory data analysis, model development, and model
evaluation.&lt;/p&gt;
&lt;p&gt;During the tutorial session, we would use a banking loan scenario using
a subset of the Fannie Mae and Freddie Mac datasets where we would show
how to munge loan-level data. Additionally, we would give an overview of
how &lt;strong&gt;Python datatable&lt;/strong&gt; is used to obtain basic insights that start
with data wrangling, exploratory data analysis, model development, and
model evaluation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Python datatable&lt;/strong&gt; is a library that implements a wide (and growing)
range of operators for manipulating two-dimensional data frames. It
focuses on: big data support, high performance, both in-memory and
out-of-memory datasets, and multithreaded algorithms. Datatable’s
powerful API is similar to R data.table’s, and it strives in providing
friendlier and intuitive API experience with helpful error messages to
accelerate problem-solving.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Learn more about Python datatable:&lt;/strong&gt;
&lt;a class="reference external" href="https://github.com/h2oai/datatable"&gt;https://github.com/h2oai/datatable&lt;/a&gt;&lt;/p&gt;
&lt;div class="section" id="prerequisites"&gt;
&lt;h4&gt;Prerequisites&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Basic knowledge of Statistics and Machine Learning&lt;/li&gt;
&lt;li&gt;Basic knowledge of Python&lt;/li&gt;
&lt;li&gt;JupyterLab&lt;/li&gt;
&lt;li&gt;Python datatable installed on your local machine or use cloud env:&lt;ul&gt;
&lt;li&gt;datatable can be install by following:
&lt;a class="reference external" href="https://datatable.readthedocs.io/en/latest/install.html"&gt;https://datatable.readthedocs.io/en/latest/install.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; As of now, datatable is only supported on Linux and Mac OS X.
However, one can use it on Windows via a docker container.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="tutorial"&gt;
&lt;h4&gt;Tutorial:&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Task 0:&lt;/strong&gt; Introduction to Python datatable(10 min)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task 1:&lt;/strong&gt; datatable vs Pandas (10 mins)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task 2:&lt;/strong&gt; Understand the dataset (10 mins)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task 3:&lt;/strong&gt; datatable - Data Wrangling (10 mins)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task 4:&lt;/strong&gt; datatable - Exploratory Data Analysis (10 mins)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task 5:&lt;/strong&gt; datatable - Model Development (10 mins)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task 6:&lt;/strong&gt; datatable - Model Evaluation (10 mins)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task 7:&lt;/strong&gt; Q &amp;amp;A (10 - 15 mins)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ana Castro Salazar</dc:creator><pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-03:pydata-la-2019/introduction-to-data-analysis-with-python-datatable.html</guid></item><item><title>Introduction to H2O AutoML with Python</title><link>https://pyvideo.org/pydata-la-2019/introduction-to-h2o-automl-with-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this tutorial, we intend to do automated modeling on a subset of the
loan- level data from Fannie Mae and Freddie Mac using H2O's automated
algorithm(AutoML). We will solve a binary classification problem
(predicting if a loan is delinquent or not). Also, we will explore a
regression use-case (predicting interest rates on the same dataset). We
will be using the h2o Python module in a JupyterLab.&lt;/p&gt;
&lt;p&gt;Choosing the best machine learning models and tuning them can be time
consuming and exhaustive. Often, it requires levels of expertise to know
what parameters to tune. The field of Automated Machine Learning
(AutoML) focuses on solving this issue. AutoML is useful both for
experts, by automating the process of choosing and tuning a model; and
for non-experts as well, by helping them to create high performing
models in a short time frame. H2O is an open-source, distributed machine
learning platform with APIs in Python, R, Java, and Scala. H2O AutoML is
an automated algorithm for automating the machine learning workflow,
which includes automatic training, hyper-parameter optimization, model
search and selection under time, space, and resource constraints. H2O's
AutoML further optimizes model performance by stacking an ensemble of
models.&lt;/p&gt;
&lt;div class="section" id="references"&gt;
&lt;h4&gt;References&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html"&gt;H2O
AutoML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://arxiv.org/pdf/1907.00909.pdf"&gt;An Open Source AutoML
Benchmark&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="prerequisites"&gt;
&lt;h4&gt;Prerequisites:&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Basic knowledge of Machine Learning&lt;/li&gt;
&lt;li&gt;Familiarity with Python&lt;/li&gt;
&lt;li&gt;JupyterLab&lt;/li&gt;
&lt;li&gt;H2O installed on local machine or cloud environment&lt;ul&gt;
&lt;li&gt;Quick H2O installation (requires Java and h2o Python module)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="outline"&gt;
&lt;h4&gt;Outline:&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Task 0: Introduction to Automatic Machine Learning, H2O and H2O
AutoML (15 min)&lt;/li&gt;
&lt;li&gt;Task 1: Importing libraries, initializing H2O, importing data (5 min)&lt;/li&gt;
&lt;li&gt;Task 2: Data Preparation and Transformations (5 min)&lt;/li&gt;
&lt;li&gt;Task 3: H2O AutoML Classification and Model Evaluation
(Interpretation) (15 min)&lt;/li&gt;
&lt;li&gt;Task 4: H2O AutoML Regression and Model Evaluation (Interpretation)
(15 min)&lt;/li&gt;
&lt;li&gt;Task 5: H2O AutoML Classification in Flow (10 min)&lt;/li&gt;
&lt;li&gt;Task 6: H2O AutoML Regression in Flow (15 min)&lt;/li&gt;
&lt;li&gt;Task 7: Q&amp;amp;A (10 min)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Franklin Velasquez</dc:creator><pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-03:pydata-la-2019/introduction-to-h2o-automl-with-python.html</guid></item><item><title>Kedro + MLflow – Reproducible and versioned data pipelines at scale</title><link>https://pyvideo.org/pydata-la-2019/kedro-mlflow-reproducible-and-versioned-data-pipelines-at-scale.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Kedro is a development workflow tool open sourced by QuantumBlack, a
McKinsey company. Many data science teams have started using the library
for their pipelines but are unsure how to integrate with other model
tracking tools, such as MLflow. In this tutorial, we will give an
overview of Kedro and MLflow and demo how to leverage the best of both.&lt;/p&gt;
&lt;p&gt;The goal of this session is to demonstrate how Kedro and MLflow fit
together in a scalable AI architecture. To start, we will give an
overview of Kedro and an overview of MLflow: - What are they used for? -
What functionality do they provide? - How do they compare as tools?&lt;/p&gt;
&lt;p&gt;Next, we will walk through a demo of a Kedro project that has MLflow
integrated into it. Finally, we will go over deployment options.&lt;/p&gt;
&lt;p&gt;There will be time allocated at the end for Q&amp;amp;A.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tom Goldenberg</dc:creator><pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-03:pydata-la-2019/kedro-mlflow-reproducible-and-versioned-data-pipelines-at-scale.html</guid></item><item><title>Reinforcement Learning: Pac-Man</title><link>https://pyvideo.org/pydata-la-2019/reinforcement-learning-pac-man.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This workshop serves as an introduction to reinforcement learning where
the participants will implement a Pac-Man agent. The Pac-Man agent will
learn how to solve different maps using Q-learning and Deep Q-learning.
We start out by exploring Q-learning, before diving into deep
Q-learning, which utilizes neural networks. Jupyter notebook and GPUs
will be used to aid us in our work.&lt;/p&gt;
&lt;p&gt;Over the past few years, reinforcement learning (RL) has achieved
promising results and it is currently being explored in a wide range of
fields. In areas such as self driving cars, gaming and medicine, RL is
the frontier of state- of-the-art results. In this workshop we will
explore what the fuss is all about!&lt;/p&gt;
&lt;p&gt;This workshop serves as an introduction to reinforcement learning where
the participants will implement a Pac-Man agent. The Pac-Man agent will
learn how to solve different maps using Q-learning and Deep Q-learning.
We start out by exploring Q-learning, a cornerstone in RL. Expanding
further, we continue on to deep Q-learning, which utilizes neural
networks. The code is executed in the cloud on Jupyter notebooks, and
for training the neural networks we use GPUs in the cloud. Everything is
written in Python.&lt;/p&gt;
&lt;p&gt;No prior knowledge of reinforcement learning is necessary.&lt;/p&gt;
&lt;p&gt;If reinforcement learning has been a mysterious domain to you, this
session will most likely leave you with a greater understanding of the
process and aid you in how to set up projects of your own.&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;strong&gt;Optional preparation for the tutorial&lt;/strong&gt;&lt;/div&gt;
&lt;div class="line"&gt;The tutorial will be much like a walkthrough, so it is quite fine to
just follow along without programming yourself. If you do, however,
want to interact with the actual code, it is recommended that you
clone the project and set up the Python environment beforehand. While
most of the tutorial will be in Jupyter Notebook, some setup is also
required on local machines. Since we only have 1.5 hours, we will not
have time to help individual participants setting up the project
during the actual tutorial, but if you do face issues you can send us
an email ahead of the tutorial. We will be happy to help!&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Project repository: &lt;a class="reference external" href="https://github.com/knowit/ml-pacman"&gt;https://github.com/knowit/ml-pacman&lt;/a&gt;&lt;/div&gt;
&lt;div class="line"&gt;Manu: &lt;a class="reference external" href="/cdn-cgi/l/email-protection"&gt;[email protected]&lt;/a&gt;&lt;/div&gt;
&lt;div class="line"&gt;Malte: &lt;a class="reference external" href="/cdn-cgi/l/email-protection"&gt;[email protected]&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Manu Gopinathan</dc:creator><pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-03:pydata-la-2019/reinforcement-learning-pac-man.html</guid></item><item><title>Turn Python Scripts into Beautiful ML Tools</title><link>https://pyvideo.org/pydata-la-2019/turn-python-scripts-into-beautiful-ml-tools.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This tutorial will discuss the use of internal machine learning tooling
in real self-driving car projects. We'll download a human-annotated
image dataset from the Udacity Self-Driving Car Project and discuss how
stakeholders would approach this data in a real company. Finally we will
live-code an app using Streamlit to semantically search and visualize
the dataset and run models against it.&lt;/p&gt;
&lt;p&gt;We've all seen poor tooling slow down data science and machine learning
projects. In fact, most projects develop their own unique ecosystem of
bug- ridden and unmaintainable internal tools to analyze data, often
through a patchwork of Jupyter Notebooks and Flask apps.&lt;/p&gt;
&lt;p&gt;In this workshop, we'll discover a new workflow to write ML tools as
Python scripts using Streamlit, the first app framework for ML
engineers.&lt;/p&gt;
&lt;p&gt;Part one will be a whirlwind tour of Streamlit, creating apps, UIs, and
data caches. Then we'll download a human-annotated image dataset from
the Udacity Self-Driving Car Project and explore it.&lt;/p&gt;
&lt;p&gt;Part two will be about product management. We'll discuss how
stakeholders would approach this data in a real self-driving car
project. How would a machine learning engineer or product manager want
to understand this data? We'll then live-code a Streamlit app to
facilitate their needs.&lt;/p&gt;
&lt;p&gt;Part three will get nerdier! We'll integrate an object detection model
(YOLO v3) into our app to explore the potential tooling benefits from
interactive inference.&lt;/p&gt;
&lt;p&gt;At the end of the workshop you will have (1) a beautiful demo to show
off to friends, and (2) a new weapon to tackle tooling problems in your
own projects.&lt;/p&gt;
&lt;p&gt;See the GitHub: &lt;a class="reference external" href="https://github.com/streamlit/demo-self-driving"&gt;https://github.com/streamlit/demo-self-driving&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adrien Treuille</dc:creator><pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-03:pydata-la-2019/turn-python-scripts-into-beautiful-ml-tools.html</guid></item><item><title>Web Scraping w BeautifulSoup &amp; Yelp's API</title><link>https://pyvideo.org/pydata-la-2019/web-scraping-w-beautifulsoup-yelps-api.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this tutorial, we will explore web scraping basics using requests,
BeautifulSoup, and the Yelp API. The tutorial will be split up into two
use cases, the first scraping a business directory and the second Yelp
business listngs. This hands-on tutorial will be played out using a
Jupyter Notebook.&lt;/p&gt;
&lt;p&gt;Participants will need to create a Yelp Developer Account.&lt;/p&gt;
&lt;p&gt;In this web scraping tutorial we will cover the following:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Why data enrichment and web scraping can be helpful - operational
insights, resource allocation, business intelligence&lt;/li&gt;
&lt;li&gt;Core puzzle pieces that work together to scrape - requests,
BeautifulSoup, pandas, for loops, f-strings&lt;/li&gt;
&lt;li&gt;Yellow Pages Web Scrape with BeautifulSoup: Scrape a top category of
the Yellow Pages, turn into df and export as csv&lt;/li&gt;
&lt;li&gt;Yelp Scrape using Yelp Fusion API: Scrape Yelp listings around
specific locations&lt;/li&gt;
&lt;li&gt;Summarize &amp;amp; Debrief&lt;/li&gt;
&lt;/ol&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Juan S Vasquez</dc:creator><pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-03:pydata-la-2019/web-scraping-w-beautifulsoup-yelps-api.html</guid></item></channel></rss>