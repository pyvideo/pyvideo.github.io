<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_sonali-fotedar.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-11-29T00:00:00+00:00</updated><entry><title>Deep generative models for image and text generation</title><link href="https://pyvideo.org/pydata-eindhoven-2019/deep-generative-models-for-image-and-text-generation.html" rel="alternate"></link><published>2019-11-29T00:00:00+00:00</published><updated>2019-11-29T00:00:00+00:00</updated><author><name>Dimitra Gkorou</name></author><id>tag:pyvideo.org,2019-11-29:pydata-eindhoven-2019/deep-generative-models-for-image-and-text-generation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deep generative models for text and image generation&lt;/p&gt;
&lt;p&gt;Can we program a computer to be creative? Doesnâ€™t everyone dream of
painting a portrait or writing poetry? If you are not a good painter nor
a good writer you can now rely on generative modeling, just like us.
Recently, computers became able to paint, write, produce movies, and
compose music thanks to the advance of generative modeling. In this
workshop we will demonstrate the principles and the architecture of
selected generative models for text and image.&lt;/p&gt;
&lt;p&gt;In the first part of the workshop, we will focus on image generation and
manipulation using Variational AutoEncoders (VAE). VAE is one the most
fundamental and well-established deep learning architectures for
generative modeling. We will describe the principles of VAE architecture
and its advantages over simple Autoencoders. We will guide the audience
to build VAE from scratch to generate images and to morph between
images.&lt;/p&gt;
&lt;p&gt;In the second part of the workshop, we will generate our own stories. We
will first cover the principles and architecture of Recurrent Neural
Networks (RNNs) and take a look at how these models can be used to
generate text. Then, we describe Long Short Term Memory Networks (LSTM),
which is another type of RNN. We observe its advantages over a basic RNN
model and see how it improves our generated text.&lt;/p&gt;
&lt;p&gt;We will provide notebooks. All you need is a laptop and basic python
knowledge!&lt;/p&gt;
</summary></entry></feed>