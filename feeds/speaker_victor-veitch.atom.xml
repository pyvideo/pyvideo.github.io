<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Victor Veitch</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_victor-veitch.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-08-03T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Adapting Text Embeddings for Causal Inference</title><link href="https://pyvideo.org/uai-2020/adapting-text-embeddings-for-causal-inference.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Victor Veitch</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/adapting-text-embeddings-for-causal-inference.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Adapting Text Embeddings for Causal Inference&lt;/p&gt;
&lt;p&gt;Victor Veitch (Columbia University)*; Dhanya Sridhar (Columbia University); David Blei (Columbia University)&lt;/p&gt;
&lt;p&gt;Does adding a theorem to a paper affect its chance of acceptance? Does labeling a post with the author’s gender affect the post popularity? This paper develops a method to …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Adapting Text Embeddings for Causal Inference&lt;/p&gt;
&lt;p&gt;Victor Veitch (Columbia University)*; Dhanya Sridhar (Columbia University); David Blei (Columbia University)&lt;/p&gt;
&lt;p&gt;Does adding a theorem to a paper affect its chance of acceptance? Does labeling a post with the author’s gender affect the post popularity? This paper develops a method to estimate such causal effects from observational text data, adjusting for confounding features of the text such as the subject or writing quality. We assume that the text suffices for causal adjustment but that, in practice, it is prohibitively high-dimensional. To address this challenge, we develop causally sufficient embeddings, low- dimensional document representations that preserve sufficient information for causal identification and allow for efficient estimation of causal effects. Causally sufficient embeddings combine two ideas. The first is supervised dimensionality reduction: causal adjustment requires only the aspects of text that are predictive of both the treatment and outcome. The second is efficient language modeling: representations of text are designed to dispose of linguistically irrelevant information, and this information is also causally irrelevant. Our method adapts language models (specifically, word embeddings and topic models) to learn document embeddings that are able to predict both treatment and outcome. We study causally sufficient embeddings with semi-synthetic datasets and find that they improve causal estimation over related embedding methods. We illustrate the methods by answering the two motivating questions---the effect of a theorem on paper acceptance and the effect of a gender label on post popularity. Code and data available at github.com/vveitch/causal-text-embeddings-tf2.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry></feed>