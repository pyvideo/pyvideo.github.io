<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_maria-khalusova.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-12-05T00:00:00+00:00</updated><entry><title>Machine Learning Model Evaluation Metrics</title><link href="https://pyvideo.org/pydata-la-2019/machine-learning-model-evaluation-metrics.html" rel="alternate"></link><published>2019-12-05T00:00:00+00:00</published><updated>2019-12-05T00:00:00+00:00</updated><author><name>Maria Khalusova</name></author><id>tag:pyvideo.org,2019-12-05:pydata-la-2019/machine-learning-model-evaluation-metrics.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Choosing the right evaluation metric for your machine learning project
is crucial, as it decides which model youâ€™ll ultimately use. How do you
choose an appropriate metric? This talk will explore the important
evaluation metrics used in regression and classification tasks, their
pros and cons, and how to make a smart decision.&lt;/p&gt;
&lt;p&gt;In this talk, we'll go through evaluation metrics for regression tasks
(R squared, MAE, MSE, RMSE, and RMSLE) and classification tasks
(Classification accuracy, Precision, Recall, F1 Score, ROC/AUC,
Precision/Recall AUC, Matthews Correlation Coefficient, and ways to
extend some of these from binary to multiclass problems). I'll talk
about the differences between them, the trade- offs, and when some may
be more helpful than others.&lt;/p&gt;
</summary></entry></feed>