<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/event_pycon-israel-2018.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-06-05T00:00:00+00:00</updated><entry><title>Advanced Celery Tricks</title><link href="https://pyvideo.org/pycon-israel-2018/advanced-celery-tricks.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Itamar Hartstein</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/advanced-celery-tricks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Advanced Celery Tricks - How we adapted and extended Celery to fit our data pipeline&lt;/p&gt;
&lt;p&gt;In Singular, we have a data pipeline which consists of hundreds of thousands of daily tasks, in varying length (from less than a second to hours per task), and with complex dependencies between them. In addition, we integrate with hundreds of third-party providers, which means that tasks are not necessarily reliable / predictable, so we need to be robust to failures and delays and be able to monitor them easily. We found Celery to be highly suitable to our needs as a task infrastructure, especially due to its distributed nature, its support for various workflows and its modular design. In particular, the fact that it is compatible with multiple technologies for conveying messages (&amp;quot;brokers&amp;quot;) and storing results (&amp;quot;backends&amp;quot;) greatly appealed to us.&lt;/p&gt;
&lt;p&gt;It wasn't an immediate fit however. We needed to extend Celery so it will fit our use cases: (1) We implemented a custom backend and a custom serialization method. (2) We tweaked the behavior of Celery's workflows (chains, groups and chords). (3) We needed to be able to update code easily without restarting workers. (4) and more..&lt;/p&gt;
&lt;p&gt;In this session we will discuss how we adapted Celery to our needs, as well as tools we developed for working with it better, and various advanced tips &amp;amp; tricks.&lt;/p&gt;
</summary><category term="celery"></category></entry><entry><title>Anomaly Detection using Neural Networks</title><link href="https://pyvideo.org/pycon-israel-2018/anomaly-detection-using-neural-networks.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Dean Langsam</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/anomaly-detection-using-neural-networks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;BlueVine is a leading provider of funding for small and medium sized businesses with a primary focus on speed, simplicity and transparency. Models that make decisions in real-time are a critical part of that effort and must be strictly monitored. Consequently, it is the responsibility of every data scientist at BlueVine to both develop and maintain a high level of performance for every model they own. Maintaining code is a hard task in itself and it is discussed a lot among software developers: code needs to run without errors, and more importantly - must run as expected. In data science, the notion of what’s expected becomes quite complex and sometimes not well-defined, due to the statistical nature of the problems. Without anomaly detection, it is possible for critical decisions to be made based on unexpected changes in the data or simply incorrect calculations. Therefore, it is critical to be able to detect such anomalies quickly while getting a concise message as to what is their nature. This quickly becomes a challenging task when keeping the human factor in mind - too many false positive may cause the user to become alert prone, thus rendering them useless, while a low detection rate may affect the integrity of our data. We leverage our historical data and some of the most advanced techniques in the field to classify anomalies against normal behaviour. We use Keras to train a neural network that predicts expected values in a time series using a series of previous timestamps. We also add auxiliary information for a rich multi-input prediction. If there were clear labels for anomalous data, a classifier could then be employed. This is not our case, and we need to find another strategy. We start with a trivial approach, comparing the difference between the prediction and the actual values. This method proved problematic as they would yield too many false positives and as robust thresholds would be hard to set manually for hundreds of time series. Therefore we used other methods for detection such as accumulating repeating anomalies that indicate continuous bursts and bayesian inference to detect shift in value distributions. Detecting changes in the behaviour of our data lets us quickly adapt and react. We can fix errors, change our ETL methods or retrain our models in a proactive manner.&lt;/p&gt;
</summary></entry><entry><title>Conversation Intelligence</title><link href="https://pyvideo.org/pycon-israel-2018/conversation-intelligence.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Raphael Cohen</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/conversation-intelligence.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Conversation Intelligence: Extracting Insights from Conversations&lt;/p&gt;
&lt;p&gt;Sales conversations are a valuable and still underutilized asset for organizations. Recording and analyzing these conversations allow companies to quickly train new representatives, identify optimal behaviour, share and enforce best practices and also propagate customer requests and pain points to other parts of the organization helping product designers prioritize the best features. To create value from recorded conversations one needs a Conversation Intelligence (CI) stack. We outline the different layers of our CI stack, namely Diarization (also known as Speaker Separation), Automatic Speech Recognition (ASR) and various Natural Language Processing (NLP), Deep Learning and data science algorithms for extracting insights. CI is a relatively new field because until recently conversations were not amenable to automated analysis at scale due to the high bar of applying speech recognition. However, recent developments in ASR technology (based on Deep Learning) have given rise to significantly higher accuracy rates and with that the ability to robustly extract information from conversations. We review recent advances as well the cutting-edge approaches we use for Speaker Separation which is critical to understanding the roles various speakers play in a conversation, review latest methods for embedding a segment of speech for speaker clustering and review overall system structure for a multi-modal solution. On top of these we demonstrate how both standard and novel NLP and Data Science approaches can help reveal conversational insights including: weak language, inclusive language or identifying customer propensity to buy. The insights are drawn from over 2 million sales calls we analyzed at Chorus.ai to help our customers’ sales reps have better conversations and close more deals.&lt;/p&gt;
</summary></entry><entry><title>Data leakage: How to avoid one of the most deceptive mistakes</title><link href="https://pyvideo.org/pycon-israel-2018/data-leakage-how-to-avoid-one-of-the-most-deceptive-mistakes.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Noah Eyal Altman</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/data-leakage-how-to-avoid-one-of-the-most-deceptive-mistakes.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Data leakage: How to avoid one of the most deceptive mistakes in data science&lt;/p&gt;
&lt;p&gt;Recently, my team started working on a project that aimed to detect fraud attacks. The performances of the initial model were excellent and we started to fantasize about moving to production. A more in-depth investigation discovered that our model suffered from data leakage. Data leakage is the creation of unexpected additional information in the training data, allowing a model or machine learning algorithm to make unrealistically good predictions. But the joy of good predictions won’t last long since the model learns from information that will not be available in real life. Data leakage is a wide field of problems ranging from the obvious mistake of using the target itself as an input to the model, to leaking of information from the future into the past. In this talk, I will explain what data leakage is, give real-world examples and share my experience with the audience. In addition, I will sharpen the differences between overfitting and data leakage and explain how to avoid both. During the talk I will also demonstrate some cool and useful pandas “good to know” tricks.&lt;/p&gt;
</summary></entry><entry><title>Deep model serving - scale and ergonomics</title><link href="https://pyvideo.org/pycon-israel-2018/deep-model-serving-scale-and-ergonomics.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Jenia Gorokhovsky</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/deep-model-serving-scale-and-ergonomics.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A serving system for Deep Learning models is a tricky design problem. It's a large scale production system, so we want it to scale well, adapt to changing traffic patterns, and have low latency. It’s also part of the Data Scientist’s core loop - so it should be very flexible, and running an experiment on live traffic should be easy. In this talk, I’ll discuss key design considerations for such a system covering both perspectives. I’ll also describe a system we built at Taboola for serving TensorFlow models. It serves billions of requests per day, spread over dozens of models, and still has pretty good ergonomics,&lt;/p&gt;
</summary></entry><entry><title>Evolutionary Computation Examples with Inspyred</title><link href="https://pyvideo.org/pycon-israel-2018/evolutionary-computation-examples-with-inspyred.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Jacob Barhak</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/evolutionary-computation-examples-with-inspyred.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This is joined work with Aaron Garrett who wrote Inspyred.&lt;/p&gt;
&lt;p&gt;Evolutionary Computation (EC) allows solving very complex optimization problems and NP Hard problems with relatively simple formulation. The Inspyred python library provides proper tools to solve such problems in a generic way, it supports genetic algorithms, simulated annealing and other EC techniques. The talk will provide an overview of the library and will show examples of application of the library to complex problems such as population generation with constraints and fair matching of groups towards tournament creation.&lt;/p&gt;
</summary><category term="inspyred"></category></entry><entry><title>Game Theory in Python</title><link href="https://pyvideo.org/pycon-israel-2018/game-theory-in-python.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Omer Nevo</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/game-theory-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Game theory has vast applications including international relations, economics, psychology and computer science. In this lecture we show how to create games and strategies and test or improve them. We'll start out very simply, with easy strategies for the prisoner's dilemma, and work our way up to using evolutionary heuristics to find optimal strategies for complex situations. It's an incredibly cool use of Python, and most people don't realize how easy it is to create things that sound relatively complex.&lt;/p&gt;
</summary><category term="game theory"></category></entry><entry><title>How Mobileye generates augmented images to boost autonomous driving</title><link href="https://pyvideo.org/pycon-israel-2018/how-mobileye-generates-augmented-images-to-boost-autonomous-driving.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Asya Frumkin</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/how-mobileye-generates-augmented-images-to-boost-autonomous-driving.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Detecting lanes and road markings are some of the great challenges autonomous driving technologies face today. In Mobileye, we do it by training neural networks. This method requires an enormous amount of data from many countries, different weather conditions etc. However, in some road scenarios the available data set is still too small, or the data is not accurate. In this session, I will discuss how we developed a system that uses Python with OpenCV to generate augmented images and matching ground truth data in order to improve accuracy of neural networks.&lt;/p&gt;
</summary></entry><entry><title>Launch Jupyter to the Cloud with Docker and Terraform</title><link href="https://pyvideo.org/pycon-israel-2018/launch-jupyter-to-the-cloud-with-docker-and-terraform.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Cheuk Ting Ho</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/launch-jupyter-to-the-cloud-with-docker-and-terraform.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Launch Jupyter to the Cloud: an example of using Docker and Terraform&lt;/p&gt;
&lt;p&gt;In this talk, we will use a task: hiring a GPU on Google Cloud Platform to train neural network, as an example to show how an application can be deployed on a cloud platform with Docker and Terraform. The goal is to have Jupyter Notebook running in an environment with Tensorflow (GPU version) and other libraries installed on a Google Compute Engine.&lt;/p&gt;
&lt;p&gt;This talk is for people with no experience in application deployment on cloud service but would benefit form computational reproducibility and cloud service, potentially data scientists/ analysts or tech practitioners who didn't have a software developing background. We will use an example that is simple but useful in data science to demonstrate basic usage of Docker and Terraform which would be beneficial to beginners who would like to simplify their work flow with those tools.&lt;/p&gt;
</summary><category term="jupyter"></category><category term="docker"></category><category term="terraform"></category></entry><entry><title>Let's build a Python profiler from scratch</title><link href="https://pyvideo.org/pycon-israel-2018/lets-build-a-python-profiler-from-scratch.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Noam Elfanbaum</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/lets-build-a-python-profiler-from-scratch.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we'll build a Python profiler from scratch and so learn about the dynamic nature of Python and how do well know profilers such as cProfile work. Also, we'll learn the difference between a tracing and a sampling profiler and which one to use in what circumstance.&lt;/p&gt;
</summary><category term="profiler"></category></entry><entry><title>ML for automated behavior analysis in schizophrenia</title><link href="https://pyvideo.org/pycon-israel-2018/ml-for-automated-behavior-analysis-in-schizophrenia.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Talia Tron</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/ml-for-automated-behavior-analysis-in-schizophrenia.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we will describe the usage of accelerometer and 3d cameras for analysis of motor behavior and facial expressions in schizophrenia patients. We combine descriptive statistical methods together with data-driven analysis techniques including time series forecasting, machine learning and natural language processing (NLP) algorithms. With these techniques, we obtain a wide range of nonverbal characteristic measures, including the intensity, dynamics, consistency and appropriateness of facial and motor behavior. These measures are used to automatically classify clinical sub-population, evaluate symptom severity and identify significant irregularities in patients behavior over time.&lt;/p&gt;
</summary><category term="schizophrenia"></category></entry><entry><title>Model Calibration - is your model ready for the real world?</title><link href="https://pyvideo.org/pycon-israel-2018/model-calibration-is-your-model-ready-for-the-real-world.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Inbar Naor</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/model-calibration-is-your-model-ready-for-the-real-world.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Evaluating the performance of a machine learning model is important, but in many real world applications it is not enough. We often care about the confidence of the model in its predictions, its error distribution and how probability estimates are being made. Many classifiers have good overall results but bad probability estimates. For these cases, different calibration techniques have been developed over the years. Intuitively, a model is calibrated if among the samples that get 0.8 probability estimates, about 80% actually belong to the positive class. Even good data scientists sometimes forget about calibration and wrongly treat the model output as real probabilities, which could result in poor system performance or bad decision making. In this talk I will present different methods to calibrate a model such as platt scaling and isotonic regression, discuss how they behave with different classification methods and show how to test the calibration of your model. The lecture will be accompanied by code examples in python.&lt;/p&gt;
</summary></entry><entry><title>My journey for python3 readiness on a huge python code base</title><link href="https://pyvideo.org/pycon-israel-2018/my-journey-for-python3-readiness-on-a-huge-python-code-base.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Yehuda Lavy</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/my-journey-for-python3-readiness-on-a-huge-python-code-base.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;My journey for python3 readiness in the biggest python code base I know. JP Morgan has one of the largest python code bases in the world, We will discuss the preperation steps for the upgrade to python3.&lt;/p&gt;
</summary></entry><entry><title>Overcoming the Development Challenges of Machine Learning Products</title><link href="https://pyvideo.org/pycon-israel-2018/overcoming-the-development-challenges-of-machine-learning-products.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Ohad Zadok</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/overcoming-the-development-challenges-of-machine-learning-products.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When building Machine Learning products, developers often encounter challenges that can waste both time and money. Common pitfalls include complex model pipelines, which can lead to exponential increases in development time. Data tagging, typically a tedious job, can be reduced significantly when using techniques such as Transfer Learning. In many cases, solutions that show great promise in development or test cycles fail to materialize in production. Data Driven Development (DDD) can create a more focused development cycle, reducing unwanted surprises when the model is released.&lt;/p&gt;
&lt;p&gt;In this presentation, Ohad Zadok will focus specifically on the Machine Learning challenges developers face. Ohad will provide methodologies that will enable the scalability and performance needed to succeed. The presentation will also highlight examples of Machine Learning failures and how seemingly promising solutions may never reach expected levels of success. The lecture is based on Ohad's experience in a Machine Learning focused startup, which grew from six employees to more than eighty employees during his tenure, and this Google research paper &amp;quot;Hidden Technical Debt in Machine Learning Systems&amp;quot;.&lt;/p&gt;
</summary></entry><entry><title>Pied PyPIer: Why packaging is important</title><link href="https://pyvideo.org/pycon-israel-2018/pied-pypier-why-packaging-is-important.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Shay Palachy</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/pied-pypier-why-packaging-is-important.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pied PyPIer: Why packaging is important for both close and open data science projects&lt;/p&gt;
&lt;p&gt;When working on data science projects we are often tempted to leave our code to rot in scattered notebooks or Python modules deep in the project’s repository.&lt;/p&gt;
&lt;p&gt;However, even when you can’t release parts of your code as open source, breaking some important components into standalone Python packages can help with managing technical debt and code maintenance, facilitate in-house code reuse and repurposing, and make production-ising and deployment of code easier.&lt;/p&gt;
&lt;p&gt;In this talk I'll try to demonstrate the ways treating your components and problem solutions as independent packages can benefit both your colleagues and (present and future) you, and review the tools Python provides for building and managing these packages, both in-company and openly.&lt;/p&gt;
&lt;p&gt;I will also share from my experience in packaging some of my code, and discuss the extra benefits from open sourcing packages even when they are used mainly internally.&lt;/p&gt;
</summary></entry><entry><title>Pulling Radio Data out of Thin Air</title><link href="https://pyvideo.org/pycon-israel-2018/pulling-radio-data-out-of-thin-air.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Yuval Adam</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/pulling-radio-data-out-of-thin-air.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Radio waves are all around us, yet they are usually inaccessible from typical software applications. Recent years have seen an explosion of software-defined radio (SDR) applications, mainly due to the availability of cheap ($10) USB radio dongles. SDR can be utilized not only to listen to FM radio, but also to track airplanes in the sky, interact with wireless consumer electronics, and even receive satellite imagery. This interactive and fast-paced talk will provide a glimpse into the vast world of SDR, and show which tools in the Python ecosystem are available for building radio-aware applications.&lt;/p&gt;
</summary><category term="software defined radio"></category><category term="sdr"></category><category term="pyrtlsdr"></category></entry><entry><title>PyVCR - Or how we cut our testing time from 5mins to 5s</title><link href="https://pyvideo.org/pycon-israel-2018/pyvcr-or-how-we-cut-our-testing-time-from-5mins-to-5s.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Nir Krakowski</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/pyvcr-or-how-we-cut-our-testing-time-from-5mins-to-5s.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A few months ago we decided to upgrade our CI to include integration tests beyond the usual unit tests for our DNA synthesis and ordering platform. Rather than mocking our complex microservices environment, we chose to use VCR to record and replay the interactions. We will discuss the pros &amp;amp; cons of using PyVCR with examples and a walk through on how to use it.&lt;/p&gt;
</summary><category term="testing"></category><category term="pyvcr"></category></entry><entry><title>Raspberry pi as a home automation controller using pymodbus</title><link href="https://pyvideo.org/pycon-israel-2018/raspberry-pi-as-a-home-automation-controller-using-pymodbus.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Yaacov Zamir</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/raspberry-pi-as-a-home-automation-controller-using-pymodbus.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Raspberry pi as a home automation controller using pymodbus and node-red&lt;/p&gt;
&lt;p&gt;In this session we will introduce pymodbus, talk about the pros and cons of using serial communication in our modern publish-subscribe messaging age, and demo the use of pymodbus for home automation using Raspberry pi and node-red.&lt;/p&gt;
</summary><category term="pymodbus"></category><category term="raspberry pi"></category><category term="home automation"></category></entry><entry><title>Testing at scale - Leveraging py.test</title><link href="https://pyvideo.org/pycon-israel-2018/testing-at-scale-leveraging-pytest.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Carine Belle Feder</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/testing-at-scale-leveraging-pytest.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Testing at scale - Leveraging py.test to test over multiple clouds&lt;/p&gt;
&lt;p&gt;Oracle-Ravello enables enterprises to simply lift and shift complex virtualized environments to the cloud - with no changes to the virtual machines or their network. To do it well, we leverage py.test as the backbone of our host and networking testing infrastructure. We wanted to test our product over multiple environments, with a huge set of parameters - but still run them in parallel. For us - a cloud company - the solution seemed obvious; We mixed and matched several python packages with cloud APIs to create a robust yet simple testing system. Want to work on a different cloud? Just add a command line flag. Want to test if your product can work on any hardware? just add a parameter. We will start by introducing our own testing use cases and the python packages that were useful to us. Then, we'll take a look at several tests while demonstrating how easy it is to add more tests and features, and run an example on Oracle Cloud Infrastructure with python API.&lt;/p&gt;
</summary></entry><entry><title>Text Analysis With SpaCy, NLTK, Gensim, Skearn...</title><link href="https://pyvideo.org/pycon-israel-2018/text-analysis-with-spacy-nltk-gensim-skearn.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Bhargav Srinivasa Desikan</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/text-analysis-with-spacy-nltk-gensim-skearn.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Text Analysis With SpaCy, NLTK, Gensim, Skearn, Keras and TensorFlow&lt;/p&gt;
&lt;p&gt;The explosion in Artificial Intelligence and Machine Learning is unprecedented now - and text analysis is likely the most easily accessible and understandable part of this. And with python, it is crazy easy to do this - python has been used as a parsing langauge forever, and with the rich set of Natural Language Processing and Computational Linguistic tools, it's worth doing text analysis even if you don't want to.&lt;/p&gt;
&lt;p&gt;The purpose of this talk is to convince the python community to do text analysis - and explain both the hows and the whys. Python has traditionally been a very good parsing language, aruguably replacing perl for all text file handling tasks. Reading files, regular expressions, writring to files, crawling on the web for textual data have all been standard ways to use python - and now with the Machine Learning and AI explosion - we have a great set of tools in python to understand all the textual data we can so easily play with.&lt;/p&gt;
&lt;p&gt;I will be briefly talking aboubt the merits, de-merits and use-cases of the most popular text processing libraries. In particular, these will be spaCy, NLTK, gensim. I will also talk about how to use traditional Machine Learning libraries for text analysis, such as scikit-learn, Keras and TensorFlow.&lt;/p&gt;
&lt;p&gt;Pre-processing is the one of the most important steps of Text Analysis, and I will talk more about this - after all, garbage in, garbage out!&lt;/p&gt;
&lt;p&gt;The final part of the talk will be about where to get your data - and how to create your own textual data as well. You could analyse anything, from your own emails and whatsapp conversations to freely available British Parliament transcripts!&lt;/p&gt;
</summary></entry><entry><title>The web is terrifying</title><link href="https://pyvideo.org/pycon-israel-2018/the-web-is-terrifying.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Sarah Bird</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/the-web-is-terrifying.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Using PyData tools and a new dataset from Mozilla, we can explore some of the many ways we are tracked around the internet, and look at what this means now that the EU's General Data Protection Regulation (GDPR) has come into force. Sarah will also talk about becoming a software engineer, then a builder of data science tools, and her new journey into a data science.&lt;/p&gt;
</summary></entry><entry><title>Women in Tech/startups/coding - Does it matter?</title><link href="https://pyvideo.org/pycon-israel-2018/women-in-techstartupscoding-does-it-matter.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Michal Michaeli</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/women-in-techstartupscoding-does-it-matter.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While being geeky supposed to hold more appeal than ever, it seems it doesn’t affect women, or girls, the same way. And though the rise in technology and coding in our life is undeniable – women still take less than 20% of jobs in technology, less than 10% of startup entrepreneurs and not even 15% coders. Those numbers matter cause they tell a story and based on it we can discuss if that is how we want/need it to be. And if not – what can be done to change it.&lt;/p&gt;
</summary></entry><entry><title>A tale of DNA, Numpy, and 3 types of Jews</title><link href="https://pyvideo.org/pycon-israel-2018/a-tale-of-dna-numpy-and-3-types-of-jews.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Daniel Levy</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/a-tale-of-dna-numpy-and-3-types-of-jews.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We all know that our DNA is what makes us US. So if we have our DNA data, what can we tell about us ? Our presentation will focus on one of the problems that we’ve been working on at MyHeritage, which is telling you, based only on your DNA, what is your ethnic background.&lt;/p&gt;
&lt;p&gt;In the talk we’ll discuss how to treat this question as a machine learning problem (using standard tools like sklearn and numpy for a distinctive set of problems), what sets it apart from classical classification problems, and our approach for answering this question using thousands of models, not too many samples, but way too many features.&lt;/p&gt;
&lt;p&gt;We will also talk about how Jewish genealogy introduces additional difficulties.&lt;/p&gt;
&lt;p&gt;This is joint work by Professor Yaniv Erlich, Dr Daniel Levy, and Luis Voloch.&lt;/p&gt;
</summary></entry><entry><title>Apache Amaterasu (incubating): A CD Framework for your Big Data Pipelines</title><link href="https://pyvideo.org/pycon-israel-2018/apache-amaterasu-incubating-a-cd-framework-for-your-big-data-pipelines.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Nadav Har Tzvi</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/apache-amaterasu-incubating-a-cd-framework-for-your-big-data-pipelines.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the last few years, the DevOps movement has introduced ground breaking approaches to the way we manage the lifecycle of software development and deployment. Today organisations aspire to fully automate the deployment of microservices and web applications with tools such as Chef, Puppet and Ansible. However, the deployment of data-processing pipelines remains a relic from the dark-ages of software development.&lt;/p&gt;
&lt;p&gt;Processing large-scale data pipelines is the main engineering task of the Big Data era, and it should be treated with the same respect and craftsmanship as any other piece of software. That is why we created Apache Amaterasu (Incubating) - an open source framework that takes care of the specific needs of Big Data applications in the world of continuous delivery.&lt;/p&gt;
&lt;p&gt;In this session, we will take a close look at Apache Amaterasu (Incubating) a simple and powerful framework to build and dispense pipelines. Amaterasu aims to help data engineers and data scientists to compose, configure, test, package, deploy and execute data pipelines written using multiple tools, languages and frameworks. We will see what Amaterasu provides today, and how it can help existing Big Data application and demo some of the new bits that are coming in the near future.&lt;/p&gt;
</summary><category term="amaterasu"></category></entry><entry><title>Boosting development in a containerised microservices environment</title><link href="https://pyvideo.org/pycon-israel-2018/boosting-development-in-a-containerised-microservices-environment.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Ron Anavi</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/boosting-development-in-a-containerised-microservices-environment.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We started as a development team of two people working on 2 containerised services. While we were concerned about scale, we weren't concerned about scaling the team itself, so we built our services using simple makefiles and each service had its own compose file. After a few months we found ourselves working with ~20 developers from 3 different teams, across several countries, collaborating on the same project, with 25 containerised python microservices.&lt;/p&gt;
&lt;p&gt;A major growing pain we experienced was the “onboarding” process for our new team members. In order to automate and expedite the process, we wrote deployment scripts intended to easily create new dev environments. It didn’t work out as planned and the consequence was the vast majority of developers debugging/testing their own code remotely, rather than on their local machines.&lt;/p&gt;
&lt;p&gt;After taking some time to reflect on the topic, we set out to solve the challenge of maintaining a stable and scalable dev environment within a growing team. These efforts can be summarized as the following:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Simplify container orchestration for local development environments&lt;/li&gt;
&lt;li&gt;Build time optimization for local and CI processes&lt;/li&gt;
&lt;li&gt;Maintaining and developing on multiple python environments (Python2/Python3/PyPy) with minimal setup overhead&lt;/li&gt;
&lt;li&gt;Taking care of different caching aspects related to our CI and local builds&lt;/li&gt;
&lt;li&gt;Enabling debug of the code in the container using its python interpreter&lt;/li&gt;
&lt;li&gt;Creation of a monitoring solution for inter-service communication&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This was and continues to be a journey towards improving our processes and mindset of growing a development team while reducing unnecessary pain. After learning the lessons above, we are excited to share our experiences with the community in an effort to help us all grow and improve together.&lt;/p&gt;
</summary></entry><entry><title>Cross platform automation in Python</title><link href="https://pyvideo.org/pycon-israel-2018/cross-platform-automation-in-python.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Aharon Rubin</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/cross-platform-automation-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Automating multiple platforms together for testing a complicated environment with complicated scenario is always a challenge. I will show a case study and how we implemented a solution that was running end to end scenario with mobile phones (iOS and Android), windows native and browser technologies. I will show how we met the challenge and orchestrated the entire testing with continuous integration (GIT and Jenkins).&lt;/p&gt;
</summary></entry><entry><title>Dataclasses: The effortless tool to define data</title><link href="https://pyvideo.org/pycon-israel-2018/dataclasses-the-effortless-tool-to-define-data.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Eli Gur</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/dataclasses-the-effortless-tool-to-define-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Available starting Python 3.7, the dataclasses (introduced in PEP 557) are finally here. Amazingly simple solution for data with great exressiveness, the next generation of dicts, named tuples and records. The presentation will explain what the dataclasses are, show practical examples, and go over the main features and the key design decisions as well as the capabilities.&lt;/p&gt;
</summary><category term="dataclasses"></category></entry><entry><title>Dataframe Validation In Python - A Practical Introduction</title><link href="https://pyvideo.org/pycon-israel-2018/dataframe-validation-in-python-a-practical-introduction.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Yotam Perkal</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/dataframe-validation-in-python-a-practical-introduction.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As Machine Learning models rely on data in order to make their predictions, data quality evaluation is a crucial aspect of any ML pipeline. We as Engineers/Data-Scientists, should validate our data in the same manner in which we validate our code. Data errors can lead to: Bad and costly decisions, Inaccurate predictions due to invalid data and Time waste. There is an abundance of different libraries that perform various kinds of data integrity checks. I will specifically focus on Dataframe validation.&lt;/p&gt;
&lt;p&gt;In this talk, I will present the problem and give a practical overview (accompanied by Jupyter Notebook code examples) of three libraries that aim to address it:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Voluptuous - Which uses Schema definitions in order to validate data [&lt;a class="reference external" href="https://github.com/alecthomas/voluptuous"&gt;https://github.com/alecthomas/voluptuous&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Engarde - A lightweight way to explicitly state your assumptions about the data and check that they're actually true [&lt;a class="reference external" href="https://github.com/TomAugspurger/engarde"&gt;https://github.com/TomAugspurger/engarde&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;TDDA - Test Driven Data Analysis [ &lt;a class="reference external" href="https://github.com/tdda/tdda"&gt;https://github.com/tdda/tdda&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By the end of this talk, you will understand the Importance of data validation and get a sense of how to integrate data validation principles as part of the ML pipeline.&lt;/p&gt;
</summary></entry><entry><title>Developing Cloud Serverless Components in Python</title><link href="https://pyvideo.org/pycon-israel-2018/developing-cloud-serverless-components-in-python.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Asher Sterkin</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/developing-cloud-serverless-components-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Serverless cloud architectures gain momentum.The number of completely managed services and serverless computation environments (Function As a Service) is already large and growing at substantial pace. For computation services (aka Function as a Service) Python is usually supported out of the box and at least in some environments (AWS) yields superior performance. However the same is for JavaScript with a strong argument in favor of full-stack development. In this talk I will demonstrate how by applying Domain-Driven Design patterns front-end services where JavaScript might be more suitable could be delineated from core domain services where Python has a number of clear advantages.&lt;/p&gt;
</summary><category term="serverless"></category></entry><entry><title>ETL-ing the Israeli Government (and living to tell the tale)</title><link href="https://pyvideo.org/pycon-israel-2018/etl-ing-the-israeli-government-and-living-to-tell-the-tale.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Adam Kariv</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/etl-ing-the-israeli-government-and-living-to-tell-the-tale.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the past 8 years we've been collecting, scraping and processing government data - overcoming technical, legal and other hurdles - to create Israel's richest database of fiscal data (and growing!). In this talk I will talk about how we're doing this (we - at the Public Knowledge Workshop), and present the unique software frameworks and tools we've built to accomplish this goal. In particular, I will talk about the data-package pipelines framework, which combines a suite of standards and tools for 'packaging' data as well as a versatile engine for processing data streams.&lt;/p&gt;
</summary><category term="etl"></category><category term="government"></category></entry><entry><title>Exploiting network namespaces for fun and profit</title><link href="https://pyvideo.org/pycon-israel-2018/exploiting-network-namespaces-for-fun-and-profit.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Omri Bahumi</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/exploiting-network-namespaces-for-fun-and-profit.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;What are namespaces?
What network namespaces do?
How containers use namespaces?
What can we do with this?&lt;/p&gt;
&lt;p&gt;Eventually, we will be able to write this:&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;Tor&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
  &lt;span class="c1"&gt;# all code in here will be routed through the Tor container's network&lt;/span&gt;
  &lt;span class="c1"&gt;# namespace, even subprocesses!&lt;/span&gt;
  &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'http://jsonip.com/'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;
</summary><category term="namespaces"></category></entry><entry><title>Hacking for Fun &amp; Profit: The Kubernetes Way</title><link href="https://pyvideo.org/pycon-israel-2018/hacking-for-fun-profit-the-kubernetes-way.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Demi Ben Ari</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/hacking-for-fun-profit-the-kubernetes-way.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;To defend against attacks, think like a hacker. But does that mean you need to be a DevOps expert? Security researchers today need to discover new attack techniques. However, much of their focus is diverged to backend coding. We share how to build an infrastructure for researchers that allows them concentrate on business logic and writing hacker “tasks”. Using Python, Celery, Docker and Kubernetes on Google Cloud, these tasks can then be performed in parallel and without a lot of DevOps hassle. Our technique removes two common barriers: first, long and risky deployment processes and second, low transparency within the production system.&lt;/p&gt;
&lt;p&gt;Promise to share the stupid things too.&lt;/p&gt;
</summary></entry><entry><title>Help your colleagues help themselves - a Sphinx tutorial</title><link href="https://pyvideo.org/pycon-israel-2018/help-your-colleagues-help-themselves-a-sphinx-tutorial.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Dalya Gartzman</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/help-your-colleagues-help-themselves-a-sphinx-tutorial.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever found yourself developing a tool only to find it already exists somewhere else in the code? Have you ever wondered what does AlexsCoolFunction do? Did you ever put a funny comment in your code and was upset that noone will read it? Then maybe it’s time to have a better documentation system! Join me for this tutorial, where we will sail through the onboarding stage of Sphinx - an automated documentation package, and learn how we can all collaborate better.&lt;/p&gt;
</summary><category term="sphinx"></category></entry><entry><title>How to scale up your morning commute with python</title><link href="https://pyvideo.org/pycon-israel-2018/how-to-scale-up-your-morning-commute-with-python.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Asaf Azar</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/how-to-scale-up-your-morning-commute-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Via has built the world's leading operating system for on-demand shared mobility. Think about a dynamic &amp;amp; smart fleet of “moniot sherut” - routing and scheduling is computed in real time to maximize the potential of each and every seat across all the vehicles on the platform. Our service provides over 1M rides a months across cities like NYC, Chicago, Washington DC, London, Amsterdam and more.&lt;/p&gt;
&lt;p&gt;We also join efforts with transportation companies, municipalities and other partners in order to help cities transition their bus systems from rigid lines and fixed schedules to on-demand networks of dynamic shuttles.&lt;/p&gt;
&lt;p&gt;Our service is essential all over the world, and we're scaling up very fast within each location and into new locations. Each city might also require specific and unique customizations of our operating system, whether they’d be regulatory or business-related.&lt;/p&gt;
&lt;p&gt;Thus, scaling up both horizontally and vertically while maintaining flexibility, reliability and continuous introduction of new capabilities raises challenges such as:&lt;/p&gt;
&lt;p&gt;Having a different set of features for each service;&lt;/p&gt;
&lt;p&gt;Developing numerous setup variations;&lt;/p&gt;
&lt;p&gt;Handling Dependencies between various modules;&lt;/p&gt;
&lt;p&gt;Managing multiple application brands;&lt;/p&gt;
&lt;p&gt;And more....&lt;/p&gt;
&lt;p&gt;We will demonstrate how we tackle these challenges using Python tools while keeping our system fast, efficient, stable and easy to maintain.&lt;/p&gt;
</summary></entry><entry><title>"I Abstain" - teaching DL when to shut up</title><link href="https://pyvideo.org/pycon-israel-2018/i-abstain-teaching-dl-when-to-shut-up.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Tsvi Lev</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/i-abstain-teaching-dl-when-to-shut-up.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When a single decision by a deep network has significant implications (e.g. Medical, Financial, Safety), accuracy is critical. We show some novel methods (some invented at NEC and some public knowledge) to improve accuracy at the cost of 'not answering' in cases the network model feels uncertain.&lt;/p&gt;
</summary></entry><entry><title>I Code Life – is DNA the next coding language?</title><link href="https://pyvideo.org/pycon-israel-2018/i-code-life-is-dna-the-next-coding-language.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Yogev Debbi</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/i-code-life-is-dna-the-next-coding-language.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The next generation of Genetic Engineering is the ability to design and make synthetic genes - the DNA of all living organisms. This is used across multiple industries, like pharma, agriculture, chemical production and even data storage. Twist Bioscience developed disruptive technology to synthesize DNA and its Israel R&amp;amp;D center develops software tools to design and debug DNA sequences by its customers. Yogev will describe the challenges, technology and application of the next generation of Genetic engineering, led by Nano-technology and Software.&lt;/p&gt;
</summary><category term="DNA"></category></entry><entry><title>Learning to Control Any Device With Python and Salt</title><link href="https://pyvideo.org/pycon-israel-2018/learning-to-control-any-device-with-python-and-salt.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Mike Place</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/learning-to-control-any-device-with-python-and-salt.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;From data centers with tens of thousands of servers, to cloud deployments with millions of containers and from IoT weather stations across Africa to computers labs in universities and home offices -- people use Python and Salt to control a myriad of devices.&lt;/p&gt;
&lt;p&gt;In this talk, we'll show people without any previous systems management experience how easy it is to leverage Salt and Python to write basic modules to control anything from a laptop to a datacenter. Attendees will come away with practical knowledge about how translate their Python knowledge into systems management know-how that can be applied straight away.&lt;/p&gt;
</summary><category term="salt"></category></entry><entry><title>Opening Session</title><link href="https://pyvideo.org/pycon-israel-2018/opening-session.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Sahi Berger</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/opening-session.html</id><summary type="html"></summary></entry><entry><title>Pushing the right button</title><link href="https://pyvideo.org/pycon-israel-2018/pushing-the-right-button.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Dana Averbuch</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/pushing-the-right-button.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever been asked to implement some crazy idea? To scratch your right ear with your left hand? To solve a problem which intuitively should not be solved as a data science problem? There are all kind of situations in which, as a data scientist, you may be asked to use your magic and find a solution for a problem that seems out of scope and very different from the problems you usually deal with. Whether those reasons are business constraints, customers demand, unavailable simple solutions, it all comes down to the same question: Would you accept the challenge?&lt;/p&gt;
&lt;p&gt;In this talk we’ll explore a real-world challenge and try to answer some questions that all data scientists should ask themselves when facing a new problem:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Does a “data science” approach make any sense for a certain problem?&lt;/li&gt;
&lt;li&gt;What other alternatives are available?&lt;/li&gt;
&lt;li&gt;How much time and resources should be spent?&lt;/li&gt;
&lt;li&gt;What is the accuracy level that a good solution should reach?&lt;/li&gt;
&lt;/ul&gt;
</summary></entry><entry><title>Python: Behind The Scenes</title><link href="https://pyvideo.org/pycon-israel-2018/python-behind-the-scenes.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Diana Gastrin</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/python-behind-the-scenes.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When you are writing code, you have a very clear target: that the code will run and that the output will be accurate. But have you ever stopped and thought about the language in which you are writing?&lt;/p&gt;
&lt;p&gt;The lecture will deal with topics that programmers usually don't talk about: evaluation order, the variables environment, what happens behind the scenes, and in general - the meaning of every line of the code.&lt;/p&gt;
</summary></entry><entry><title>Python tools to Manage Large Scale</title><link href="https://pyvideo.org/pycon-israel-2018/python-tools-to-manage-large-scale.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Arie Abramovici</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/python-tools-to-manage-large-scale.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python tools to Manage Large Scale, Multi-cloud Deployments&lt;/p&gt;
&lt;p&gt;Managing large scale deployments over multiple clouds can be a bit of a hassle. In this talk we will discuss the challenges (and opportunities) Waze found, in it's quest to Outsmart Traffic over GCP and AWS, how we overcame them. We will also showcase our open source python libraries used for that purpose.&lt;/p&gt;
</summary></entry><entry><title>Speeding up Python with Rust to synthesize DNA</title><link href="https://pyvideo.org/pycon-israel-2018/speeding-up-python-with-rust-to-synthesize-dna.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Pablo Klijnjan</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/speeding-up-python-with-rust-to-synthesize-dna.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When performance is a key factor for your algorithm, Python might not be the best tool. Rust is a system programming language with strong security guarantees and C-like performance while remaining as productive as Python. We will explore why we chose Rust as the language to implement parts of our biological algorithm.&lt;/p&gt;
</summary></entry><entry><title>Tackling Location Based Data Challenges</title><link href="https://pyvideo.org/pycon-israel-2018/tackling-location-based-data-challenges.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Eli Safra</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/tackling-location-based-data-challenges.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Geographic data requires special treatment when tackling Data challenges. For example, bucketing latitude/longitude into equal size buckets may be misleading due to the curvature of the earth surface and land usage. At this talk we will discuss what Python libraries can be used for working with Geospatial data and how to use them properly.&lt;/p&gt;
</summary><category term="gis"></category></entry><entry><title>telluric: interactive manipulation of Geospatial data</title><link href="https://pyvideo.org/pycon-israel-2018/telluric-interactive-manipulation-of-geospatial-data.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Guy Doulberg</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/telluric-interactive-manipulation-of-geospatial-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;telluric: interactive manipulation of Geospatial data with Jupyter and Python&lt;/p&gt;
&lt;p&gt;telluric library is an open source library developed by Satellogic, which aims to be an one stop source (library) for manipulating geospatial data in an interactive way. The library facilitates the use and manipulation of Geo Vectors and Geo Rasters by creating an integrated and unified API on top of a combination of domain specific python libraries, such us: rasterio, Shapely, Fiona, and more. For wide compatibility, telluric library supports all known GIS raster and vector formats. telluric library was developed with Jupyter notebook in mind, in which all operations auto-generate the appropriate visualization, and presented on top of an interactive map, with no additional effort.&lt;/p&gt;
&lt;p&gt;In this presentation we will show how to use telluric library to manipulate geospatial information and how it integrates in a Python GIS ecosystem, explain how we utilize telluric in Satellogic for diversity of tasks like: geospatial data management, coverage analysis of satellites constellation and visualization, and commenting on the plans for the future releases.&lt;/p&gt;
</summary><category term="telluric"></category><category term="gis"></category></entry><entry><title>Tidy Data in Python</title><link href="https://pyvideo.org/pycon-israel-2018/tidy-data-in-python.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Aviv Rotman</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/tidy-data-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you ask any data scientist what is the most frustrating and time consuming part of a data science project, surprisingly they won't say visualization, neural network architecture, or feature engineering, they will most probably say cleaning and shaping data. The struggle to work with messy data is what can make or break a project and sometimes hide the real gems the data has to show us. Many junior data practitioners shrug off this stage as mechanic and boring, and tend to put little thought towards it. It turns out that there is a &amp;quot;right&amp;quot; way to tidy data that allows for easy analysis and visualization down the line Tidy data has a specific structure, which can be summarized in two sentences: each variable is a column; each observation is a row. The simplicity of this strategy makes it easy to understand how to tidy data, and only requires a small set of tools to deal with a wide range of messy datasets. These tools have been developed in the popular r packages dplyr and tidyr. Alas, this is not an r conference, and we are but hapless python developers. Is our fate to be left out in the cold with all our messy data?!? Not on my watch! In this talk we will learn about &amp;quot;tidy data&amp;quot;, a strategy formulated by Hadley Wickham in 2014. We will also go over common cases of messy data and how to tidy them with python tools, and we will see how using this system we can quickly achieve complex analyses and intuitive visualizations.&lt;/p&gt;
</summary></entry><entry><title>Value Driven Threat Modeling - Security by Design</title><link href="https://pyvideo.org/pycon-israel-2018/value-driven-threat-modeling-security-by-design.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Avi Douglen</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/value-driven-threat-modeling-security-by-design.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Threat Modeling is a great method to identify potential security weaknesses, and is an important part of any secure design. A threat model can help analyze how to best protect your assets, prevent attacks, harden your systems, and efficiently prioritize security investment. Regardless of programming language, threat modeling provides a far greater return than most any other security technique in the development process. Therefore, threat modeling should be an early priority in application design process. Unfortunately, it is common knowledge that building a full threat model is always heavily resource intensive, requires a full team of expensive security professionals, takes up far too much developer time, and does not scale at all.&lt;/p&gt;
&lt;p&gt;But the common knowledge is wrong! In fact, this is not at all necessary, and should not be an excuse to avoid building a robust system. Using a value-driven approach, skilled development teams can very efficiently ensure that the features they build can protect themselves, the application, and the business value that the features were created for. Value Driven Threat Modeling offers an alternative to top-heavy, big-model-up-front threat modeling that security pros love, in favor of agility, speed, and developer independence.&lt;/p&gt;
&lt;p&gt;This talk will describe Value Driven Threat Modeling, and show how to incorporate it into your existing agile development. We will discuss how developers can efficiently produce and leverage a threat model to improve application development, and walkthrough some example scenarios. If you want to be a good developer in 2018, you need to prepare for the threats of 2020!&lt;/p&gt;
</summary><category term="security"></category></entry><entry><title>Writing Command Line Friendly Applications</title><link href="https://pyvideo.org/pycon-israel-2018/writing-command-line-friendly-applications.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Miki Tebeka</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/writing-command-line-friendly-applications.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In &amp;quot;The Art of Unix Programming&amp;quot; ESR defines the rule of composition as: Design programs to be connected with other programs.&lt;/p&gt;
&lt;p&gt;We'll discuss how to write applications that are good citizens of the command line. These applications can be show display nice help, accept data from standard input or files, emit only required data to standard output or files and more. We'll show how to use the argparse module to achieve these goals.&lt;/p&gt;
</summary><category term="command line"></category><category term="argparse"></category></entry><entry><title>You Have Control: Learning From Aviation</title><link href="https://pyvideo.org/pycon-israel-2018/you-have-control-learning-from-aviation.html" rel="alternate"></link><published>2018-06-04T00:00:00+00:00</published><updated>2018-06-04T00:00:00+00:00</updated><author><name>Andrew Godwin</name></author><id>tag:pyvideo.org,2018-06-04:pycon-israel-2018/you-have-control-learning-from-aviation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As we move forward into the world of distributed systems, microservices, and hosted platforms, we find ourselves in a world where there are more moving parts and potential points of failure than ever, in an industry that traditionally has a poor approach to error handling and failure. What are these problems? How do we solve them not only through code, but through training and processes? And how can we learn from other industries that have tackled them before?&lt;/p&gt;
</summary></entry></feed>