<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_data-pipelines.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-12-07T00:00:00+00:00</updated><entry><title>AI pipelines powered by Jupyter notebooks</title><link href="https://pyvideo.org/pydata-austin-2019/ai-pipelines-powered-by-jupyter-notebooks.html" rel="alternate"></link><published>2019-12-07T00:00:00+00:00</published><updated>2019-12-07T00:00:00+00:00</updated><author><name>Luciano Resende</name></author><id>tag:pyvideo.org,2019-12-07:pydata-austin-2019/ai-pipelines-powered-by-jupyter-notebooks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Jupyter Notebook has become the de-facto platform used by data scientists to develop their AI/ML models. In this scenario, itâ€™s very common to decompose various phases of the development into multiple notebooks to simplify the development and management of the model lifecycle. This session will detail different approaches to compose notebook based AI pipelines and running in different runtimes&lt;/p&gt;
</summary><category term="data pipelines"></category><category term="ai"></category><category term="artificial intelligence"></category><category term="jupyter notebooks"></category></entry><entry><title>Frictionless Data Pipelines</title><link href="https://pyvideo.org/pydata-austin-2019/frictionless-data-pipelines.html" rel="alternate"></link><published>2019-12-07T00:00:00+00:00</published><updated>2019-12-07T00:00:00+00:00</updated><author><name>Lilly Winfree</name></author><id>tag:pyvideo.org,2019-12-07:pydata-austin-2019/frictionless-data-pipelines.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will discuss the technical ideas behind Frictionless Data by showcasing a recent collaborative use case with oceanographers. Together, we implemented Frictionless Data Python code into their data ingest pipelines to integrate disparate data while maintaining quality metadata in an easy to use interface.&lt;/p&gt;
</summary><category term="data pipelines"></category></entry></feed>