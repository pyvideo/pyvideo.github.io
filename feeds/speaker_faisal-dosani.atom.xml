<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_faisal-dosani.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-11-11T00:00:00+00:00</updated><entry><title>Open Sourcing at Work</title><link href="https://pyvideo.org/pycon-ca-2018/open-sourcing-at-work.html" rel="alternate"></link><published>2018-11-11T00:00:00+00:00</published><updated>2018-11-11T00:00:00+00:00</updated><author><name>Faisal Dosani</name></author><id>tag:pyvideo.org,2018-11-11:pycon-ca-2018/open-sourcing-at-work.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We just open sourced 2 projects (datacompy, and locopy) with roots in Data Science and Engineering which we will showcase. While is it exciting and rewarding to share your ideas with the world it isn't always easy. Thinking about licenses, copyrights, and protecting confidential information is a must!&lt;/p&gt;
&lt;p&gt;Working in a large organization which is embracing the mantra 'open source first' is really exciting. Part of this journey is to make sure we give back to the open source community when we can. Two of our projects had gained traction internally: datacompy, and locopy. As part of our commitment we wanted to make sure we could open source these projects for others to use and contribute back to. DataComPy is a package to compare two Pandas DataFrames. Originally started to be something of a replacement for SAS's PROC COMPARE for Pandas DataFrames with some more functionality than just Pandas.DataFrame.equals(Pandas.DataFrame) (in that it prints out some stats, and lets you tweak how accurate matches have to be). Then extended to carry that functionality over to Spark Dataframes. Locopy helps load flat files to S3 and then to Amazon Redshift, and assist with ETL processing. It is DB Driver (Adapter) agnostic, provides basic functionality to move data to S3 buckets, execute COPY commands to load data to S3, and into Redshift, and UNLOAD commands to unload data from Redshift into S3. While building these products was exciting and fun, some of the legal considerations were as interesting, complex, and required collaboration between many teams, from security, licensing, brand, and IP/copyright. We'll explore the projects, and some of these other considerations which can make or break if you decide to release a project into the wild, along with the road blocks we faced with in these areas.&lt;/p&gt;
</summary><category term="open source"></category><category term="licensing"></category><category term="copyright"></category><category term="data"></category><category term="security"></category><category term="testing"></category><category term="best practices"></category><category term="data science"></category></entry></feed>