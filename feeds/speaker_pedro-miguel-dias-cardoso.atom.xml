<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_pedro-miguel-dias-cardoso.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2014-07-26T00:00:00+00:00</updated><entry><title>Parallel processing using python and gearman</title><link href="https://pyvideo.org/pydata-berlin-2014/parallel-processing-using-python-and-gearman.html" rel="alternate"></link><published>2014-07-26T00:00:00+00:00</published><updated>2014-07-26T00:00:00+00:00</updated><author><name>Pedro Miguel Dias Cardoso</name></author><id>tag:pyvideo.org,2014-07-26:pydata-berlin-2014/parallel-processing-using-python-and-gearman.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When talking of parallel processing, some task requires a substantial
set-up time. This is the case of Natural Language Processing (NLP) tasks
such as classification, where models need to be loaded into memory. In
these situations, we can not start a new process for every data set to
be handled, but the system needs to be ready to process new incoming
data. This talk will look at job queue systems, with particular focus on
gearman. We will see how we are using it at Synthesio for NLP tasks; how
to set up workers and clients, make it redundant and robust, monitor its
activity and adapt to demand.&lt;/p&gt;
</summary></entry></feed>