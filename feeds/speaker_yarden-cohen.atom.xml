<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_yarden-cohen.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2017-11-27T00:00:00+00:00</updated><entry><title>Neural Networks for Segmentation of Vocalizations</title><link href="https://pyvideo.org/pydata-new-york-city-2017/neural-networks-for-segmentation-of-vocalizations.html" rel="alternate"></link><published>2017-11-27T00:00:00+00:00</published><updated>2017-11-27T00:00:00+00:00</updated><author><name>David Nicholson</name></author><id>tag:pyvideo.org,2017-11-27:pydata-new-york-city-2017/neural-networks-for-segmentation-of-vocalizations.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Neural networks for speech-to-text avoid dividing speech into segments, such as syllables, but segmenting has important applications. We compare different neural networks for segmentation of vocalizations using the song of songbirds, which we study as neuroscientists. Initial results suggest a bidirectional LSTM-CNN architecture outperforms others in both segmentation and classification.&lt;/p&gt;
</summary></entry></feed>