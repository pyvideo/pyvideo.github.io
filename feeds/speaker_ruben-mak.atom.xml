<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_ruben-mak.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-11-30T00:00:00+00:00</updated><entry><title>Advertising, algorithms and Privacy: recent opensource developments</title><link href="https://pyvideo.org/pydata-eindhoven-2019/advertising-algorithms-and-privacy-recent-opensource-developments.html" rel="alternate"></link><published>2019-11-30T00:00:00+00:00</published><updated>2019-11-30T00:00:00+00:00</updated><author><name>Ruben Mak</name></author><id>tag:pyvideo.org,2019-11-30:pydata-eindhoven-2019/advertising-algorithms-and-privacy-recent-opensource-developments.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Now more than ever, the trade-off between privacy and the benefits of
optimally training your algorithms is under heavy discussion. Luckily,
companies (mainly Google), heavily invest in research in this field
which resulted in open sourcing various libraries. In this talk we will
go into the technical details or differential privacy, federated
learning in Tensorflow and Multi-Party Compute.&lt;/p&gt;
&lt;p&gt;The digital advertising industry has been a great driving factor in the
recent developments in data science and AI. However, now more than ever,
the trade- off between privacy and the benefits of optimally training
your algorithms is under heavy discussion. Luckily, companies (mainly
Google), heavily invest in research in this field which resulted in open
sourcing various libraries.&lt;/p&gt;
&lt;p&gt;After a brief introduction about the context privacy in online
advertising, we'll dive into the technical details of:&lt;/p&gt;
&lt;p&gt;-Differential privacy -Federated learning in Tensorflow -Multi-Party
Compute -Chromium's Privacy Sandbox -My own vision around Private and
Public layers present in a blog from 2018&lt;/p&gt;
</summary></entry><entry><title>Thompson Sampling for Machine Learning</title><link href="https://pyvideo.org/pydata-amsterdam-2018/thompson-sampling-for-machine-learning.html" rel="alternate"></link><published>2018-05-26T00:00:00+00:00</published><updated>2018-05-26T00:00:00+00:00</updated><author><name>Ruben Mak</name></author><id>tag:pyvideo.org,2018-05-26:pydata-amsterdam-2018/thompson-sampling-for-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk I hope to give a clear overview of the opportunities for applying Thompson Sampling in machine learning. I will share some technical examples in recent developments (for example Bayesian Neural Networks using Edward) but more importantly I hope to trigger the audience to start thinking strategically about how we want our machine learning models to learn from new data.&lt;/p&gt;
</summary><category term="bayesian neural networks"></category><category term="edward"></category></entry><entry><title>Successfully applying Bayesian statistics to A/B testing in your business</title><link href="https://pyvideo.org/pydata-amsterdam-2017/successfully-applying-bayesian-statistics-to-ab-testing-in-your-business.html" rel="alternate"></link><published>2017-04-08T00:00:00+00:00</published><updated>2017-04-08T00:00:00+00:00</updated><author><name>Ruben Mak</name></author><id>tag:pyvideo.org,2017-04-08:pydata-amsterdam-2017/successfully-applying-bayesian-statistics-to-ab-testing-in-your-business.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2017&lt;/p&gt;
&lt;p&gt;A lot of theory is available on how the statistics of A/B testing could be improved using Bayesian statistics. In this talk I will discuss several theoretical problems and I will share my experiences on whether they actually impact A/B testing in practice. This will be demonstrated using hierarchical models build with pymc. Finally, I will share how I successfully implemented this into business.&lt;/p&gt;
&lt;p&gt;I will first shortly discuss frequentist calculation of an A/B test, and three problems: the normal distribution instead of the beta distribution, multiple comparison problem and biased stopping times. Using these topics, I will shortly introduce Bayesian statistics and more specifically hierarchical Bayes, by using examples in pymc. I will then share whether these topics actually have direct implications for testing in practice and illustrate why several aspects hardly change the decisions made. I will then focus on one of the most important aspects from a business perspective: when to stop an insignificant test. I will present the stopping rule I currently use, explain how this works in practice and how this relates to solving the theoretical problems.&lt;/p&gt;
</summary></entry></feed>