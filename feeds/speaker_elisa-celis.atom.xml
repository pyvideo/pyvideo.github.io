<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_elisa-celis.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-07-08T00:00:00+00:00</updated><entry><title>Keynote - Fairness and Diversity in Online Social Systems</title><link href="https://pyvideo.org/pydata-berlin-2018/keynote-fairness-and-diversity-in-online-social-systems.html" rel="alternate"></link><published>2018-07-08T00:00:00+00:00</published><updated>2018-07-08T00:00:00+00:00</updated><author><name>Elisa Celis</name></author><id>tag:pyvideo.org,2018-07-08:pydata-berlin-2018/keynote-fairness-and-diversity-in-online-social-systems.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, we will first understand the emergence of bias in data and
algorithmic decision making and present first steps towards developing a
systematic framework to control biases in classical problems such as
data summarization and personalization. This work leads to new
algorithms that have the ability to alleviate bias and increase
diversity while often simultaneously maintaining their the&lt;/p&gt;
</summary></entry><entry><title>Q&amp;A with Elisa Celis</title><link href="https://pyvideo.org/pydata-berlin-2018/qa-with-elisa-celis.html" rel="alternate"></link><published>2018-07-06T00:00:00+00:00</published><updated>2018-07-06T00:00:00+00:00</updated><author><name>Elisa Celis</name></author><id>tag:pyvideo.org,2018-07-06:pydata-berlin-2018/qa-with-elisa-celis.html</id><summary type="html"></summary></entry></feed>