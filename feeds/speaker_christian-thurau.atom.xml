<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_christian-thurau.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2014-07-26T00:00:00+00:00</updated><entry><title>Low-rank matrix approximations in Python</title><link href="https://pyvideo.org/pydata-berlin-2014/low-rank-matrix-approximations-in-python.html" rel="alternate"></link><published>2014-07-26T00:00:00+00:00</published><updated>2014-07-26T00:00:00+00:00</updated><author><name>Christian Thurau</name></author><id>tag:pyvideo.org,2014-07-26:pydata-berlin-2014/low-rank-matrix-approximations-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Low-rank approximations of data matrices have become an important tool
in machine learning and data mining. They allow for embedding high
dimensional data in lower dimensional spaces and can therefore mitigate
effects due to noise, uncover latent relations, or facilitate further
processing. These properties have been proven successful in many
application areas such as bio-informatics, computer vision, text
processing, recommender systems, social network analysis, among others.
Present day technologies are characterized by exponentially growing
amounts of data. Recent advances in sensor technology, internet
applications, and communication networks call for methods that scale to
very large and/or growing data matrices. In this talk, we will describe
how to efficiently analyze data by means of matrix factorization using
the Python Matrix Factorization Toolbox (PyMF) and HDF5. We will briefly
cover common methods such as k-means clustering, PCA, or Archetypal
Analysis which can be easily cast as a matrix decomposition, and explain
their usefulness for everyday data analysis tasks.&lt;/p&gt;
</summary></entry></feed>