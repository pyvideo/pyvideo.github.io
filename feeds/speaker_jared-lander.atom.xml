<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_jared-lander.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2014-09-16T00:00:00+00:00</updated><entry><title>Confidence in the Lasso</title><link href="https://pyvideo.org/pygotham-2014/confidence-in-the-lasso.html" rel="alternate"></link><published>2014-09-16T00:00:00+00:00</published><updated>2014-09-16T00:00:00+00:00</updated><author><name>Jared Lander</name></author><id>tag:pyvideo.org,2014-09-16:pygotham-2014/confidence-in-the-lasso.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The lasso is one of the most significant machine learning algorithms
from the past 15 years. Conceived by Hastie, Tibshirani and Friedman
from Stanford, the lasso performs dimension reduction and variable
selection making it well suited for the high dimensionality of today's
datasets. In this talk we will go over some of the math behind the lasso
and discuss some recent advancements in performing inference on
lasso-fitted models.&lt;/p&gt;
</summary></entry></feed>