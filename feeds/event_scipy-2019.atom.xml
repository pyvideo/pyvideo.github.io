<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/event_scipy-2019.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-07-13T00:00:00+00:00</updated><entry><title>Anatomy of Probabilistic Programming Languages</title><link href="https://pyvideo.org/scipy-2019/anatomy-of-probabilistic-programming-languages.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Suriyadeepan Ramamoorthy</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/anatomy-of-probabilistic-programming-languages.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The ability to estimate uncertainty and incorporate it in decision making is crucial to sensitive applications like Self-driving Cars, Industrial Automation, etc, where the consequences of a wrong decision is potentially catastrophic. A Probabilistic Program is the natural way to express such probabilistic models. This talk demonstrates how to build a minimal PPL on top of python. We leverage tensor manipulation and optimization tools provided by machine learning frameworks including pytorch and tensorflow. We will use our PPL implementation to build Bayesian Linear Regression and Logistic Regression models, and perform inference conditioned on data.&lt;/p&gt;
</summary></entry><entry><title>apricot: Submodular Selection for Data Summarization</title><link href="https://pyvideo.org/scipy-2019/apricot-submodular-selection-for-data-summarization.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Jacob Schreiber</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/apricot-submodular-selection-for-data-summarization.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Submodular selection can be used to reduce a complex data set down to a representative subset. This subset can then be used to train machine learning models with high efficiency and resulting accuracy. In this talk we will introduce apricot, a Python package for submodular selection, and show examples of its usage.&lt;/p&gt;
</summary></entry><entry><title>Astropy Beyond Astronomy: Infrastructure of an Open Source Ecosystem</title><link href="https://pyvideo.org/scipy-2019/astropy-beyond-astronomy-infrastructure-of-an-open-source-ecosystem.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Thomas Robitaille</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/astropy-beyond-astronomy-infrastructure-of-an-open-source-ecosystem.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Astropy Project is a community effort to develop a common core package and to foster an ecosystem of interoperable astronomy packages. In addition to these domain specific libraries we also maintain a suite of infrastructure packages. This infrastructure can be easily utilized to cover the needs of most scientific Python projects. Sharing the tools we developed for maintenance, testing, documenting, and general upkeep of the most essential parts of our project maximizes the impact of the software engineering expertise and resources within the whole ecosystem to ensure that others can benefit from the efforts of the core Astropy team.&lt;/p&gt;
</summary></entry><entry><title>Better and Faster Hyper Parameter Optimization with Dask</title><link href="https://pyvideo.org/scipy-2019/better-and-faster-hyper-parameter-optimization-with-dask.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Tom Augspurger</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/better-and-faster-hyper-parameter-optimization-with-dask.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Nearly every machine learning model requires that the user specify certain parameters before training begins, aka &amp;quot;hyper-parameters&amp;quot;. Finding the optimal set of hyper-parameters is often a time- and resource-consuming process. A recent breakthrough hyper-parameter optimization algorithm, Hyperband, can find high performing hyper-parameters with minimal training and has theoretical backing. This talk will provide intuition for Hyperband, explain it's use and why it's well-suited for Dask, a Python library that scales Python to larger datasets and more computational resources. Experiments find high performing hyper-parameters more quickly in the presence of parallel computational resources and with a deep learning model.&lt;/p&gt;
</summary></entry><entry><title>Building &amp; Replicating Models of Visual Search Behavior w/ Tensorflow, Nengo, &amp; Scientific Python Stack</title><link href="https://pyvideo.org/scipy-2019/building-replicating-models-of-visual-search-behavior-w-tensorflow-nengo-scientific-python-stack.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>David Nicholson</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/building-replicating-models-of-visual-search-behavior-w-tensorflow-nengo-scientific-python-stack.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Animals constantly use their eyes to search their environment. What can neural networks and other cognitive models tell us about this behavior? We present two related studies that leverage scientific Python libraries to address this question. The first uses Tensorflow to replicate and extend a previous study of how convolutional neural networks perform a classic visual search task. The second study compares visual search behavior of two types of models: a recurrent neural network model from Google DeepMind, and spiking cognitive models built with the Nengo neural simulator. We discuss what our results suggest about such models.&lt;/p&gt;
</summary></entry><entry><title>Chainer: A Deep Learning Framework for Fast Research &amp; Applications</title><link href="https://pyvideo.org/scipy-2019/chainer-a-deep-learning-framework-for-fast-research-applications.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Seiya Tokui</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/chainer-a-deep-learning-framework-for-fast-research-applications.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Chainer is a deep learning framework for flexible and intuitive coding of high performance experiments and applications. It is designed to maximize the trial-and-error speed with its Define-by-Run paradigm, which provides Pythonic programming of auto-differentiated neural networks. The framework can accelerate performance with multiple GPUs in distributed environments and add-on packages enable quickly jumping into specific domains. In this talk, we introduce the abstract of Chainer’s API, its capabilities for accelerating the deep learning research and applications, and the future direction of the framework development.&lt;/p&gt;
</summary></entry><entry><title>Challenges in Detecting Physiological Changes Using Wearable Sensor Data</title><link href="https://pyvideo.org/scipy-2019/challenges-in-detecting-physiological-changes-using-wearable-sensor-data.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Edward Preble</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/challenges-in-detecting-physiological-changes-using-wearable-sensor-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Numerous challenges exist when trying to detect changes in a person’s health status using data from wearable sensors. A core issue is that wearable sensor data varies tremendously between individuals and over time due to a person’s daily activities. “Reasonably comparable” time periods must be identified based on activity levels and other variables, which can then be analyzed to determine if a change in health status has occurred. SciPy, NumPy, Pandas, and Matplotlib were used to process the massive number of variable combinations in our data and to output visualizations that highlight useful patterns in the data.&lt;/p&gt;
</summary></entry><entry><title>Composing and Decomposing Quantum Chemistry Software: Transitioning a Field from ASCII Text to Relational Data Documents and Schema</title><link href="https://pyvideo.org/scipy-2019/composing-and-decomposing-quantum-chemistry-software-transitioning-a-field-from-ascii-text-to-relational-data-documents-and-schema.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Lori Burns</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/composing-and-decomposing-quantum-chemistry-software-transitioning-a-field-from-ascii-text-to-relational-data-documents-and-schema.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Practitioners in computational chemistry are loath to give up neither their many formats of ASCII output files that summarize the precious results of terabytes of algorithm crunching nor the exact software configurations to which they trained in their youth. This paper describes a year of refactoring several open source quantum chemistry projects into modularity and imposing archivable data interchange, while sustaining development over the Psi4, QCDB common driver, and Molecular Sciences Software Institute (MolSSI) Quantum Chemistry Archive integrated software ecosystems.&lt;/p&gt;
</summary></entry><entry><title>CuPy: A NumPy Compatible Library for High Performance Computing with GPU</title><link href="https://pyvideo.org/scipy-2019/cupy-a-numpy-compatible-library-for-high-performance-computing-with-gpu.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Masayuki Takagi</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/cupy-a-numpy-compatible-library-for-high-performance-computing-with-gpu.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;CuPy is an open-source library which has NumPy-compatible API and brings high performance in N-dimensional array computation with utilizing Nvidia GPU. Its API is to designed to provide high compatibility with NumPy so that in most cases you can gain several times speed improvement from drop-in replacement to your code. CuPy is actively developed and is continuously well-maintained, resulting in 2,700+ GitHub stars and 13,000+ commits. CuPy was also presented at PyCon 2018&lt;/p&gt;
</summary></entry><entry><title>dask image:A Library for Distributed Image Processing</title><link href="https://pyvideo.org/scipy-2019/dask-imagea-library-for-distributed-image-processing.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>John Kirkham</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/dask-imagea-library-for-distributed-image-processing.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Image processing in various domains like geospatial imaging, astronomy, neuroscience, etc. has seen the size of collected image datasets grow both due to novel techniques to expand the field of view and improve resolution. This presents a number of different challenges to workflows that were often traditionally designed to work in memory. We explore useful primitives in dask and explain how these can be used to aid analyis. Using these primitives, we show users how common image processing functions can be built in this framework and point out their implementations in the dask-image library.&lt;/p&gt;
</summary></entry><entry><title>Day 2 SciPy Tools Plenary Session</title><link href="https://pyvideo.org/scipy-2019/day-2-scipy-tools-plenary-session.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Unknown</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/day-2-scipy-tools-plenary-session.html</id><summary type="html"></summary></entry><entry><title>Day 3 Lightning Talks</title><link href="https://pyvideo.org/scipy-2019/day-3-lightning-talks.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Unknown</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/day-3-lightning-talks.html</id><summary type="html"></summary></entry><entry><title>Day 3 SciPy Tools Plenary Session</title><link href="https://pyvideo.org/scipy-2019/day-3-scipy-tools-plenary-session.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Unknown</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/day-3-scipy-tools-plenary-session.html</id><summary type="html"></summary></entry><entry><title>Echopype: Enhancing the Interoperability and Scalability of Ocean Sonar Data Processing for Biological Information</title><link href="https://pyvideo.org/scipy-2019/echopype-enhancing-the-interoperability-and-scalability-of-ocean-sonar-data-processing-for-biological-information.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Wu-Jung Lee</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/echopype-enhancing-the-interoperability-and-scalability-of-ocean-sonar-data-processing-for-biological-information.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Instrumentation advancements in the last decade have produced a deluge of ocean sonar data. These data provide opportunities to study the marine ecosystems at unprecedented spatial and temporal scales. However, to date, these data remain significantly under-utilized, mainly due to the lack of data interoperability and scalable analysis workflow. We address these challenges by developing an open-source Python package, echopype, which defines an interoperable netCDF file format and leverages the power of Xarray and Dask for explicit and efficient sonar data analysis in the Jupyter environment.&lt;/p&gt;
</summary></entry><entry><title>Efficient Atmospheric Analogue Selection with Xarray and Dask</title><link href="https://pyvideo.org/scipy-2019/efficient-atmospheric-analogue-selection-with-xarray-and-dask.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Tyler Wixstrom</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/efficient-atmospheric-analogue-selection-with-xarray-and-dask.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Large numerical forecast datasets are commonly used for atmospheric research with dataset sizes exceeding several terabytes. An efficient means of pattern matching within such datasets is commonly required during data analysis. This project aims to develop an efficient and yet flexible means for such pattern matching within an ensemble dataset. A description of the resulting algorithm and search methodology is presented, along with some of the technical challenges of working with multiple data types and formats. Performance comparisons of varying chunk sizes and system resource allocations will be compared. Finally, best practices for development will be presented.&lt;/p&gt;
</summary></entry><entry><title>Experience Building Local Communities of Open Source Practices Users through The Carpentries' Membership Program</title><link href="https://pyvideo.org/scipy-2019/experience-building-local-communities-of-open-source-practices-users-through-the-carpentries-membership-program.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Kari Jordan</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/experience-building-local-communities-of-open-source-practices-users-through-the-carpentries-membership-program.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Carpentries, an open source project that develops training and instructing resources for researchers, has developed a membership program that is key to our sustainability and mission. This program creates communities of open source practices at organisations around the world and supports the open materials and forums of The Carpentries. We have learned from our various successes and challenges, continue to assess the effectiveness of this program, and are preparing for the challenges of adapting this program to be effective in our rapidly growing and diversifying community.&lt;/p&gt;
</summary></entry><entry><title>Fully Automated Behavioral Experiments on Cultural Transmission through Crowdsourcing</title><link href="https://pyvideo.org/scipy-2019/fully-automated-behavioral-experiments-on-cultural-transmission-through-crowdsourcing.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Carlos de la Guardia</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/fully-automated-behavioral-experiments-on-cultural-transmission-through-crowdsourcing.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The logistics of in-laboratory experiments on cultural evolution, social learning, cooperation, and collective decision-making drive experiment designs towards simple population structures, small groups, and limited interaction between participants. Here we describe Dallinger, a software-based tool that automates large-scale experiments on cultural transmission through crowdsourcing. The tool handles the full experimental pipeline from participant recruitment through data management, enabling experiments that are efficient, reproducible, and unprecedented in their complexity and scale.&lt;/p&gt;
</summary></entry><entry><title>Generational Changes in Support for Gun Laws: A Case Study in Computational Statistics</title><link href="https://pyvideo.org/scipy-2019/generational-changes-in-support-for-gun-laws-a-case-study-in-computational-statistics.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Allen Downey</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/generational-changes-in-support-for-gun-laws-a-case-study-in-computational-statistics.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the United States, support for gun control has been declining among all age groups since 1990; among young adults, support is substantially lower than among previous generations. Using data from the General Social Survey (GSS), I perform age-period-cohort analysis to measure generational effects. In this talk, I demonstrate a computational approach to statistics that replaces mathematical analysis with random simulation. Using Python and libraries like NumPy and StatsModels, we can define basic operations — like resampling, filling missing values, modeling, and prediction — and assemble them into a data analysis pipeline.&lt;/p&gt;
</summary></entry><entry><title>Getting Lost in Community Building</title><link href="https://pyvideo.org/scipy-2019/getting-lost-in-community-building.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Matthew Turk</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/getting-lost-in-community-building.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Developing a strategy for community building in a project, and ultimately transitioning that project to a peer-supported collaborative enterprise, is an intensely challenging process. This talk will describe some community building strategies, talk about lots of (painful, demoralizing, embarrassing) ways they fall short, and suggest a path forward for projects to collaborate as a meta-community.&lt;/p&gt;
</summary></entry><entry><title>How to Accelerate an Existing Codebase with Numba</title><link href="https://pyvideo.org/scipy-2019/how-to-accelerate-an-existing-codebase-with-numba.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Siu Kwan Lam</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/how-to-accelerate-an-existing-codebase-with-numba.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you have ever said to yourself &amp;quot;my code works, but it is too slow!&amp;quot; then this is the talk for you. We will describe best practices for applying the Numba just-in-time compiler to an existing project. This includes techniques for assessing whether Numba is appropriate for your use case, analyzing your program to identify where Numba can help, modifying your core algorithms to be Numba compatible, and understanding compiler errors. In addition, we'll discuss considerations for packaging and distribution of projects that depend on Numba.&lt;/p&gt;
</summary></entry><entry><title>How to Track Plastic in the Ocean? The Parcels Lagrangian Ocean Framework</title><link href="https://pyvideo.org/scipy-2019/how-to-track-plastic-in-the-ocean-the-parcels-lagrangian-ocean-framework.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Philippe Delandmeter</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/how-to-track-plastic-in-the-ocean-the-parcels-lagrangian-ocean-framework.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Parcels ocean framework is an open-source Python library for building Lagrangian particle models (&lt;a class="reference external" href="http://oceanparcels.org"&gt;http://oceanparcels.org&lt;/a&gt;). It has been designed specifically for the purpose of combining (1) a large modularity to simulate the trajectory of different types of particles, from water to tracers and particulates such as plastic, algae or even fish, etc. and (2) an efficient implementation in accordance with modern computing infrastructure (Delandmeter et al., 2019, &lt;a class="reference external" href="https://doi.org/10.5194/gmd-2018-339"&gt;https://doi.org/10.5194/gmd-2018-339&lt;/a&gt;). The presentation will focus on Parcels design including a two-level Python-C dynamic structure and the new parallel routine to scale up with both increasing input data and number of particles.&lt;/p&gt;
</summary></entry><entry><title>Inequality of Underrepresented Groups in Core Project Leadership</title><link href="https://pyvideo.org/scipy-2019/inequality-of-underrepresented-groups-in-core-project-leadership.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Anthony Scopatz</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/inequality-of-underrepresented-groups-in-core-project-leadership.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Different core projects in our ecosystem have a dramatically different make up among the leadership of the their developer teams. This talk explores those differences in representation, and how to measure them quantitatively. It will then present some of the qualitative lessons we can learn from this data.&lt;/p&gt;
</summary></entry><entry><title>Invisible Work, Incentives, &amp; Burnout in Open Communities</title><link href="https://pyvideo.org/scipy-2019/invisible-work-incentives-burnout-in-open-communities.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Dorothy Howard</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/invisible-work-incentives-burnout-in-open-communities.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We present insights gathered from a combination of ethnographic interviews with maintainers of a cross section of open-source projects, as well as through analysis of datasets that speak to the dynamics of maintenance work on GitHub and spaces of coordination. From reviewing pull requests to conflict resolution, maintenance involves many forms of work, yet certain tasks and roles are prominent than others. We draw on the concepts of visible and invisible work to analyze the infrastructures which configure different forms of recognition. We also explore the attributes of burnout to consider the ways that open source knowledge production permeates peoples’ lives and how burnout affects community sustainability.&lt;/p&gt;
</summary></entry><entry><title>Jupyter: Always Open for Learning and Discovery</title><link href="https://pyvideo.org/scipy-2019/jupyter-always-open-for-learning-and-discovery.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Carol Willing</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/jupyter-always-open-for-learning-and-discovery.html</id><summary type="html"></summary><category term="keynote"></category></entry><entry><title>Microscopium: Interactive Exploration of Large Imaging Datasets</title><link href="https://pyvideo.org/scipy-2019/microscopium-interactive-exploration-of-large-imaging-datasets.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Genevieve Buckley</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/microscopium-interactive-exploration-of-large-imaging-datasets.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Microscopium is an open source library and web application to explore large datasets of related images interactively. It is being developed openly at &lt;a class="reference external" href="https://github.com/microscopium/microscopium"&gt;https://github.com/microscopium/microscopium&lt;/a&gt;, and runs on a SciPy stack of NumPy, SciPy, scikit-image, scikit-learn, and Bokeh. We will show that 2D embedding of images according to similarity is sufficient to discover relationships between drugs and genes of interest.&lt;/p&gt;
</summary></entry><entry><title>Model Remodeling with Modern Deep Learning Frameworks</title><link href="https://pyvideo.org/scipy-2019/model-remodeling-with-modern-deep-learning-frameworks.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Ethan Rosenthal</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/model-remodeling-with-modern-deep-learning-frameworks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While modern deep learning frameworks have revolutionized the ability for non-experts to train deep learning models, they have also democratized a host of other innovations which extend beyond the niche of deep learning. In this talk, I will explore some models and domains that are not commonly thought of as “machine learning” problems and show how PyTorch allows one to build more complex and scalable models than ever before. This represents an opportunity to revisit existing models, which I will do by showing how to implement them with PyTorch and integrate them into the rest of the PyData ecosystem.&lt;/p&gt;
</summary></entry><entry><title>Multi Dimensional Linked Data Exploration with Glue</title><link href="https://pyvideo.org/scipy-2019/multi-dimensional-linked-data-exploration-with-glue.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Thomas Robitaille</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/multi-dimensional-linked-data-exploration-with-glue.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We have developed an open-source multi-disciplinary Python package named glue (&lt;a class="reference external" href="http://glueviz.org"&gt;http://glueviz.org&lt;/a&gt;) that allows users to explore relationships within and across related datasets, making it easy for them to create multi-dimensional linked visualizations of datasets, select subsets of data interactively or programmatically in 1, 2, or 3 dimensions, and to see those selections propagate live across all open visualizations of the data (e.g., graphs, maps, diagnostics charts, etc.). In this talk, I will present both the desktop and the new Jupyter-based versions of glue, along with plugins that can be used to extend glue for different disciplines.&lt;/p&gt;
</summary></entry><entry><title>Panel: Turn any Notebook into a Deployable Dashboard</title><link href="https://pyvideo.org/scipy-2019/panel-turn-any-notebook-into-a-deployable-dashboard.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>James Bednar</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/panel-turn-any-notebook-into-a-deployable-dashboard.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Panel (panel.pyviz.org) is a new package that lets you create custom interactive apps and dashboards by connecting user-defined widgets to plots, images, tables, or text. Compared to other approaches, Panel is novel in that it works across nearly all plotting libraries, works just as well in a Jupyter notebook as on a standalone secure web server, uses the same code for both those cases, supports both Python-backed and static HTML/JavaScript exported applications, and can be used to develop rich interactive applications without tying your domain-specific code to any particular GUI or web tools.&lt;/p&gt;
</summary></entry><entry><title>Parameter Estimation Using the Python Package pymcmcstat</title><link href="https://pyvideo.org/scipy-2019/parameter-estimation-using-the-python-package-pymcmcstat.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Alistair Miles</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/parameter-estimation-using-the-python-package-pymcmcstat.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Metropolis algorithms have greatly expanded our ability to estimate parameter distributions. In this talk we introduce pymcmcstat [Miles, 2018], which utilizes the Delayed Rejection Adaptive Metropolis (DRAM) algorithm [Haario et al., 2006, Haario et al., 2001] to perform Markov Chain Monte Carlo (MCMC) simulations. The user interface provides a straight forward environment for experienced and new Python users to quickly compare their models with data. Furthermore, the package provides a wide variety of diagnostic tools for visualizing uncertainty propagation. This package has been utilized in a wide array of scientific and engineering problems, including radiation source localization and constitutive model development of smart material systems.&lt;/p&gt;
</summary></entry><entry><title>Processing Extremely Large Images: Theory and Practice</title><link href="https://pyvideo.org/scipy-2019/processing-extremely-large-images-theory-and-practice.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Deepak Chittajallu</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/processing-extremely-large-images-theory-and-practice.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Images encountered by today's scientist, with the advent of new hardware and methods in areas such as microscopy, synchrotron x-ray imaging, and satellite imaging, are a challenge to process within the common memory constraints and compute capabilities of a single CPU core. Through a resampling example, we provide an overview of the theory and modern practice of processing large images. By the end of this talk, attendees will understand how to develop and apply streaming methods. Furthermore, they will understand how to apply node-based and distributed parallelism to accelerate computation with SciPy tools such as NumPy, Dask, ITK, and the itk-jupyter-widgets.&lt;/p&gt;
</summary></entry><entry><title>PyDDA: A New Pythonic Package for Wind Retrievals</title><link href="https://pyvideo.org/scipy-2019/pydda-a-new-pythonic-package-for-wind-retrievals.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Robert Jackson</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/pydda-a-new-pythonic-package-for-wind-retrievals.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyDDA is a new community framework aimed at wind retrievals that depends only upon utilities in the SciPy ecosystem such as scipy, numpy, and dask. It can support retrievals of winds using information from weather radar networks constrained by high resolution forecast models over grids that cover thousands of kilometers at kilometer-scale resolution. Unlike past wind retrieval packages, this package can be installed using anaconda for easy installation and, with a focus on ease of use can retrieve winds from gridded radar and model data with just a few lines of code.&lt;/p&gt;
</summary></entry><entry><title>pyjanitor: Clean APIs for Cleaning Data</title><link href="https://pyvideo.org/scipy-2019/pyjanitor-clean-apis-for-cleaning-data.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Eric Ma</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/pyjanitor-clean-apis-for-cleaning-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Data cleaning with the &lt;cite&gt;pandas&lt;/cite&gt; API can sometimes be confusing. I will describe team efforts on &lt;cite&gt;pyjanitor&lt;/cite&gt;, to create a cleaner API for data cleaning, focusing on readability and expressivity. &lt;cite&gt;pyjanitor&lt;/cite&gt; is a port of the R &lt;cite&gt;janitor&lt;/cite&gt; package, and provides a cleaner, verb-based method-chaining API to pandas users. I will explain &lt;cite&gt;pyjanitor&lt;/cite&gt;'s history and design, and provide a suite of examples coded in Jupyter notebooks on how to use &lt;cite&gt;pyjanitor&lt;/cite&gt;'s data cleaning functions.&lt;/p&gt;
</summary></entry><entry><title>Python in Seismology at the National Earthquake Information Center: APIs and Applications</title><link href="https://pyvideo.org/scipy-2019/python-in-seismology-at-the-national-earthquake-information-center-apis-and-applications.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Michael Hearne</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/python-in-seismology-at-the-national-earthquake-information-center-apis-and-applications.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The use of Python at the U.S. Geological Survey (USGS) National Earthquake Information Center has grown over the past several years to encompass research support, Application Programming Interface (API) development, and operational applications. We discuss two of the APIs (libcomcat and gmprocess) and two operational applications (ShakeMap and PAGER) that depend on these libraries.&lt;/p&gt;
</summary></entry><entry><title>Raiders of the Pottery GAN: Using 3D Generative Adversarial Networks for Data Augmentation in Archaeological Studies</title><link href="https://pyvideo.org/scipy-2019/raiders-of-the-pottery-gan-using-3d-generative-adversarial-networks-for-data-augmentation-in-archaeological-studies.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Celia Cintas</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/raiders-of-the-pottery-gan-using-3d-generative-adversarial-networks-for-data-augmentation-in-archaeological-studies.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Reassembly of 3D fragmented objects from a collection of hundreds of randomly mixed fragments is a problem that arises in several applied disciplines, such as archaeology, failure analysis, paleontology, etc. In this talk we will walk through the pipeline of 3D data generation in archaeological studies, from pre-processing of images, moving from 2D to 3D space, and finally the training and evaluation of generative adversarial networks in Python for 3D meshes corresponding to Iberian vessels. We will report several python libraries (scikit-image, pytorch, visdom, etc.) and how they are used in this particular pipeline. The main goal of augmenting our dataset in 3D is to perform fragment part identification and vessel reconstruction.&lt;/p&gt;
</summary></entry><entry><title>Real World Numba: Creating a Skeleton Analysis Library</title><link href="https://pyvideo.org/scipy-2019/real-world-numba-creating-a-skeleton-analysis-library.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Juan Nunez-Iglesias</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/real-world-numba-creating-a-skeleton-analysis-library.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;kan is a Python library to analyze skeleton images, such as images of branching neurons, or of the molecular skeleton of a cell. It is written using NumPy, SciPy, and pandas, with key functions compiled by Numba for speed. I'll briefly describe the library and application, but then spend most of the time discussing Skan's gritty innards, including: how to write n-dimensional image analysis code instead of baking in 2D- or 3D-only logic; examples of using Numba to speed up real-world array-based code; why you should know about memory layout; and the versatility of SciPy's sparse matrix formats.&lt;/p&gt;
</summary></entry><entry><title>Refactoring the SciPy Ecosystem for Heterogeneous Computing</title><link href="https://pyvideo.org/scipy-2019/refactoring-the-scipy-ecosystem-for-heterogeneous-computing.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Matthew Rocklin</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/refactoring-the-scipy-ecosystem-for-heterogeneous-computing.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk summarizes a number of efforts across the community to build standardization into the ecosystem. We include topics like accelerator hardware (GPUs, TPUs, multi-core CPUs), API extension points in NumPy and Pandas, file formats, and other community efforts to establish cohesion.&lt;/p&gt;
</summary></entry><entry><title>Renewable Power Forecast Generation with Dask &amp; Visualization with Bokeh</title><link href="https://pyvideo.org/scipy-2019/renewable-power-forecast-generation-with-dask-visualization-with-bokeh.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Leland J. Boeman</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/renewable-power-forecast-generation-with-dask-visualization-with-bokeh.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The University of Arizona Power Forecasting Group uses scientific Python to research and produce solar and wind power forecasts for electric utilities in the Southwest. We will describe our forecast generation system that relies on Dask.distributed for easy parallelism and quick transitions from research to operations. We will also describe three Bokeh applications we’ve developed to explore the output of numerical weather models. Two of these applications can be viewed at &lt;a class="reference external" href="https://forecasting.energy.arizona.edu/advi"&gt;https://forecasting.energy.arizona.edu/advi&lt;/a&gt; and &lt;a class="reference external" href="https://forecasting.energy.arizona.edu/artsy"&gt;https://forecasting.energy.arizona.edu/artsy&lt;/a&gt;.&lt;/p&gt;
</summary></entry><entry><title>Scikit TDA: Topological Tools for the Python Ecosystem</title><link href="https://pyvideo.org/scipy-2019/scikit-tda-topological-tools-for-the-python-ecosystem.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Hendrik Jacob van Veen</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/scikit-tda-topological-tools-for-the-python-ecosystem.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Topological Data Analysis is a suite of tools designed to help you understand the structure of high dimensional data. Techniques of persistent homology and mapper have been growing in popularity and breadth of application. Scikit-TDA is a new library designed to provide usable implementations of these techniques for data scientists in both industry and academia. This talk will introduce the fundamental ideas of Topological Data Analysis and show how Scikit-TDA can be used for making sense of your data. This talk is intended for anyone with an interest in new approaches for understanding their data.&lt;/p&gt;
</summary></entry><entry><title>Skorch: A Union of Scikit learn and PyTorch</title><link href="https://pyvideo.org/scipy-2019/skorch-a-union-of-scikit-learn-and-pytorch.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Thomas Fan</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/skorch-a-union-of-scikit-learn-and-pytorch.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Skorch is a scikit-learn compatible neural network library that wraps PyTorch. skorch reduces the boilerplate needed to train a neural network by abstracting away the training loop and providing a callback API for common tasks such as recording metrics and model checkpointing. This talk is targeted to users familiar with the scikit-learn API and have had some exposure to neural networks.&lt;/p&gt;
</summary></entry><entry><title>Supporting Open Source Software for Science</title><link href="https://pyvideo.org/scipy-2019/supporting-open-source-software-for-science.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>J. Freeman</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/supporting-open-source-software-for-science.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;I'll describe how we are supporting the open-source community through grantmaking, software development, and collaboration, including both domain-specific tools and cross-cutting foundational infrastructure.&lt;/p&gt;
</summary></entry><entry><title>Sustainable Open Source Community with NumFOCUS</title><link href="https://pyvideo.org/scipy-2019/sustainable-open-source-community-with-numfocus.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Andy Terrel</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/sustainable-open-source-community-with-numfocus.html</id><summary type="html"></summary></entry><entry><title>The New Era in NLP</title><link href="https://pyvideo.org/scipy-2019/the-new-era-in-nlp.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Rachel Thomas</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/the-new-era-in-nlp.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the past year, we have seen a remarkable number of breakthroughs in the field of natural language processing, including huge leaps forward in classifying, generating, and translating text. I will share a survey of the field, how it is changing, and what you need to know to get involved.&lt;/p&gt;
</summary><category term="keynote"></category></entry><entry><title>Turning HPC Systems into Interactive Data Analysis Platforms</title><link href="https://pyvideo.org/scipy-2019/turning-hpc-systems-into-interactive-data-analysis-platforms.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Anderson Banihirwe</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/turning-hpc-systems-into-interactive-data-analysis-platforms.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk demonstrates how to use Dask and Jupyter on large high-performance computing (HPC) systems to scale and accelerate large interactive data analysis tasks -- effectively turning HPC systems into interactive big-data platforms. We will introduce dask-jobqueue which allows users to seamlessly deploy and scale dask on HPC clusters that use a variety of job queuing systems such as PBS, Slurm, SGE, and LSF. We will also introduce dask-mpi, a Python package that makes deploying Dask easy from within a distributed MPI environment.&lt;/p&gt;
</summary></entry><entry><title>Using a Stacking Model Ensemble Approach to Predict Rare Events</title><link href="https://pyvideo.org/scipy-2019/using-a-stacking-model-ensemble-approach-to-predict-rare-events.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Susan Yuhou Xia</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/using-a-stacking-model-ensemble-approach-to-predict-rare-events.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we will discuss a common and highly effective model ensemble technique known as stacking and how it can be used for classification to predict rare target events. We will start with the business problem, predicting which users will respond to online advertising and creating a list of these users called an “audience” to be used in ad serving. We will then describe stacking and explain the advantages, from reducing generalization bias to the practical implications of parallelization of model development amongst developers. Finally we will describe how we optimized a stacked model ensemble to create audiences.&lt;/p&gt;
</summary></entry><entry><title>Work Open, Lead Open #WOLO for Sustainability</title><link href="https://pyvideo.org/scipy-2019/work-open-lead-open-wolo-for-sustainability.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Abigail Cabunoc Mayes</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/work-open-lead-open-wolo-for-sustainability.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Unique principles of working open provide the best platform to sustainably solve the problems we face today. Open leaders design and build projects that empower others to collaborate in inclusive communities. By designing for open, projects lower barriers to participation and encourage sustainable use and contribution. In this talk, we'll take experiences mentoring over 500 open projects to discuss how and why working open leads to sustainable software.&lt;/p&gt;
</summary></entry><entry><title>Xgcm: Analyzing General Circulation Models in Python</title><link href="https://pyvideo.org/scipy-2019/xgcm-analyzing-general-circulation-models-in-python.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Ryan Abernathey</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/xgcm-analyzing-general-circulation-models-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We will introduce and demonstrate xgcm, a python package which builds on top of xarray and dask to allow users to easily analyze data finite-volume general circulation models, as commonly found in weather, climate, and ocean modeling.&lt;/p&gt;
</summary></entry><entry><title>Day 2 Lightning Talks</title><link href="https://pyvideo.org/scipy-2019/day-2-lightning-talks.html" rel="alternate"></link><published>2019-07-12T00:00:00+00:00</published><updated>2019-07-12T00:00:00+00:00</updated><author><name>Unknown</name></author><id>tag:pyvideo.org,2019-07-12:scipy-2019/day-2-lightning-talks.html</id><summary type="html"></summary></entry><entry><title>Day 3 Welcome</title><link href="https://pyvideo.org/scipy-2019/day-3-welcome.html" rel="alternate"></link><published>2019-07-12T00:00:00+00:00</published><updated>2019-07-12T00:00:00+00:00</updated><author><name>Serge Rey</name></author><id>tag:pyvideo.org,2019-07-12:scipy-2019/day-3-welcome.html</id><summary type="html"></summary></entry><entry><title>Visual Diagnostics at Scale: More Informed Machine Learning with Large Datasets</title><link href="https://pyvideo.org/scipy-2019/visual-diagnostics-at-scale-more-informed-machine-learning-with-large-datasets.html" rel="alternate"></link><published>2019-07-12T00:00:00+00:00</published><updated>2019-07-12T00:00:00+00:00</updated><author><name>Rebecca Bilbro</name></author><id>tag:pyvideo.org,2019-07-12:scipy-2019/visual-diagnostics-at-scale-more-informed-machine-learning-with-large-datasets.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The hunt for the most effective machine learning model is hard enough with a modest dataset, and much more so as our data grow! As we search for the optimal combination of features, algorithm, and hyperparameters, we often use tools like histograms, heatmaps, embeddings, and other plots to make our processes more informed and effective. However, large, high-dimensional datasets can prove particularly challenging. In this talk, we'll explore a suite of visual diagnostics, investigate their strengths and weaknesses in face of increasingly big data, and consider how we can steer the machine learning process, not only purposefully but at scale!&lt;/p&gt;
</summary></entry><entry><title>A Geographers Journey into AI: Mapping Urban Trees from Scratch</title><link href="https://pyvideo.org/scipy-2019/a-geographers-journey-into-ai-mapping-urban-trees-from-scratch.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Verena Griess</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/a-geographers-journey-into-ai-mapping-urban-trees-from-scratch.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We will share our experience and lessons learned in choosing, training and deploying deep learning models for single urban tree detection, localization and classification using street-level imagery. Drawing on our case study of Canada-wide urban tree mapping, we provide guidance on questions such as: what to think about when choosing a Deep Learning framework for your computer vision use case? How can you be creative in acquiring your training data? How do you train an instance segmentation model with limited labeled examples? Which open source projects to choose to quickly get started?&lt;/p&gt;
</summary></entry><entry><title>Bayesian Data Science: Probabilistic Programming</title><link href="https://pyvideo.org/scipy-2019/bayesian-data-science-probabilistic-programming.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Hugo Browne Anderson</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/bayesian-data-science-probabilistic-programming.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This tutorial will introduce you to the wonderful world of Bayesian data science through the lens of probabilistic programming. In the first hour of the tutorial, we will begin reintroduce the key concept of probability distributions via hacker statistics, hands-on simulation and telling stories of the data-generation processes. We will also cover the basics joint and conditional probability, and Bayes' rule and Bayesian inference. In the latter 2/3 of the tutorial, we will use a series of models to build your familiarity with PyMC3, showcasing how to perform the foundational inference tasks of group comparison and arbitrary curve regression. By the end of this tutorial, you will be equipped with a solid grounding in Bayesian inference, able to write arbitrary models, and have experienced basic model checking workflow.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Bayesian Statistics Made Simple</title><link href="https://pyvideo.org/scipy-2019/bayesian-statistics-made-simple.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Allen Downey</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/bayesian-statistics-made-simple.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Bayesian statistical methods are becoming more common, but there are not many resources to help beginners get started. People who know Python can use their programming skills to get a head start. In this tutorial, I introduce Bayesian methods using grid algorithms, which help develop understanding, and MCMC, which is a powerful algorithm for real-world problems.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Complexity Science</title><link href="https://pyvideo.org/scipy-2019/complexity-science.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Allen Downey</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/complexity-science.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Complexity Science is an approach to modeling systems using tools from discrete mathematics and computer science, including networks, cellular automata, and agent-based models. It has applications in many areas of natural and social science. Python is a particularly good language for exploring and implementing models of complex systems. In this tutorial, I present material from the second edition of &lt;em&gt;Think Complexity&lt;/em&gt; and from a class I teach at Olin College. We will work with random networks using NetworkX, with cellular automata using NumPy, and we will implement simple agent-based models.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Dashboarding with Jupyter Notebooks, Voila and Widgets</title><link href="https://pyvideo.org/scipy-2019/dashboarding-with-jupyter-notebooks-voila-and-widgets.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Maarten Breddels</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/dashboarding-with-jupyter-notebooks-voila-and-widgets.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Turn your Jupyter notebook into a beautiful modern React or Vue based dashboard using voila and Jupyter widgets&lt;/p&gt;
</summary></entry><entry><title>Data Analysis Tools for the James Webb Space Telescope: Confluence of Academia, NASA, &amp; Open Source</title><link href="https://pyvideo.org/scipy-2019/data-analysis-tools-for-the-james-webb-space-telescope-confluence-of-academia-nasa-open-source.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Erik Tollerud</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/data-analysis-tools-for-the-james-webb-space-telescope-confluence-of-academia-nasa-open-source.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The James Webb Space Telescope, the successor to Hubble, is NASA's upcoming flagship astrophysics mission and one of the largest scientific projects in history. Its Data Analysis Tools are written almost entirely in Python. I will provide an overview of these tools, and describe some of the technical aspects of how they leverage and contribute to the wider Python scientific ecosystem. I will also describe some of the unusual sociological and organizational elements of this effort that arise from the 3-way collaboration between academic scientists, NASA funded engineers/developers, and the Open Source Astropy project.&lt;/p&gt;
</summary></entry><entry><title>Day 2 Welcome</title><link href="https://pyvideo.org/scipy-2019/day-2-welcome.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Serge Rey</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/day-2-welcome.html</id><summary type="html"></summary></entry><entry><title>Deep Learning Fundamentals: Forward Model, Differentiable Loss Function &amp; Optimization Routine</title><link href="https://pyvideo.org/scipy-2019/deep-learning-fundamentals-forward-model-differentiable-loss-function-optimization-routine.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Eric Ma</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/deep-learning-fundamentals-forward-model-differentiable-loss-function-optimization-routine.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Does deep learning feel like a mystical topic with a myriad of jargon? If so, then this tutorial is for you. We will dive deeply into the foundational ideas that power any deep learning model: a model specification, a differentiable loss function, and an optimization routine. To make the core and ancillary ideas concrete, we will be writing our own NumPy-based implementations of the relevant models and algorithms. By the end of the tutorial, your mastery of the foundational ideas should set you free to use any framework to write any arbitrary model that you want.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Fast Gradient Boosting Decision Trees with PyGBM and Numba</title><link href="https://pyvideo.org/scipy-2019/fast-gradient-boosting-decision-trees-with-pygbm-and-numba.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Nicolas Hug</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/fast-gradient-boosting-decision-trees-with-pygbm-and-numba.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;With a high predictive power and a low tendency to overfit, Gradient Boosting Decision Trees (GBDT) are very popular, and they are often used in winning solutions to machine learning competitions, as well as industry applications. After presenting Gradient Boosting as a special kind of gradient descent, we will describe various tricks and techniques that can speed up a GBDT implementation by multiple orders of magnitude. We will also present PyGBM, a fast pure-Python implementation of GBDTs inspired by LightGBM, that leverages Numba's JIT compilation. We will also provide feedback about our extensive use of Numba.&lt;/p&gt;
</summary></entry><entry><title>freud: A Software Suite for High Throughput Analysis of Nanoscale Simulation Data</title><link href="https://pyvideo.org/scipy-2019/freud-a-software-suite-for-high-throughput-analysis-of-nanoscale-simulation-data.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Bradley Dice</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/freud-a-software-suite-for-high-throughput-analysis-of-nanoscale-simulation-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Improvements in high-performance particle-based computer simulations demand a commensurate increase in the performance of analysis codes. We address this need with freud, a Python library containing TBB-parallelized C++ routines for various analysis techniques. All inputs and outputs are NumPy arrays, enabling integration with the scientific Python ecosystem. In addition to standard analyses used in molecular simulation, freud implements novel methods for tasks such as characterizing local order. Used in conjunction with simulation software like HOOMD-blue, freud can dynamically analyze simulations on-the-fly, allowing users to study phase transition kinetics and other complex phenomena.&lt;/p&gt;
</summary></entry><entry><title>Getting Started with JupyterLab</title><link href="https://pyvideo.org/scipy-2019/getting-started-with-jupyterlab.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Matthias Bussonnier</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/getting-started-with-jupyterlab.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;JupyterLab is a new frontend for Jupyter. JupyterLab provides notebooks, text editors, terminals, and custom components arranged using tabs and collapsible sidebars. These components can be used together or separately (for example, a user can send code from a file to a console with a keystroke, or can pop out an output from a notebook to work with it alone). Users can install or write third-party plugins to view custom file formats, interact with external services, or display their data, such as interactive maps, tables, or plots. We'll walk users through JupyterLab and discuss the powerful new features in JupyterLab.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Git “Hooked” On Images In Your Version Control &amp; Up Your Documentation Game</title><link href="https://pyvideo.org/scipy-2019/git-hooked-on-images-in-your-version-control-up-your-documentation-game.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Veronica Hanus</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/git-hooked-on-images-in-your-version-control-up-your-documentation-game.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Can you remember the difference between two hex color values? Me neither! Tracking screenshots of changes to visual projects in version control (Git) makes review of past changes easier, speeds acclimation to a new web project, and increases our understanding of tools used for automated testing. Join me for a review of integrated screenshot methods currently in use (ie. Python’s Pyppeteer) and explore how you can customize a system to integrate screenshots into your version control, lower your cognitive load, and support new contributors.&lt;/p&gt;
</summary></entry><entry><title>imglyb: Bridging The Chasm Between ImageJ and NumPy</title><link href="https://pyvideo.org/scipy-2019/imglyb-bridging-the-chasm-between-imagej-and-numpy.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Philipp Hanslovsky</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/imglyb-bridging-the-chasm-between-imagej-and-numpy.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Python and Java communities have produced outstanding image processing tools, in particular the whole numpy environment on the Python side and imglib2 in Java. Combining these tools in a single workflow has been cumbersome at best, and required duplicating data in inter-process communication. I will present imglyb, a compatibility layer for numpy and imglib2 with shared memory between numpy arrays and imglib2 data structures. Python users now have access to the all imglib2 based image processing frameworks, including fast visualization of 3D image sequences for terabyte-sized data with the BigDataViewer.&lt;/p&gt;
</summary></entry><entry><title>Inclusive Leadership: Engaging Contributors in the Long Term</title><link href="https://pyvideo.org/scipy-2019/inclusive-leadership-engaging-contributors-in-the-long-term.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Tania Allard</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/inclusive-leadership-engaging-contributors-in-the-long-term.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk draws on my experience as an open source leader and community builder to provide actionable recommendations to engage with contributors in the long term. This talk will focus on the concept of inclusive leadership and how this can help us with open source sustainability.&lt;/p&gt;
</summary></entry><entry><title>Inside NumPy: Preparing for the Next Decade</title><link href="https://pyvideo.org/scipy-2019/inside-numpy-preparing-for-the-next-decade.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Ralf Gommers</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/inside-numpy-preparing-for-the-next-decade.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Over the past year, and for the first time since its creation, NumPy has been operating with dedicated funding. NumPy developers think it has invigorated the project and its community. But is that true, and how can we know? We will give an overview of the actions we've taken to improve the sustainability of the NumPy project and its community. We will draw some lessons from a first year of grant-funded activity, discuss key obstacles faced, attempt to quantify what we need to operate sustainably, and present a vision for the project and how we plan to realize it.&lt;/p&gt;
</summary></entry><entry><title>Intermediate Methods for Geospatial Data Analysis</title><link href="https://pyvideo.org/scipy-2019/intermediate-methods-for-geospatial-data-analysis.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Serge Rey</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/intermediate-methods-for-geospatial-data-analysis.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This tutorial will provide attendees with tricks, tips, and techniques that are often necessary to work with geographic data in Python. These methods will range from the basics of reading &amp;amp; writing spatial data to the mechanics of combining and summarizing disparate geographic data types and representations. Overall, participants will gain a better understanding of practical methods to bring many different geographic datasets together for analysis.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Intro to Bayesian Model Evaluation, Visualization, &amp; Comparison Using ArviZ</title><link href="https://pyvideo.org/scipy-2019/intro-to-bayesian-model-evaluation-visualization-comparison-using-arviz.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Colin Carroll</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/intro-to-bayesian-model-evaluation-visualization-comparison-using-arviz.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this tutorial we will build your expertise in handling, diagnosing, and understanding Bayesian models. It is intended for Bayesian modelers that know how to fit models, but desire further understanding on model criticism and visualization techniques. We will cover how to work with model data, how to evaluate model fit and how to communicate results. Attendees learn how to 1. Evaluate and visualize models 2. Understand plots commonly encountered in Bayesian contexts Bayesian modeling expertise is not required. Knowledge of python syntax and Numpy/Pandas are helpful to complete activities in this tutorial. Even without coding experience attendees may find value in learning how to interpret Bayesian model diagnoses and visualizations created by others.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Introduction to Data Processing in Python with Pandas</title><link href="https://pyvideo.org/scipy-2019/introduction-to-data-processing-in-python-with-pandas.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Daniel Chen</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/introduction-to-data-processing-in-python-with-pandas.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This is a tutorial for beginners on using the Pandas library in Python for data manipulation. We will go from the basics of how to load and look at a dataset in pandas (python) for the first time, and begin the process of preparing data for analysis. The topics covered are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Load and look at slices and views of data&lt;/li&gt;
&lt;li&gt;Groupby aggregates to summarize data&lt;/li&gt;
&lt;li&gt;Tidy and reshape data&lt;/li&gt;
&lt;li&gt;Write functions and apply them to data&lt;/li&gt;
&lt;li&gt;Plotting data using Seaborn&lt;/li&gt;
&lt;li&gt;Encode dummy variables to prepare for analysis and model fit&lt;/li&gt;
&lt;li&gt;Fitting a model using sklearn&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By the end of this tutorial, you should have a solid foundation on working with datasets in Python. The last topic of encoding dummy variables segues into using other libraries, such as scikit-learn and statsmodels to fit models on your data.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Introduction to Matplotlib</title><link href="https://pyvideo.org/scipy-2019/introduction-to-matplotlib.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Hannah Aizenman</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/introduction-to-matplotlib.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Users will learn how to plot some of the most common types of data- such as discrete, continuous and categorical, in 1D and 2D - using Matplotlib. In doing so, this tutorial will unpack some of the fundamental concepts that underlie the architecture of Matplotlib. Using these concepts, attendees will learn how to change the &amp;quot;look and feel&amp;quot; of plots. The concepts taught in this tutorial will lay the foundation for creating effective visualizations using Matplotlib.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Introduction to Numerical Computing with NumPy</title><link href="https://pyvideo.org/scipy-2019/introduction-to-numerical-computing-with-numpy.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Alex Chabot-Leclerc</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/introduction-to-numerical-computing-with-numpy.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;NumPy provides Python with a powerful array processing library and an elegant syntax that is well suited to expressing computational algorithms clearly and efficiently. We'll introduce basic array syntax and array indexing, review some of the available mathematical functions in NumPy, and discuss how to write your own routines. Along the way, we'll learn just enough about matplotlib to display results from our examples.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Introduction to Python</title><link href="https://pyvideo.org/scipy-2019/introduction-to-python.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Matt Davis</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/introduction-to-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This tutorial is a gentle introduction to Python for folks who are completely new to it and may not have much experience programming. We’ll work in a Jupyter Notebook, one of the most popular tools in scientific Python. You’ll learn how to write beautiful Python while practicing loops, if’s, functions, and usage of Python’s built-in features in a series of fun, interactive exercises. By the end of the tutorial we think you’ll be ready to write your own basic Python -- but most importantly, we want you to learn the form and vocabulary of Python so that you can understand Python documentation and interpret code written by others. To continue learning more about Python as it’s applied to data and science, join our companion tutorial titled Introduction to Scientific Python.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Land on Vector Spaces: Practical Linear Algebra with Python</title><link href="https://pyvideo.org/scipy-2019/land-on-vector-spaces-practical-linear-algebra-with-python.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Lorena Barba</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/land-on-vector-spaces-practical-linear-algebra-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Linear algebra is the foundational mathematical subject that everyone needs to know today. Get lost, calculus! Conventional presentations of linear algebra in undergraduate STEM curricula are overly focused on rules and memorization, overloaded with nomenclature, and slowed down by pen-and-paper methods. This tutorial skips the rule-based procedures and instead uses a visualization-rich approach and computation with NumPy to illuminate the concepts and usefulness of linear algebra. We promise a launching pad for participants to venture into this subject and continue learning after, with a solid conceptual grasp and none of the slog. You don't need previous experience in the subject; some recollection of having learned about matrices and linear systems of equations could help, but is not required.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Lightning Talks 2019-07-11</title><link href="https://pyvideo.org/scipy-2019/lightning-talks-2019-07-11.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Unknown</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/lightning-talks-2019-07-11.html</id><summary type="html"></summary><category term="lightning talks"></category></entry><entry><title>Lights Camera Action! Scrape, Explore, and Model to Predict Oscar Winners</title><link href="https://pyvideo.org/scipy-2019/lights-camera-action-scrape-explore-and-model-to-predict-oscar-winners.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Deborah Hanus</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/lights-camera-action-scrape-explore-and-model-to-predict-oscar-winners.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Using Jupyter notebooks, HTTP requests, BeautifulSoup, NumPy, Pandas,
scikit learn, and matplotlib, you’ll predict whether a movie is likely
to &lt;a class="reference external" href="http://oscarpredictor.github.io/"&gt;win an Oscar&lt;/a&gt; or be a box office hit. We’ll step through the
creation of an effective dataset: asking a question your data can
answer, writing a web scraper, and answering those questions using
nothing but Python libraries and data from the Internet.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>ML.NET in Python with NimbusML</title><link href="https://pyvideo.org/scipy-2019/mlnet-in-python-with-nimbusml.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Matteo Interlandi</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/mlnet-in-python-with-nimbusml.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;ML.NET is an open source, cross-platform, machine learning framework for .NET developers. ML.NET was originally developed in Microsoft Research and is now used across many products in Microsoft such as Windows, Bing, and PowerPoint. This talk introduces NimbusML, which brings the ML.NET library to Python. With NimbusML, developers familiar with the Scikit-learn API can start to take advantage of ML.NET performance just with few simple changes to their Scikit pipeline. The talk will also cover differentiators, such as NimbusML support for streaming datasets that don’t fit in memory, and featurizers/algorithms not easily available elsewhere.&lt;/p&gt;
</summary></entry><entry><title>Modern Time Series Analysis</title><link href="https://pyvideo.org/scipy-2019/modern-time-series-analysis.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Aileen Nielsen</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/modern-time-series-analysis.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This tutorial will cover the newest and most successful methods of time series analysis. 1. Bayesian methods for time series 2. Adapting common machine learning methods for time series 3. Deep learning for time series These methods are producing state-of-the-art results in a variety of disciplines, and attendees will learn both the underlying concepts and the Python implementations and uses of these analytical approaches to generate forecasts and estimate uncertainty for a variety of scientific time series.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Optimizing Python Based Spectroscopic Data Processing on NERSC Supercomputers</title><link href="https://pyvideo.org/scipy-2019/optimizing-python-based-spectroscopic-data-processing-on-nersc-supercomputers.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Stephen Bailey</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/optimizing-python-based-spectroscopic-data-processing-on-nersc-supercomputers.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk is a case study that describes how a Python image processing pipeline was optimized for increased throughput of 5-7x on a high-performance system. The workflow of using profiling tools to find candidate kernels for optimization and the techniques for speeding up these kernels will be described. The most successful method used to obtain speedup was just-in-time compiling using Numba; several successful examples will be provided. Parallelization strategies using MPI and Dask will be compared, and preliminary considerations for moving the code to GPUs will be discussed.&lt;/p&gt;
</summary></entry><entry><title>Optuna: A Define by Run Hyperparameter Optimization Framework</title><link href="https://pyvideo.org/scipy-2019/optuna-a-define-by-run-hyperparameter-optimization-framework.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Takuya Akiba</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/optuna-a-define-by-run-hyperparameter-optimization-framework.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, we introduce Optuna, a next-generation hyperparameter optimization framework with new design-criteria: (1) define-by-run API that allows users to concisely construct dynamic, nested, or conditional search spaces, (2) efficient implementation of both sampling and early stopping strategies, and (3) easy-to-setup, versatile architecture that can be deployed for various purposes, ranging from scalable distributed computing to lightweight experiment conducted in a local laptop machine. Our software is available under the MIT license (&lt;a class="reference external" href="https://github.com/pfnet/optuna/"&gt;https://github.com/pfnet/optuna/&lt;/a&gt;)&lt;/p&gt;
</summary></entry><entry><title>Safe Handling Instructions for Probabilistic Classification</title><link href="https://pyvideo.org/scipy-2019/safe-handling-instructions-for-probabilistic-classification.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Gordon Chen</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/safe-handling-instructions-for-probabilistic-classification.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In machine learning, a common task is to predict whether an unclassified observation belongs to one class or another. However, people are often actually more interested to know the probability of belonging to a class rather than just the most likely class. In such cases, a traditional classification problem becomes a probabilistic classification problem. This distinction is subtle yet crucial. Firstly, the probability-ish outputs of most classifiers are not true probabilities. Moreover, if we use traditional metrics such as the AUC score on probabilistic classification problems, we may end up selecting the wrong models. Fortunately, probability calibration techniques, advanced model stacking/blending methods, and more suitable metrics can fix these issues.&lt;/p&gt;
</summary></entry><entry><title>SciPy Tools Plenary Session</title><link href="https://pyvideo.org/scipy-2019/scipy-tools-plenary-session.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Unknown</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/scipy-tools-plenary-session.html</id><summary type="html"></summary><category term="plenary session"></category></entry><entry><title>Starfish: Standardizing Pipelines for Image Based Transcriptomics</title><link href="https://pyvideo.org/scipy-2019/starfish-standardizing-pipelines-for-image-based-transcriptomics.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Shannon Axelrod</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/starfish-standardizing-pipelines-for-image-based-transcriptomics.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Building a platform for standardization and collaboration for the field of image-based transcriptomics.&lt;/p&gt;
</summary></entry><entry><title>Test Research Code the Easy Way: By Generating Random Inputs with Hypothesis</title><link href="https://pyvideo.org/scipy-2019/test-research-code-the-easy-way-by-generating-random-inputs-with-hypothesis.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Zac Hatfield-Dodds</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/test-research-code-the-easy-way-by-generating-random-inputs-with-hypothesis.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Writing correct software is difficult, and even scientists don’t always get it right. Hypothesis is a testing package that will search for counterexamples to your assertions – so you can write tests that provide a high-level description of your code or system, and let the computer attempt a Popperian falsification. If it fails, your code is (probably) OK… and if it succeeds you have a minimal input to debug. Come along and learn the principles of property-based testing, how to use Hypothesis, and how to use it to check scientific code – whether highly-polished or quick-and-dirty!&lt;/p&gt;
</summary></entry><entry><title>Testing your Python Code with PyTest</title><link href="https://pyvideo.org/scipy-2019/testing-your-python-code-with-pytest.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>John Leeman</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/testing-your-python-code-with-pytest.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Every developer has heard the saying that “untested software is broken software.” In this tutorial we will show you the best practices for software testing in Python using the pytest framework. Learners will write tests for several existing functions in a provided library, including testing strings, integers, floats, lists, and arrays. We will also use the pytest-mpl library to test matplotlib plotting functions with image comparison. Topics such as test fixtures, parameterization, and test coverage will also be demonstrated. Finally, students will implement new functionality in the example library and employ test-driven-development practices. This course is targeted at anyone writing code for their own scientific use or for a scientific library and wants to learn effective ways to test that code. Learners are expected to have a grasp on the Python language features, be able to write functions, be able to create and run python scripts, and be comfortable with the command line. Learners are also encouraged to have a GitHub account and be comfortable with git, though it is not necessary for the core testing materials that will be taught. By the end of this tutorial, learners will be able to write tests for numerical and string returning functions, write image tests for plotting functions, and check the coverage of their existing codebase. This knowledge will equip them to be able to implement a test suite on their new or legacy code bases.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>The Invisible Work of Maintaining &amp; Sustaining Open Source Software</title><link href="https://pyvideo.org/scipy-2019/the-invisible-work-of-maintaining-sustaining-open-source-software.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Stuart Geiger</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/the-invisible-work-of-maintaining-sustaining-open-source-software.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Open-source software has become critical infrastructure for many sectors, including academic research, industry, governments, non-profits, activism, and more. However, the work of maintaining these projects is no small feat, particularly given the many different kinds of work expected of maintainers. In this talk, I share findings and insights from our team’s ongoing mixed-method research into the maintenance of open-source software in and beyond scientific computing, which is based on ethnographic interviews with maintainers and stakeholders, as well as quantitative analyses of code repositories. In particular, I discuss the often-invisible work that maintainers do to support their projects, and how invisible work intersects with other relevant issues to the sustainability of OSS projects, including funding models, governance, diversity &amp;amp; inclusion, and burnout.&lt;/p&gt;
</summary><category term="keynote"></category></entry><entry><title>To a Billion and Beyond: How to Visually Explore, Compare and Share Large Quantitative. Datasets with HiGlass</title><link href="https://pyvideo.org/scipy-2019/to-a-billion-and-beyond-how-to-visually-explore-compare-and-share-large-quantitative-datasets-with-higlass.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Nezar Abdennur</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/to-a-billion-and-beyond-how-to-visually-explore-compare-and-share-large-quantitative-datasets-with-higlass.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Features and patterns in large quantitative datasets are difficult to explore, compare, and communicate. We present the HiGlass application and library for interactive visualization and comparison of multiple multiscale datasets. Using a tile based API, we demonstrate how data can be dynamically rendered on the client irrespective of its size on the server. For comparison between datasets we demonstrate multiple interactively selectable modes for synchronized panning, zooming and value scaling. Finally, to share interactive views into the data, we store and disseminate the visualization as a combination of data location, aesthetics and synchronizations.&lt;/p&gt;
</summary></entry><entry><title>To Comment or Not to Comment? A Data Driven Look at Conflicting Attitudes Towards Commenting</title><link href="https://pyvideo.org/scipy-2019/to-comment-or-not-to-comment-a-data-driven-look-at-conflicting-attitudes-towards-commenting.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Patricia Hanus</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/to-comment-or-not-to-comment-a-data-driven-look-at-conflicting-attitudes-towards-commenting.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While many agree commenting is essential for maintainable code, it’s difficult for someone who hasn’t yet worked in a community-reviewed codebase to implement best practice. Commenting questions often bring conflicting answers: Code should be DRY, but well-placed comments save future devs. How can someone find the commenting style that is best for them as they learn, grow, &amp;amp; contribute? My survey of 130 developers, CS majors, bootcamp grads, &amp;amp; hobbyists confirms some expectations and brings others into question. Join me for a data-based chat about the experiences of growing developers and the steps we can take to encourage a growth mindset in developers at all levels.&lt;/p&gt;
</summary></entry><entry><title>Using Nix for Repeatable Python Environments</title><link href="https://pyvideo.org/scipy-2019/using-nix-for-repeatable-python-environments.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Daniel Wheeler</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/using-nix-for-repeatable-python-environments.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Packaging and dependency management is foundational in software deployment, but is often implemented so that outcomes depend on state and are not repeatable. This has implications for reproducing computational experiments, which require repeatable deployment of environments whenever possible. For example, the popular package managers Conda and Pip are both examples of imperative and stateful implementations. In contrast, the Nix package manager is a functional package manager that implements fully repeatable environment deployment in a systematic manner. The talk will introduce the Nix package manager and demonstrate using Nix to generate repeatable Python environments as well as environments involving multiple languages.&lt;/p&gt;
</summary></entry><entry><title>Using SatPy to Process Earth observing Satellite Data</title><link href="https://pyvideo.org/scipy-2019/using-satpy-to-process-earth-observing-satellite-data.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>David Hoese</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/using-satpy-to-process-earth-observing-satellite-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This tutorial is an introduction to SatPy, a python library for easily reading and working with earth-observing satellite data like that of the NOAA-20 VIIRS or GOES-16 ABI instruments. It is aimed at scientific users who would like to simplify some of their satellite data processing tasks. No previous experience with SatPy is needed. During this tutorial we’ll work through common satellite processing tasks using SatPy using Jupyter Notebook examples with real instrument data.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Vaex: Out of Core Dataframes for Python</title><link href="https://pyvideo.org/scipy-2019/vaex-out-of-core-dataframes-for-python.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Maarten Breddels</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/vaex-out-of-core-dataframes-for-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Vaex is a Python library with a DataFrame API that works efficiently with big (~1 billion rows) tabular datasets. Using an expression system and memory mapping, all operations can be performed lazily and in chunks, while using a familiar DataFrame API and regular numpy expressions, enabling data cleansing, on the fly computations and visualizations for massive datasets on even laptops.&lt;/p&gt;
</summary></entry><entry><title>Visualization of Bioinformatics Data with Dash Bio</title><link href="https://pyvideo.org/scipy-2019/visualization-of-bioinformatics-data-with-dash-bio.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Shammamah Hossain</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/visualization-of-bioinformatics-data-with-dash-bio.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Plotly's Dash library is a data visualization tool used in many places from laboratories to corporate settings. Dash Bio is the latest extension to Dash, and aims to bring Dash to the world of bioinformatics with a suite of components created for visualization and analysis.&lt;/p&gt;
</summary></entry><entry><title>Visualize any Data Easily, from Notebooks to Dashboards</title><link href="https://pyvideo.org/scipy-2019/visualize-any-data-easily-from-notebooks-to-dashboards.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>James Bednar</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/visualize-any-data-easily-from-notebooks-to-dashboards.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this tutorial you will see how to visualize and communicate your data easily and effectively using Python tools. You'll learn how to use Panel to lay out your existing plots with widgets to make apps in the notebook or as deployed dashboards, hvPlot to make your Pandas or Xarray .plot() API calls return interactive, explorable plots, HoloViews and GeoViews to help you explore multidimensional data naturally without having to build a plot for each combination or sample of the data space, and Datashader to visualize even the very largest datasets faithfully in a web browser. See pyviz.org for links to all these tools and more.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Xonsh: Bringing Python Data Science to your Shell</title><link href="https://pyvideo.org/scipy-2019/xonsh-bringing-python-data-science-to-your-shell.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Gilbert Forsyth</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/xonsh-bringing-python-data-science-to-your-shell.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Xonsh is an interactive, cross-platform Python/Unix Shell hybrid language that makes it easy to switch between Python operations and command line interfaces. While Python has a wealth of data science libraries and tools, there are still plenty of utilities that live outside of the scientific Python ecosystem. Xonsh provides a way of gluing ALL of your tools together. Additionally, as a shell, xonsh comes with batteries-included features that are important in a scientific context. If you are new to shells, want to use Python for &lt;em&gt;everything&lt;/em&gt;, or just plain fed up with sh-lang syntax, this tutorial is for you!&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Zarr: Scalable Storage of Tensor Data for Use in Parallel and Distributed Computing</title><link href="https://pyvideo.org/scipy-2019/zarr-scalable-storage-of-tensor-data-for-use-in-parallel-and-distributed-computing.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Alistair Miles</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/zarr-scalable-storage-of-tensor-data-for-use-in-parallel-and-distributed-computing.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Many scientific problems involve computing over large N-dimensional typed arrays of data, and reading or writing data is often the major bottleneck limiting speed or scalability. The Zarr project is developing a simple, scalable approach to storage of such data in a way that is compatible with a range of approaches to distributed and parallel computing. We describe the Zarr protocol and data storage format, and the current state of implementations for various programming languages including Python. We also describe current uses of Zarr in malaria genomics, the Human Cell Atlas, and the Pangeo project.&lt;/p&gt;
</summary></entry><entry><title>An Overview to Simulations and Generating Synthetic Data Sets</title><link href="https://pyvideo.org/scipy-2019/an-overview-to-simulations-and-generating-synthetic-data-sets.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Aileen Nielsen</name></author><id>tag:pyvideo.org,2019-07-10:scipy-2019/an-overview-to-simulations-and-generating-synthetic-data-sets.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever wanted to simulate a system but didn't know how to get started? Or maybe you wanted to create a data set with certain characteristics but weren't sure how to get the characteristics you had in mind. This tutorial will give you an overview of the mathematics and programming involved in simulating systems and generating synthetic data. Attendees of this tutorial will understand how simulations are built, the fundamental techniques of crafting probabilistic systems, and the options available for generating synthetic data sets. The skills of simulation and synthesis of data are both invaluable in generating and testing hypotheses about scientific data sets.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Escape from Auto manual Testing with Hypothesis!</title><link href="https://pyvideo.org/scipy-2019/escape-from-auto-manual-testing-with-hypothesis.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Zac Hatfield-Dodds</name></author><id>tag:pyvideo.org,2019-07-10:scipy-2019/escape-from-auto-manual-testing-with-hypothesis.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Hypothesis is a testing package that will search for counterexamples to your assertions – so you can write tests that provide a high-level description of your code or system, and let the computer attempt a Popperian falsification. If it fails, your code is (probably) OK… and if it succeeds you have a minimal input to debug. Come along and learn the principles of property-based testing, how to use Hypothesis, and how to use it to check scientific code – whether highly-polished or quick-and-dirty!&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Hands-on Satellite Imagery Analysis</title><link href="https://pyvideo.org/scipy-2019/hands-on-satellite-imagery-analysis.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Samapriya Roy</name></author><id>tag:pyvideo.org,2019-07-10:scipy-2019/hands-on-satellite-imagery-analysis.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Satellite data is more widely available than ever before, and it is now possible for the public to access sub-weekly and even daily imagery of the Earth's entire landmass. In this tutorial, gain hands-on experience exploring Planet’s publicly-available satellite imagery and using Python tools for geospatial and time-series analysis of medium- and high-resolution imagery data. Using free &amp;amp; open source libraries, learn how to perform foundational imagery analysis techniques and apply these techniques to real satellite data. At the end of the workshop, we’ll demonstrate how the skills you've learned can be applied to investigate real-world environmental and humanitarian challenges.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Image Analysis in Python with SciPy and Scikit Image</title><link href="https://pyvideo.org/scipy-2019/image-analysis-in-python-with-scipy-and-scikit-image.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Juan Nunez-Iglesias</name></author><id>tag:pyvideo.org,2019-07-10:scipy-2019/image-analysis-in-python-with-scipy-and-scikit-image.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;From telescopes to satellite cameras to electron microscopes, scientists are producing more images than they can manually inspect. This tutorial will introduce image analysis using the idea that &amp;quot;images are just NumPy arrays&amp;quot;. Then we will run through various fundamental image analysis operations (filters, morphology, segmentation), and finally we will demonstrate one or two advanced real-world examples. This tutorial is aimed at people who are familiar with NumPy, SciPy, and Matplotlib, but it does not require any previous knowledge of image analysis or image processing.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Multi-dimensional Linked Data Exploration with Glue (Tutorial)</title><link href="https://pyvideo.org/scipy-2019/multi-dimensional-linked-data-exploration-with-glue-tutorial.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Thomas Robitaille</name></author><id>tag:pyvideo.org,2019-07-10:scipy-2019/multi-dimensional-linked-data-exploration-with-glue-tutorial.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We have developed an open-source multi-disciplinary Python package named glue (&lt;a class="reference external" href="http://glueviz.org"&gt;http://glueviz.org&lt;/a&gt;) that allows users to explore relationships within and across related datasets, making it easy for them to create multi-dimensional linked visualizations of datasets, select subsets of data interactively or programmatically in 1, 2, or 3 dimensions, and to see those selections propagate live across all open visualizations of the data (e.g., graphs, maps, diagnostics charts, etc.). In this tutorial, participants will learn how to use and customize the desktop and Jupyter version of glue, using example data as well as their own data.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Network Analysis Made Simple</title><link href="https://pyvideo.org/scipy-2019/network-analysis-made-simple.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Eric Ma</name></author><id>tag:pyvideo.org,2019-07-10:scipy-2019/network-analysis-made-simple.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever wondered about how those data scientists at Facebook and LinkedIn make friend recommendations? Or how epidemiologists track down patient zero in an outbreak? If so, then this tutorial is for you. In this tutorial, we will use a variety of datasets to help you understand the fundamentals of network thinking, with a particular focus on constructing, summarizing, and visualizing complex networks. Finally, at the end of the tutorial, allow yourself to be entertained and hopefully also enlightened by the link between applied network science and linear algebra!&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>RAPIDS: Open GPU Data Science</title><link href="https://pyvideo.org/scipy-2019/rapids-open-gpu-data-science.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Anthony Scopatz</name></author><id>tag:pyvideo.org,2019-07-10:scipy-2019/rapids-open-gpu-data-science.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The RAPIDS suite of open source software libraries gives you the freedom to execute end-to-end data science pipelines entirely on GPUs. RAPIDS is incubated by NVIDIA® based on years of accelerated data science experience. RAPIDS relies on NVIDIA CUDA® primitives for low-level compute optimization, GPU parallelism, and high-bandwidth memory speed through user-friendly Python interfaces. This tutorial will teach you how to use the RAPIDS software stack from Python, including cuDF (a DataFrame library interoperable with Pandas), dask-cudf (for distributing DataFrame work over many GPUs), and cuML (a machine learning library that provides GPU-accelerated versions of the algorithms in scikit-learn).&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Reproducible Data Science in Python</title><link href="https://pyvideo.org/scipy-2019/reproducible-data-science-in-python.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Xu Fei</name></author><id>tag:pyvideo.org,2019-07-10:scipy-2019/reproducible-data-science-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The expectation of reproducibility in scientific work has been long established, and, increasingly, communities and funding sources are actually demanding it. Within the Python ecosystem, there are a variety of tools available to support reproducible data science, but choosing and using one is not always straightforward. In this tutorial, we will take a closer look at the concept of _reproducibility_, and, we will examine the technologies that provide building blocks and survey the landscape of tools. We spend the majority of the time looking at two solutions in particular, Code Ocean and Renku, and work through end-to-end scenarios in both.&lt;/p&gt;
</summary><category term="tutorial"></category></entry></feed>