<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_joe-cabrera.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-08-18T00:00:00+00:00</updated><entry><title>High Performance Python Microservice Communication</title><link href="https://pyvideo.org/pybay-2018/high-performance-python-microservice-communication.html" rel="alternate"></link><published>2018-08-18T00:00:00+00:00</published><updated>2018-08-18T00:00:00+00:00</updated><author><name>Joe Cabrera</name></author><id>tag:pyvideo.org,2018-08-18:pybay-2018/high-performance-python-microservice-communication.html</id><summary type="html"></summary></entry><entry><title>Indexing all the things: Building your search engine in Python</title><link href="https://pyvideo.org/pygotham-2017/indexing-all-the-things-building-your-search-engine-in-python.html" rel="alternate"></link><published>2017-10-06T00:00:00+00:00</published><updated>2017-10-06T00:00:00+00:00</updated><author><name>Joe Cabrera</name></author><id>tag:pyvideo.org,2017-10-06:pygotham-2017/indexing-all-the-things-building-your-search-engine-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Since the emergence of Elasticsearch, common Information Retrieval tasks such as indexing, scoring and retrieval of documents into a search engine have never been easier. However unique challenges still exist for indexing large sets of data from databases. At Jopwell, we need to insure that data in our database is kept in constant sync with data in our search index.&lt;/p&gt;
&lt;p&gt;Initially you need to take data from a traditional SQL database and flatten it for indexing in Elasticsearch. Since indexing this data can be a memory intensive task, Celery is useful for ensuring you can index large sets of data in both a distributed and memory-conservative manner. Once all your documents are in your Elasticsearch index, you need to retrieve data from your database related to a user’s search results.&lt;/p&gt;
&lt;p&gt;In this talk, I’ll show the basics of creating a search engine in Python, keeping these it synced with another data store and how you can keep your index running smoothly.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Talk Outline&lt;/strong&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Introduction to the problem (2 min)&lt;/li&gt;
&lt;li&gt;Building your document indexer (7 min)&lt;ul&gt;
&lt;li&gt;Flattening database data into a search document&lt;/li&gt;
&lt;li&gt;Using Celery to index documents efficiently&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scoring and search results retrieval (7 min)&lt;ul&gt;
&lt;li&gt;Scoring algorithms&lt;/li&gt;
&lt;li&gt;Retrieving matching results from the database&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Strategies for syncing data from (7 min)&lt;ul&gt;
&lt;li&gt;Traditional SQL database&lt;/li&gt;
&lt;li&gt;Elasticsearch index&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Future work (2 min)&lt;/li&gt;
&lt;/ul&gt;
</summary></entry><entry><title>Building a data processing pipeline in Python</title><link href="https://pyvideo.org/pygotham-2015/building-a-data-processing-pipeline-in-python.html" rel="alternate"></link><published>2015-08-15T00:00:00+00:00</published><updated>2015-08-15T00:00:00+00:00</updated><author><name>Joe Cabrera</name></author><id>tag:pyvideo.org,2015-08-15:pygotham-2015/building-a-data-processing-pipeline-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Recently, the growth of publicly available data has been enormous.
Python has a number of libraries and tool to aid you in building your
data processing pipeline. These tools include Celery, Requests,
BeautifulSoup and SQL-Alchemy. When combined together you can build an
efficient and scalable data processing pipeline.&lt;/p&gt;
</summary></entry></feed>