<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Helge Langseth</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_helge-langseth.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-08-03T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Prediction Intervals: Split Normal Mixture from Quality-Driven Deep Ensembles</title><link href="https://pyvideo.org/uai-2020/prediction-intervals-split-normal-mixture-from-quality-driven-deep-ensembles.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Tárik Saleh Salem</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/prediction-intervals-split-normal-mixture-from-quality-driven-deep-ensembles.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Prediction Intervals: Split Normal Mixture from Quality-Driven Deep Ensembles&lt;/p&gt;
&lt;p&gt;Tárik Saleh Salem (NTNU)*; Helge Langseth (Norwegian University of Science and Technology); Heri Ramampiaro (Norwegian University of Science and Technology (NTNU))&lt;/p&gt;
&lt;p&gt;Prediction intervals are a machine- and human-interpretable way to represent predictive uncertainty in a regression analysis. In this paper …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Prediction Intervals: Split Normal Mixture from Quality-Driven Deep Ensembles&lt;/p&gt;
&lt;p&gt;Tárik Saleh Salem (NTNU)*; Helge Langseth (Norwegian University of Science and Technology); Heri Ramampiaro (Norwegian University of Science and Technology (NTNU))&lt;/p&gt;
&lt;p&gt;Prediction intervals are a machine- and human-interpretable way to represent predictive uncertainty in a regression analysis. In this paper, we present a method for generating prediction intervals along with point estimates from an ensemble of neural networks. We propose a multi-objective loss function fusing quality measures related to prediction intervals and point estimates, and a penalty function, which enforces semantic integrity of the results and stabilizes the training process of the neural networks. The ensembled prediction intervals are aggregated as a split normal mixture accounting for possible multimodality and asymmetricity of the posterior predictive distribution, and resulting in prediction intervals that capture aleatoric and epistemic uncertainty. Our results show that both our quality-driven loss function and our aggregation method contribute to well-calibrated prediction intervals and point estimates. &amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry></feed>