<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 30 May 2016 00:00:00 +0000</lastBuildDate><item><title>The failure of python object serialization: why HPC in python is broken</title><link>https://pyvideo.org/pycon-uk-2014/the-failure-of-python-object-serialization-why-hpc-in-python-is-broken.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Presented by: Mike McKerns&lt;/p&gt;
&lt;p&gt;Parallel and asynchronous computing in python is crippled by pickle's poor object serialization. However, a more robust serialization package would drastically improve the situation. To leverage the cores found in modern processors we need to communicate functions between different processes -- and that means callables must be serialized without pickle barfing. Similarly, parallel and distributed computing with MPI, GPUs, sockets, and across other process boundaries all need serialized functions (or other callables). So why is pickling in python so broken? Python's ability to leverage these awesome communication technologies is limited by python's own inability to be a fully serializable language. In actuality, serialization in python is quite limited, and for really no good reason.&lt;/p&gt;
&lt;p&gt;Many raise security concerns for full object serialization, however it can be argued that it is not pickle's responsibility to do proper authentication. In fact, one could apply rather insecure serialization of all objects the objects were all sent across RSA-encrypted ssh-tunnels, for example.&lt;/p&gt;
&lt;p&gt;Dill is a serialization package that strives to serialize all of python. We have forked python's multiprocessing to use dill. Dill can also be leveraged by mpi4py, ipython, and other parallel or distributed python packages. Dill serves as the backbone for a distributed parallel computing framework that is being used to design the next generation of large-scale heterogeneous computing platforms, and has been leveraged in large-scale calculations of risk and uncertainty. Dill has been used to enable state persistence and recovery, global caching, and the coordination of distributed parallel calculations across a network of the world's largest computers.     &lt;a class="reference external" href="http://pythonhosted.org/dill"&gt;http://pythonhosted.org/dill&lt;/a&gt;     &lt;a class="reference external" href="https://github.com/uqfoundation"&gt;https://github.com/uqfoundation&lt;/a&gt;     &lt;a class="reference external" href="http://matthewrocklin.com/blog/work/2013/12/05/Parallelism-and-Serialization/"&gt;http://matthewrocklin.com/blog/work/2013/12/05/Parallelism-and-Serialization/&lt;/a&gt;     &lt;a class="reference external" href="http://stackoverflow.com/questions/19984152/what-can-multiprocessing-and-dill-do-together?rq=1"&gt;http://stackoverflow.com/questions/19984152/what-can-multiprocessing-and-dill-do-together?rq=1&lt;/a&gt;     &lt;a class="reference external" href="https://groups.google.com/forum/#!topic/mpi4py/1fd4FwdgpWY"&gt;https://groups.google.com/forum/#!topic/mpi4py/1fd4FwdgpWY&lt;/a&gt;     &lt;a class="reference external" href="http://nbviewer.ipython.org/gist/anonymous/5241793"&gt;http://nbviewer.ipython.org/gist/anonymous/5241793&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mike McKerns</dc:creator><pubDate>Mon, 20 Oct 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2014-10-20:pycon-uk-2014/the-failure-of-python-object-serialization-why-hpc-in-python-is-broken.html</guid><category>dill</category><category>serialization</category><category>pickle</category></item><item><title>Efficient Python for High Performance Parallel Computing</title><link>https://pyvideo.org/scipy-2015/efficient-python-for-high-performance-parallel-computing.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mike McKerns</dc:creator><pubDate>Fri, 10 Jul 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-07-10:scipy-2015/efficient-python-for-high-performance-parallel-computing.html</guid><category>Tutorial</category></item><item><title>Modern Optimization Methods in Python</title><link>https://pyvideo.org/scipy-2015/modern-optimization-methods-in-python.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mike McKerns</dc:creator><pubDate>Fri, 10 Jul 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-07-10:scipy-2015/modern-optimization-methods-in-python.html</guid><category>tutorial</category></item><item><title>klepto Unified Persistent Storage to Memory, Disk, or Database</title><link>https://pyvideo.org/euroscipy-2015/klepto-unified-persistent-storage-to-memory-disk-or-database.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;klepto is a new python package that provides a unified programming interface to caching and archiving to memory, disk, or database. klepto provides a dictionary interface to caches and archives, where all caches can also be applied to any python callable as a decorator. klepto can be used to create dual caching strategies for speed and robustness, with design abstractions for things like multiple&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mike McKerns</dc:creator><pubDate>Mon, 05 Oct 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-10-05:euroscipy-2015/klepto-unified-persistent-storage-to-memory-disk-or-database.html</guid></item><item><title>Efficient Python for High-Performance Parallel Computing</title><link>https://pyvideo.org/pycon-us-2016/mike-mckerns-efficient-python-for-high-performance-parallel-computing-pycon-2016.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Speaker: Mike McKerns&lt;/p&gt;
&lt;p&gt;This tutorial is targeted at the intermediate-to-advanced Python user who wants to extend Python into High-Performance Computing. The tutorial will provide hands-on examples and essential performance tips every developer should know for writing effective parallel Python. The result will be a clear sense of possibilities and best practices using Python in HPC environments.&lt;/p&gt;
&lt;p&gt;Slides can be found at: &lt;a class="reference external" href="https://speakerdeck.com/pycon2016"&gt;https://speakerdeck.com/pycon2016&lt;/a&gt; and &lt;a class="reference external" href="https://github.com/PyCon/2016-slides"&gt;https://github.com/PyCon/2016-slides&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mike McKerns</dc:creator><pubDate>Mon, 30 May 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-05-30:pycon-us-2016/mike-mckerns-efficient-python-for-high-performance-parallel-computing-pycon-2016.html</guid></item></channel></rss>