<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - UAI 2023</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 31 Jul 2023 00:00:00 +0000</lastBuildDate><item><title>Algorithms in Unjust Systems</title><link>https://pyvideo.org/uai-2023/algorithms-in-unjust-systems.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Introduction by Kun Zhang and Opening remarks by Richard Scheines and Peter Spirtes&lt;/p&gt;
&lt;p&gt;Keynote Talk 1: Alexandra Chouldechova. Algorithms in Unjust Systems. (session chair: Peter Spirtes)&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexandra Chouldechova</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/algorithms-in-unjust-systems.html</guid><category>UAI 2023</category><category>Keynote</category></item><item><title>An Improved Variational Approximate Posterior for the Deep Wishart</title><link>https://pyvideo.org/uai-2023/an-improved-variational-approximate-posterior-for-the-deep-wishart.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;An Improved Variational Approximate Posterior for the Deep Wishart Process&amp;quot;
Sebastian W. Ober, Ben Anson, Edward Milsom, Laurence Aitchison
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/ober23a.html"&gt;https://proceedings.mlr.press/v216/ober23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Deep kernel processes are a recently introduced class of deep Bayesian models that have the flexibility of neural networks, but work entirely with Gram matrices. They operate by alternately sampling a Gram matrix from a distribution over positive semi-definite matrices, and applying a deterministic transformation. When the distribution is chosen to be Wishart, the model is called a deep Wishart process (DWP). This particular model is of interest because its prior is equivalent to a deep Gaussian process (DGP) prior, but at the same time it is invariant to rotational symmetries, leading to a simpler posterior distribution. Practical inference in the DWP was made possible in recent work (“A variational approximate posterior for the deep Wishart process” Ober and Aitchison, 2021a) where the authors used a generalisation of the Bartlett decomposition of the Wishart distribution as the variational approximate posterior. However, predictive performance in that paper was less impressive than one might expect, with the DWP only beating a DGP on a few of the UCI datasets used for comparison. In this paper, we show that further generalising their distribution to allow linear combinations of rows and columns in the Bartlett decomposition results in better predictive performance, while incurring negligible additional computation cost.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/402-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/402-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sebastian W. Ober</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/an-improved-variational-approximate-posterior-for-the-deep-wishart.html</guid><category>UAI 2023</category></item><item><title>Causal Representation Learning</title><link>https://pyvideo.org/uai-2023/causal-representation-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Causal Representation Learning&amp;quot;
Dhanya Sridhar, Jason Hartford&lt;/p&gt;
&lt;p&gt;Causal Representation Learning (CRL) is an emerging area of research that seeks to address an important gap in the field of causality: how can we learn causal models and mechanisms without direct measurements of all the variables? To this end, CRL combines recent advances in machine learning withnew assumptions that guarantee that causal variables can be identified up to some indeterminacies from low-level observations such as text, images or biological measurements. In this tutorial, we will review the broad classes of assumptions driving CRL. We strive to build strong intuitions about the core technical problems underpinning CRL and draw connections across different results. We will conclude the tutorial by discussing open questions for CRL, motivated by the kind of methods we would need if we wanted to extend causal models to scientific discovery.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dhanya Sridhar</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/causal-representation-learning.html</guid><category>UAI 2023</category><category>tutorial</category></item><item><title>Causal Representation Learning &amp; Optimal Intervention Design</title><link>https://pyvideo.org/uai-2023/causal-representation-learning-optimal-intervention-design.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Keynote talk 3: Caroline Uhler. Causal Representation Learning &amp;amp; Optimal Intervention Design. (session chair: Daniel Malinsky)&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Caroline Uhler</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/causal-representation-learning-optimal-intervention-design.html</guid><category>UAI 2023</category><category>Keynote</category></item><item><title>Conditional Abstraction Trees for Sample-Efficient Reinforcement Learning</title><link>https://pyvideo.org/uai-2023/conditional-abstraction-trees-for-sample-efficient-reinforcement-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Conditional Abstraction Trees for Sample-Efficient Reinforcement Learning&amp;quot;
Mehdi Dadvar, Rashmeet Kaur Nayyar, Siddharth Srivastava
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/dadvar23a.html"&gt;https://proceedings.mlr.press/v216/dadvar23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
In many real-world problems, the learning agent needs to learn a problem’s abstractions and solution simultaneously. However, most such abstractions need to be designed and refined by hand for different problems and domains of application. This paper presents a novel top-down approach for constructing state abstractions while carrying out reinforcement learning (RL). Starting with state variables and a simulator, it presents a novel domain-independent approach for dynamically computing an abstraction based on the dispersion of temporal difference errors in abstract states as the agent continues acting and learning. Extensive empirical evaluation on multiple domains and problems shows that this approach automatically learns semantically rich abstractions that are finely-tuned to the problem, yield strong sample efficiency, and result in the RL agent significantly outperforming existing approaches.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/701-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/701-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mehdi Dadvar</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/conditional-abstraction-trees-for-sample-efficient-reinforcement-learning.html</guid><category>UAI 2023</category></item><item><title>Data Compression With Machine Learning</title><link>https://pyvideo.org/uai-2023/data-compression-with-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;dl class="docutils"&gt;
&lt;dt&gt;Data Compression With Machine Learning&lt;/dt&gt;
&lt;dd&gt;Karen Ullrich, Yibo Yang, Stephan Man
The efficient communication of information is an application with enormous societal and environmental impact, and stands to benefit from the machine learning revolution seen in other fields. Through this tutorial, we hope to disseminate the ideas of information theory and compression to a broad audience, overview the core methodologies in learning-based compression (i.e., neural compression), and present the relevant technical challenges and open problems defining a new frontier for probabilistic machine learning.&lt;/dd&gt;
&lt;/dl&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Karen Ullrich</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/data-compression-with-machine-learning.html</guid><category>UAI 2023</category><category>tutorial</category></item><item><title>Establishing Markov Equivalence in Cyclic Directed Graphs</title><link>https://pyvideo.org/uai-2023/establishing-markov-equivalence-in-cyclic-directed-graphs.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Establishing Markov Equivalence in Cyclic Directed Graphs&amp;quot;
Tom Claassen, Joris Mooij
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/claassen23a.html"&gt;https://proceedings.mlr.press/v216/claassen23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
We present a new, efficient procedure to establish Markov equivalence between directed graphs that may or may not contain cycles. It is based on the Cyclic Equivalence Theorem (CET) in the seminal works on cyclic models by Thomas Richardson in the mid ’90s, but now rephrased from an ancestral perspective. The resulting characterization leads to a procedure for establishing Markov equivalence between graphs that no longer requires explicit tests for d-separation, leading to a significantly reduced algorithmic complexity. The conceptually simplified characterization may help to reinvigorate theoretical research towards sound and complete cyclic discovery in the presence of latent confounders.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/504-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/504-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tom Claassen</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/establishing-markov-equivalence-in-cyclic-directed-graphs.html</guid><category>UAI 2023</category></item><item><title>Functional Causal Bayesian Optimization</title><link>https://pyvideo.org/uai-2023/functional-causal-bayesian-optimization.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Functional Causal Bayesian Optimization&amp;quot;
Limor Gultchin, Virginia Aglietti, Alexis Bellot, Silvia Chiappa
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/gultchin23a.html"&gt;https://proceedings.mlr.press/v216/gultchin23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
We propose functional causal Bayesian optimization (fCBO), a method for finding interventions that optimize a target variable in a known causal graph. fCBO extends the CBO family of methods to enable functional interventions, which set a variable to be a deterministic function of other variables in the graph. fCBO models the unknown objectives with Gaussian processes whose inputs are defined in a reproducing kernel Hilbert space, thus allowing to compute distances among vector-valued functions. In turn, this enables to sequentially select functions to explore by maximizing an expected improvement acquisition functional while keeping the typical computational tractability of standard BO settings. We introduce graphical criteria that establish when considering functional interventions allows attaining better target effects, and conditions under which selected interventions are also optimal for conditional target effects. We demonstrate the benefits of the method in a synthetic and in a real-world causal graph.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/486-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/486-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Limor Gultchin</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/functional-causal-bayesian-optimization.html</guid><category>UAI 2023</category></item><item><title>Human-in-the-Loop Mixup</title><link>https://pyvideo.org/uai-2023/human-in-the-loop-mixup.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Human-in-the-Loop Mixup&amp;quot;
Katherine M. Collins, Umang Bhatt, Weiyang Liu, Vihari Piratla, Ilia Sucholutsky, Bradley C. Love, Adrian Weller
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/collins23a.html"&gt;https://proceedings.mlr.press/v216/collins23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Aligning model representations to humans has been found to improve robustness and generalization. However, such methods often focus on standard observational data. Synthetic data is proliferating and powering many advances in machine learning; yet, it is not always clear whether synthetic labels are perceptually aligned to humans – rendering it likely model representations are not human aligned. We focus on the synthetic data used in mixup: a powerful regularizer shown to improve model robustness, generalization, and calibration. We design a comprehensive series of elicitation interfaces, which we release as HILL MixE Suite, and recruit 159 participants to provide perceptual judgments along with their uncertainties, over mixup examples. We find that human perceptions do not consistently align with the labels traditionally used for synthetic points, and begin to demonstrate the applicability of these findings to potentially increase the reliability of downstream models, particularly when incorporating human uncertainty. We release all elicited judgments in a new data hub we call H-Mix.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/256-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/256-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Katherine M. Collins</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/human-in-the-loop-mixup.html</guid><category>UAI 2023</category></item><item><title>Is the Volume of a Credal Set a Good Measure for Epistemic Uncertainty?</title><link>https://pyvideo.org/uai-2023/is-the-volume-of-a-credal-set-a-good-measure-for-epistemic-uncertainty.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Is the Volume of a Credal Set a Good Measure for Epistemic Uncertainty?&amp;quot;
Yusuf Sale, Michele Caprio, Eyke Hüllermeier
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/sale23a.html"&gt;https://proceedings.mlr.press/v216/sale23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Adequate uncertainty representation and quantification have become imperative in various scientific disciplines, especially in machine learning and artificial intelligence. As an alternative to representing uncertainty via one single probability measure, we consider credal sets (convex sets of probability measures). The geometric representation of credal sets as d-dimensional polytopes implies a geometric intuition about (epistemic) uncertainty. In this paper, we show that the volume of the geometric representation of a credal set is a meaningful measure of epistemic uncertainty in the case of binary classification, but less so for multi-class classification. Our theoretical findings highlight the crucial role of specifying and employing uncertainty measures in machine learning in an appropriate way, and for being aware of possible pitfalls.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/482-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/482-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yusuf Sale</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/is-the-volume-of-a-credal-set-a-good-measure-for-epistemic-uncertainty.html</guid><category>UAI 2023</category></item><item><title>Keep-Alive Caching for the Hawkes Process</title><link>https://pyvideo.org/uai-2023/keep-alive-caching-for-the-hawkes-process.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Keep-Alive Caching for the Hawkes Process&amp;quot;
Sushirdeep Narayana, Ian A. Kash
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/narayana23a.html"&gt;https://proceedings.mlr.press/v216/narayana23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
We study the design of caching policies in applications such as serverless computing where there is not a fixed size cache to be filled, but rather there is a cost associated with the time an item stays in the cache. We present a model for such caching policies which captures the trade-off between this cost and the cost of cache misses. We characterize optimal caching policies in general and apply this characterization by deriving a closed form for Hawkes processes. Since optimal policies for Hawkes processes depend on the history of arrivals, we also develop history-independent policies which achieve near-optimal average performance. We evaluate the performances of the optimal policy and approximate polices using simulations and a data trace of Azure Functions, Microsoft’s FaaS (Function as a Service) platform for serverless computing.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/621-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/621-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sushirdeep Narayana</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/keep-alive-caching-for-the-hawkes-process.html</guid><category>UAI 2023</category></item><item><title>Learning from Low Rank Tensor Data: A Random Tensor Theory Perspective</title><link>https://pyvideo.org/uai-2023/learning-from-low-rank-tensor-data-a-random-tensor-theory-perspective.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Learning from Low Rank Tensor Data  A Random Tensor Theory Perspective&amp;quot;
Mohamed El Amine Seddik, Malik Tiomoko, Alexis Decurninge, Maxime Guillaud, Maxim Panov
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/seddik23a.html"&gt;https://proceedings.mlr.press/v216/seddik23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Under a simplified data model, this paper provides a theoretical analysis of learning from data that have an underlying low-rank tensor structure in both supervised and unsupervised settings. For the supervised setting, we provide an analysis of a Ridge classifier (with high regularization parameter) with and without knowledge of the low-rank structure of the data. Our results quantify analytically the gain in misclassification errors achieved by exploiting the low-rank structure for denoising purposes, as opposed to treating data as mere vectors. We further provide a similar analysis in the context of clustering, thereby quantifying the exact performance gap between tensor methods and standard approaches which treat data as simple vectors.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/432-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/432-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mohamed El Amine Seddik</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/learning-from-low-rank-tensor-data-a-random-tensor-theory-perspective.html</guid><category>UAI 2023</category></item><item><title>Local Message Passing on Frustrated Systems</title><link>https://pyvideo.org/uai-2023/local-message-passing-on-frustrated-systems.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Local Message Passing on Frustrated Systems&amp;quot;
Luca Schmid, Joshua Brenk, Laurent Schmalen
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/schmid23a.html"&gt;https://proceedings.mlr.press/v216/schmid23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Message passing on factor graphs is a powerful framework for probabilistic inference, which finds important applications in various scientific domains. The most wide-spread message passing scheme is the sum-product algorithm (SPA) which gives exact results on trees but often fails on graphs with many small cycles. We search for an alternative message passing algorithm that works particularly well on such cyclic graphs. Therefore, we challenge the extrinsic principle of the SPA, which loses its objective on graphs with cycles. We further replace the local SPA message update rule at the factor nodes of the underlying graph with a generic mapping, which is optimized in a data-driven fashion. These modifications lead to a considerable improvement in performance while preserving the simplicity of the SPA. We evaluate our method for two classes of cyclic graphs: the 2x2 fully connected Ising grid and factor graphs for symbol detection on linear communication channels with inter-symbol interference. To enable the method for large graphs as they occur in practical applications, we develop a novel loss function that is inspired by the Bethe approximation from statistical physics and allows for training in an unsupervised fashion.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/430-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/430-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Luca Schmid</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/local-message-passing-on-frustrated-systems.html</guid><category>UAI 2023</category></item><item><title>Long Story Short: Omitted Variable Bias in Causal ML</title><link>https://pyvideo.org/uai-2023/long-story-short-omitted-variable-bias-in-causal-ml.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Keynote talk 2. Victor Chernozhukov. Long Story Short: Omitted Variable Bias in Causal Machine Learning. (session chair: Ilya Shpitser)&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Victor Chernozhukov</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/long-story-short-omitted-variable-bias-in-causal-ml.html</guid><category>UAI 2023</category><category>Keynote</category></item><item><title>Meta Learning Control Variates Variance Reduction with Limited Data</title><link>https://pyvideo.org/uai-2023/meta-learning-control-variates-variance-reduction-with-limited-data.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Meta Learning Control Variates Variance Reduction with Limited Data&amp;quot;
Zhuo Sun, Chris J. Oates, Francois-Xavier Briol
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/sun23a.html"&gt;https://proceedings.mlr.press/v216/sun23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Control variates can be a powerful tool to reduce the variance of Monte Carlo estimators, but constructing effective control variates can be challenging when the number of samples is small. In this paper, we show that when a large number of related integrals need to be computed, it is possible to leverage the similarity between these integration tasks to improve performance even when the number of samples per task is very small. Our approach, called meta learning CVs (Meta-CVs), can be used for up to hundreds or thousands of tasks. Our empirical assessment indicates that Meta-CVs can lead to significant variance reduction in such settings, and our theoretical analysis establishes general conditions under which Meta-CVs can be successfully trained.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/447-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/447-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Zhuo Sun</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/meta-learning-control-variates-variance-reduction-with-limited-data.html</guid><category>UAI 2023</category></item><item><title>MixupE Understanding and Improving Mixup from Directional Derivative</title><link>https://pyvideo.org/uai-2023/mixupe-understanding-and-improving-mixup-from-directional-derivative.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;MixupE: Understanding and Improving Mixup from Directional Derivative Perspective&amp;quot;
Yingtian Zou, Vikas Verma, Sarthak Mittal, Wai Hoh Tang, Hieu Pham, Juho Kannala, Yoshua Bengio, Arno Solin, Kenji Kawaguchi
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/zou23a.html"&gt;https://proceedings.mlr.press/v216/zou23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Mixup is a popular data augmentation technique for training deep neural networks where additional samples are generated by linearly interpolating pairs of inputs and their labels. This technique is known to improve the generalization performance in many learning paradigms and applications. In this work, we first analyze Mixup and show that it implicitly regularizes infinitely many directional derivatives of all orders. Based on this new insight, we propose an improved version of Mixup, theoretically justified to deliver better generalization performance than the vanilla Mixup. To demonstrate the effectiveness of the proposed method, we conduct experiments across various domains such as images, tabular data, speech, and graphs. Our results show that the proposed method improves Mixup across multiple datasets using a variety of architectures, for instance, exhibiting an improvement over Mixup by 0.8% in ImageNet top-1 accuracy.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/129-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/129-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yingtian Zou</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/mixupe-understanding-and-improving-mixup-from-directional-derivative.html</guid><category>UAI 2023</category></item><item><title>Neural Probabilistic Logic Programming in Discrete Continuous Domains</title><link>https://pyvideo.org/uai-2023/neural-probabilistic-logic-programming-in-discrete-continuous-domains.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Neural Probabilistic Logic Programming in Discrete-Continuous Domains&amp;quot;   Lennert De Smet, Pedro Zuidberg Dos Martires, Robin Manhaeve, Giuseppe Marra, Angelika Kimmig, Luc De Raedt
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/de-smet23a.html"&gt;https://proceedings.mlr.press/v216/de-smet23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Neural-symbolic AI (NeSy) allows neural networks to exploit symbolic background knowledge in the form of logic. It has been shown to aid learning in the limited data regime and to facilitate inference on out-of-distribution data. Probabilistic NeSy focuses on integrating neural networks with both logic and probability theory, which additionally allows learning under uncertainty. A major limitation of current probabilistic NeSy systems, such as DeepProbLog, is their restriction to finite probability distributions, i.e., discrete random variables. In contrast, deep probabilistic programming (DPP) excels in modelling and optimising continuous probability distributions. Hence, we introduce DeepSeaProbLog, a neural probabilistic logic programming language that incorporates DPP techniques into NeSy. Doing so results in the support of inference and learning of both discrete and continuous probability distributions under logical constraints. Our main contributions are 1) the semantics of DeepSeaProbLog and its corresponding inference algorithm, 2) a proven asymptotically unbiased learning algorithm, and 3) a series of experiments that illustrate the versatility of our approach.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/233-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/233-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lennert De Smet</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/neural-probabilistic-logic-programming-in-discrete-continuous-domains.html</guid><category>UAI 2023</category></item><item><title>On Minimizing the Impact of Dataset Shifts on Actionable Explanations</title><link>https://pyvideo.org/uai-2023/on-minimizing-the-impact-of-dataset-shifts-on-actionable-explanations.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;On Minimizing the Impact of Dataset Shifts on Actionable Explanations &amp;quot;
Anna P. Meyer, Dan Ley, Suraj Srinivas, Himabindu Lakkaraju
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/meyer23a.html"&gt;https://proceedings.mlr.press/v216/meyer23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
The Right to Explanation is an important regulatory principle that allows individuals to request actionable explanations for algorithmic decisions. However, several technical challenges arise when providing such actionable explanations in practice. For instance, models are periodically retrained to handle dataset shifts. This process may invalidate some of the previously prescribed explanations, thus rendering them unactionable. But, it is unclear if and when such invalidations occur, and what factors determine explanation stability i.e., if an explanation remains unchanged amidst model retraining due to dataset shifts. In this paper, we address the aforementioned gaps and provide one of the first theoretical and empirical characterizations of the factors influencing explanation stability. To this end, we conduct rigorous theoretical analysis to demonstrate that model curvature, weight decay parameters while training, and the magnitude of the dataset shift are key factors that determine the extent of explanation (in)stability. Extensive experimentation with real-world datasets not only validates our theoretical results, but also demonstrates that the aforementioned factors dramatically impact the stability of explanations produced by various state-of-the-art methods.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/517-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/517-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Anna P. Meyer</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/on-minimizing-the-impact-of-dataset-shifts-on-actionable-explanations.html</guid><category>UAI 2023</category></item><item><title>On Testability and Goodness of Fit Tests in Missing Data Models</title><link>https://pyvideo.org/uai-2023/on-testability-and-goodness-of-fit-tests-in-missing-data-models.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;On Testability and Goodness of Fit Tests in Missing Data Models&amp;quot;
Razieh Nabi, Rohit Bhattacharya
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/nabi23a.html"&gt;https://proceedings.mlr.press/v216/nabi23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Significant progress has been made in developing identification and estimation techniques for missing data problems where modeling assumptions can be described via a directed acyclic graph. The validity of results using such techniques rely on the assumptions encoded by the graph holding true; however, verification of these assumptions has not received sufficient attention in prior work. In this paper, we provide new insights on the testable implications of three broad classes of missing data graphical models, and design goodness-of-fit tests for them. The classes of models explored are: sequential missing-at-random and missing-not-at-random models which can be used for modeling longitudinal studies with dropout/censoring, and a no self-censoring model which can be applied to cross-sectional studies and surveys.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/597-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/597-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Razieh Nabi</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/on-testability-and-goodness-of-fit-tests-in-missing-data-models.html</guid><category>UAI 2023</category></item><item><title>Online Optimization Meets Federated Learning</title><link>https://pyvideo.org/uai-2023/online-optimization-meets-federated-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Online Optimization Meets Federated Learning&amp;quot;
Aadirupa Saha, Kumar Kshitij Patel&lt;/p&gt;
&lt;blockquote&gt;
In this tutorial, we aim to cover the state-of-the-art theoretical results in (1) online and bandit convex optimization, (2) federated/distributed optimization, and (3) emerging results at their intersection. The first part of the tutorial will focus on the Online Optimization setting (especially for the adversarial model), the notion of regret, different feedback models (first-order, zeroth-order, comparisons, etc.), and analyze the performance guarantees of online gradient descent-based algorithms. The second part of the tutorial will detail the Distributed/Federated Stochastic Optimization model, discussing the data heterogeneity assumptions, local update algorithms, and min-max optimal algorithms. We will also underline the lack of results beyond the stochastic setting, i.e., in the presence of adaptive adversaries. In the final third part of the tutorial, we describe the emerging and very practical direction of Distributed Online Optimization problem. In this part, we will introduce a distributed notion of regret, followed by some recent developments studying the first, zeroth order feedback for this problem. We will conclude with many open questions, especially for distributed online optimization and underline the various applications of this framework captures.&lt;/blockquote&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aadirupa Saha</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/online-optimization-meets-federated-learning.html</guid><category>UAI 2023</category><category>tutorial</category></item><item><title>Parity Calibration</title><link>https://pyvideo.org/uai-2023/parity-calibration.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Parity Calibration&amp;quot;
Youngseog Chung, Aaron Rumack, Chirag Gupta
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/chung23a.html"&gt;https://proceedings.mlr.press/v216/chung23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
In a sequential regression setting, a decision-maker may be primarily concerned with whether the future observation will increase or decrease compared to the current one, rather than the actual value of the future observation. In this context, we introduce the notion of parity calibration, which captures the goal of calibrated forecasting for the increase-decrease (or “parity&amp;quot;) event in a timeseries. Parity probabilities can be extracted from a forecasted distribution for the output, but we show that such a strategy leads to theoretical unpredictability and poor practical performance. We then observe that although the original task was regression, parity calibration can be expressed as binary calibration. Drawing on this connection, we use an online binary calibration method to achieve parity calibration. We demonstrate the effectiveness of our approach on real-world case studies in epidemiology, weather forecasting, and model-based control in nuclear fusion.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/631-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/631-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Youngseog Chung</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/parity-calibration.html</guid><category>UAI 2023</category></item><item><title>Partial Identification of Dose Responses with Hidden Confounders</title><link>https://pyvideo.org/uai-2023/partial-identification-of-dose-responses-with-hidden-confounders.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Partial Identification of Dose Responses with Hidden Confounders&amp;quot;
Myrl G Marmarelis, Greg Ver Steeg, Andrew Jesson, Elizabeth Haddad, Neda Jahanshad, Aram Galstyan
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/marmarelis23a.html"&gt;https://proceedings.mlr.press/v216/marmarelis23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Inferring causal effects of continuous-valued treatments from observational data is a crucial task promising to better inform policy- and decision-makers. A critical assumption needed to identify these effects is that all confounding variables—causal parents of both the treatment and the outcome—are included as covariates. Unfortunately, given observational data alone, we cannot know with certainty that this criterion is satisfied. Sensitivity analyses provide principled ways to give bounds on causal estimates when confounding variables are hidden. While much attention is focused on sensitivity analyses for discrete-valued treatments, much less is paid to continuous-valued treatments. We present novel methodology to bound both average and conditional average continuous-valued treatment-effect estimates when they cannot be point identified due to hidden confounding. A semi-synthetic benchmark on multiple datasets shows our method giving tighter coverage of the true dose-response curve than a recently proposed continuous sensitivity model and baselines. Finally, we apply our method to a real-world observational case study to demonstrate the value of identifying dose-dependent causal effects.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/249-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/249-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Myrl G Marmarelis</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/partial-identification-of-dose-responses-with-hidden-confounders.html</guid><category>UAI 2023</category></item><item><title>Poster Spotlights 1</title><link>https://pyvideo.org/uai-2023/poster-spotlights-1.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Poster Spotlights 1 (session chair: Nicolas Gisolfi, all spotlights virtual)&lt;/p&gt;
&lt;p&gt;91   |   Quasi-Bayesian Nonparametric Density Estimation via Autoregressive Predictive Updates   Sahra Ghalebikesabi, Christopher C. Holmes, Edwin Fong, Brieuc Lehmann
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/ghalebikesabi23a.html"&gt;https://proceedings.mlr.press/v216/ghalebikesabi23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;190   |   Conditional Counterfactual Causal Effect for Individual Attribution
Ruiqi Zhao, lei zhang, Shengyu Zhu, Zitong Lu, Zhenhua Dong, Chaoliang Zhang, Jun Xu, Zhi Geng, Yangbo He,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/zhao23a.html"&gt;https://proceedings.mlr.press/v216/zhao23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;196   |   Random Reshuffling with Variance Reduction: New Analysis and Better Rates
Grigory Malinovsky, Alibek Sailanbayev, Peter Richtárik,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/malinovsky23a.html"&gt;https://proceedings.mlr.press/v216/malinovsky23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;227   |   Multi-View Graph Contrastive Learning for Solving Vehicle Routing Problems
Yuan Jiang, Zhiguang Cao, Yaoxin Wu, Jie Zhang,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/jiang23a.html"&gt;https://proceedings.mlr.press/v216/jiang23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;303   |   MFA: Multi-scale Feature-aware Attack for Object Detection
Wen Chen, Yushan Zhang, Zhiheng Li, Yuehuan Wang,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/chen23d.html"&gt;https://proceedings.mlr.press/v216/chen23d.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;325   |   Incentivising Diffusion while Preserving Differential Privacy
Fengjuan Jia, Mengxiao Zhang, Jiamou Liu, Bakh Khoussainov,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/jia23a.html"&gt;https://proceedings.mlr.press/v216/jia23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;472   |   Residual-Based Error Bound for Physics-Informed Neural Networks
Shuheng Liu, Xiyue Huang, Pavlos Protopapas,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/liu23b.html"&gt;https://proceedings.mlr.press/v216/liu23b.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;617   |   On the Informativeness of Supervision Signals
Ilia Sucholutsky, Ruairidh McLennan Battleday, Katherine M. Collins, Raja Marjieh, Joshua Peterson, Pulkit Singh, Umang Bhatt, Nori Jacoby, Adrian Weller, Thomas L. Griffiths
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/sucholutsky23a.html"&gt;https://proceedings.mlr.press/v216/sucholutsky23a.html&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Nicolas Gisolfi</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/poster-spotlights-1.html</guid><category>UAI 2023</category></item><item><title>Poster Spotlights 2</title><link>https://pyvideo.org/uai-2023/poster-spotlights-2.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Poster Spotlights 2 (session chair: Taposh Banerjee)&lt;/p&gt;
&lt;p&gt;651   |   Adaptivity Complexity for Causal Graph Discovery
Davin Choo, Kirankumar Shiragur,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/choo23a.html"&gt;https://proceedings.mlr.press/v216/choo23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;707   |   Phase-shifted Adversarial Training
Yeachan Kim, Seongyeon Kim, Ihyeok Seo, Bonggun Shin,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/kim23b.html"&gt;https://proceedings.mlr.press/v216/kim23b.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;804   |   Fast Proximal Gradient Descent for Support Regularized Sparse Graph
Dongfang Sun, Yingzhen Yang,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/sun23c.html"&gt;https://proceedings.mlr.press/v216/sun23c.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;56   |   Stochastic Generative Flow Networks
Ling Pan, Dinghuai Zhang, Moksh Jain, Longbo Huang, Yoshua Bengio,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/pan23a.html"&gt;https://proceedings.mlr.press/v216/pan23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;654   |   Dirichlet Proportions Model for Hierarchically Coherent Probabilistic Forecasting
Abhimanyu Das, Weihao Kong, Biswajit Paria, Rajat Sen,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/das23b.html"&gt;https://proceedings.mlr.press/v216/das23b.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;186   |   Inference for Mark-Censored Temporal Point Processes
Alex James Boyd, Yuxin Chang, Stephan Mandt, Padhraic Smyth,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/boyd23a.html"&gt;https://proceedings.mlr.press/v216/boyd23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;643   |   Testing Conventional Wisdom (of the Crowd)
Noah Burrell, Grant Schoenebeck,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/burrell23a.html"&gt;https://proceedings.mlr.press/v216/burrell23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;297   |   Validation of Composite Systems by Discrepancy Propagation
David Reeb, Kanil Patel, Karim Said Barsim, Martin Schiegg, Sebastian Gerwinn,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/reeb23a.html"&gt;https://proceedings.mlr.press/v216/reeb23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;480   |   Investigating a Generalization of Probabilistic Material Implication and Bayesian Conditional
Matthias Scheutz, Michael Jahn.
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/reeb23a.html"&gt;https://proceedings.mlr.press/v216/reeb23a.html&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Taposh Banerjee</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/poster-spotlights-2.html</guid><category>UAI 2023</category></item><item><title>Poster Spotlights 3</title><link>https://pyvideo.org/uai-2023/poster-spotlights-3.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Poster Spotlights 3 (session chair: Jakob Runge)&lt;/p&gt;
&lt;p&gt;79   |   BISCUIT: Causal Representation Learning from Binary Interactions   Phillip Lippe, Sara Magliacane, Sindy Löwe, Yuki M Asano, Taco Cohen, Efstratios Gavves
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/lippe23a.html"&gt;https://proceedings.mlr.press/v216/lippe23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;257   |   Composing Efficient, Robust Tests for Policy Selection   Dustin Morrill, Thomas Walsh, Daniel Hernandez, Peter R. Wurman, Peter Stone
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/morrill23a.html"&gt;https://proceedings.mlr.press/v216/morrill23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;294   |   Nyström $M$-Hilbert-Schmidt Independence Criterion   Florian Kalinke, Zoltán Szabó
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/kalinke23a.html"&gt;https://proceedings.mlr.press/v216/kalinke23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;354   |   JANA: Jointly Amortized Neural Approximation of Complex Bayesian Models   Stefan T. Radev, Marvin Schmitt, Valentin Pratz, Umberto Picchini, Ullrich Koethe, Paul Buerkner
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/radev23a.html"&gt;https://proceedings.mlr.press/v216/radev23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;476   |   Causal Inference With Outcome-Dependent Missingness And Self-Censoring   Jacob Morris Chen, Daniel Malinsky, Rohit Bhattacharya
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/chen23f.html"&gt;https://proceedings.mlr.press/v216/chen23f.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;516   |   CUE: An Uncertainty Interpretation Framework for Text Classifiers Built on Pre-Trained Language Models   Jiazheng Li, ZHAOYUE SUN, Bin Liang, Lin Gui, Yulan He
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/li23d.html"&gt;https://proceedings.mlr.press/v216/li23d.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;556   |   Fast and Scalable Score-Based Kernel Calibration Tests   Pierre Glaser, David Widmann, Fredrik Lindsten, Arthur Gretton
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/glaser23a.html"&gt;https://proceedings.mlr.press/v216/glaser23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;559   |   &amp;quot;Private Prediction Strikes Back!&amp;quot; Private Kernelized Nearest Neighbors with Individual R'{e}nyi Filter   Yuqing Zhu, Xuandong Zhao, Chuan Guo, Yu-Xiang Wang
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/zhu23b.html"&gt;https://proceedings.mlr.press/v216/zhu23b.html&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jakob Runge</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/poster-spotlights-3.html</guid><category>UAI 2023</category></item><item><title>Poster Spotlights 4</title><link>https://pyvideo.org/uai-2023/poster-spotlights-4.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Poster Spotlights 4 (session chair: Christopher Quinn)
41   |   Inference and Sampling of Point Processes from Diffusion Excursions   Ali Hasan, Yu Chen, Yuting Ng, Mohamed Abdelghani, Anderson Schneider, Vahid Tarokh
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/hasan23a.html"&gt;https://proceedings.mlr.press/v216/hasan23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;261   |   Studying the Effect of GNN Spatial Convolutions On The Embedding Space's Geometry   Claire Donnat, So Won Jeong
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/donnat23a.html"&gt;https://proceedings.mlr.press/v216/donnat23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;747   |   A Decoder Suffices for Query-Adaptive Variational Inference   Sakshi Agarwal, Gabriel Hope, Ali Younis, Erik B. Sudderth
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/agarwal23a.html"&gt;https://proceedings.mlr.press/v216/agarwal23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;658   |   Aligned Diffusion Schrödinger Bridges   Vignesh Ram Somnath, Matteo Pariset, Ya-Ping Hsieh, Maria Rodriguez Martinez, Andreas Krause, Charlotte Bunne
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/somnath23a.html"&gt;https://proceedings.mlr.press/v216/somnath23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;611   |   Bayesian Inference Approach for Entropy Regularized Reinforcement Learning with Stochastic Dynamics   Argenis Arriojas, Jacob Adamczyk, Stas Tiomkin, Rahul V Kulkarni
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/arriojas23a.html"&gt;https://proceedings.mlr.press/v216/arriojas23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;797   |   Inference for Probabilistic Dependency Graphs   Oliver Ethan Richardson, Joseph Halpern, Christopher De Sa
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/richardson23a.html"&gt;https://proceedings.mlr.press/v216/richardson23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;764   |   Robust Gaussian Process Regression with the Trimmed Marginal Likelihood   Daniel Andrade, Akiko Takeda
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/andrade23a.html"&gt;https://proceedings.mlr.press/v216/andrade23a.html&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Christopher Quinn</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/poster-spotlights-4.html</guid><category>UAI 2023</category></item><item><title>Probabilistic Circuits That Know What They Don't Know</title><link>https://pyvideo.org/uai-2023/probabilistic-circuits-that-know-what-they-dont-know.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Probabilistic Circuits That Know What They Don't Know&amp;quot;
Fabrizio Ventola, Steven Braun, Zhongjie Yu, Martin Mundt, Kristian Kersting
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/ventola23a.html"&gt;https://proceedings.mlr.press/v216/ventola23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Probabilistic circuits (PCs) are models that allow exact and tractable probabilistic inference. In contrast to neural networks, they are often assumed to be well-calibrated and robust to out-of-distribution (OOD) data. In this paper, we show that PCs are in fact not robust to OOD data, i.e., they don’t know what they don’t know. We then show how this challenge can be overcome by model uncertainty quantification. To this end, we propose tractable dropout inference (TDI), an inference procedure to estimate uncertainty by deriving an analytical solution to Monte Carlo dropout (MCD) through variance propagation. Unlike MCD in neural networks, which comes at the cost of multiple network evaluations, TDI provides tractable sampling-free uncertainty estimates in a single forward pass. TDI improves the robustness of PCs to distribution shift and OOD data, demonstrated through a series of experiments evaluating the classification confidence and uncertainty estimates on real-world data.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/HANDOUT_118.pdf"&gt;https://www.auai.org/uai2023/oral_slides/HANDOUT_118.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Fabrizio Ventola</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/probabilistic-circuits-that-know-what-they-dont-know.html</guid><category>UAI 2023</category></item><item><title>Provably Efficient Adversarial Imitation Learning with Unknown Transitions</title><link>https://pyvideo.org/uai-2023/provably-efficient-adversarial-imitation-learning-with-unknown-transitions.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Provably Efficient Adversarial Imitation Learning with Unknown Transitions&amp;quot;
Tian Xu, Ziniu Li, Yang Yu, Zhi-Quan Luo
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/xu23c.html"&gt;https://proceedings.mlr.press/v216/xu23c.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Imitation learning (IL) has proven to be an effective method for learning good policies from expert demonstrations. Adversarial imitation learning (AIL), a subset of IL methods, is particularly promising, but its theoretical foundation in the presence of unknown transitions has yet to be fully developed. This paper explores the theoretical underpinnings of AIL in this context, where the stochastic and uncertain nature of environment transitions presents a challenge. We examine the expert sample complexity and interaction complexity required to recover good policies. To this end, we establish a framework connecting reward-free exploration and AIL, and propose an algorithm, MB-TAIL, that achieves the minimax optimal expert sample complexity and interaction complexity. MB-TAIL is the first algorithm to achieve this level of expert sample complexity in the unknown transition setting and improves upon the interaction complexity of the best-known algorithm, OAL. Additionally, we demonstrate the generalization ability of MB-TAIL by extending it to the function approximation setting.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/380-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/380-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tian Xu</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/provably-efficient-adversarial-imitation-learning-with-unknown-transitions.html</guid><category>UAI 2023</category></item><item><title>Quantifying Aleatoric and Epistemic Uncertainty in Machine Learning</title><link>https://pyvideo.org/uai-2023/quantifying-aleatoric-and-epistemic-uncertainty-in-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Quantifying Aleatoric and Epistemic Uncertainty in Machine Learning: Are Conditional Entropy and Mutual Information Appropriate Measures?&amp;quot;
Lisa Wimmer, Yusuf Sale, Paul Hofman, Bernd Bischl, Eyke Hüllermeier
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/wimmer23a.html"&gt;https://proceedings.mlr.press/v216/wimmer23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
The quantification of aleatoric and epistemic uncertainty in terms of conditional entropy and mutual information, respectively, has recently become quite common in machine learning. While the properties of these measures, which are rooted in information theory, seem appealing at first glance, we identify various incoherencies that call their appropriateness into question. In addition to the measures themselves, we critically discuss the idea of an additive decomposition of total uncertainty into its aleatoric and epistemic constituents. Experiments across different computer vision tasks support our theoretical findings and raise concerns about current practice in uncertainty quantification.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/374-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/374-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lisa Wimmer</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/quantifying-aleatoric-and-epistemic-uncertainty-in-machine-learning.html</guid><category>UAI 2023</category></item><item><title>Revisiting Bayesian Network Learning with Small Vertex Cover</title><link>https://pyvideo.org/uai-2023/revisiting-bayesian-network-learning-with-small-vertex-cover.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Revisiting Bayesian Network Learning with Small Vertex Cover&amp;quot;
Juha Harviainen, Mikko Koivisto
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/harviainen23a.html"&gt;https://proceedings.mlr.press/v216/harviainen23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
The problem of structure learning in Bayesian networks asks for a directed acyclic graph (DAG) that maximizes a given scoring function. Since the problem is NP-hard, research effort has been put into discovering restricted classes of DAGs for which the search problem can be solved in polynomial time. Here, we initiate investigation of questions that have received less attention thus far: Are the known polynomial algorithms close to the best possible, or is there room for significant improvements? If the interest is in Bayesian learning, that is, in sampling or weighted counting of DAGs, can we obtain similar complexity results? Focusing on DAGs with bounded vertex cover number—a class studied in Korhonen and Parviainen’s seminal work (NIPS 2015)—we answer the questions in the affirmative. We also give, apparently the first, proof that the counting problem is #P-hard in general. In addition, we show that under the vertex-cover constraint counting is #W[1]-hard.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/342-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/342-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Juha Harviainen</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/revisiting-bayesian-network-learning-with-small-vertex-cover.html</guid><category>UAI 2023</category></item><item><title>Structure Learning Using Benchpress</title><link>https://pyvideo.org/uai-2023/structure-learning-using-benchpress.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Structure Learning Using Benchpress&amp;quot;
Felix L. Rios, Giusi Moffa, Jack Kuipers&lt;/p&gt;
&lt;p&gt;Describing the relationship between the variables in a study domain and modeling the data-generating mechanism is a fundamental problem in many empirical sciences. Probabilistic graphical models are one common approach to tackle the problem. Learning the graphical structure for such models (sometimes called causal discovery) is computationally challenging and a fervent area of current research with a plethora of algorithms being developed. To facilitate access to the different methods we present Benchpress, a scalable and platform-independent Snakemake workflow to run, develop, and create reproducible benchmarks of structure learning algorithms for probabilistic graphical models. Benchpress is interfaced via a simple JSON file, which makes it accessible for all users, while the code is designed in a fully modular fashion to enable researchers to contribute additional methodologies. Benchpress provides an interface to a large number of state-of-the-art algorithms from libraries such as BDgraph, BiDAG, bnlearn, gCastle, GOBNILP, pcalg, scikit-learn, and TETRAD as well as a variety of methods for data generating models and performance evaluation. Alongside user-defined models and randomly generated datasets, the workflow also includes a number of standard datasets and graphical models from the literature. In this tutorial, the attendees will be shown how to use Benchpress in practice.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Felix L. Rios</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/structure-learning-using-benchpress.html</guid><category>UAI 2023</category><category>tutorial</category></item><item><title>The Shrinkage-Delinkage Trade-off: An Analysis of Factorized Gaussian Approximations for Variational Inference</title><link>https://pyvideo.org/uai-2023/the-shrinkage-delinkage-trade-off-an-analysis-of-factorized-gaussian-approximations-for-variational-inference.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;The Shrinkage-Delinkage Trade-off: An Analysis of Factorized Gaussian Approximations for Variational Inference&amp;quot;
Charles Margossian, Lawrence K. Saul
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/margossian23a.html"&gt;https://proceedings.mlr.press/v216/margossian23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
When factorized approximations are used for variational inference (VI), they tend to underestimate the uncertainty—as measured in various ways—of the distributions they are meant to approximate. We consider two popular ways to measure the uncertainty deficit of VI: (i) the degree to which it underestimates the componentwise variance, and (ii) the degree to which it underestimates the entropy. To better understand these effects, and the relationship between them, we examine an informative setting where they can be explicitly (and elegantly) analyzed: the approximation of a Gaussian, p, with a dense covariance matrix, by a Gaussian, q, with a diagonal covariance matrix. We prove that q always underestimates both the componentwise variance and the entropy of p, though not necessarily to the same degree. Moreover we demonstrate that the entropy of q is determined by the trade-off of two competing forces: it is decreased by the shrinkage of its componentwise variances (our first measure of uncertainty) but it is increased by the factorized approximation which delinks the nodes in the graphical model of p. We study various manifestations of this trade-off, notably one where, as the dimension of the problem grows, the per-component entropy gap between p and q becomes vanishingly small even though q underestimates every componentwise variance by a constant multiplicative factor. We also use the shrinkage-delinkage trade-off to bound the entropy gap in terms of the problem dimension and the condition number of the correlation matrix of p. Finally we present empirical results on both Gaussian and non-Gaussian targets, the former to validate our analysis and the latter to explore its limitations.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Charles Margossian</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/the-shrinkage-delinkage-trade-off-an-analysis-of-factorized-gaussian-approximations-for-variational-inference.html</guid><category>UAI 2023</category></item><item><title>Towards Causal Foundations of Safe AI</title><link>https://pyvideo.org/uai-2023/towards-causal-foundations-of-safe-ai.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Towards Causal Foundations of Safe AI&amp;quot;
James Fox, Tom Everitt&lt;/p&gt;
&lt;p&gt;With great power comes great responsibility. Artificial intelligence (AI) is rapidly gaining new capabilities, and is increasingly trusted to make decisions impacting humans in significant ways (from self-driving cars to stock-trading to hiring decisions). To ensure that AI behaves in ethical and robustly beneficial ways, we must identify potential pitfalls and develop effective mitigation strategies. In this tutorial, we will explain how (Pearlian) causality offers a useful formal framework for reasoning about AI risk and describe recent work on this topic. In particular, we’ll cover: causal models of agents and how to discover them; causal definitions of fairness, intent, harm, and incentives; and risks from AI such as misgeneralization and preference manipulation, as well as how mitigation techniques including impact measures, interpretability, and path-specific objectives can help address them.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">James Fox</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/towards-causal-foundations-of-safe-ai.html</guid><category>UAI 2023</category><category>tutorial</category></item><item><title>Towards Physically Reliable Molecular Representation Learning</title><link>https://pyvideo.org/uai-2023/towards-physically-reliable-molecular-representation-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Towards Physically Reliable Molecular Representation Learning&amp;quot;
Seunghoon Yi, Youngwoo Cho, Jinhwan Sul, Seung Woo Ko, Soo Kyung Kim, Jaegul Choo, Hongkee Yoon, Joonseok Lee
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/yi23a.html"&gt;https://proceedings.mlr.press/v216/yi23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Estimating the energetic properties of molecular systems is a critical task in material design. Machine learning has shown remarkable promise on this task over classical force fields, but a fully data-driven approach suffers from limited labeled data; not just the amount of available data lacks, but the distribution of labeled examples is highly skewed to stable states. In this work, we propose a molecular representation learning method that extrapolates well beyond the training distribution, powered by physics-driven parameter estimation from classical energy equations and self-supervised learning inspired from masked language modeling. To ensure reliability of the proposed model, we introduce a series of novel evaluation schemes in multifaceted ways, beyond the energy or force accuracy that has been dominantly used. From extensive experiments, we demonstrate that the proposed method is effective in discovering molecular structures, outperforming other baselines. Furthermore, we extrapolate it to the chemical reaction pathways beyond stable states, taking a step towards physically reliable molecular representation learning.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/95-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/95-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Seunghoon Yi</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/towards-physically-reliable-molecular-representation-learning.html</guid><category>UAI 2023</category></item><item><title>UAI 2023 Oral Session 6: On Inference and Learning With Probabilistic Generating Circuits</title><link>https://pyvideo.org/uai-2023/uai-2023-oral-session-6-on-inference-and-learning-with-probabilistic-generating-circuits.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;On Inference and Learning With Probabilistic Generating Circuits&amp;quot;
Juha Harviainen, Vaidyanathan Peruvemba Ramaswamy, Mikko Koivisto
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/harviainen23b.html"&gt;https://proceedings.mlr.press/v216/harviainen23b.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Probabilistic generating circuits (PGCs) are economical representations of multivariate probability generating polynomials (PGPs). They unify and extend decomposable probabilistic circuits and determinantal point processes, admitting tractable computation of marginal probabilities. However, the need for addition and multiplication of high-degree polynomials incurs a significant additional factor in the complexity of inference. Here, we give a new inference algorithm that eliminates this extra factor. Specifically, we show that it suffices to keep track of the highest degree coefficients of the computed polynomials, rendering the algorithm linear in the circuit size. In addition, we show that determinant-based circuits need not be expanded to division-free circuits, but can be handled by division-based fast algorithms. While these advances enhance the appeal of PGCs, we also discover an obstacle to learning them from data: it is NP-hard to recognize whether a given PGC encodes a PGP. We discuss the implications of our ambivalent findings and sketch a method, in which learning is restricted to PGCs that are composed of moderate-size subcircuits.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/353-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/353-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Juha Harviainen</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/uai-2023-oral-session-6-on-inference-and-learning-with-probabilistic-generating-circuits.html</guid><category>UAI 2023</category></item><item><title>UAI 2023 Oral Session 6: Probabilistic Flow Circuits: Towards Deep Models for Tractable Inference</title><link>https://pyvideo.org/uai-2023/uai-2023-oral-session-6-probabilistic-flow-circuits-towards-deep-models-for-tractable-inference.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Probabilistic Flow Circuits: Towards Unified Deep Models for Tractable Probabilistic Inference&amp;quot;
Sahil Sidheekh, Kristian Kersting, Sriraam Natarajan
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/sidheekh23a.html"&gt;https://proceedings.mlr.press/v216/sidheekh23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
We consider the problem of increasing the expressivity of probabilistic circuits by augmenting them with the successful generative models of normalizing flows. To this effect, we theoretically establish the requirement of decomposability for such combinations to retain tractability of the learned models. Our model, called Probabilistic Flow Circuits, essentially extends circuits by allowing for normalizing flows at the leaves. Our empirical evaluation clearly establishes the expressivity and tractability of this new class of probabilistic circuits.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/526-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/526-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sahil Sidheekh</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/uai-2023-oral-session-6-probabilistic-flow-circuits-towards-deep-models-for-tractable-inference.html</guid><category>UAI 2023</category></item></channel></rss>