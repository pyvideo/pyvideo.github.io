<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_jack-pan.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-09-20T00:00:00+00:00</updated><entry><title>Useful Tools to Explain ML Models</title><link href="https://pyvideo.org/pycon-taiwan-2019/useful-tools-to-explain-ml-models.html" rel="alternate"></link><published>2019-09-20T00:00:00+00:00</published><updated>2019-09-20T00:00:00+00:00</updated><author><name>Jack Pan</name></author><id>tag:pyvideo.org,2019-09-20:pycon-taiwan-2019/useful-tools-to-explain-ml-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Day 1, R1 13:55–14:40&lt;/p&gt;
&lt;p&gt;現今建立各種機器學習模型的套件很多，但是最常被詬病的是如何去解釋建立出來的機器學習模型。&lt;/p&gt;
&lt;p&gt;尤其是若需要將模型應用到與人高度相關的行業中，如：金融業決定是否要發信用卡、醫療業協助診斷疾病等，若無法解釋模型，常會導致使用者或老闆不敢用、不相信模型之問題。&lt;/p&gt;
&lt;p&gt;實際上現在已經有很多工具套件來協助解釋機器學習模型。
介紹三種常用的模型，以及如何運用套件來解釋這些模型。
包含線性迴歸可以用 p-value 和係數，Tree-based 模型可以用 feature importance 和 SHAP ，最後是類神經網路的模型一樣也可以用 SHAP 來對其做解釋。&lt;/p&gt;
&lt;p&gt;主要會以結構化資料介紹 SHAP 套件的原理以及它的應用方式。&lt;/p&gt;
&lt;p&gt;Slides not uploaded by the speaker.&lt;/p&gt;
&lt;p&gt;Speaker: Jack Pan&lt;/p&gt;
&lt;p&gt;喜歡用Python開發的工程師。有三年以上的機器學習經驗，特別是將其運用到金融相關的問題上。&lt;/p&gt;
</summary></entry></feed>