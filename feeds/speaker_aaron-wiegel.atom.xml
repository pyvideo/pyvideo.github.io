<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Aaron Wiegel</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_aaron-wiegel.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2025-10-18T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Using pandas and pyspark to address challenges in processing and storing time series instrument data</title><link href="https://pyvideo.org/pybay-2023/Using_pandas_and_pyspark_to_address_challenges_in_processing_and_storing_time_series_instrument_data.html" rel="alternate"></link><published>2023-10-08T15:45:00+00:00</published><updated>2023-10-08T15:45:00+00:00</updated><author><name>Aaron Wiegel</name></author><id>tag:pyvideo.org,2023-10-08:/pybay-2023/Using_pandas_and_pyspark_to_address_challenges_in_processing_and_storing_time_series_instrument_data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Time series data from scientific instruments for fermentation, environmental sensors, or spectroscopy often comes in proprietary or unusual formats that are require custom logic to process. In addition, processing data at scale is challenge since enterprise laboratory information management systems (LIMS) typically rely on transactional, row-oriented databases that are …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Time series data from scientific instruments for fermentation, environmental sensors, or spectroscopy often comes in proprietary or unusual formats that are require custom logic to process. In addition, processing data at scale is challenge since enterprise laboratory information management systems (LIMS) typically rely on transactional, row-oriented databases that are not designed to handle millions of records at a time. However, with clever use of pandas for unusually formatted files or pyspark (via Databricks) for large numbers of records, this data can be processed into cleaner, more useful forms for further analysis.&lt;/p&gt;
</content><category term="PyBay 2023"></category></entry><entry><title>The Zen of the Bronze Layer: Ingestion of Data with Unstable Schema</title><link href="https://pyvideo.org/pybay-2025/the-zen-of-the-bronze-layer-ingestion-of-data-with-unstable-schema.html" rel="alternate"></link><published>2025-10-18T00:00:00+00:00</published><updated>2025-10-18T00:00:00+00:00</updated><author><name>Aaron Wiegel</name></author><id>tag:pyvideo.org,2025-10-18:/pybay-2025/the-zen-of-the-bronze-layer-ingestion-of-data-with-unstable-schema.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the medallion data architecture, the bronze layer is for staging incoming raw data before further transformation and cleaning. Ideally, tabular CSV data undergoes minimal transformations and is queryable upon ingestion; however, third party data sources can contain unstable schema that make this challenging even using pandas. With native …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the medallion data architecture, the bronze layer is for staging incoming raw data before further transformation and cleaning. Ideally, tabular CSV data undergoes minimal transformations and is queryable upon ingestion; however, third party data sources can contain unstable schema that make this challenging even using pandas. With native Python data structures and a more flexible data schema, such this messy data can more reliably be ingested for cleaning and monitoring.&lt;/p&gt;
&lt;p&gt;For more information, see &lt;a class="reference external" href="https://pybay.org/"&gt;https://pybay.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Follow us on LinkedIn &lt;a class="reference external" href="https://www.linkedin.com/company/pybay"&gt;https://www.linkedin.com/company/pybay&lt;/a&gt;&lt;/p&gt;
</content><category term="PyBay 2025"></category></entry></feed>