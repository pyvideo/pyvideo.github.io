<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - pytorch</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_pytorch.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2023-04-17T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Keynote: PyTorch: a framework for fast, dynamic deep learning and scientific computi</title><link href="https://pyvideo.org/euroscipy-2017/keynote-pytorch-a-framework-for-fast-dynamic-deep-learning-and-scientific-computi.html" rel="alternate"></link><published>2017-08-31T00:00:00+00:00</published><updated>2017-08-31T00:00:00+00:00</updated><author><name>Soumith Chintala</name></author><id>tag:pyvideo.org,2017-08-31:/euroscipy-2017/keynote-pytorch-a-framework-for-fast-dynamic-deep-learning-and-scientific-computi.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this session, you shall be introduced to a new framework for
scientific computing, mainly
aimed at deep learning workloads. The framework consists of an ndarray
library that natively
supports GPU execution, an automatic differentiation engine that is
flexible and fast, and
an optimization package for gradient based optimization …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this session, you shall be introduced to a new framework for
scientific computing, mainly
aimed at deep learning workloads. The framework consists of an ndarray
library that natively
supports GPU execution, an automatic differentiation engine that is
flexible and fast, and
an optimization package for gradient based optimization methods. We
shall discuss practical
workflows, our features on top of python multiprocessing for efficient
parallel data loaders
and finally we shall briefly look at our upcoming just-in-time Tensor
compiler to fuse
computations and execute them more efficiently.&lt;/p&gt;
&lt;div class="section" id="biographical-sketch"&gt;
&lt;h4&gt;Biographical sketch&lt;/h4&gt;
&lt;p&gt;Soumith Chintala is a Researcher at Facebook AI Research, where he
works on deep learning,
reinforcement learning, generative image models, agents for video
games and large-scale
high-performance deep learning. Prior to joining Facebook in August
2014, he worked at
MuseAmi, where he built deep learning models for music and vision
targeted at mobile
devices. He holds a Masters in CS from NYU, and spent time in Yann
LeCun's NYU lab building
deep learning models for pedestrian detection, natural image OCR,
depth-images among others.&lt;/p&gt;
&lt;p&gt;(Reproduced from &lt;a class="reference external" href="https://research.fb.com/people/chintala-soumith/"&gt;https://research.fb.com/people/chintala-soumith/&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
</content><category term="EuroSciPy 2017"></category><category term="keynote"></category><category term="pytorch"></category></entry><entry><title>Really Deep Neural Networks with PyTorch</title><link href="https://pyvideo.org/pycon-de-2017/really-deep-neural-networks-with-pytorch.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>David Dao</name></author><id>tag:pyvideo.org,2017-10-25:/pycon-de-2017/really-deep-neural-networks-with-pytorch.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;David Dao&lt;/strong&gt; (&amp;#64;dwddao)&lt;/p&gt;
&lt;p&gt;David is a PhD student at ETH Zurich, working on Deep Reinforcement Learning. Before joining ETH Zurich, he was an autonomous driving researcher at Mercedes-Benz Research in Silicon Valley and a graduate student at the Broad Institute of MIT and Harvard.&lt;/p&gt;
&lt;p&gt;David is a firm believer …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;David Dao&lt;/strong&gt; (&amp;#64;dwddao)&lt;/p&gt;
&lt;p&gt;David is a PhD student at ETH Zurich, working on Deep Reinforcement Learning. Before joining ETH Zurich, he was an autonomous driving researcher at Mercedes-Benz Research in Silicon Valley and a graduate student at the Broad Institute of MIT and Harvard.&lt;/p&gt;
&lt;p&gt;David is a firm believer in open source and is organising Germany's largest deep learning meetup series, and Silicon Valley's self-driving AI series. He is a contributor to popular machine intelligence frameworks such as TensorFlow and PyTorch and speaks chinese with swabian accent.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Modern neural networks have hundreds of layers! How can we train such deep networks? Simply stacking layers on top doesn't work! This talk introduces the deep learning library PyTorch by explaining the exciting math, cool ideas and simple code behind what makes really deep neural networks work.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Modern neural networks consist of hundreds of computation layers! These very deep architectures consistently outperform shallower networks in a variety of tasks. However just simply stacking layers on top of each other won't work because the gradients are either vanishing or exploding during optimisation procedure. This talk explains the exciting math, cool ideas and elegant code that modern neural network architectures such as ResNets, HighwayNets and DenseNets are applying to circumvent the problem using PyTorch. PyTorch is a relatively new deep learning framework that is deeply integrated into Python. Unlike other frameworks such as TensorFlow and Theano, it uses tape-based automatic differentiation to run computation immediately, supports dynamic neural networks and provides a powerful GPU-accelerated Tensor library. The talk concludes with some real-world use-cases for very deep neural networks in chemical-genetic profiling and autonomous driving.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</content><category term="PyCon DE 2017"></category><category term="deep learning"></category><category term="ai"></category><category term="machine learning"></category><category term="python"></category><category term="autonomous-driving"></category><category term="pytorch"></category></entry><entry><title>Population Anomaly Detection with PyTorch</title><link href="https://pyvideo.org/pycon-israel-2017/population-anomaly-detection-with-pytorch.html" rel="alternate"></link><published>2017-06-12T00:00:00+00:00</published><updated>2017-06-12T00:00:00+00:00</updated><author><name>David Tolpin</name></author><id>tag:pyvideo.org,2017-06-12:/pycon-israel-2017/population-anomaly-detection-with-pytorch.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We introduce a scheme for population anomaly detection based on gaussianization through an adversarial autoencoder. This scheme is applicable to detection of 'soft' anomalies in arbitrarily distributed highly-dimensional data. A soft, or population, anomaly is characterized by a shift in the distribution of the data set, where certain elements …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We introduce a scheme for population anomaly detection based on gaussianization through an adversarial autoencoder. This scheme is applicable to detection of 'soft' anomalies in arbitrarily distributed highly-dimensional data. A soft, or population, anomaly is characterized by a shift in the distribution of the data set, where certain elements appear with higher or lower probability than anticipated. Such anomalies must be detected by considering a large sample set rather than a single sample. Applications include, but not limited to, payment fraud trends, data exfiltration, and system security and health monitoring. We evaluate the scheme on credit card payment and DNS data exfiltration data and obtain both quantitative results and qualitative insights. We discuss our PyTorch implementation of deep gaussianization, and review implementation details, pitfalls, and performance.&lt;/p&gt;
</content><category term="PyCon Israel 2017"></category><category term="pytorch"></category></entry><entry><title>PyTorch: a modern scientific computing library for Python</title><link href="https://pyvideo.org/pycon-italia-2018/pytorch-a-modern-scientific-computing-library-for-python.html" rel="alternate"></link><published>2018-04-22T00:00:00+00:00</published><updated>2018-04-22T00:00:00+00:00</updated><author><name>Adam Paszke</name></author><id>tag:pyvideo.org,2018-04-22:/pycon-italia-2018/pytorch-a-modern-scientific-computing-library-for-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python is very well known for its ecosystem of mature scientific
computing packages. They range from low-level providers of generic
functionality like NumPy to very domain specific tools like
scikit-learn. A few years back, machine learning frameworks could be
easily classified into the second category, but this is changing …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python is very well known for its ecosystem of mature scientific
computing packages. They range from low-level providers of generic
functionality like NumPy to very domain specific tools like
scikit-learn. A few years back, machine learning frameworks could be
easily classified into the second category, but this is changing now.
They become increasingly powerful and start to be applied in a whole
variety of settings different than their original purpose. In this talk,
I’ll present a basic tour of PyTorch, a relatively new library that has
already gathered a significant user base. I’ll describe features useful
both in machine learning and other domains, explain how it fits into the
Python landscape, and showcase scenarios where it provides benefits over
existing tools.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;domenica 22 aprile&lt;/strong&gt; at 09:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</content><category term="PyCon Italia 2018"></category><category term="deep learning"></category><category term="Pytorch"></category><category term="pydata"></category></entry><entry><title>Deep Learning with PyTorch for Fun and Profit (Part III / Italian Edition: Divina Commedia)</title><link href="https://pyvideo.org/pycon-italia-2019/deep-learning-with-pytorch-for-fun-and-profit-part-iii-italian-edition-divina-commedia.html" rel="alternate"></link><published>2019-05-03T00:00:00+00:00</published><updated>2019-05-03T00:00:00+00:00</updated><author><name>Alexander Hendorf</name></author><id>tag:pyvideo.org,2019-05-03:/pycon-italia-2019/deep-learning-with-pytorch-for-fun-and-profit-part-iii-italian-edition-divina-commedia.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There are all these great articles and blog posts about Deep Learning
describing all that awesome stuff. - Is it all that easy? Let’s check!&lt;/p&gt;
&lt;p&gt;We’ll look into: style transfer (making a picture look like painting),
speech generation (like Siri or Alexa) and text generation (writing a
story …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There are all these great articles and blog posts about Deep Learning
describing all that awesome stuff. - Is it all that easy? Let’s check!&lt;/p&gt;
&lt;p&gt;We’ll look into: style transfer (making a picture look like painting),
speech generation (like Siri or Alexa) and text generation (writing a
story). In this talk I’ll describe the whole journey: A fun ride from
the idea to the very end including all the struggles, failures and
successes.&lt;/p&gt;
&lt;p&gt;This is an ongoing talk on how far we can get creating a full &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Radio_drama"&gt;radio
drama (Hörspiel)&lt;/a&gt; with
deep learning and the resources required.&lt;/p&gt;
&lt;p&gt;Steps, we’ll cover:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The data challenge: get the data ready&lt;/li&gt;
&lt;li&gt;Creating a character-level language models with an Recurrent Neural
Network&lt;/li&gt;
&lt;li&gt;Creating a text generator&lt;/li&gt;
&lt;li&gt;Creating artwork&lt;/li&gt;
&lt;li&gt;Synthesising speech&lt;/li&gt;
&lt;li&gt;Making it sound like a real person&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this special PyCon X edition we will also try to recreate text in the
style of Dante’ Divina Commedia.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1687"&gt;https://python.it/feedback-1687&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 12:00 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</content><category term="PyCon Italia 2019"></category><category term="deep learning"></category><category term="Pytorch"></category><category term="art"></category><category term="Artificial Intelligence"></category><category term="nlp"></category></entry><entry><title>Exploring Deep Learning Framework PyTorch</title><link href="https://pyvideo.org/pycon-us-2018/exploring-deep-learning-framework-pytorch.html" rel="alternate"></link><published>2018-05-11T00:00:00+00:00</published><updated>2018-05-11T00:00:00+00:00</updated><author><name>Stephanie Kim</name></author><id>tag:pyvideo.org,2018-05-11:/pycon-us-2018/exploring-deep-learning-framework-pytorch.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Anyone who is interested in deep learning has gotten their hands dirty playing around with Tensorflow, Google's open source deep learning framework. Tensorflow has its benefits like wide scale adoption, deployment on mobile, and support for distributed computing, but it also has a somewhat challenging learning curve, is difficult …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Anyone who is interested in deep learning has gotten their hands dirty playing around with Tensorflow, Google's open source deep learning framework. Tensorflow has its benefits like wide scale adoption, deployment on mobile, and support for distributed computing, but it also has a somewhat challenging learning curve, is difficult to debug, and hard to deploy in production. PyTorch is a new deep learning framework that solves a lot of those problems.&lt;/p&gt;
&lt;p&gt;PyTorch is only in beta, but users are rapidly adopting this modular deep learning framework. PyTorch supports tensor computation and dynamic computation graphs that allow you to change how the network behaves on the fly unlike static graphs that are used in frameworks such as Tensorflow. PyTorch offers modularity which enhances the ability to debug or see within the network and for many, is more intuitive to learn than Tensorflow.&lt;/p&gt;
&lt;p&gt;This talk will objectively look at PyTorch and why it might be the best fit for your deep learning use case and we'll look at use cases that will showcase why you might want consider using Tensorflow instead.&lt;/p&gt;
</content><category term="PyCon US 2018"></category><category term="pytorch"></category></entry><entry><title>Improving Machine Learning from Human Feedback</title><link href="https://pyvideo.org/pydata-berlin-2023/improving-machine-learning-from-human-feedback.html" rel="alternate"></link><published>2023-04-17T00:00:00+00:00</published><updated>2023-04-17T00:00:00+00:00</updated><author><name>Erin Mikail Staples</name></author><id>tag:pyvideo.org,2023-04-17:/pydata-berlin-2023/improving-machine-learning-from-human-feedback.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Large generative models rely upon massive data sets that are collected automatically. For example, GPT-3 was trained with data from &amp;quot;Common Crawl&amp;quot; and &amp;quot;Web Text&amp;quot;, among other sources. As the saying goes — bigger isn't always better. While powerful, these data sets (and the models that they create) often come …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Large generative models rely upon massive data sets that are collected automatically. For example, GPT-3 was trained with data from &amp;quot;Common Crawl&amp;quot; and &amp;quot;Web Text&amp;quot;, among other sources. As the saying goes — bigger isn't always better. While powerful, these data sets (and the models that they create) often come at a cost, bringing their &amp;quot;internet-scale biases&amp;quot; along with their &amp;quot;internet-trained models.&amp;quot; While powerful, these models beg the question — is unsupervised learning the best future for machine learning?&lt;/p&gt;
&lt;p&gt;ML researchers have developed new model-tuning techniques to address the known biases within existing models and improve their performance (as measured by response preference, truthfulness, toxicity, and result generalization). All of this at a fraction of the initial training cost. In this talk, we will explore these techniques, known as Reinforcement Learning from Human Feedback (RLHF), and how open-source machine learning tools like PyTorch and Label Studio can be used to tune off-the-shelf models using direct human feedback.&lt;/p&gt;
</content><category term="PyData Berlin 2023"></category><category term="reinforcement learning"></category><category term="human feedback"></category><category term="pytorch"></category><category term="label studio"></category></entry><entry><title>Apex</title><link href="https://pyvideo.org/pytorch-conference-2019/apex.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Michael Carilli</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/apex.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Apex is an open-source PyTorch extension that helps users maximize deep learning training performance on NVIDIA GPUs. Mixed precision utilities in Apex are designed to improve training speed while maintaining the accuracy and stability of training in single precision. Learn more in this talk.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="APEX"></category><category term="Artificial Intelligence"></category><category term="Deep Learning"></category><category term="Distributed Training"></category><category term="Facebook"></category><category term="ML"></category><category term="Machine Learning"></category><category term="Mixed Precision"></category><category term="NVIDIA"></category><category term="NVIDIA GPU"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category></entry><entry><title>Collaborative Natural Language Inference</title><link href="https://pyvideo.org/pytorch-conference-2019/collaborative-natural-language-inference.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Sasha Rush</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/collaborative-natural-language-inference.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Get an overview from Professor Sasha Rush of Cornell on the latest research in collaborative natural language inference.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="AI Research"></category><category term="Artificial Intelligence"></category><category term="Cornell"></category><category term="Facebook"></category><category term="ML"></category><category term="Machine Learning"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="natural language inference"></category></entry><entry><title>CrypTen</title><link href="https://pyvideo.org/pytorch-conference-2019/crypten.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Laurens van der Maaten</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/crypten.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Practical applications of ML via cloud-based or machine-learning-as-a-service (MLaaS) platforms pose a range of security and privacy challenges. In particular, users of these platforms may not want or be able to share unencrypted data, which prevents them from taking full advantage of ML tools. CrypTen is a new community-based …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Practical applications of ML via cloud-based or machine-learning-as-a-service (MLaaS) platforms pose a range of security and privacy challenges. In particular, users of these platforms may not want or be able to share unencrypted data, which prevents them from taking full advantage of ML tools. CrypTen is a new community-based research platform for taking the field of privacy-preserving ML forward.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="CrypTen"></category><category term="Facebook"></category><category term="ML"></category><category term="MLaaS"></category><category term="Machine Learning"></category><category term="Privacy"></category><category term="Private AI"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category></entry><entry><title>Dataloader Design for PyTorch</title><link href="https://pyvideo.org/pytorch-conference-2019/dataloader-design-for-pytorch.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Tongzhou Wang</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/dataloader-design-for-pytorch.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Learn about the PyTorch data loading pipeline and components - the dataset, the sampler, and the dataloader.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="AI research"></category><category term="Artificial Intelligence"></category><category term="Dataloader Design"></category><category term="Facebook"></category><category term="MIT"></category><category term="ML"></category><category term="Machine Learning"></category><category term="Massachusetts Institute of Technology"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="PyTorch Datasets"></category><category term="data loading pipelines"></category><category term="data sets"></category></entry><entry><title>Detectron2 - Next Gen Object Detection Library</title><link href="https://pyvideo.org/pytorch-conference-2019/detectron2-next-gen-object-detection-library.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Yuxin Wu</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/detectron2-next-gen-object-detection-library.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Object detection and segmentation are used for tasks ranging from autonomous vehicles to content understanding for platform integrity. Learn about Detectron2, an object detection library now implemented in PyTorch. Detectron2 provides support for the latest models and tasks, increased flexibility to aid computer vision research, and improvements in maintainability …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Object detection and segmentation are used for tasks ranging from autonomous vehicles to content understanding for platform integrity. Learn about Detectron2, an object detection library now implemented in PyTorch. Detectron2 provides support for the latest models and tasks, increased flexibility to aid computer vision research, and improvements in maintainability and scalability to support production use cases.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="Detection library"></category><category term="Detectron2"></category><category term="Facebook"></category><category term="ML"></category><category term="Machine Learning"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="Segmentation"></category><category term="computer vision"></category><category term="computer vision research"></category><category term="cv"></category><category term="detectron"></category><category term="object detection"></category></entry><entry><title>Keynote</title><link href="https://pyvideo.org/pytorch-conference-2019/keynote.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Mike Schroepfer</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/keynote.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyTorch has become a popular open source machine learning framework for cutting edge research, and is increasingly being used in production. Watch Mike Schroepfer, Chief Technology Officer at Facebook, open the keynote at the second annual PyTorch Developer Conference.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="Facebook"></category><category term="Framework"></category><category term="Keynote"></category><category term="ML"></category><category term="Machine Learning"></category><category term="Open Source"></category><category term="PyTorch"></category></entry><entry><title>Linear Algebra in PyTorch</title><link href="https://pyvideo.org/pytorch-conference-2019/linear-algebra-in-pytorch.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Vishwak Srinivasan</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/linear-algebra-in-pytorch.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyTorch 1.2 and 1.3 have added several enhancements for linear algebra in PyTorch, including native batching support, support for gradients, and new semantic naming schemes. Learn more in this session.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="Facebook"></category><category term="Linear Algebra in PyTorch"></category><category term="ML"></category><category term="Machine Learning"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="Semantic naming schemes"></category><category term="Support for Gradients"></category><category term="native batching support"></category></entry><entry><title>Panel Discussion</title><link href="https://pyvideo.org/pytorch-conference-2019/panel-discussion.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Soumith Chintala</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/panel-discussion.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Hear from users and creators in the PyTorch community as they discuss their needs and thoughts around ML tooling, open source ecosystems, and more. This panel is moderated by Soumith Chintala, and includes Lisha Li from Rosebud, Michela Paganini from Facebook, Clément Delangue from HuggingFace, Rachel Thomas from fast …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Hear from users and creators in the PyTorch community as they discuss their needs and thoughts around ML tooling, open source ecosystems, and more. This panel is moderated by Soumith Chintala, and includes Lisha Li from Rosebud, Michela Paganini from Facebook, Clément Delangue from HuggingFace, Rachel Thomas from fast.ai, Maria Popova from UNC.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="Facebook"></category><category term="HuggingFace"></category><category term="ML"></category><category term="ML tooling"></category><category term="Machine Learning"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="PyTorch community"></category><category term="Rosebud"></category><category term="fast.ai"></category><category term="open source"></category><category term="open source ecosystems"></category></entry><entry><title>Privacy Preserving AI</title><link href="https://pyvideo.org/pytorch-conference-2019/privacy-preserving-ai.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Andrew Trask</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/privacy-preserving-ai.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Learn the basics of secure and private AI techniques, including federated learning and secure multi-party computation. In this talk, Andrew Trask of OpenMined highlights the importance of privacy preserving machine learning, and how to use privacy-focused tools like PySyft.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="Facebook"></category><category term="ML"></category><category term="Machine Learning"></category><category term="OpenMined"></category><category term="Privacy"></category><category term="Private AI"></category><category term="PySyft"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="private AI techniques"></category></entry><entry><title>PyTorch at Dolby Labs</title><link href="https://pyvideo.org/pytorch-conference-2019/pytorch-at-dolby-labs.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Vivek Kumar</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-at-dolby-labs.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Hear how Dolby Labs is using PyTorch to develop deep learning for audio, and learn about the challenges that audio AI presents and the breakthroughs and applications they’ve built at Dolby to push the field forward.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="Deep learning audio"></category><category term="Dolby Labs"></category><category term="Facebook"></category><category term="ML"></category><category term="Machine Learning"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="audio ai"></category></entry><entry><title>PyTorch at Microsoft</title><link href="https://pyvideo.org/pytorch-conference-2019/pytorch-at-microsoft.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Saurabh Tiwary</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-at-microsoft.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyTorch is becoming the deep learning tool of choice inside Microsoft. Learn how it’s being used to improve existing features and enable new capabilities in products such as Bing, Outlook, Powerpoint Designer, and more.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="Deep Learning tools"></category><category term="Facebook"></category><category term="ML"></category><category term="Machine Learning"></category><category term="Microsoft"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category></entry><entry><title>PyTorch at Tesla</title><link href="https://pyvideo.org/pytorch-conference-2019/pytorch-at-tesla.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Andrej Karpathy</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-at-tesla.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Hear from Andrej Karpathy on how Tesla is using PyTorch to develop full self-driving capabilities for its vehicles, including AutoPilot and Smart Summon.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="Autonomous driving cars"></category><category term="Autopilot"></category><category term="Facebook"></category><category term="ML"></category><category term="Machine Learning"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="PyTorch at Tesla"></category><category term="Self-driving cars"></category><category term="Tesla"></category><category term="smart Summon"></category></entry><entry><title>PyTorch at Uber</title><link href="https://pyvideo.org/pytorch-conference-2019/pytorch-at-uber.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Sidney Zhang</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-at-uber.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, Sidney Zhang from Uber talks about how Uber ATG uses PyTorch, and specific features including TorchScript, to develop and deploy cutting-edge deep learning models to power self-driving cars.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="Autonomous driving cars"></category><category term="Deep Learning Models"></category><category term="Facebook"></category><category term="ML"></category><category term="Machine Learning"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="Self-driving cars"></category><category term="TorchScript"></category><category term="Uber"></category><category term="Uber AGT"></category></entry><entry><title>PyTorch Front-End Features: Named Tensors and Type Promotion</title><link href="https://pyvideo.org/pytorch-conference-2019/pytorch-front-end-features-named-tensors-and-type-promotion.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Gregory Chanan</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-front-end-features-named-tensors-and-type-promotion.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Cornell University’s Sasha Rush has argued that, despite its ubiquity in deep learning, the traditional implementation of tensors has significant shortcomings, such as exposing private dimensions, broadcasting based on absolute position, and keeping type information in documentation. He proposed named tensors as an alternative approach. PyTorch now supports …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Cornell University’s Sasha Rush has argued that, despite its ubiquity in deep learning, the traditional implementation of tensors has significant shortcomings, such as exposing private dimensions, broadcasting based on absolute position, and keeping type information in documentation. He proposed named tensors as an alternative approach. PyTorch now supports the ability to name tensors, allowing for clearer code with less need for inline comments.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="Cornell University"></category><category term="Deep Learning"></category><category term="Facebook"></category><category term="ML"></category><category term="Machine Learning"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="named tensor"></category><category term="type promotion"></category></entry><entry><title>PyTorch in Robotics</title><link href="https://pyvideo.org/pytorch-conference-2019/pytorch-in-robotics.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Yisong Yue</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-in-robotics.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Learn about the research work at Caltech focused on risk aware machine learning for dynamic robotics control, and how PyTorch is being used to build deep learning systems for projects like the neural lander.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="AI research"></category><category term="Artificial Intelligence"></category><category term="Caltech"></category><category term="Facebook"></category><category term="ML"></category><category term="Machine Learning"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="Robotics"></category><category term="dynamic robotics control"></category></entry><entry><title>PyTorch Mobile</title><link href="https://pyvideo.org/pytorch-conference-2019/pytorch-mobile.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>David Reiss</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-mobile.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Running ML on edge devices is growing in importance as applications continue to demand lower latency. It is also a foundational element for privacy-preserving techniques such as federated learning. To enable more efficient on-device ML, PyTorch 1.3 now supports an end-to-end workflow from Python to deployment on iOS …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Running ML on edge devices is growing in importance as applications continue to demand lower latency. It is also a foundational element for privacy-preserving techniques such as federated learning. To enable more efficient on-device ML, PyTorch 1.3 now supports an end-to-end workflow from Python to deployment on iOS and Android. Learn more about this early, experimental release.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="AI Privacy"></category><category term="Artificial Intelligence"></category><category term="Facebook"></category><category term="ML"></category><category term="Machine Learning"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="PyTorch Android"></category><category term="PyTorch Mobile"></category><category term="PyTorch iOS"></category></entry><entry><title>PyTorch on Google Cloud TPUs</title><link href="https://pyvideo.org/pytorch-conference-2019/pytorch-on-google-cloud-tpus.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Vishal Mishra</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-on-google-cloud-tpus.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Google Cloud TPU support in PyTorch is now broadly available. Hear how engineers from Facebook, Google, and Salesforce worked together to enable and pilot Google Cloud TPU support in PyTorch, including experimental support for Cloud TPU Pods.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="Cloud TPU Pods"></category><category term="Facebook"></category><category term="Google"></category><category term="Google Cloud"></category><category term="Google Cloud TPU Support in PyTorch"></category><category term="ML"></category><category term="Machine Learning"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="Salesforce"></category></entry><entry><title>PyTorch ONNX Export Support</title><link href="https://pyvideo.org/pytorch-conference-2019/pytorch-onnx-export-support.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Lara Haidar</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-onnx-export-support.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The PyTorch ONNX exporter allows trained models to be easily exported to the ONNX model format. Learn about the latest updates including increased model coverage, improved performance, and support for multiple ONNX opset versions for multiple backends.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="AI Frame works"></category><category term="Artificial Intelligence"></category><category term="Facebook"></category><category term="ML"></category><category term="Machine Learning"></category><category term="Microsoft"></category><category term="ONNX"></category><category term="ONNX Exporter"></category><category term="ONNX Runtime"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category></entry><entry><title>PyTorch Summer Hackathon Winners</title><link href="https://pyvideo.org/pytorch-conference-2019/pytorch-summer-hackathon-winners.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Joe Spisak</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-summer-hackathon-winners.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The in-person and online Global PyTorch Summer Hackathon brought together researchers and developers around the world to build innovative new projects with PyTorch. Developers submitted creative projects ranging from livestock disease detection to AI-powered financial assistants.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="Facebook"></category><category term="Global PyTorch Summer Hackathon"></category><category term="Global PyTorch Summer Hackathon 2019"></category><category term="Hackathon"></category><category term="ML"></category><category term="Machine Learning"></category><category term="PyTorch"></category></entry><entry><title>Quantization</title><link href="https://pyvideo.org/pytorch-conference-2019/quantization.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Dmytro Dzhulgakov</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/quantization.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;It’s important to make efficient use of both server-side and on-device compute resources when developing ML applications. To support more efficient deployment on servers and edge devices, PyTorch 1.3 now supports 8-bit model quantization using the familiar eager mode Python API.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="Facebook"></category><category term="ML"></category><category term="Machine Learning"></category><category term="Machine learning"></category><category term="Machine learning applications"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="PyTorch API"></category><category term="PyTorch Quantization"></category><category term="Quantization"></category></entry><entry><title>Research to Production: PyTorch JIT/TorchScript Updates</title><link href="https://pyvideo.org/pytorch-conference-2019/research-to-production-pytorch-jittorchscript-updates.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Michael Suo</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/research-to-production-pytorch-jittorchscript-updates.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;TorchScript allows developers to create serializable and optimizable models from PyTorch code. Any TorchScript program can be saved from a Python process and loaded in a process where there is no Python dependency. Using TorchScript and the PyTorch JIT compiler, organizations and businesses have been able to use PyTorch …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;TorchScript allows developers to create serializable and optimizable models from PyTorch code. Any TorchScript program can be saved from a Python process and loaded in a process where there is no Python dependency. Using TorchScript and the PyTorch JIT compiler, organizations and businesses have been able to use PyTorch not just for state-of-the-art research, but also to more easily take their trained models to production.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="AI deployment"></category><category term="Artificial Intelligence"></category><category term="Facebook"></category><category term="JIT Compiler"></category><category term="ML"></category><category term="ML deployment"></category><category term="Machine Learning"></category><category term="Production AI"></category><category term="Production ML"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="TorchScript"></category></entry><entry><title>Sotabench for Reproducible Research</title><link href="https://pyvideo.org/pytorch-conference-2019/sotabench-for-reproducible-research.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Robert Stojnic</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/sotabench-for-reproducible-research.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Papers with Code recently launched Sotabench, a free and open website created to benchmark and rate the performance of state-of-the-art open source models from GitHub. Learn more about this new resource for reproducible research.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="AI research"></category><category term="Artificial Intelligence"></category><category term="Facebook"></category><category term="Github"></category><category term="ML"></category><category term="Machine Learning"></category><category term="Papers with code"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="open source"></category><category term="sotabench"></category></entry><entry><title>Speech Extensions to Fairseq</title><link href="https://pyvideo.org/pytorch-conference-2019/speech-extensions-to-fairseq.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Dmytro Okhonko</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/speech-extensions-to-fairseq.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Language translation and audio processing are critical components in systems and applications such as search, translation, speech, and assistants. Fairseq, a framework for sequence-to-sequence applications such as language translation, has been extended to include support for end-to-end learning for speech and audio recognition tasks. These extensions enable faster exploration …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Language translation and audio processing are critical components in systems and applications such as search, translation, speech, and assistants. Fairseq, a framework for sequence-to-sequence applications such as language translation, has been extended to include support for end-to-end learning for speech and audio recognition tasks. These extensions enable faster exploration and prototyping of new speech research ideas while offering a clear path to production.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="Audio processing"></category><category term="Facebook"></category><category term="Fairseq"></category><category term="Language Translation"></category><category term="ML"></category><category term="Machine Learning"></category><category term="NLP"></category><category term="Natural Language Processing"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="Speech Extensions to Fairseq"></category></entry><entry><title>StanfordNLP</title><link href="https://pyvideo.org/pytorch-conference-2019/stanfordnlp.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Yuhao Zhang</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/stanfordnlp.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;StanfordNLP is a new Python natural language processing analysis package built on PyTorch that’s designed to process many human languages. Learn more about the StanfordNLP library in this talk.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Ai Research"></category><category term="Artificial Intelligence"></category><category term="Facebook"></category><category term="ML"></category><category term="Machine Learning"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="Python"></category><category term="Python libraries"></category><category term="Python natural language"></category><category term="Stanford"></category><category term="StanfordNLP"></category><category term="StanfordNLP library"></category></entry><entry><title>What's new in PyTorch 1.3</title><link href="https://pyvideo.org/pytorch-conference-2019/whats-new-in-pytorch-13.html" rel="alternate"></link><published>2019-10-16T00:00:00+00:00</published><updated>2019-10-16T00:00:00+00:00</updated><author><name>Lin Qiao</name></author><id>tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/whats-new-in-pytorch-13.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Get an overview of the latest updates in PyTorch 1.3. This release includes new experimental features and capabilities including the ability to name tensors, seamless model deployment to mobile devices, quantization, and more.&lt;/p&gt;
</content><category term="PyTorch Conference 2019"></category><category term="AI"></category><category term="Artificial Intelligence"></category><category term="CAPTUM"></category><category term="Detectron2"></category><category term="Facebook"></category><category term="Fairseq Extensions"></category><category term="Introduction to PyTorch"></category><category term="ML"></category><category term="Machine Learning"></category><category term="Named Tensors"></category><category term="PyTorch"></category><category term="PyTorch 1.3"></category><category term="PyTorch Mobile"></category><category term="PyTorch Overview"></category><category term="Tensorboard"></category><category term="TorchScript"></category></entry></feed>