<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Thu, 31 Oct 2019 00:00:00 +0000</lastBuildDate><item><title>Writing highly scalable and provenanceable data pipelines</title><link>https://pyvideo.org/pycon-se-2019/writing-highly-scalable-and-provenanceable-data-pipelines.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we are gonna explore launching and maintaining highly scalable data pipelines using Kubernetes. We are gonna go through the process of setting up a Pachyderm cluster and deploying Python-based data processing workloads. This setup enables teams to develop and maintain very robust data pipelines, with the benefits of autoscaling clusters and quick code iteration.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guilherme Caminha</dc:creator><pubDate>Thu, 31 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-31:pycon-se-2019/writing-highly-scalable-and-provenanceable-data-pipelines.html</guid><category>kubernetes</category><category>data pipeline</category></item></channel></rss>