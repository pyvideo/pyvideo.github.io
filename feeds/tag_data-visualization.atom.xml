<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_data-visualization.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-12-07T00:00:00+00:00</updated><entry><title>Building a User Maintainable Visualization Dashboard for the Large Synoptic Survey Telescope (LSST)</title><link href="https://pyvideo.org/pydata-austin-2019/building-a-user-maintainable-visualization-dashboard-for-the-large-synoptic-survey-telescope-lsst.html" rel="alternate"></link><published>2019-12-07T00:00:00+00:00</published><updated>2019-12-07T00:00:00+00:00</updated><author><name>Dharhas Pothina</name></author><id>tag:pyvideo.org,2019-12-07:pydata-austin-2019/building-a-user-maintainable-visualization-dashboard-for-the-large-synoptic-survey-telescope-lsst.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Starting in 2023, the Large Synoptic Survey Telescope (LSST) project will image the entire visible sky every few days for ten years. When in production the LSST will generate 15 Terabytes of data per night. Critical to the success of this project is ensuring the quality of the data processing pipeline. We will demonstrate the complex multi page data visualization dashboard used by scientists.&lt;/p&gt;
</summary><category term="data-visualization"></category><category term="Visualization"></category><category term="dashboard"></category></entry><entry><title>Visualisation in Python</title><link href="https://pyvideo.org/pycon-ireland-2018/visualisation-in-python.html" rel="alternate"></link><published>2018-11-10T00:00:00+00:00</published><updated>2018-11-10T00:00:00+00:00</updated><author><name>Shane Lynn</name></author><id>tag:pyvideo.org,2018-11-10:pycon-ireland-2018/visualisation-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The ability to explore and grasp data structures through quick and intuitive visualisation is a key skill of any data scientist. Different tools in the Python ecosystem required varying levels of mental-gymnastics to manipulate and visualise information during a data exploration session. The array of Python libraries, each with their own idiosyncrasies, available can be daunting for newcomers and data scientists-in-training. In this talk, we will examine the core data visualisation libraries compatible with the popular Pandas data wrangling library. We'll look at the base-level Matplotlib library first, and then show the benefits of the higher-level Pandas visualisation toolkit and the popular Seaborne library. By the end of the talk, you'll be bar plotting, scatter plotting, and line plotting (never pie charting) your way to data visualisation bliss.&lt;/p&gt;
</summary><category term="data visualization"></category><category term="seaborn"></category><category term="matplotlib"></category><category term="pandas"></category></entry><entry><title>GPU-accelerated data analysis in Python: a study case in Material Sciences</title><link href="https://pyvideo.org/pycon-italia-2018/gpu-accelerated-data-analysis-in-python-a-study-case-in-material-sciences.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Giuseppe Di Bernardo</name></author><id>tag:pyvideo.org,2018-04-21:pycon-italia-2018/gpu-accelerated-data-analysis-in-python-a-study-case-in-material-sciences.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Max Planck Computing and Data Facility is engaged in the development
and optimization of algorithms and applications for high performance
computing as well as for data-intensive projects. As programming
language in data science, Python is now used at MPCDF in the scientific
area of “atom probe crystallography” (APT): a Fourier analysis in 3D
space can be simulated in order to reveal composition and
crystallographic structure at the atomic scale of billions APT
experimental data sets.&lt;/p&gt;
&lt;p&gt;The Python data ecosystem has proved to be well suited to this, as it
has grown beyond the confines of single machines to embrace scalability.
The talk aims to describe our approach to scaling across multiple GPUs,
and the role of visualization methods too.&lt;/p&gt;
&lt;p&gt;Our data workflow analysis relies on the GPU-accelerated Python software
package PyNX, an open source library which provides fast parallel
computation scattering. The code takes advantage of the high throughput
of GPUs, using the pyCUDA library.&lt;/p&gt;
&lt;p&gt;Exploratory data analysis, high productivity and rapid prototyping with
high performance are enabled through Jupyter Notebooks and Python
packages e.g., pandas, matplotlib/plotly. In production stage,
interactive visualization is realized by using standard scientific tool,
e.g. Paraview, an open-source 3D visualization program which requires
Python modules to generate visualization components within VTK files.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 14:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="GPUComputing"></category><category term="visualization"></category><category term="mathematical-modelling"></category><category term="image-processing"></category><category term="bigdata"></category><category term="matplotlib"></category><category term="analytics"></category><category term="data-visualization"></category><category term="data-analysis"></category><category term="Data Mining"></category><category term="scientific-computing"></category><category term="physics"></category><category term="python3"></category></entry><entry><title>Hacking Your Way Into Machine Learning</title><link href="https://pyvideo.org/pycon-italia-2018/hacking-your-way-into-machine-learning.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Laksh Arora</name></author><id>tag:pyvideo.org,2018-04-21:pycon-italia-2018/hacking-your-way-into-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;You might have heard of Machine Learning from your co-worker or in a local meetup and are enticed to get started but not sure how to take that first step. Confused between different sources, where to start from or how to proceed given a particular problem statement or dataset, then this talk is for you. It is aimed at complete beginners ( maybe you? ) who are just starting in machine learning and are ready to commit.
The talk will go something like this - each of the following items will be explained how it’s useful and why we should use it. Then alongside showcase, that same step applied to the real example(dataset) of that particular item so that the audience will be able to grasp the idea. It will add to around 35 minutes leaving us with 10 minutes for Q&amp;amp;A.
1) Context ( 5 mins ):
Discuss why we need Machine Learning and how we can use Machine Learning in different domains.
2) Resources ( 3 mins):
Talks about the dataset availability, online competitions, and Open Source libraries such as Scikit-learn, Matplotlib, Keras.
3) Jupyter Notebook (25 mins):
This Jupyter notebook will be a great starting point for most Supervised Machine Learning projects that involve common tasks: a) Imports and data loading (2 mins )
b) Data Exploration (5 mins)
c) Data Cleaning (3 mins)
d) Feature Engineering (4 mins)
e) Model Exploration (6 mins)
f) Final Model Building and Prediction ( 5 mins)
4) Wrap up ( 2 mins ):
Finalizing my talk, sharing some tips etc.
5) Q&amp;amp;A ( 10 mins ):
Question and Answering with the Audience.
Hope to inspire the audience to get started with machine learning, explore different domains, to learn, to create and engage with the Machine Learning Community.&lt;/p&gt;
</summary><category term="data-analysis"></category><category term="data-visualization"></category><category term="Python"></category><category term="scikit-learn"></category><category term="matplotlib"></category><category term="analytics"></category><category term="scipy"></category><category term="machine-learning"></category><category term="data"></category><category term="Statistical Learning"></category></entry><entry><title>Lies, damned lies, and statistics</title><link href="https://pyvideo.org/pycon-italia-2018/lies-damned-lies-and-statistics.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Marco Bonzanini</name></author><id>tag:pyvideo.org,2018-04-21:pycon-italia-2018/lies-damned-lies-and-statistics.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Statistics show that eating ice cream causes death by drowning.&lt;/p&gt;
&lt;p&gt;If this sounds baffling, this talk will help you to understand
correlation, bias, statistical significance and other statistical
techniques that are commonly (mis)used to support an argument that
leads, by accident or on purpose, to drawing the wrong conclusions.&lt;/p&gt;
&lt;p&gt;The casual observer is exposed to the use of statistics and probability
in everyday life, but it is extremely easy to fall victim of a
statistical fallacy, even for professional users.&lt;/p&gt;
&lt;p&gt;The purpose of this talk is to help the audience understand how to
recognise and avoid these fallacies, by combining an introduction to
statistics with examples of lies and damned lies, in a way that is
approachable for beginners.&lt;/p&gt;
&lt;p&gt;Agenda:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Correlation and causation&lt;/li&gt;
&lt;li&gt;Simpson’s Paradox&lt;/li&gt;
&lt;li&gt;Sampling bias and polluted surveys&lt;/li&gt;
&lt;li&gt;Data visualisation gone wild&lt;/li&gt;
&lt;li&gt;Statistical significance (and Data dredging a.k.a. p-hacking)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="reference external" href="https://speakerdeck.com/marcobonzanini/lies-damned-lies-and-statistics-at-pycon-italia-2018"&gt;Slides&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 12:00 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="data-visualization"></category><category term="statistics"></category><category term="data-analysis"></category><category term="pydata"></category></entry><entry><title>Using Python to bring democracy to the A.I. age</title><link href="https://pyvideo.org/pycon-italia-2018/using-python-to-bring-democracy-to-the-ai-age.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Felipe Cabral</name></author><id>tag:pyvideo.org,2018-04-21:pycon-italia-2018/using-python-to-bring-democracy-to-the-ai-age.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;TL;DR&lt;/p&gt;
&lt;div class="section" id="when-you-go-full-big-data-at-public-data-and-become-a-citzen"&gt;
&lt;h4&gt;When you go full Big Data at public data and become a citzen.&lt;/h4&gt;
&lt;p&gt;Audience type: developers, data scientists of any level of expertise.&lt;/p&gt;
&lt;p&gt;After a political coup Brazil drowned in scandals and political
disbelief. That was the final straw for us.&lt;/p&gt;
&lt;p&gt;We created a bot persona who uses Machine Learning to analyze public
spending, launching our own data journalism investigations. As expected
we use the internet publicize our findings and icing on it was to use
Twitter to directly engage the public and politicians under the topic of
suspicious expenses.&lt;/p&gt;
&lt;p&gt;Come with me and I’ll show some figures from Brazilian corruption, share
some code and cherry-pick the best of our toolbox to deal with public
data and machine learning. I’ll introduce our public dashboard that
makes visualization and browsing government data easy peasy. And surely
we can take a look in some tweets from Rosie, the robot, and how some
politicians are now vociferating with a ROBOT on social media.&lt;/p&gt;
&lt;p&gt;And you guessed it right: everything is open-source and our mission is
to create a global community to bring democracy to the A.I. age.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 18:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</summary><category term="machine-learning"></category><category term="Python"></category><category term="agile"></category><category term="Data Mining"></category><category term="bigdata"></category><category term="data-visualization"></category><category term="OpenSource"></category><category term="data-analysis"></category><category term="e-gov"></category><category term="data"></category></entry><entry><title>Introduction to Data-Analysis with Pandas / Time Series Analysis with Pandas</title><link href="https://pyvideo.org/pycon-italia-2017/introduction-to-data-analysis-with-pandas-time-series-analysis-with-pandas.html" rel="alternate"></link><published>2017-04-08T00:00:00+00:00</published><updated>2017-04-08T00:00:00+00:00</updated><author><name>Alexander Hendorf</name></author><id>tag:pyvideo.org,2017-04-08:pycon-italia-2017/introduction-to-data-analysis-with-pandas-time-series-analysis-with-pandas.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas is the &lt;em&gt;Swiss-Multipurpose Knife&lt;/em&gt; for Data Analysis in Python.
With Pandas dealing with data-analysis is easy and simple but there are
some things you need to get your head around first as Data-Frames and
Data-Series.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;first part&lt;/strong&gt; of talk with provide an &lt;strong&gt;introduction to Pandas&lt;/strong&gt;
for beginners, while the &lt;strong&gt;second part&lt;/strong&gt; will focus on &lt;strong&gt;Time Series
Analysis&lt;/strong&gt; with Pandas.&lt;/p&gt;
&lt;p&gt;part &lt;strong&gt;one&lt;/strong&gt; (~40&amp;quot;) &lt;em&gt;Introduction to Pandas&lt;/em&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;reading and writing data across multiple formats (CSV, Excel, JSON,
SQL, HTML,…)&lt;/li&gt;
&lt;li&gt;statistical data analysis and aggregation.&lt;/li&gt;
&lt;li&gt;work with built-in data visualisation&lt;/li&gt;
&lt;li&gt;inner-mechanics of Pandas: Data-Frames, Data-Series &amp;amp; Numpy.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;part &lt;strong&gt;two&lt;/strong&gt; (~20&amp;quot;) &lt;em&gt;Time Series Analysis&lt;/em&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;how to analyse periodical data with pandas&lt;/li&gt;
&lt;li&gt;how to mangle, reshape and pivot&lt;/li&gt;
&lt;li&gt;caveats when working with timed data&lt;/li&gt;
&lt;li&gt;visualize your data on the fly&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;bonus (if we have time left)&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;gain insights with statsmodels (e.g. seasonality)&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="data-visualization"></category><category term="computer-science"></category><category term="statistics"></category><category term="data-analysis"></category></entry><entry><title>Sparking Pandas: an experiment</title><link href="https://pyvideo.org/pycon-italia-2017/sparking-pandas-an-experiment.html" rel="alternate"></link><published>2017-04-07T00:00:00+00:00</published><updated>2017-04-07T00:00:00+00:00</updated><author><name>Francesco Bruni</name></author><id>tag:pyvideo.org,2017-04-07:pycon-italia-2017/sparking-pandas-an-experiment.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas is a good library to deal with tabular data. What if you need to
manage an amount of data that doesn’t fit into memory? What if you want
to “distribute” your computations among multiple machines?&lt;/p&gt;
&lt;p&gt;Starting from a real scenario, Apache Spark will be presented as the
main tool to read and process collected data. It will be shown how a
Pandas-like syntax will come in handy to run aggregations, filtering and
grouping using a Spark Dataframe.&lt;/p&gt;
&lt;p&gt;A previous knowledge of Docker and Docker Compose will be very useful
while knowing MongoDB (where data will be fetched from) is not
mandatory. Basics of functional programming will help to understand
Spark inner logic.&lt;/p&gt;
</summary><category term="microservices"></category><category term="Jupyter"></category><category term="mongodb"></category><category term="data-visualization"></category><category term="data-analysis"></category><category term="spark"></category><category term="docker"></category></entry><entry><title>Data Science &amp; Data Visualization in Python. How to harness power of Python for social good?</title><link href="https://pyvideo.org/pydata-berlin-2017/data-science-data-visualization-in-python-how-to-harness-power-of-python-for-social-good.html" rel="alternate"></link><published>2017-06-30T00:00:00+00:00</published><updated>2017-06-30T00:00:00+00:00</updated><author><name>Radovan Kavicky</name></author><id>tag:pyvideo.org,2017-06-30:pydata-berlin-2017/data-science-data-visualization-in-python-how-to-harness-power-of-python-for-social-good.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python as an Open Data Science tool offers many libraries for data visualization and I will show you how to use and combine the best. I strongly believe that power of data is not only in the information &amp;amp; insight that data can provide us, Data is and can be really beautiful and can not only transform our perception but also the world that we all live in.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In my talk I will primarily focus on answering/offer the answer to these questions:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Why we need data science and why more and more people should be really interested in analyzing data and data visualization? (motivation)&lt;/li&gt;
&lt;li&gt;What is data science and how to start doing it in Python? (introduction of procedures, tools, most popular IDE-s for Python, etc.)&lt;/li&gt;
&lt;li&gt;What tools for data analysis and data visualization Python offers? (in each stage of analysis the best libraries will be shown for the specific purpose; as for data visualization we will focus particularly on Bokeh, Seaborn, Plotly and use of Jupyter Notebook and Plotly)&lt;/li&gt;
&lt;li&gt;How to 'unlock' the insight hidden in data through Python and how to use it to transform not only public administration or business, but ultimately the transformation of the whole society and economy towards the insight &amp;amp; knowledge based? (potential of data science)&lt;/li&gt;
&lt;li&gt;Open Data, Open Government Partnership, Open Public Administration &amp;amp; all the advantages of Open Data Science &amp;amp; Python. Data-Driven Approach. Everywhere. Now. (the end of talk +vision)&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="python"></category><category term="data-science"></category><category term="data-visualization"></category><category term="analytics"></category><category term="PyData"></category><category term="PyDataBLN"></category><category term="PyDataBerlin"></category><category term="PyDataBA"></category><category term="PyDataBratislava"></category><category term="talk"></category><category term="Data"></category><category term="Bokeh"></category><category term="Social Good"></category><category term="datascience"></category><category term="jupyter"></category><category term="open science"></category><category term="open data science"></category><category term="DataVisualization"></category><category term="data-analysis"></category><category term="analysis"></category><category term="matplotlib"></category><category term="numpy"></category><category term="data wrangling"></category><category term="jupyter notebook"></category><category term="pandas"></category><category term="machine learning"></category><category term="deep learning"></category><category term="Open Data"></category><category term="Citizen Data Science"></category></entry><entry><title>Matplotlib Plot Tutorial: Histograms, Scatter Plots &amp; Legend</title><link href="https://pyvideo.org/datacamp/Matplotlib-Plot-Tutorial-For-Beginners.html" rel="alternate"></link><published>2016-02-01T00:00:00+00:00</published><updated>2016-02-01T00:00:00+00:00</updated><author><name>Filip Schouwenaars</name></author><id>tag:pyvideo.org,2016-02-01:datacamp/Matplotlib-Plot-Tutorial-For-Beginners.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Matplotlib makes it easy to create meaningful and insightful plots. In this beginner video, you will learn how to build various types of data visualizations such as histograms, scatter plots and line plots. You will also see how to customize them to make them more visually appealing and interpretable.&lt;/p&gt;
&lt;p&gt;Want to do the corresponding exercises? Go to our &lt;cite&gt;Python For Data Science Tutorial &amp;lt;https://www.datacamp.com/courses/intro-to-python-for-data-science&amp;gt;&lt;/cite&gt; where you can do them for free.&lt;/p&gt;
</summary><category term="Matplotlib"></category><category term="data science"></category><category term="data visualization"></category><category term="tutorial"></category><category term="DataCamp"></category></entry><entry><title>How do I work with dates and times in pandas?</title><link href="https://pyvideo.org/data-school/pandas-25-dates-and-times.html" rel="alternate"></link><published>2016-07-19T00:00:00+00:00</published><updated>2016-07-19T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-07-19:data-school/pandas-25-dates-and-times.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Let's say that you have dates and times in your DataFrame and you want to analyze your data by minute, month, or year. What should you do? In this video, I'll demonstrate how you can convert your data to &amp;quot;datetime&amp;quot; format, enabling you to access a ton of convenient attributes and perform datetime comparisons and mathematical operations.&lt;/p&gt;
&lt;p&gt;This is video 25 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="data visualization"></category></entry><entry><title>How do I explore a pandas Series?</title><link href="https://pyvideo.org/data-school/pandas-15-explore-series.html" rel="alternate"></link><published>2016-05-24T00:00:00+00:00</published><updated>2016-05-24T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-05-24:data-school/pandas-15-explore-series.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When you start working with a new dataset, how should you go about exploring it? In this video, I'll demonstrate some of the basic tools in pandas for exploring both numeric and non-numeric data. I'll also show you how to create simple visualizations in a single line of code!&lt;/p&gt;
&lt;p&gt;This is video 15 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="data visualization"></category></entry><entry><title>When should I use a "groupby" in pandas?</title><link href="https://pyvideo.org/data-school/pandas-14-analyze-data-by-category.html" rel="alternate"></link><published>2016-05-19T00:00:00+00:00</published><updated>2016-05-19T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-05-19:data-school/pandas-14-analyze-data-by-category.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The pandas &amp;quot;groupby&amp;quot; method allows you to split a DataFrame into groups, apply a function to each group independently, and then combine the results back together. This is called the &amp;quot;split-apply-combine&amp;quot; pattern, and is a powerful tool for analyzing data across different categories. In this video, I'll explain when you should use a groupby and then demonstrate its flexibility using four different examples.&lt;/p&gt;
&lt;p&gt;This is video 14 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="data visualization"></category></entry><entry><title>Winning Ways for Your Visualization Plays</title><link href="https://pyvideo.org/pydata-amsterdam-2016/winning-ways-for-your-visualization-plays.html" rel="alternate"></link><published>2016-03-26T00:00:00+00:00</published><updated>2016-03-26T00:00:00+00:00</updated><author><name>Mark Grundland</name></author><id>tag:pyvideo.org,2016-03-26:pydata-amsterdam-2016/winning-ways-for-your-visualization-plays.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2016&lt;/p&gt;
&lt;p&gt;Description&lt;/p&gt;
&lt;p&gt;What enables an effective data visualization to deliver insight at a glance? This talk presents practical techniques for how information visualization design can take better account of the fundamental limitations of visual perception, exploring the design choices that determine whether a picture can meaningfully convey the data set it is meant to represent.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;Data deserves to be seen. In an information economy, there is no shortage of information; only genuine understanding is in short supply. Knowledge workers are continually asked to make sense of more information than they could possibly have time to read and assimilate. Users have come to demand insight at a glance: the whole picture, not just an endless list of results. After all, as information becomes ever more abundant, attention remains as scarce as ever. Visualization, animation, and interaction can be gainfully employed to develop information systems that are both useful, enabling users to get the job done well, and usable, empowering users to do job with ease. Effective information visualization should be immediately appealing to the eye and directly relevant to the task, routinely enjoyable to the user and uniquely valuable to the business. By integrating the power of computational analysis with the expertise of human judgment, visualization serves to turn aggregated information into actionable insight, illustrating the way numbers can tell a story compelling enough for people to make decisions they can trust.&lt;/p&gt;
&lt;p&gt;This presentation explores practical techniques for information visualization design to take better account of the fundamental limitations of visual perception. It includes examples of innovative visualizations used in a variety of applications, including a research project for Grapeshot and IBM to create an online news analysis service that tracks the relative influence of different news sources on shaping how news coverage evolves over time.&lt;/p&gt;
</summary><category term="data visualization"></category></entry></feed>