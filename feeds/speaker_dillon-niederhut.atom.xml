<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_dillon-niederhut.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-07-13T00:00:00+00:00</updated><entry><title>Safe Handling Instructions for Missing Data</title><link href="https://pyvideo.org/scipy-2018/safe-handling-instructions-for-missing-data.html" rel="alternate"></link><published>2018-07-13T00:00:00+00:00</published><updated>2018-07-13T00:00:00+00:00</updated><author><name>Dillon Niederhut</name></author><id>tag:pyvideo.org,2018-07-13:scipy-2018/safe-handling-instructions-for-missing-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In machine learning tasks, it is common to handle missing data by simply
removing observations with missing values, or just replacing missing
data with the mean value for its feature. To show why this is
problematic, we use listwise deletion and mean imputing to recover
missing values from artificially created datasets, and we compare those
models against ones with full information. Unless quite strong
independence assumptions are met, we observe large biases in the
resulting coefficients and an increase in the model's prediction error.
We conclude by repeating the experiment on a real dataset, and showing
the appropriate diagnostic and correction steps to handle missing
values.Presenter(s): Speaker: Dillon Niederhut, Enthought&lt;/p&gt;
</summary></entry><entry><title>pandas .head() to .tail() (Beginner Level)</title><link href="https://pyvideo.org/scipy-2018/pandas-head-to-tail-beginner-level.html" rel="alternate"></link><published>2018-07-10T00:00:00+00:00</published><updated>2018-07-10T00:00:00+00:00</updated><author><name>Dillon Niederhut</name></author><id>tag:pyvideo.org,2018-07-10:scipy-2018/pandas-head-to-tail-beginner-level.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This tutorial is an introduction to pandas, a library providing data
structures and algorithms for tabular data analysis. It's aimed at
scientists and data analysts new to scientific Python. No previous
experience with pandas is expected. Familiarity with the basics of
Python will be helpful. We'll work through a series of Jupyter notebooks
together, with an emphasis on solving realistic problems as exercises.
We'll cover 1. A definition of tabular data and pandas' data structures
for tabular data 2. How pandas' alignment by row and column labels
simplifies data analysis 3. groupby for analyzing subsets of a table
grouped by some common factor 4. Tidy data: how to structure your data
to facilitate analysis. 5. Performance: How to benchmark and profile
code, and some common pandas performance pitfalls 6. pandas' special
support for time-series data.Presenter(s): Speaker: Dillon Niederhut,
Enthought Speaker: Tom Augspurger, Anaconda, Inc. Speaker: Joris Van den
Bossche, Université Paris-Saclay Center for Data Science&lt;/p&gt;
</summary></entry><entry><title>Introduction to Numerical Computing with NumPy</title><link href="https://pyvideo.org/scipy-2017/introduction-to-numerical-computing-with-numpy.html" rel="alternate"></link><published>2017-07-13T00:00:00+00:00</published><updated>2017-07-13T00:00:00+00:00</updated><author><name>Dillon Niederhut</name></author><id>tag:pyvideo.org,2017-07-13:scipy-2017/introduction-to-numerical-computing-with-numpy.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;NumPy provides Python with a powerful array processing library and an elegant syntax that is well suited to expressing computational algorithms clearly and efficiently. We'll introduce basic array syntax and array indexing, review some of the available mathematical functions in numpy, and discuss how to write your own routines. Along the way, we'll learn just enough of matplotlib to display results from our examples.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Cython for Data, Scientists, and Data Scientists</title><link href="https://pyvideo.org/scipy-2017/cython-for-data-scientists-and-data-scientists.html" rel="alternate"></link><published>2017-07-12T00:00:00+00:00</published><updated>2017-07-12T00:00:00+00:00</updated><author><name>Dillon Niederhut</name></author><id>tag:pyvideo.org,2017-07-12:scipy-2017/cython-for-data-scientists-and-data-scientists.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Cython is a foundational technology behind many packages you use everyday, including NumPy, SciPy, Pandas, Scikit-Learn, Scikit-Image, PyTables, and h5py. Developers, data scientists, and researchers use Cython to accelerate Python, access NumPy efficiently at the C level, and interface Python with C or C++. Cython's expressivity, its stability and maturity, and its gradual typing approach make it a uniquely flexible tool that has become a critical component for many projects.&lt;/p&gt;
&lt;p&gt;This tutorial will be fast paced, and is geared towards data scientists and Python users looking to take their Python performance to the next level. Basic familiarity with C or C++ is assumed.&lt;/p&gt;
</summary><category term="tutorial"></category><category term="cython"></category></entry><entry><title>What to do when your data is large, but not big</title><link href="https://pyvideo.org/pybay-2016/what-to-do-when-your-data-is-large-but-not-big.html" rel="alternate"></link><published>2016-08-20T00:00:00+00:00</published><updated>2016-08-20T00:00:00+00:00</updated><author><name>Dillon Niederhut</name></author><id>tag:pyvideo.org,2016-08-20:pybay-2016/what-to-do-when-your-data-is-large-but-not-big.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will present strategies in Python for handling data that is too large to fit in memory and/or too slow to process in one thread, but small enough to still fit in one machine.
​
Abstract
Unless you work at a large internet company, you probably don't have BIG data, but you might have LARGE data. Large data consume an unacceptable amount of time and memory when medium strategies are used, but also incur unnecessary financial and latency costs when big strategies are used. Two basic strategies for handling large data, chunking and parallelization, will be discussed with live coded examples in Python.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt;
I'm a research scientist currently living in the Bay Area and working in neuroethology, human evolution, and natural language processing. I currently work at D-Lab, where I help researchers apply advances in computation to their research paradigms.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://speakerdeck.com/pybay2016/dillon-niederhut-what-to-do-when-your-data-is-large-but-not-big"&gt;https://speakerdeck.com/pybay2016/dillon-niederhut-what-to-do-when-your-data-is-large-but-not-big&lt;/a&gt;&lt;/p&gt;
</summary></entry></feed>