<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 13 Jul 2019 00:00:00 +0000</lastBuildDate><item><title>Adv. Software Testing for Data Scientists</title><link>https://pyvideo.org/pydata-london-2019/adv-software-testing-for-data-scientists.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The journey to deploy a model to production starts with testing it rigorously, including its code implementation. In this tutorial, you will learn about state of the art software testing approach. You will learn how to write unit tests with enhanced diagnostics, leverage validation tools from numpy, pandas, scikit-learn, apply test doubles and generate test cases using property-based testing.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Raoul-Gabriel Urma</dc:creator><pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-13:pydata-london-2019/adv-software-testing-for-data-scientists.html</guid></item><item><title>Maintainable code in data science</title><link>https://pyvideo.org/pydata-london-2019/maintainable-code-in-data-science.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Notebooks are great, they allow to explore your data and prototype models quickly. But they make it hard to follow good software practices. In this tutorial, we will go through a case study.We will see how to refactor our code as a testable and maintainable Python package with entry-points to tune, train and test our model so it can easily be integrated to a CI/CD flow.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Lemagnen</dc:creator><pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-13:pydata-london-2019/maintainable-code-in-data-science.html</guid></item><item><title>Open the Black Box: an Introduction to Model Interpretability in Python</title><link>https://pyvideo.org/pycon-us-2019/open-the-black-box-an-introduction-to-model-interpretability-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;What's the use of sophisticated machine learning models if you can't
interpret them?&lt;/p&gt;
&lt;p&gt;In fact, many industries including finance and healthcare require clear
explanations of why a decision is made. This tutorial covers recent
model interpretability techniques that are essentials in your data
scientist toolbox: Eli5, LIME (Local Interpretable Model-Agnostic
Explanations) and SHAP (SHapley Additive exPlanations).&lt;/p&gt;
&lt;p&gt;You will learn how to apply these techniques in Python on real-world
data science problems in order to debug your models and explain their
decisions.&lt;/p&gt;
&lt;p&gt;You will also learn the conceptual background behind these techniques so
you can better understand when they are appropriate.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Lemagnen</dc:creator><pubDate>Thu, 02 May 2019 13:20:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-02:pycon-us-2019/open-the-black-box-an-introduction-to-model-interpretability-in-python.html</guid><category>tutorial</category></item><item><title>Open the Black Box: an Introduction to Model Interpretability with LIME and SHAP</title><link>https://pyvideo.org/pydata-new-york-city-2018/open-the-black-box-an-introduction-to-model-interpretability-with-lime-and-shap.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Lemagnen</dc:creator><pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-08-17:pydata-new-york-city-2018/open-the-black-box-an-introduction-to-model-interpretability-with-lime-and-shap.html</guid></item><item><title>Walking the Random Forest and boosting the trees</title><link>https://pyvideo.org/europython-2018/walking-the-random-forest-and-boosting-the-trees.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deep Learning is all the rage, but ensemble models are still in the
game. With libraries such as the recent and performant LightGBM, the
Kaggle superstar XGboost or the classic Random Forest from scikit-learn,
ensembles models are a must-have in a data scientist’s toolbox. They’ve
been proven to provide good performance on a wide range of problems, and
are usually simpler to tune and interpret. This talk focuses on two of
the most popular tree-based ensemble models. You will learn about Random
Forest and Gradient Boosting, relying respectively on bagging and
boosting. This talk will attempt to build a bridge between the theory of
ensemble models and their implementation in Python.&lt;/p&gt;
&lt;p&gt;Notebook:
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;https://github.com/klemag/europython2018_walking_the_random_forest&lt;/span&gt;&lt;/tt&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Lemagnen</dc:creator><pubDate>Fri, 27 Jul 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-07-27:europython-2018/walking-the-random-forest-and-boosting-the-trees.html</guid></item></channel></rss>