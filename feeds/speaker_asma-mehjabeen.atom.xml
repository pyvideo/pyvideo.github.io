<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_asma-mehjabeen.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2014-11-13T00:00:00+00:00</updated><entry><title>November 2014 Chipy Talks</title><link href="https://pyvideo.org/chipy/november-2014-chipy-talks.html" rel="alternate"></link><published>2014-11-13T00:00:00+00:00</published><updated>2014-11-13T00:00:00+00:00</updated><author><name>Asma Mehjabeen</name></author><id>tag:pyvideo.org,2014-11-13:chipy/november-2014-chipy-talks.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Talks from the November 2014 meeting. Hidden Markov Models to improve
activity recognition in patients with spinal cord injury and Innate
learning: training the brain before the eyes open.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="section" id="hidden-markov-models-to-improve-activity-recognition-in-patients-with-spinal-cord-injury"&gt;
&lt;h4&gt;Hidden Markov Models to improve activity recognition in patients with spinal cord injury&lt;/h4&gt;
&lt;p&gt;By: Asma Mehjabeen&lt;/p&gt;
&lt;p&gt;Fitness tracking is great for calories and steps, but similar sensors
are capable of reporting much more about how we move throughout the day.
This is especially important in assessing the quality of movement for
those with limited mobility. Doctors often want to know more detail
about patient behavior after therapy to select and adjust the
appropriate intervention. Using machine learning on wearable
accelerometer signals, we estimate the activities patients with
incomplete spinal cord injury are performing. By combining windowed
classifier estimates over time using a hidden markov model, we show how
error rates can be significantly decreased, which brings more detailed
assessments of patient activity closer to a clinical reality.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="innate-learning-training-the-brain-before-the-eyes-open"&gt;
&lt;h4&gt;Innate learning: training the brain before the eyes open&lt;/h4&gt;
&lt;p&gt;By: Isaac Adorno&lt;/p&gt;
&lt;p&gt;Amorphous, blob-like patterns of neural activity form and move over the
eye during visual development in animals. Why do such patterns exist? We
show that these patterns are this way to better prepare the visual
system for natural vision. Essentially, these are movies played in the
eyes to refine the visual system before the eyes even open. We use
python to model the developing visual system, produce an efficient code
based on those patterns, and show how that code matches what is seen
biologically. In this way, we show that during your early development
you are learning from innately generated patterns - a unique twist in
the debates of nature and nurture.&lt;/p&gt;
&lt;/div&gt;
</summary></entry></feed>