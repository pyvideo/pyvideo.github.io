<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_lightfm.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2016-03-26T00:00:00+00:00</updated><entry><title>Hybrid Recommender Systems in Python</title><link href="https://pyvideo.org/pydata-amsterdam-2016/hybrid-recommender-systems-in-python.html" rel="alternate"></link><published>2016-03-26T00:00:00+00:00</published><updated>2016-03-26T00:00:00+00:00</updated><author><name>Maciej Kula</name></author><id>tag:pyvideo.org,2016-03-26:pydata-amsterdam-2016/hybrid-recommender-systems-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2016&lt;/p&gt;
&lt;p&gt;Systems based on collaborative filtering are the workhorse of recommender systems. They yield great results when abundant data is available. Unfortunately, their performance suffers when encountering new items or new users.&lt;/p&gt;
&lt;p&gt;In this talk, I'm going to talk about hybrid approaches that alleviate this problem, and introduce a mature, high-performance Python recommender package called LightFM.&lt;/p&gt;
&lt;p&gt;Introduction to collaborative filtering.
Works well when data is abundant (MovieLens, Amazon), but poorly when new users and items are common.
Introduce hybrid approaches: metadata embeddings.
This is implemented in LightFM.
LightFM has a couple of tricks up its sleeve: multicore training, training with superior ranking losses.&lt;/p&gt;
&lt;p&gt;Slides available here: &lt;a class="reference external" href="https://speakerdeck.com/maciejkula/hybrid-recommender-systems-at-pydata-amsterdam-2016"&gt;https://speakerdeck.com/maciejkula/hybrid-recommender-systems-at-pydata-amsterdam-2016&lt;/a&gt;&lt;/p&gt;
</summary><category term="lightfm"></category></entry></feed>