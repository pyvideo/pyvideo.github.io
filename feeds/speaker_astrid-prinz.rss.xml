<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 13 Jul 2019 00:00:00 +0000</lastBuildDate><item><title>Building &amp; Replicating Models of Visual Search Behavior w/ Tensorflow, Nengo, &amp; Scientific Python Stack</title><link>https://pyvideo.org/scipy-2019/building-replicating-models-of-visual-search-behavior-w-tensorflow-nengo-scientific-python-stack.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Animals constantly use their eyes to search their environment. What can neural networks and other cognitive models tell us about this behavior? We present two related studies that leverage scientific Python libraries to address this question. The first uses Tensorflow to replicate and extend a previous study of how convolutional neural networks perform a classic visual search task. The second study compares visual search behavior of two types of models: a recurrent neural network model from Google DeepMind, and spiking cognitive models built with the Nengo neural simulator. We discuss what our results suggest about such models.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">David Nicholson</dc:creator><pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-13:scipy-2019/building-replicating-models-of-visual-search-behavior-w-tensorflow-nengo-scientific-python-stack.html</guid></item></channel></rss>