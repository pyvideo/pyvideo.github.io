<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Max Hinne</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_max-hinne.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-08-03T00:00:00+00:00</updated><subtitle></subtitle><entry><title>The Indian Chefs Process</title><link href="https://pyvideo.org/uai-2020/the-indian-chefs-process.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Patrick Dallaire</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/the-indian-chefs-process.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Indian Chefs Process&lt;/p&gt;
&lt;p&gt;Patrick Dallaire (Université Laval)*; Luca Ambrogioni (Radboud University); Ludovic Trottier (University of Laval); Umut Güçlü (Radboud University, Donders Institute for Brain, Cognition and Behaviour); Max Hinne (Radboud University); Philippe Giguère (Laval University); Marcel van Gerven (Radboud University); François Laviolette (Université Laval)&lt;/p&gt;
&lt;p&gt;This paper introduces the …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Indian Chefs Process&lt;/p&gt;
&lt;p&gt;Patrick Dallaire (Université Laval)*; Luca Ambrogioni (Radboud University); Ludovic Trottier (University of Laval); Umut Güçlü (Radboud University, Donders Institute for Brain, Cognition and Behaviour); Max Hinne (Radboud University); Philippe Giguère (Laval University); Marcel van Gerven (Radboud University); François Laviolette (Université Laval)&lt;/p&gt;
&lt;p&gt;This paper introduces the Indian chefs process (ICP) as a Bayesian nonparametric prior on the joint space of infinite directed acyclic graphs (DAGs) and orders that generalizes the Indian buffet process. As our construction shows, the proposed distribution relies on a latent Beta process controlling both the orders and outgoing connection probabilities of the nodes, and yields a probability distribution on sparse infinite graphs. The main advantage of the ICP over previously proposed Bayesian nonparametric priors for DAG structures is its greater flexibility. To the best of our knowledge, the ICP is the first Bayesian nonparametric model supporting every possible DAG involving latent nodes. We demonstrate the usefulness of the ICP on learning the structure of deep generative sigmoid networks as well as convolutional neural networks.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry></feed>