<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Maanav Dalal</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Wed, 18 Sep 2024 00:00:00 +0000</lastBuildDate><item><title>Lightning Talk: Streamlining Model Export with the New ONNX Exporter</title><link>https://pyvideo.org/pytorch-conference-2023/lightning-talk-streamlining-model-export-with-the-new-onnx-exporter.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Join us for a 10-minute talk on the new TorchDynamo-based ONNX exporter, redefining how we convert machine learning models to the ONNX format, with the power of PyTorch 2.0. The talk covers: Exporting with torch.onnx.dynamo_export, Inference with ONNXRuntime, and a variety of of State-of-the-Art models being converted easily. Learn about how ONNX enables more PyTorch models to be cross-platform, all the great benefits of ONNX standard, and all the other features we have baked into the new exporter, including: Symbolic model tracing: Export large models without computation cost involving original data/parameters, saving time and preventing OOM issues. ONNX Script: A new way to architect ONNX Models and the backbone of the Dynamo Exporter Preserving original modules structure as ONNX functions: allowing for a better resulting model that is layered. Better diagnostics: Clearly identify the root of your conversion issues faster!&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Maanav Dalal</dc:creator><pubDate>Mon, 16 Oct 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-10-16:/pytorch-conference-2023/lightning-talk-streamlining-model-export-with-the-new-onnx-exporter.html</guid><category>PyTorch Conference 2023</category><category>Lightning Talk</category></item><item><title>Implementing a Custom Torch.Compile Backend - A Case Study</title><link>https://pyvideo.org/pytorch-conference-2024/implementing-a-custom-torchcompile-backend-a-case-study.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Implementing a Custom Torch.Compile Backend - A Case Study - Maanav Dalal &amp;amp; Yulong Wang, Microsoft&lt;/p&gt;
&lt;p&gt;This presentation will dive into the development of the ONNXRuntime (ORT) backend for torch.compile. We'll cover the implementation process, starting with a PyTorch 2.0 generated FX graph, highlighting the unique challenges encountered when serving ORT-specific scenarios and how we solved them. Attendees will gain insights into optimizing performance, overcoming integration hurdles, and achieving efficient execution. Whether you're a developer looking to extend PyTorch's capabilities for your own use cases, keen to learn about ONNX Runtime, or interested in backend performance optimization, and the many steps we've taken to get to where we are now, this session promises valuable takeaways and practical knowledge.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Maanav Dalal</dc:creator><pubDate>Wed, 18 Sep 2024 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2024-09-18:/pytorch-conference-2024/implementing-a-custom-torchcompile-backend-a-case-study.html</guid><category>PyTorch Conference 2024</category></item></channel></rss>