<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 07 Dec 2019 00:00:00 +0000</lastBuildDate><item><title>Speeding up Machine Learning tasks using GPUs in Python</title><link>https://pyvideo.org/pydata-austin-2019/speeding-up-machine-learning-tasks-using-gpus-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;GPUs are typically used to accelerate deep learning models, but they haven't been widely deployed for traditional machine learning. This talk will cover cuML's GPU based implementation of Decision Trees and Random Forest algorithms, aimed to provide 10x-50x speedup and a new library called Forest Inference Library (FIL), which allows GPU accelerated inference of different pretrained forest models&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Saloni Jain</dc:creator><pubDate>Sat, 07 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-07:pydata-austin-2019/speeding-up-machine-learning-tasks-using-gpus-in-python.html</guid><category>GPU</category><category>GPUComputing</category><category>machine learning</category></item><item><title>CUDA in your Python: Effective Parallel Programming on the GPU</title><link>https://pyvideo.org/pytexas-2019/cuda-in-your-python-effective-parallel-programming-on-the-gpu.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;It’s 2019, and Moore’s Law is dead. CPU performance is plateauing, but GPUs provide a chance for continued hardware performance gains, if you can structure your programs to make good use of them. In this talk you will learn how to speed up your Python programs using Nvidia’s CUDA platform.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">William Horton</dc:creator><pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-04-13:pytexas-2019/cuda-in-your-python-effective-parallel-programming-on-the-gpu.html</guid><category>GPU</category><category>cuda</category></item><item><title>Geospatial Analysis using Python and JupyterHub</title><link>https://pyvideo.org/europython-2019/geospatial-analysis-using-python-and-jupyterhub.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Geospatial data is data containing a spatial component – describing
objects with a reference to the planet's surface. This data usually
consists of a spatial component, of various attributes, and sometimes of
a time reference (where, what, and when). Efficient processing and
visualization of small to large-scale spatial data is a challenging
task.&lt;/p&gt;
&lt;p&gt;This talk describes how to process and visualize geospatial vector and
raster data using Python and the Jupyter Notebook.&lt;/p&gt;
&lt;p&gt;To process the data a high performance computer with 4 GPUS (NVidia
Tesla V100), 192 GB RAM, 44 CPU Cores is used to run JupyterHub.&lt;/p&gt;
&lt;p&gt;There are numerous modules available which help using geospatial data in
using low- and high-level interfaces, which are shown in this
presentation. In addition, it is shown how to use deep learning for
raster analysis using the high performance GPUs and several deep
learning frameworks.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Martin Christen</dc:creator><pubDate>Wed, 10 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-10:europython-2019/geospatial-analysis-using-python-and-jupyterhub.html</guid><category>Analytics</category><category>Big Data</category><category>Deep Learning</category><category>GPU</category><category>Visualization</category></item><item><title>The unconventional Introduction to Deep Learning</title><link>https://pyvideo.org/pycon-italia-2017/the-unconventional-introduction-to-deep-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you are into Deep Learning, sooner or later, it inevitbly happens
that you’re asked at least once to explain what actually means &lt;strong&gt;Deep
Learning&lt;/strong&gt; , and what’s all the fuss about it.&lt;/p&gt;
&lt;p&gt;Indeed, answering this question in a proper way, may vary (and it has
to) depending on the kind of audience you’ve been talking to.&lt;/p&gt;
&lt;p&gt;If you are talking to a machine learning experts, you have to
concentrate on what &lt;em&gt;deep&lt;/em&gt; means, for the multiple learning models you
can come up with. Most importarly, you have to convince them that a deep
learning model would work by far better than a more standard and robust
Random Forest or Support Vector Machine.&lt;/p&gt;
&lt;p&gt;On the other hand, if your audience is made up of engineers, they
[STRIKEOUT:don’t give a damn..] are definitely more interested in how
you implement your Artificial Neural Networks (ANN) rather than
understanding what are the implications of different &lt;em&gt;activations&lt;/em&gt; and
&lt;em&gt;optimizers&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Finally, if your audience is made up of data scientists - who are a good
mixture of the previous two, according to &lt;a class="reference external" href="http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram"&gt;Drew
Conway&lt;/a&gt;
- they are more or less interested in both the two aspects.&lt;/p&gt;
&lt;p&gt;The other way, that is the &lt;em&gt;unconventional way&lt;/em&gt;, to explain what Deep
Learning means, is from the perspective of the computational model it
requires to be properly effective. Therefore, you may want to talk about
ANN in terms of matrix multiplications algorithms, running on a (series
of) GPUs in parallel. And this is &lt;strong&gt;exactly&lt;/strong&gt; the perspecitve I intend
to pursue in this talk.&lt;/p&gt;
&lt;p&gt;This talk is for PyData scientists who are interested in understanding
Deep Learning models from this unconventional perspective, learning what
are the libraries and tools they may leverage for their experiments on
GPUs. Experienced engineers may likely benefit from this talk as well,
learning how they can make their models run fast(er).&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Valerio Maggio</dc:creator><pubDate>Fri, 07 Apr 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-04-07:pycon-italia-2017/the-unconventional-introduction-to-deep-learning.html</guid><category>Keras</category><category>rumba</category><category>Deep-Learning</category><category>machine-learning</category><category>Theano</category><category>GPU</category><category>tensorflow</category></item><item><title>Exploit your GPU power with PyCUDA (and friends)</title><link>https://pyvideo.org/europython-2011/exploit-your-gpu-power-with-pycuda-and-friends.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Stefano Brilli - 22 June 2011 in &amp;quot;Track Spaghetti&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;CUDA technology permits to exploit the power of modern NVIDIA GPUs. In
this talk, after a brief introduction to GPU architecture, we will focus
on how CUDA got inside Python through libraries like PyCUDA and others…&lt;/p&gt;
&lt;p&gt;By some examples we will show the main concepts and techniques for good
GPU programming.&lt;/p&gt;
&lt;p&gt;This talk targets anyone who wants to know how to exploit this
technology from Python, the suitable use cases, the using techniques and
the do-not-using techniques to get the best from his own GPU&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Stefano Brilli</dc:creator><pubDate>Thu, 21 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-21:europython-2011/exploit-your-gpu-power-with-pycuda-and-friends.html</guid><category>gpu</category><category>nvidia</category><category>pycuda</category><category>python,</category><category>technology</category></item><item><title>Best Practices for Python in the Cloud</title><link>https://pyvideo.org/europython-2011/best-practices-for-python-in-the-cloud.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Gisle Aas - 21 June 2011 in &amp;quot;Track Lasagne&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Abstract: Whether you’re an independent developer or development manager
in a large company, “the cloud” is on everyone’s mind. But just because
it’s in the cloud, doesn’t mean development and deployment is
effortless. The cloud presents infrastructure and development challenges
in a new way.&lt;/p&gt;
&lt;p&gt;In this presentation, ActiveState's Gisle Aas will share best practices
in building and deploying a Python-centric LAMP stack(s) on the cloud
for a range of web-based applications from simple Django site to HPC GPU
Clusters.&lt;/p&gt;
&lt;p&gt;Based on ActiveState’s experiences, Gisle will discuss the challenges
faced and lessons learned in building an infrastructure to deploy web
applications to the cloud with Python.&lt;/p&gt;
&lt;p&gt;You will learn about:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Which packages are critical for a secure, Python-centric LAMP stack
(and what it takes to build them)!&lt;/li&gt;
&lt;li&gt;Tips for developing, deploying, and scaling Python applicaitons in
the cloud&lt;/li&gt;
&lt;li&gt;How to use Python to connect and build infrastructure to support and
manage your deployment&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Gisle Aas</dc:creator><pubDate>Mon, 18 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-18:europython-2011/best-practices-for-python-in-the-cloud.html</guid><category>cloud</category><category>deploy</category><category>deployment</category><category>django</category><category>gpu</category><category>hpc</category><category>infrastructure</category><category>lamp</category><category>packages</category><category>scaling</category><category>web</category></item><item><title>Python for High Performance and Scientific Computing</title><link>https://pyvideo.org/europython-2011/python-for-high-performance-and-scientific-comput.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Andreas Schreiber - 23 June 2011 in &amp;quot;Track Lasagne&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python is an accepted high-level scripting language with a growing
community in academia and industry. It is used in a lot of scientific
applications in many different scientific fields and in more and more
industries, for example, in engineering or life science). In all fields,
the use of Python for high- performance and parallel computing is
increasing. Several organizations and companies are providing tools or
support for Python development. This includes libraries for scientific
computing, parallel computing, and MPI. Python is also used on many core
architectures and GPUs, for which specific Python interpreters are being
developed. A related topic is the performance of the various interpreter
and compiler implementations for Python. The talk gives an overview of
Python’s use in HPC and Scientific Computing and gives information on
many topics, such as Python on massively parallel systems, GPU
programming with Python, scientific libraries in Python, and Python
interpreter performance issues. The talk will include examples for
scientific codes and applications from many domains.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://bit.ly/k94rC4"&gt;Slides&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andreas Schreiber</dc:creator><pubDate>Wed, 13 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-13:europython-2011/python-for-high-performance-and-scientific-comput.html</guid><category>community</category><category>engineering</category><category>gpu</category><category>hpc</category><category>interpreters</category><category>parallel</category><category>performance</category><category>python,</category><category>scientific</category></item><item><title>Sfrutta la potenza della GPU con PyCUDA (e compagni)</title><link>https://pyvideo.org/europython-2011/sfrutta-la-potenza-della-gpu-con-pycuda-e-compag.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Stefano Brilli - 22 June 2011 in &amp;quot;Track Italiana Big
Mac &amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;CUDA è una tecnologia che permette di sfruttare la potenza di calcolo
delle moderne schede video prodotte da NVIDIA. In questo talk, dopo una
breve introduzione all'architettura della GPU, si vedrà come CUDA entra
all'interno di Python attraverso librerie come PyCUDA e non solo…&lt;/p&gt;
&lt;p&gt;Mediante alcuni esempi si metteranno in luce i concetti e le pratiche
fondamentali per una buona programmazione della GPU.&lt;/p&gt;
&lt;p&gt;Il talk è rivolto a chiunque voglia conoscere come sfruttare questa
tecnologia all'interno di Python, i casi in cui è conveniente
utilizzarla, le pratiche da adottare e le pratiche da non adottare per
trarre il massimo dalla propria GPU.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Stefano Brilli</dc:creator><pubDate>Wed, 13 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-13:europython-2011/sfrutta-la-potenza-della-gpu-con-pycuda-e-compag.html</guid><category>gpu</category><category>pycuda</category><category>python,</category></item><item><title>Python for High Performance Computing</title><link>https://pyvideo.org/pycon-us-2011/pycon-2011--python-for-high-performance-computing.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python for High Performance Computing&lt;/p&gt;
&lt;p&gt;Presented by William Scullin&lt;/p&gt;
&lt;p&gt;Python is becoming increasingly popular within the high performance
computing community. While it initially gained traction as a scripting
language, Python's role has continued to expand with Python applications
for science scaling to hundreds of thousands of cores and bindings to
high performance libraries becoming commonplace. This talk is meant as
an overview of Python's role in the HPC space.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;This talk is focused on raising awareness of Python in the high
performance computing space. Specific topics include:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;building the Python interpreter for speed&lt;/li&gt;
&lt;li&gt;an overview of bindings to numerical libraries&lt;/li&gt;
&lt;li&gt;using GPUs and accelerators with Python&lt;/li&gt;
&lt;li&gt;scaling codes with MPI&lt;/li&gt;
&lt;li&gt;issues when scaling on very large systems&lt;/li&gt;
&lt;li&gt;an overview of successful science codes&lt;/li&gt;
&lt;li&gt;a live demonstration of Python running on 163,840 cores&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">William Scullin</dc:creator><pubDate>Fri, 11 Mar 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-03-11:pycon-us-2011/pycon-2011--python-for-high-performance-computing.html</guid><category>gpu</category><category>highperformancecomputing</category><category>hpc</category><category>mpi</category><category>pycon</category><category>pycon2011</category></item></channel></rss>