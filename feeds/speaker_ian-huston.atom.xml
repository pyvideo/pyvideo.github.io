<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_ian-huston.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2016-11-06T00:00:00+00:00</updated><entry><title>Getting Started with Cloud Foundry for Data Science</title><link href="https://pyvideo.org/pydata-london-2015/getting-started-with-cloud-foundry-for-data-science.html" rel="alternate"></link><published>2015-06-19T00:00:00+00:00</published><updated>2015-06-19T00:00:00+00:00</updated><author><name>Ian Huston</name></author><id>tag:pyvideo.org,2015-06-19:pydata-london-2015/getting-started-with-cloud-foundry-for-data-science.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Cloud Foundry is an open source Platform-as-a-Service that can be
used to easily deliver data driven applications. In this tutorial we
will learn how to push an application to a real CF instance, how to
connect to managed data services like Redis and PostgreSQL and how to
deploy PyData and R projects using community buildpacks.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;a class="reference external" href="http://cloudfoundry.org/"&gt;Cloud Foundry&lt;/a&gt; is an open source
Platform-as-a- Service that can be used to easily deliver data driven
applications. In this tutorial we will learn how to push an application
to a real CF instance, how to connect to managed data services like
Redis and PostgreSQL and how to deploy PyData and R projects using
community buildpacks.&lt;/p&gt;
&lt;p&gt;By the end of the tutorial participants will know how to _ deploy your
first app using Cloud Foundry, _ connect to databases and other data
services, _ use PyData packages with a Heroku-style buildpack, _ find
public and private Cloud Foundry installation options.&lt;/p&gt;
&lt;p&gt;Participants will need to register on a public Cloud Foundry instance to
follow along with the tutorial. Detailed instructions will be provided
for &lt;a class="reference external" href="http://run.pivotal.io/"&gt;Pivotal Web Services&lt;/a&gt; which offers a 60
day free trial. Other options include IBM Bluemix and HP Helion
Development Platform.&lt;/p&gt;
&lt;p&gt;Participants should be comfortable on the command line and download and
install the &lt;a class="reference external" href="http://docs.cloudfoundry.org/devguide/installcf/install-go-cli.html"&gt;CF CLI
tools&lt;/a&gt;
before the tutorial.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Massively Parallel Processing with Procedural Python</title><link href="https://pyvideo.org/pydata-london-2014/massively-parallel-processing-with-procedural-python.html" rel="alternate"></link><published>2014-02-22T00:00:00+00:00</published><updated>2014-02-22T00:00:00+00:00</updated><author><name>Ian Huston</name></author><id>tag:pyvideo.org,2014-02-22:pydata-london-2014/massively-parallel-processing-with-procedural-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Python data ecosystem has grown beyond the confines of single
machines to embrace scalability. Here we describe one of our approaches
to scaling, which is already being used in production systems. The goal
of in-database analytics is to bring the calculations to the data,
reducing transport costs and I/O bottlenecks. Using PL/Python we can run
parallel queries across terabytes of data using not only pure SQL but
also familiar PyData packages such as scikit- learn and nltk. This
approach can also be used with PL/R to make use of a wide variety of R
packages. We look at examples on Postgres compatible systems such as the
Greenplum Database and on Hadoop through Pivotal HAWQ. We will also
introduce MADlib, Pivotal’s open source library for scalable in-database
machine learning, which uses Python to glue SQL queries to low level C++
functions and is also usable through the PyMADlib package.&lt;/p&gt;
</summary></entry><entry><title>How Data Science fits in the Balanced Team</title><link href="https://pyvideo.org/pycon-ireland-2016/how-data-science-fits-in-the-balanced-team.html" rel="alternate"></link><published>2016-11-06T00:00:00+00:00</published><updated>2016-11-06T00:00:00+00:00</updated><author><name>Ian Huston</name></author><id>tag:pyvideo.org,2016-11-06:pycon-ireland-2016/how-data-science-fits-in-the-balanced-team.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The goal of a Balanced Team is to share ownership and responsibility
for the success of a project between team members. Each team member
has specific obligations to the team and a specific area of authority.
Until recently, designers, product managers and developers were the
usual team members considered. In this talk I will explore how data
scientists can function in a balanced team and discuss my experience
working as a data scientist on balanced teams at Pivotal Labs with our
global clients. I will consider what obligations and authority a data
scientist can provide as part of a balanced team and how this
situation differs from the usual jack-of-all-trades type data science
work. I will outline specific examples where data science can help
user centric design and product management, and where the practices of
lean-startup and agile development can help accelerate analysis and
data science. Based on my experience building data science driven
products with a global bank and European car manufacturers, I will
outline what we tried, what worked and most importantly what didn’t.&lt;/p&gt;
&lt;p&gt;If you are a data scientist or need to work with one, this talk will
equip you to understand how data science can be an integral part of a
balanced team.&lt;/p&gt;
</summary></entry></feed>