<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 10 Nov 2018 00:00:00 +0000</lastBuildDate><item><title>High Performance Data Processing in Python</title><link>https://pyvideo.org/pycon-ireland-2018/high-performance-data-processing-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;numpy and numba are popular Python libraries for processing large quantities of data. When running complex transformations on large datasets, many developers fall into common pitfalls that kill the performance of these libraries. This talk explains how numpy/numba work under the hood and how they use vectorisation to process large amounts of data extremely quickly. We use these tools to reduce the processing time of a dataset from 3 years to 12 hours, even when the code is run on a single Macbook Pro.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Donald Whyte</dc:creator><pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-11-10:pycon-ireland-2018/high-performance-data-processing-in-python.html</guid><category>numpy</category><category>numba</category></item><item><title>High Performance Data Processing in Python</title><link>https://pyvideo.org/pycon-russia-2018/high-performance-data-processing-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Donald Whyte&lt;/strong&gt; , Engineers Gate&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://pycon.ru/2018/en/program/content/whyte/"&gt;**High Performance Data Processing in
Python**&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Internet age generates vast amounts of data. Most of this data is
unstructured and needs to cleaned. Python has become the standard tool
for transforming this data into more useable forms.&lt;/p&gt;
&lt;p&gt;numpy and pandas are the most popular Python libraries for processing
large quantities of data. For small datasets, these libraries do the job
without much effort. However, when running complex transformations on
larger datasets, many developers fall into common pitfalls that kill the
performance of these libraries.&lt;/p&gt;
&lt;p&gt;This talk explains how numpy and pandas work under the hood and how they
use vectorisation to process large amounts of data extremely quickly. We
show an example dataset being processed using numpy/pandas. We
demonstrate how to use these libraries effectively, reducing the
processing time of this large dataset from several hours to seconds.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Donald Whyte</dc:creator><pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-06-22:pycon-russia-2018/high-performance-data-processing-in-python.html</guid></item></channel></rss>