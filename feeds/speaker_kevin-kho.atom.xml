<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Kevin Kho</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_kevin-kho.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2024-05-18T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Large Scale Data Validation (with Spark and Dask)</title><link href="https://pyvideo.org/pycon-us-2021/large-scale-data-validation-with-spark-and-dask.html" rel="alternate"></link><published>2021-05-14T00:00:00+00:00</published><updated>2021-05-14T00:00:00+00:00</updated><author><name>Kevin Kho</name></author><id>tag:pyvideo.org,2021-05-14:/pycon-us-2021/large-scale-data-validation-with-spark-and-dask.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Data validation is checking if data follows certain requirements needed for data pipelines to run reliably. It is used by data scientists and data engineers to preserve the integrity of existing workflows, especially as they get modified. As an example, extreme machine learning predictions can be stopped from being …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Data validation is checking if data follows certain requirements needed for data pipelines to run reliably. It is used by data scientists and data engineers to preserve the integrity of existing workflows, especially as they get modified. As an example, extreme machine learning predictions can be stopped from being displayed to application users if a new model is bad. Missing data can be flagged if it has the potential to break downstream operations.&lt;/p&gt;
&lt;p&gt;As data volume continues to increase, we will examine how data validation differs between a single-machine setting and a distributed computing setting. We will show what validations become more computationally expensive in Spark and Dask. For large scale data, there is sometimes also a need to apply different validations on different partitions of data. This is currently not feasible with any single library. In this talk, we will show how we can achieve this by combining the strengths of different frameworks.&lt;/p&gt;
&lt;p&gt;To demonstrate the data validation journey, we'll go over a fictitious case study. The data will start small, and we'll apply Pandas-based validations with Pandera and Great Expectations while discussing the pros and cons of each. As data size increases, we'll go over in detail the pain points of transitioning to a distributed setting. We'll show one way to reuse the same Pandas-based validations on Spark and Dask by wrapping them with Fugue.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://drive.google.com/file/d/1x3w4pfk8PVw1dcy1717Qi-_kt67xQj-S/view?usp=sharing"&gt;https://drive.google.com/file/d/1x3w4pfk8PVw1dcy1717Qi-_kt67xQj-S/view?usp=sharing&lt;/a&gt;&lt;/p&gt;
</content><category term="PyCon US 2021"></category></entry><entry><title>Comparing the Different Ways to Scale Python and Pandas Code</title><link href="https://pyvideo.org/pycon-us-2022/comparing-the-different-ways-to-scale-python-and-pandas-code.html" rel="alternate"></link><published>2022-04-27T00:00:00+00:00</published><updated>2022-04-27T00:00:00+00:00</updated><author><name>Kevin Kho</name></author><id>tag:pyvideo.org,2022-04-27:/pycon-us-2022/comparing-the-different-ways-to-scale-python-and-pandas-code.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Fugue is an open-source unified interface for Pandas, Spark, and Dask that aims to let data practitioners define their compute workflows in a scale-agnostic manner. By decoupling logic and execution, users can code in a language that they are familiar with (Python, Pandas or SQL), and then choose an …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Fugue is an open-source unified interface for Pandas, Spark, and Dask that aims to let data practitioners define their compute workflows in a scale-agnostic manner. By decoupling logic and execution, users can code in a language that they are familiar with (Python, Pandas or SQL), and then choose an execution engine to run it on (Pandas, Spark or Dask). In this talk, we cover the transform() function, which lets a user execute a single function in a distributed setting. This simple interface can be incrementally adopted and allows data practitioners to be productive with distributed computing very quickly.&lt;/p&gt;
</content><category term="PyCon US 2022"></category></entry><entry><title>Speed is Not All You Need for Data Processing</title><link href="https://pyvideo.org/pycon-us-2024/speed-is-not-all-you-need-for-data-processing.html" rel="alternate"></link><published>2024-05-18T00:00:00+00:00</published><updated>2024-05-18T00:00:00+00:00</updated><author><name>Kevin Kho</name></author><id>tag:pyvideo.org,2024-05-18:/pycon-us-2024/speed-is-not-all-you-need-for-data-processing.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas was the dominant local data processing framework for majority of
the last decade. Now, there are many other options available like Polars
and DuckDB. Is it worth switching to them? One of the main reasons
developers switch is because of the supposed speed. TPCH benchmarks show
Polars and …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas was the dominant local data processing framework for majority of
the last decade. Now, there are many other options available like Polars
and DuckDB. Is it worth switching to them? One of the main reasons
developers switch is because of the supposed speed. TPCH benchmarks show
Polars and DuckDB are an order of magnitude faster than Pandas (and
Dask) because of the Rust-based or C++ implementation.&lt;/p&gt;
&lt;p&gt;For large-scale data, we are often told to use pure native Spark
whenever possible. Pandas UDFs are often discouraged because they are
deemed as a bottleneck. The optimizer works best when it can see the
entire query plan, but Pandas UDFs are a black box.&lt;/p&gt;
&lt;p&gt;But as practitioners, we have to ask two related questions: 1. Are these
assumptions true? Is it universally true that Pandas and Pandas UDFs are
slower? 2. Even if it it slower, is it worth the development overhead to
avoid using Pandas?&lt;/p&gt;
&lt;p&gt;In this talk, we'll show benchmarks across data of various sizes to show
that these common assumptions are not always true. In fact, we'll see
that Pandas UDFs can actually be faster than native Spark in some cases.
With this result in mind, data practitioners should just focus on the
tools that serve them best rather than adjusting to the tools.&lt;/p&gt;
</content><category term="PyCon US 2024"></category></entry><entry><title>Introduction to Workflow Orchestration with Prefect</title><link href="https://pyvideo.org/scipy-2022/introduction-to-workflow-orchestration-with-prefect.html" rel="alternate"></link><published>2022-07-11T00:00:00+00:00</published><updated>2022-07-11T00:00:00+00:00</updated><author><name>Kevin Kho</name></author><id>tag:pyvideo.org,2022-07-11:/scipy-2022/introduction-to-workflow-orchestration-with-prefect.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Workflow management systems are used for scheduling and monitoring data pipelines. This includes managing task dependencies, retrying failed tasks, and sending notifications to users. This talk will show data engineers and scientists how to orchestrate their data workflows with Prefect, an open-source modern workflow management system designed with Dask …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Workflow management systems are used for scheduling and monitoring data pipelines. This includes managing task dependencies, retrying failed tasks, and sending notifications to users. This talk will show data engineers and scientists how to orchestrate their data workflows with Prefect, an open-source modern workflow management system designed with Dask natively built-in. After this talk, attendees should understand the basics of workflow orchestration and how to get started implementing it for their use cases&lt;/p&gt;
</content><category term="SciPy 2022"></category></entry></feed>