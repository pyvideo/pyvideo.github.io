<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Michele Dallachiesa</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_michele-dallachiesa.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2024-07-08T00:00:00+00:00</updated><subtitle></subtitle><entry><title>MLtraq: Track your ML/AI experiments at hyperspeed</title><link href="https://pyvideo.org/europython-2024/mltraq-track-your-mlai-experiments-at-hyperspeed.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Michele Dallachiesa</name></author><id>tag:pyvideo.org,2024-07-08:/europython-2024/mltraq-track-your-mlai-experiments-at-hyperspeed.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[EuroPython 2024 — Terrace 2A on 2024-07-12]&lt;/p&gt;
&lt;p&gt;MLtraq: Track your ML/AI experiments at hyperspeed by Michele Dallachiesa&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://ep2024.europython.eu/session/mltraq-track-your-ml-ai-experiments-at-hyperspeed"&gt;https://ep2024.europython.eu/session/mltraq-track-your-ml-ai-experiments-at-hyperspeed&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Every second spent waiting for initializations and obscure delays hindering high-frequency logging, further limited by what you can track, an experiment dies. Wouldn’t loading and …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[EuroPython 2024 — Terrace 2A on 2024-07-12]&lt;/p&gt;
&lt;p&gt;MLtraq: Track your ML/AI experiments at hyperspeed by Michele Dallachiesa&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://ep2024.europython.eu/session/mltraq-track-your-ml-ai-experiments-at-hyperspeed"&gt;https://ep2024.europython.eu/session/mltraq-track-your-ml-ai-experiments-at-hyperspeed&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Every second spent waiting for initializations and obscure delays hindering high-frequency logging, further limited by what you can track, an experiment dies. Wouldn’t loading and starting tracking in nearly zero time be nice? What if we could track more and faster, even handling arbitrarily large, complex Python objects with ease?&lt;/p&gt;
&lt;p&gt;In this talk, I will present the results of comparative benchmarks covering Weights &amp;amp; Biases, MLflow, FastTrackML, Neptune, Aim, Comet, and MLtraq. You will learn their strengths and weaknesses, what makes them slow and fast, and what sets MLtraq apart, making it 100x faster and capable of handling tens of thousands of experiments.&lt;/p&gt;
&lt;p&gt;This presentation will not only be enlightening for those involved in AI/ML experimentation but will also be invaluable for anyone interested in the efficient and safe serialization of Python objects.&lt;/p&gt;
&lt;p&gt;---&lt;/p&gt;
&lt;p&gt;This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License: &lt;a class="reference external" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;https://creativecommons.org/licenses/by-nc-sa/4.0/&lt;/a&gt;&lt;/p&gt;
</content><category term="EuroPython 2024"></category></entry><entry><title>Accelerating Public Consultations with Large Language Models</title><link href="https://pyvideo.org/pydata-berlin-2023/accelerating-public-consultations-with-large-language-models.html" rel="alternate"></link><published>2023-04-17T00:00:00+00:00</published><updated>2023-04-17T00:00:00+00:00</updated><author><name>Michele Dallachiesa</name></author><id>tag:pyvideo.org,2023-04-17:/pydata-berlin-2023/accelerating-public-consultations-with-large-language-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Local Planning Authorities (LPAs) in the UK rely on written representations from the community to inform their Local Plans which outline development needs for their area. With an average of 2000 representations per consultation and 4 rounds of consultation per Local Plan, the volume of information can be overwhelming …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Local Planning Authorities (LPAs) in the UK rely on written representations from the community to inform their Local Plans which outline development needs for their area. With an average of 2000 representations per consultation and 4 rounds of consultation per Local Plan, the volume of information can be overwhelming for both LPAs and the Planning Inspectorate tasked with examining the legality and soundness of plans. In this study, we investigate the potential for Large Language Models (LLMs) to streamline representation analysis.&lt;/p&gt;
&lt;p&gt;We find that LLMs have the potential to significantly reduce the time and effort required to analyse representations, with simulations on historical Local Plans projecting a reduction in processing time by over 30%, and experiments showing classification accuracy of up to 90%.&lt;/p&gt;
&lt;p&gt;In this presentation, we discuss our experimental process which used a distributed experimentation environment with Jupyter Lab and cloud resources to evaluate the performance of the BERT, RoBERTa, DistilBERT, and XLNet models. We also discuss the design and prototyping of web applications to support the aided processing of representations using Voilà, FastAPI, and React. Finally, we highlight successes and challenges encountered and suggest areas for future improvement.&lt;/p&gt;
</content><category term="PyData Berlin 2023"></category></entry></feed>