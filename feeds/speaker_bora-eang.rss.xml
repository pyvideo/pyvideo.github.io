<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Tue, 14 Apr 2015 00:00:00 +0000</lastBuildDate><item><title>Why and how to explain machine learning predictions</title><link>https://pyvideo.org/pydata-paris-2015/why-and-how-to-explain-machine-learning-predictio.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Unfortunately, the predictive models that are most powerful are usually
the least interpretable. However in some cases, for example fraud
detection, end users need an understandable explanation of a particular
prediction, at observation level, and not only at population level (e.g.
: features importance). During this talk we will present different
approaches to tackle this issue, both for random forests and gradient
boosting trees. We will also demonstrate an implementation based on
scikit-learn.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bora Eang</dc:creator><pubDate>Tue, 14 Apr 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-04-14:pydata-paris-2015/why-and-how-to-explain-machine-learning-predictio.html</guid></item></channel></rss>