<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_peterwolf.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-09-20T00:00:00+00:00</updated><entry><title>寫個能幹的中文斷詞系統</title><link href="https://pyvideo.org/pycon-taiwan-2019/xie-ge-neng-gan-de-zhong-wen-duan-ci-xi-tong.html" rel="alternate"></link><published>2019-09-20T00:00:00+00:00</published><updated>2019-09-20T00:00:00+00:00</updated><author><name>PeterWolf</name></author><id>tag:pyvideo.org,2019-09-20:pycon-taiwan-2019/xie-ge-neng-gan-de-zhong-wen-duan-ci-xi-tong.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Day 1, R2 14:50–15:35&lt;/p&gt;
&lt;p&gt;我們利用語言學的中文句法原則，從零開始打造了一套中文斷詞引擎 - 文截斷詞 (Articut)，而且不只斷詞，它還能推理詞性標記。&lt;/p&gt;
&lt;p&gt;本演講將分享一點點中文語言學 (雖然深度不足以理解程式邏輯)、我們在開發過程中遇到的有趣語料和斷詞結果 (可能會有些冷場)以及 Python3 的 Unicode 如何省下我們和字串編碼戰鬥的力氣 (還有 Python3.5 的 re 模組有什麼問題…啊啊，扯遠了)、還有看著 Articut 犯下和人類孩童一樣的語言錯誤時的感動(底特律變人嗎？)、以不同斷詞引擎處理特殊語料的修羅場 (我們對同領域的前輩還是非常尊敬的)以及最後用 SIGHAN 2005 的資料集，和其它文獻中的演算法進行良率競爭的結果。&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://github.com/Droidtown/PyConTW2019"&gt;https://github.com/Droidtown/PyConTW2019&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speaker: PeterWolf&lt;/p&gt;
&lt;p&gt;Droidtown Linguistic Tech. Co. (卓騰語言科技) 創辦人兼核心開發者。&lt;/p&gt;
&lt;p&gt;平常開發基於語言學理論的中文斷詞(NLP)、中文語意處理(NLU)、自動語音處理、語音辨識、自然語言文本解析及資料探勘的演算法及前端應用。&lt;/p&gt;
&lt;p&gt;是一個覺得流浪很美，卻差一點成為流浪漢的大叔。&lt;/p&gt;
</summary></entry></feed>