<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_eoin-brazil.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-11-10T00:00:00+00:00</updated><entry><title>Adding the three pillars of Observibility to your Python app</title><link href="https://pyvideo.org/pycon-ireland-2018/adding-the-three-pillars-of-observibility-to-your-python-app.html" rel="alternate"></link><published>2018-11-10T00:00:00+00:00</published><updated>2018-11-10T00:00:00+00:00</updated><author><name>Eoin Brazil</name></author><id>tag:pyvideo.org,2018-11-10:pycon-ireland-2018/adding-the-three-pillars-of-observibility-to-your-python-app.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This intermediate level talk will focus on introducing the three pillars of Observibility (1: structured logging 2: metrics 3: tracing) to your Python application. The learning objective is to introduce existing Python developers to each area as well as best practices (RED/four golden signals) and the specific Python libraries they can use in their applications. It aim is that by the end people will know how to add specific tools plus related best practices to their existing applications to provide greater insight into their systems. The closest example is that this talk will pragmatically present the content of &amp;quot;Distributed Systems Observibility&amp;quot; O'Reilly into concrete actions and libraries to use. Some anecdotes and examples of how these have gone for the speaker in his production systems will also be noted.&lt;/p&gt;
</summary><category term="best-practices"></category></entry><entry><title>Two approaches to scale your processing, Task Queues and Workflows</title><link href="https://pyvideo.org/pycon-ireland-2017/two-approaches-to-scale-your-processing-task-queues-and-workflows.html" rel="alternate"></link><published>2017-10-21T00:00:00+00:00</published><updated>2017-10-21T00:00:00+00:00</updated><author><name>Eoin Brazil</name></author><id>tag:pyvideo.org,2017-10-21:pycon-ireland-2017/two-approaches-to-scale-your-processing-task-queues-and-workflows.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk covers two useful libraries/approaches to scaling your processing. Task Queues will be introduced, Celery will be covered and a specific example of a refactoring of a sequential crawler to highlight the ease and utility of this library. Workflows will then be covered, Airflow will be introduced, in the context of more complex tasks with requirements plus dependencies, building on how tasks as the atomic unit can be woven together to support complex business / app requirements as Workflows. The theme linking both aspects is the need to provide a reliable async fabric (Celery + Rabbitmq) only provides part of a solution for more complex problems, hence the need to use Airflow (with Celery executors) to provide the additional smarts / logic necessary to solve them.&lt;/p&gt;
</summary><category term="airflow"></category><category term="celery"></category></entry><entry><title>Using MongoDB and Python for data analysis pipelines (PyData)</title><link href="https://pyvideo.org/pycon-ireland-2015/using-mongodb-and-python-for-data-analysis-pipelines-pydata.html" rel="alternate"></link><published>2015-10-24T00:00:00+00:00</published><updated>2015-10-24T00:00:00+00:00</updated><author><name>Eoin Brazil</name></author><id>tag:pyvideo.org,2015-10-24:pycon-ireland-2015/using-mongodb-and-python-for-data-analysis-pipelines-pydata.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;MongoDB is a flexible, scalable, and ease to use way of storing your large data set. Python provides many useful data science tools (e.g. NumPy, SciPy, Scikit-learn, etc.). Unfortunately, they don't work well together, one of the bottlenecks is the inefficiency of loading MongoDB data into NumPy array.&lt;/p&gt;
&lt;p&gt;This talk will discuss the concerns for creating operational data analytic pipelines, introduce Monary as alternative for loading data into NumPy, and give examples of accessing data with Monary, as well as how to build scalable data analysis pipelines using these open source tools.&lt;/p&gt;
</summary></entry><entry><title>Gradient boosting: What is it and How can I use in my machine learning ?</title><link href="https://pyvideo.org/pycon-ireland-2016/gradient-boosting-what-is-it-and-how-can-i-use-in-my-machine-learning.html" rel="alternate"></link><published>2016-11-06T00:00:00+00:00</published><updated>2016-11-06T00:00:00+00:00</updated><author><name>Eoin Brazil</name></author><id>tag:pyvideo.org,2016-11-06:pycon-ireland-2016/gradient-boosting-what-is-it-and-how-can-i-use-in-my-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Gradient boosting is a very popular technique in Machine Learning and
particularly so for competitions like those hosted by Kaggle. This talk
will provide an introduction to the technique, a short historical recap
and then focus on the existing libraries in Python that allow you to use
this general family. It'll work through the advantages and disadvantage
of specific libraries using worked examples. The code and slides will be
in Github. The end learning of attendees will be sufficient knowledge to
understand when to use this technique and what is the most appropriate
Python library for their needs.&lt;/p&gt;
</summary></entry></feed>