<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 13 Jul 2019 00:00:00 +0000</lastBuildDate><item><title>How to Accelerate an Existing Codebase with Numba</title><link>https://pyvideo.org/scipy-2019/how-to-accelerate-an-existing-codebase-with-numba.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you have ever said to yourself &amp;quot;my code works, but it is too slow!&amp;quot; then this is the talk for you. We will describe best practices for applying the Numba just-in-time compiler to an existing project. This includes techniques for assessing whether Numba is appropriate for your use case, analyzing your program to identify where Numba can help, modifying your core algorithms to be Numba compatible, and understanding compiler errors. In addition, we'll discuss considerations for packaging and distribution of projects that depend on Numba.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Siu Kwan Lam</dc:creator><pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-13:scipy-2019/how-to-accelerate-an-existing-codebase-with-numba.html</guid></item><item><title>Scaling Up and Out Programming GPU Clusters with Numba and Dask</title><link>https://pyvideo.org/scipy-2016/scaling-up-and-out-programming-gpu-clusters-with-numba-and-dask-scipy-2016-siu-kwan-lam.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, we show how Python, Numba, and Dask can be used for GPU programming that easily scales from your workstation to a cluster, and can be controlled entirely from a Jupyter notebook. We will describe how the Numba JIT compiler can be used to create and compile GPU calculations entirely from the Python interpreter, and how the Dask task scheduling system can be used to farm these calculations out to a GPU cluster. Using an image processing example application, we will show how these two projects make it easy to iterate and experiment with algorithms on large data sets. Finally, we will conclude with tips and tricks for working with GPUs and distributed computing.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Siu Kwan Lam</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/scaling-up-and-out-programming-gpu-clusters-with-numba-and-dask-scipy-2016-siu-kwan-lam.html</guid><category>SciPy 2016</category></item></channel></rss>