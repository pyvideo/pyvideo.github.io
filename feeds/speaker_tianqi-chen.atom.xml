<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Tianqi Chen</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_tianqi-chen.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2024-09-18T00:00:00+00:00</updated><subtitle></subtitle><entry><title>DL Compiler Panel Discussion</title><link href="https://pyvideo.org/pytorch-conference-2024/dl-compiler-panel-discussion.html" rel="alternate"></link><published>2024-09-18T00:00:00+00:00</published><updated>2024-09-18T00:00:00+00:00</updated><author><name>Philip Tillet</name></author><id>tag:pyvideo.org,2024-09-18:/pytorch-conference-2024/dl-compiler-panel-discussion.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;DL Compiler Panel Discussion - Philip Tillet, OpenAI; Jason Ansel, Meta; Jacques Pienaar, Google; Tianqi Chen, CMU &amp;amp; OctoAI; Mikhail Zolotukhin, Modular; Peng Wu, Meta&lt;/p&gt;
&lt;p&gt;Since the release of PyTorch 2 in 2023, torch.compile() has spurred significant new thinking around DL compiler designs at the framework level. In this session …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;DL Compiler Panel Discussion - Philip Tillet, OpenAI; Jason Ansel, Meta; Jacques Pienaar, Google; Tianqi Chen, CMU &amp;amp; OctoAI; Mikhail Zolotukhin, Modular; Peng Wu, Meta&lt;/p&gt;
&lt;p&gt;Since the release of PyTorch 2 in 2023, torch.compile() has spurred significant new thinking around DL compiler designs at the framework level. In this session, we invite leaders in this space to share their insights based on real experiences of building DL compilers – Triton, TorchInductor, Halide, TVM, OpenXLA, and Mojo – and growing their ecosystems. We also invite a ‘compiler user representative,’ together.ai, to share their recent journey of redesigning the LLM inference stack around torch.compile(). Each leader will give a 10-minute lightning talk and an engaging panel discussion.&lt;/p&gt;
</content><category term="PyTorch Conference 2024"></category></entry><entry><title>Universally Deploy Large-language Models via ML Compilation</title><link href="https://pyvideo.org/pytorch-conference-2024/universally-deploy-large-language-models-via-ml-compilation.html" rel="alternate"></link><published>2024-09-18T00:00:00+00:00</published><updated>2024-09-18T00:00:00+00:00</updated><author><name>Tianqi Chen</name></author><id>tag:pyvideo.org,2024-09-18:/pytorch-conference-2024/universally-deploy-large-language-models-via-ml-compilation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deploying deep learning models on various devices has become an important topic. Machine learning compilation is an emerging field that leverages compiler and automatic search techniques to accelerate AI models. ML compilation brings a unique set of challenges: emerging machine learning models; increasing hardware specialization brings a diverse set …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deploying deep learning models on various devices has become an important topic. Machine learning compilation is an emerging field that leverages compiler and automatic search techniques to accelerate AI models. ML compilation brings a unique set of challenges: emerging machine learning models; increasing hardware specialization brings a diverse set of acceleration primitives; growing tension between flexibility and performance. In this talk. I then discuss our experience in bringing foundational models to a variety of devices and hardware environments through machine learning compilation.&lt;/p&gt;
</content><category term="PyTorch Conference 2024"></category></entry></feed>