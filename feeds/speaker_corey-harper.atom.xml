<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_corey-harper.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2017-10-06T00:00:00+00:00</updated><entry><title>Tracing the flow of knowledge using Pyspark</title><link href="https://pyvideo.org/pygotham-2017/tracing-the-flow-of-knowledge-using-pyspark.html" rel="alternate"></link><published>2017-10-06T00:00:00+00:00</published><updated>2017-10-06T00:00:00+00:00</updated><author><name>Jessica Cox</name></author><id>tag:pyvideo.org,2017-10-06:pygotham-2017/tracing-the-flow-of-knowledge-using-pyspark.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will be focused on doing Natural Language Processing (NLP) in a Python-based Spark environment using PySpark. Examples will be drawn from a Citing Sentences project underway within Elsevier Labs (&lt;a class="reference external" href="http://labs.elsevier.com/"&gt;http://labs.elsevier.com/&lt;/a&gt;). The goal of this project is to build and analyze citation networks to understand the diffusion and flow of ideas through the scientific research landscape. Much like a social network, scientists want to understand how others are ‘talking’ about their papers.  Are they supporting their work?  Disagreeing with it?  Is it being referred to as a discovery?&lt;/p&gt;
&lt;p&gt;The development of our input datasets is out of scope for this talk, partly because the framework for citing sentence extraction is built out in Spark Scala rather than PySpark. However, our citing sentence dataframe formats will be described and documented and sample data will be provided so that others can explore and reproduce our analyses.&lt;/p&gt;
&lt;p&gt;The presentation will cover:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Reformatting, manipulating, and combining dataframes to meet specific analysis needs&lt;/li&gt;
&lt;li&gt;Preparing data for use with NLP tools and techniques&lt;/li&gt;
&lt;li&gt;Using PySpark, SparkSQL, SparkML and other Spark libraries within Python code to perform NLP&lt;/li&gt;
&lt;li&gt;Moving Spark Dataframes in and out of Pandas for additional analysis and to do visualizations&lt;/li&gt;
&lt;li&gt;Performing additional natural language analysis in NLTK within the PySpark environment&lt;/li&gt;
&lt;li&gt;Generating export formats suitable for other tools, such as for visualization with Gephi&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following code will be provided for audience members to return to the topic and continue learning after the event:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;A &amp;quot;Community Edition&amp;quot; DataBricks compatible notebook with &amp;nbsp;SparkML, SparkSQL, &amp;nbsp;PySpark, and NLTK code&lt;/li&gt;
&lt;li&gt;A sample datafile of citing sentences from Elsevier's CCBY-licensed articles&lt;/li&gt;
&lt;/ul&gt;
</summary></entry></feed>