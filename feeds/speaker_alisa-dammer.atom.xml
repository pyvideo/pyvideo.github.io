<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_alisa-dammer.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-07-10T00:00:00+00:00</updated><entry><title>Python vs Rust for Simulation</title><link href="https://pyvideo.org/europython-2019/python-vs-rust-for-simulation.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Alisa Dammer</name></author><id>tag:pyvideo.org,2019-07-10:europython-2019/python-vs-rust-for-simulation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Both Python and Rust are getting more and more popularity. Although it
is unfair to compare them directly, this talk aims to provide a clear
comparison with a pre-defined criteria applied to a specific use-case.&lt;/div&gt;
&lt;div class="line"&gt;Writing a simulation engine is very similar to writing a game engine
and requires certain features from a language or framework.&lt;/div&gt;
&lt;div class="line"&gt;Possible comparison criteria:&lt;/div&gt;
&lt;div class="line"&gt;1. Performance&lt;/div&gt;
&lt;div class="line"&gt;2. Simplicity&lt;/div&gt;
&lt;div class="line"&gt;3. Amount of code necessary for a MVP&lt;/div&gt;
&lt;div class="line"&gt;4. Utilities: docs, tests, profile&lt;/div&gt;
&lt;div class="line"&gt;5. Compatibility&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Tl;dr&lt;/div&gt;
&lt;div class="line"&gt;Do I want to go back to Python after Rust? Maybe+)&lt;/div&gt;
&lt;/div&gt;
</summary><category term="Code Analysis"></category><category term="Development"></category><category term="Rust"></category><category term="python"></category></entry><entry><title>Data is not flat</title><link href="https://pyvideo.org/europython-2018/data-is-not-flat.html" rel="alternate"></link><published>2018-07-26T00:00:00+00:00</published><updated>2018-07-26T00:00:00+00:00</updated><author><name>Alisa Dammer</name></author><id>tag:pyvideo.org,2018-07-26:europython-2018/data-is-not-flat.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Feature engineering and model training often comes hand in hand. Some
tasks have an overwhelming amount of high dimensional data, some tasks
have little data or very low-dimension data. This talk targets the
latter problem: what can be done with the data itself to significantly
improve the model performance and when manual feature engineering does
make sense.&lt;/div&gt;
&lt;div class="line"&gt;A sample case of Classification problem with NN will be presented The
goal of the talk is to remind about something every person working
with the data thinks and probably uses. Slides, Jupyter notebook with
the example, test and train sets, NN configuration file are available
on: &lt;a class="reference external" href="https://github.com/Alisa"&gt;https://github.com/Alisa&lt;/a&gt;- lisa/conferences&lt;/div&gt;
&lt;/div&gt;
</summary></entry><entry><title>Baby steps in short-text classification with python</title><link href="https://pyvideo.org/europython-2017/baby-steps-in-short-text-classification-with-python.html" rel="alternate"></link><published>2017-07-12T00:00:00+00:00</published><updated>2017-07-12T00:00:00+00:00</updated><author><name>Alisa Dammer</name></author><id>tag:pyvideo.org,2017-07-12:europython-2017/baby-steps-in-short-text-classification-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk aims to provide an information about where and how one could
start using simple text-classification models.
Additionally it will be shown how a python classificator  can be incorporated
into existing system.
The presentation will be broken into 3 topics and a conclusion.&lt;/p&gt;
&lt;p&gt;First, the presentation provides an overview of how the problem was
approached, what information was useful or not and how the technologies
tack shown in the second part was decided on.&lt;/p&gt;
&lt;p&gt;Second part will concentrate on using Naive Bayesian model for text classification.
How the model was trained, what difficulties were met and how they were solved.
Additionally the talk will give a brief overview of other possible model choices
(random forest, SVM).&lt;/p&gt;
&lt;p&gt;The third part will show how the model was deployed and used in the
production. One architecture solution will be shown in details
(REST calls between Java Client and Flask Server), while other
possibilities will be mentioned briefly.&lt;/p&gt;
&lt;p&gt;As the conclusion the possible improvements for the model in use will
be suggested as well as short example of supervised learning algorithm
(CNN) and unsupervised classification algorithm (LDA) for the same purpose.
Along with the examples the proc and cons will be named.&lt;/p&gt;
&lt;p&gt;Technologies mentioned and used: Flask, Green Unicorn vs uWSGI, NLTK,
Sci-Kit, Python 3, Java 8, Jersey, Docker, Kubernetes&lt;/p&gt;
</summary></entry></feed>