<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - computer vision</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 26 Oct 2024 00:00:00 +0000</lastBuildDate><item><title>AI in Contemporary Art</title><link>https://pyvideo.org/europython-2019/ai-in-contemporary-art.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Over the past couple of years, there has been increasing interest in
applying the latest advances in machine learning to creative projects in
art and design. From DeepDream and style transfer to a GAN-generated
painting selling for $430,000 at auction, AI art has moved beyond the
world of research and academia and become a trend in its own right.
Meanwhile, the contemporary art world's fascination with the social
impact of facial recognition, recommendation systems and deep fakes has
encouraged artists to explore AI critically as subject matter. This talk
will give an overview of how artists and technologists are using and
thinking about machine learning, its creative potential and societal
impact.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Luba Elliott</dc:creator><pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-11:/europython-2019/ai-in-contemporary-art.html</guid><category>EuroPython 2019</category><category>Algorithms</category><category>Computer Vision</category><category>Deep Learning</category></item><item><title>Image processing with scikit-image and Dash</title><link>https://pyvideo.org/europython-2019/image-processing-with-scikit-image-and-dash.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Images are an ubiquitous form of data in various fields of science and&lt;/div&gt;
&lt;div class="line"&gt;industry. Images often need to be transformed and processed, for
example for helping medical diagnosis by extracting regions of
interest or measures, or for building training sets for machine
learning.&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;In this talk, I will present and discuss several tools for automatic
and&lt;/div&gt;
&lt;div class="line"&gt;interactive image processing with Python. I will start by a short&lt;/div&gt;
&lt;div class="line"&gt;introduction to scikit-image (&lt;a class="reference external" href="https://scikit-image.org/"&gt;https://scikit-image.org/&lt;/a&gt;), the
open-source&lt;/div&gt;
&lt;div class="line"&gt;image processing toolkit of the Pydata ecosystem, which aims at&lt;/div&gt;
&lt;div class="line"&gt;processing images from a large class of modalities (2-D, 3-D, etc.)
and&lt;/div&gt;
&lt;div class="line"&gt;strives to have a gentle learning curve with pedagogical example-based&lt;/div&gt;
&lt;div class="line"&gt;documentation. scikit-image provides users with a simple API based on
a large number of functions, which can be used to build pipelines of
image processing workflows.&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;In a second part, I will explain how to use Dash for building
interactive&lt;/div&gt;
&lt;div class="line"&gt;image processing operations. Dash (&lt;a class="reference external" href="https://dash.plot.ly/"&gt;https://dash.plot.ly/&lt;/a&gt;) is an&lt;/div&gt;
&lt;div class="line"&gt;open-source Python web application framework developed by Plotly.
Written on top of Flask, Plotly.js, and React.js, Dash is meant for
building data visualization apps with highly custom user interfaces in
pure Python. The dash-canvas component library of Dash
(&lt;a class="reference external" href="https://dash.plot.ly/canvas"&gt;https://dash.plot.ly/canvas&lt;/a&gt;) is an interactive component for
annotating images with several tools (freehand brush, lines, bounding
boxes, ...). It also provides utility functions for using
user-provided annotations for several image processing tasks such as
segmentation, transformation, measures, etc. The latter functions are
based on libraries such scikit-image and openCV. A gallery of examples
showcases some typical uses of Dash for image processing on&lt;/div&gt;
&lt;div class="line"&gt;&lt;a class="reference external" href="https://dash-canvas.plotly.host/"&gt;https://dash-canvas.plotly.host/&lt;/a&gt;. Also, other components of Dash can
be leveraged easily to build powerful image processing applications,
such as widgets to tune parameters or data tables for inspecting
object&lt;/div&gt;
&lt;div class="line"&gt;properties.&lt;/div&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Emmanuelle Gouillart</dc:creator><pubDate>Wed, 10 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-10:/europython-2019/image-processing-with-scikit-image-and-dash.html</guid><category>EuroPython 2019</category><category>Computer Vision</category><category>Data Science</category><category>Image Processing</category><category>JavaScript Web Frameworks (AngularJS/ReactJS/...)</category><category>Scientific Libraries (Numpy/Pandas/SciKit/...)</category></item><item><title>Building smarter solutions with no expertise in machine learning</title><link>https://pyvideo.org/europython-2020/building-smarter-solutions-with-no-expertise-in-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;ML? API? AutoML? Python is the language of choice to solve problems with machine learning, but what can we build in only a few hours or days and without any expertise? In this session, we'll see how to benefit from existing ML models and how to create a custom model with AutoML techniques. We’ll also be active players of a live demo, so don't put your smartphone on airplane mode!&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Laurent PICARD</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/building-smarter-solutions-with-no-expertise-in-machine-learning.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>Computer Vision</category><category>Human-Machine-Interaction</category><category>Machine-Learning</category><category>Natural Language Processing</category><category>Public Cloud (AWS/Google/...)</category></item><item><title>Corona-Net</title><link>https://pyvideo.org/europython-2020/corona-net.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Fighting COVID-19 with Machine Learning&lt;/p&gt;
&lt;p&gt;Identified in December 2019, the novel Coronavirus has infected 2.7 million worldwide, and claimed the lives of 0.2 million. Amidst this deadly pandemic, I started my open source project, Corona-Net, in the hopes of contributing to the global fight against the Coronavirus. Corona-Net is a 3-part project dedicated to the classification, binary segmentation and multi-class segmentation of COVID-19. I first leverage the EfficientNet model for COVID-19 diagnosis, then utilise and refine the U-Net architecture for both binary and 3-class (ground-glass, consolidation, pleural effusion) segmentation of COVID-19 symptoms, through inference on the COVID-19 CT segmentation (chest axial CT) dataset. Through Corona-Net, I aim to develop a reliable, visual-semantically balanced method for automatic COVID-19 diagnosis, as well as extend an invitation to all to collaborate and stand together against this pandemic. My PyTorch code is publicly available at &lt;a class="reference external" href="https://github.com/chinglamchoi/Corona-Net"&gt;https://github.com/chinglamchoi/Corona-Net&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ching Lam Choi</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/corona-net.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>Computer Vision</category><category>Data Science</category><category>Deep Learning</category><category>Image Processing</category><category>Scientific Libraries (Numpy/Pandas/SciKit/...)</category></item><item><title>Painting with GANs: Challenges and Technicalities of Neural Style Transfer</title><link>https://pyvideo.org/europython-2020/painting-with-gans-challenges-and-technicalities-of-neural-style-transfer.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Building Artistic Artefacts using Generative Networks&lt;/p&gt;
&lt;p&gt;A lot of advancements are happening in the field of Deep Learning and Generative Adversarial Networks are one of them. We have seen GANs being applied for photo editing and in-painting, generating new image datasets and realistic photographs, increasing resolution of images (Super Resolution), and many more things. Some people have also exploited GANs for generating fake content. All the above-mentioned examples are result of a technique where the focus is to generate uncommon yet original samples from scratch. However, these examples have very less commercial applications and GANs are capable of doing much more. The focus of this talk is a technique called &amp;quot;Neural Style Transfer (NST)&amp;quot; which has numerous commercial applications in the gaming world, fashion/design industry, mobile applications, and many more fields. Challenges and technicalities of NSTs will be covered in great detail. We will teach the machines on how to paint images and utilize Style Transfer networks to generate artistic artefacts.&lt;/p&gt;
&lt;p&gt;The flow of the talk will be as follows:
~ Self Introduction [1 minute]
~ A Succinct Prelude to GANs [10 minutes]
~ Understanding Style Transfer [5 minutes]
~ Learning about Neural Style Transfer Networks [5 minutes]
~ Loss Functions: Content, Style, Total Variantion [10 minutes]
~ Code Walkthrough and Result Analysis [5 minutes]
~ Challenges and Applications [5 minutes]
~ Questions and Answers Session [3-4 minutes]&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Anmol Krishan Sachdeva</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/painting-with-gans-challenges-and-technicalities-of-neural-style-transfer.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>Computer Vision</category><category>Deep Learning</category><category>Generative Adversarial Networks</category><category>Image Processing</category><category>Machine-Learning</category></item><item><title>Satellite data is for everyone: insights into modern remote sensing research with open data and Python</title><link>https://pyvideo.org/pycon-de-2018/satellite-data-is-for-everyone-insights-into-modern-remote-sensing-research-with-open-data-and-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The largest earth observation programme Copernicus
(&lt;a class="reference external" href="http://copernicus.eu"&gt;http://copernicus.eu&lt;/a&gt;) makes it possible to perform terrestrial
observations providing data for all kinds of purposes. One important
objective is to monitor the land-use and land-cover changes with the
Sentinel-2 satellite mission. These satellites measure the sun
reflectance on the earth surface with multispectral cameras (13 channels
between 440 nm to 2190 nm). Machine learning techniques like
convolutional neural networks (CNN) are able to learn the link between
the satellite image (spectrum) and the ground truth (land use class). In
this talk, we give an overview about the state-of-the-art land-use
classification with CNNs based on an open dataset.&lt;/p&gt;
&lt;p&gt;The EuroSAT benchmark dataset (&lt;a class="reference external" href="http://madm.dfki.de/downloads"&gt;http://madm.dfki.de/downloads&lt;/a&gt;) is freely
provided by German Research Center for Artificial Intelligence (DFKI).
It consists of 27.000 image patches for ten different land use/cover
classes, e.g. industrial and residential areas, different crop and
vegetation types and forests. All samples have 64 by 64 pixel dimension
and include either only the RGB images or all 13 bands.&lt;/p&gt;
&lt;p&gt;We will use different out-of-box CNNs for the Keras deep learning
library (&lt;a class="reference external" href="https://keras.io/"&gt;https://keras.io/&lt;/a&gt;). All networks are either included in Keras
itself or are available from Github repositories. We will show the
process of transfer learning for the RGB datasets. Furthermore, the
minimal changes required to apply commonly used CNNs to multispectral
data are demonstrated. Thus, the interested audience will be able to
perform their own classification of remote sensing data within a very
short time. Results of different network structures are visually
compared. Especially the differences of transfer learning and learning
from scratch are demonstrated. This also includes the amount of
necessary training epochs, progress of training and validation error and
visual comparison of the results of the trained networks.&lt;/p&gt;
&lt;p&gt;Finally, we give a quick overview about the current research topics
including recurrent neural networks for spatio-temporal land-use
classification and further applications of multi- and hyperspectral
data, e.g. for the estimation of water parameters and soil
characteristics. Additionally, we provide links to the code and dataset
used in this talk.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Felix M. Riese</dc:creator><pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-26:/pycon-de-2018/satellite-data-is-for-everyone-insights-into-modern-remote-sensing-research-with-open-data-and-python.html</guid><category>PyCon DE 2018</category><category>Artificial Intelligence</category><category>Computer Vision</category><category>Deep Learning &amp; Artificial Intelligence</category><category>Data Science</category><category>Machine Learning</category><category>Science</category></item><item><title>Satellite Image Segmentation Photovoltaic Potential Estimation</title><link>https://pyvideo.org/pycon-de-2018/satellite-image-segmentation-photovoltaic-potential-estimation.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The used technologies are python based and include: MongoDB tensorflow
Flask google.cloud python API&lt;/p&gt;
&lt;p&gt;A dataset of labelled satellite images is created. Several networks are
trained and tested on this dataset. The network is deployed on a
production server.&lt;/p&gt;
&lt;p&gt;The results of the classification/segmentaion are used to feed python
based photovotlaic simulation libaries. The output is displayed and the
results (the potential) evaluated.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Johannes Oos</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:/pycon-de-2018/satellite-image-segmentation-photovoltaic-potential-estimation.html</guid><category>PyCon DE 2018</category><category>Artificial Intelligence</category><category>Computer Vision</category><category>Deep Learning &amp; Artificial Intelligence</category><category>Machine Learning</category><category>Science</category></item><item><title>Experiences from applying Convolutional Neural Networks for classifying 2D sensor data</title><link>https://pyvideo.org/pycon-de-2018/experiences-from-applying-convolutional-neural-networks-for-classifying-2d-sensor-data.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When being the first in your company to apply a deep learning algorithm
on your data you often have to overcome several obstacles. One challenge
is to understand your data and to form a training and test dataset.
Another one is to get your algorithms and its performance accepted and
integrated in your existing processing workflow.&lt;/p&gt;
&lt;p&gt;Convolutional Neural Networks have become a standard tool in processing
image data. They have shown to reach human-level classification
performance on some object recognition tasks.&lt;/p&gt;
&lt;p&gt;In this talk I will present my experiences in getting started using a
convolutional neural network for classification of 2D sensor data. I
will point out the importance of understanding your data and give hints
of how to select your train and test datasets according to the
requirements. Furthermore, I will show how to get a feature extractor
out of the classifier and how to visualize it.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Matthias Peussner</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:/pycon-de-2018/experiences-from-applying-convolutional-neural-networks-for-classifying-2d-sensor-data.html</guid><category>PyCon DE 2018</category><category>Artificial Intelligence</category><category>Computer Vision</category><category>Deep Learning &amp; Artificial Intelligence</category><category>Machine Learning</category></item><item><title>Building a Fine Grained Image Classification System</title><link>https://pyvideo.org/pycon-ireland-2018/building-a-fine-grained-image-classification-system.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At Fieldguide we are developing a digital field guide for all species of flora and fauna across the planet. We are using image recognition technology to enable species identification and to help with the curation of this massive catalogue. In this talk I will describe how we are building an image recognition system with the aim of identifying all known species in the natural world. The system has gone through a number of iterations at this point using a variety of computer vision and machine learning techniques, from nearest neighbour search to classification with fine tuned deep convolutional networks. All of this has been implemented in Python using scikit-learn, Numpy, Caffe and Tensorflow. Aside from the obvious machine learning challenges in designing and training such a system we faced numerous technical challenges while implementing and scaling this system in a cost effective manner. I will discuss these challenges, our solutions and the remaining open problems. While this talk will be relatively high level with few code examples and no math (but lots moths), it will be of most interest to those who have some knowledge of machine learning concepts.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Fergal Walsh</dc:creator><pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-11-10:/pycon-ireland-2018/building-a-fine-grained-image-classification-system.html</guid><category>PyCon Ireland 2018</category><category>image-recognition</category><category>Computer Vision</category><category>machine learning</category></item><item><title>Deep Learning in Computer Vision: state of the art techniques and applications in industry</title><link>https://pyvideo.org/pycon-italia-2018/deep-learning-in-computer-vision-state-of-the-art-techniques-and-applications-in-industry.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Audience Level Data Scientists and Data Science Practitioners with basic
to intermediate level experience in image recognition/object detection
deep learning applications, basic Python programming skills.&lt;/p&gt;
&lt;p&gt;Brief Description Deep Learning is revolutionizing both Data Science and
Artificial Intelligence real-world applications. Yet, being the
discipline so young, it’s not straightforward to understand both the
reasoning at its core and its countless use cases. In this talk we will
review the basics of Neural Networks, from the classical CNNs to the
current state of the art, comparing them through real industry
applications and highlighting pros and cons in a business setting.&lt;/p&gt;
&lt;p&gt;Abstract / Summary Deep Learning has been on a hype roll for a few
years. Being such a young discipline makes deep learning interesting,
but also subject to misunderstandings. Every year, brand new
architectures rise, taking over old ones and outperforming state of the
art benchmarks for accuracy. Further, the applications of deep learning
are at the core of some of the most advanced technologies like
autonomous driving, personal assistants, and customer profiling. In such
a context it is not straightforward to grasp what is at the core of deep
learning itself, and what is common to all the architectures, neither to
realize how concrete use cases can be tackled. Using Python, we’ll take
the audience from the simplest neuron, the atom of the deep learning
world, to the most recent architectures. We’ll achieve this using a
simple Convolutional Neural Network as a building block and comparing
that to the latest breakthroughs in image recognition. In doing this
we’ll try to give an answer to the following questions: • Is deep
learning actually useful in a business setting? • What about state of
the art techniques in the Computer Vision field: are we just stacking
more and more convolutional and pooling layers? We will then address
real industry applications (e.g. the insurance sector) using analyzed
techniques. This will include opening some of these so- called black box
models and retraining them, at least partially, on our datasets, or
building a complete brand new network from scratch, tailoring it
according to the application needs and datasets characteristics.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 17:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rocco Michele Lancellotti</dc:creator><pubDate>Sat, 21 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-21:/pycon-italia-2018/deep-learning-in-computer-vision-state-of-the-art-techniques-and-applications-in-industry.html</guid><category>PyCon Italia 2018</category><category>image-recognition</category><category>transfer-learning</category><category>industry applications</category><category>deep learning</category><category>Deep-Learning</category><category>ComputerVision</category><category>computer vision</category><category>image recognition</category><category>transfer learning</category><category>industry-applications</category></item><item><title>Multi-modal classification with PyTorch</title><link>https://pyvideo.org/pycon-italia-2019/multi-modal-classification-with-pytorch.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Recent work by Kiela et al. (2018) reveals that image and text
multi-modal classification models far outperform both text- and
image-only models. This talk will review work that extends Kiela et
al.’s (2018) research by determining if accuracy in classification may
be increased by the implementation of transfer learning in language
processing. The performance of the model over a MM-IMDb (Arevalo et al.
2017) dataset is analyzed and compared to the baseline provided by Kiela
et al. (2018).&lt;/p&gt;
&lt;p&gt;The work is implemented with PyTorch and the goal of the talk will be to
review details of the implementation, and performance of the model as
compared to that recorded in Kiela et al. (2018). Attendees of this talk
should have a basic familiarity with neural nets developed in PyTorch
for the purposes of NLP and computer vision.&lt;/p&gt;
&lt;p&gt;References: Arevalo, J., Solorio, T., Montes-y-Gómez, M., &amp;amp; González, F.
A. 2017. Gated multimodal units for information fusion. arXiv preprint
arXiv:1702.01992.&lt;/p&gt;
&lt;p&gt;Kiela, Douwe, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2018.
Efficient large-scale multi-modal classification. arXiv preprint
arXiv:1802.02892.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1754"&gt;https://python.it/feedback-1754&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Saturday 4 May&lt;/strong&gt; at 10:45 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jennifer Seale</dc:creator><pubDate>Sat, 04 May 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-04:/pycon-italia-2019/multi-modal-classification-with-pytorch.html</guid><category>PyCon Italia 2019</category><category>nlp</category><category>mathematical-modelling</category><category>computer-vision</category></item><item><title>Create an Object Detection Model with One Click</title><link>https://pyvideo.org/pycon-korea-2022/create-an-object-detection-model-with-one-click.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;I would like to introduce the method I tried to speed up the sample collection and labeling process, which takes the longest time to create an Object Detection model. When the user uploads several object images, we internally use Python OpenCV to regenerate them into various image types so that they can be used for model training. I will introduce the results I was able to obtain through this and the parts I was concerned about.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Baek Seung-hoon</dc:creator><pubDate>Sat, 01 Oct 2022 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2022-10-01:/pycon-korea-2022/create-an-object-detection-model-with-one-click.html</guid><category>PyCon Korea 2022</category><category>Computer Vision</category></item><item><title>What If We Apply Python to Coloring?</title><link>https://pyvideo.org/pycon-korea-2024/what-if-we-apply-python-to-coloring.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Introducing technology that automatically converts images into PIPO painting canvases.&lt;/p&gt;
&lt;p&gt;Introducing technology that automatically converts images into PIPO painting canvases.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Gu Min-gu</dc:creator><pubDate>Sat, 26 Oct 2024 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2024-10-26:/pycon-korea-2024/what-if-we-apply-python-to-coloring.html</guid><category>PyCon Korea 2024</category><category>computer vision</category></item><item><title>Visualizing your computer vision data is not a luxury, it's a necessity</title><link>https://pyvideo.org/pydata-berlin-2023/visualizing-your-computer-vision-data-is-not-a-luxury-its-a-necessity.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Are you ready to take your Computer Vision projects to the next level? Then don't miss this talk!&lt;/p&gt;
&lt;p&gt;Data visualization is a crucial ingredient for the success of any computer vision project.
It allows you to assess the quality of your data, grasp the intricacies of your project, and communicate effectively with stakeholders.&lt;/p&gt;
&lt;p&gt;In this talk, we'll showcase the power of data visualization with compelling examples. You'll learn about the benefits of data visualization and discover practical methods and tools to elevate your projects.&lt;/p&gt;
&lt;p&gt;Don't let this opportunity pass you by: join us and learn how to make data visualization a core feature of your Computer Vision projects.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Chazareix Arnault</dc:creator><pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-04-17:/pydata-berlin-2023/visualizing-your-computer-vision-data-is-not-a-luxury-its-a-necessity.html</guid><category>PyData Berlin 2023</category><category>Computer Vision</category></item><item><title>Detectron2 - Next Gen Object Detection Library</title><link>https://pyvideo.org/pytorch-conference-2019/detectron2-next-gen-object-detection-library.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Object detection and segmentation are used for tasks ranging from autonomous vehicles to content understanding for platform integrity. Learn about Detectron2, an object detection library now implemented in PyTorch. Detectron2 provides support for the latest models and tasks, increased flexibility to aid computer vision research, and improvements in maintainability and scalability to support production use cases.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yuxin Wu</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/detectron2-next-gen-object-detection-library.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Detection library</category><category>Detectron2</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>PyTorch</category><category>PyTorch 1.3</category><category>Segmentation</category><category>computer vision</category><category>computer vision research</category><category>cv</category><category>detectron</category><category>object detection</category></item><item><title>Training data generation for Computer Vision applications</title><link>https://pyvideo.org/riiaa-2021/training-data-generation-for-computer-vision-applications.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;En este taller aprenderemos a como crear los datos necesarios para entrenar un modelo de Visión Computacional.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Paula Villamarín</dc:creator><pubDate>Wed, 25 Aug 2021 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2021-08-25:/riiaa-2021/training-data-generation-for-computer-vision-applications.html</guid><category>RIIAA 2021</category><category>#science</category><category>AI</category><category>Computer vision</category><category>MachineLearning</category></item></channel></rss>