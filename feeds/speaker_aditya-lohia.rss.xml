<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Aditya Lohia</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Tue, 22 Mar 2022 00:00:00 +0000</lastBuildDate><item><title>Deploying ML Solutions With Low Latency In Python</title><link>https://pyvideo.org/python-web-conf-2021/deploying-ml-solutions-with-low-latency-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Deploying ML Solutions With Low Latency In Python&amp;quot; by: Aditya Lohia
When we aim for better accuracies, sometimes we forget that the algorithms become more massive and slower. This fact renders the algorithms unusable in real-time scenarios. How do you deploy your solution? Which framework to use? Can you use Python for deploying my solution? Can you use Jetson Nano for multi-stream inferencing? If you are curious to solve these questions, join me in this talk to discover TensorRT and DeepStream and how they reduce your algorithm’s latency and memory footprint. NVIDIA TensorRT™ is an SDK for high-performance deep learning inference. It includes a deep learning inference optimizer and runtime that delivers low latency and high-throughput for deep learning inference applications. DeepStream offers a multi-platform scalable framework with TLS security to deploy on edge and connect to any cloud. If you are using a GPU and CUDA/Tensor cores, you can leverage the SDK framework to deploy bigger and better algorithms for your real-time scenarios. The main focus of this talk will be to demonstrate why, where, and how to use TensorRT and DeepStream.&lt;/p&gt;
&lt;p&gt;Recorded at the 2021 Python Web Conference (&lt;a class="reference external" href="https://2021.pythonwebconf.com"&gt;https://2021.pythonwebconf.com&lt;/a&gt;)&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aditya Lohia</dc:creator><pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2021-03-22:/python-web-conf-2021/deploying-ml-solutions-with-low-latency-in-python.html</guid><category>Python Web Conf 2021</category><category>PythonWebConf</category><category>PythonWebConf2021</category></item><item><title>Federated Learning in Computer Vision</title><link>https://pyvideo.org/python-web-conf-2022/federated-learning-in-computer-vision.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While researchers have been advancing computer vision algorithms month by month, developers face the problem of training and deploying those same algorithms in the real world. Often, the reason behind low accuracies is accounted for by the low quantity and quality of data available for the problem. Over the past few months, federated learning has been the talk of the town because of its promising future in computer vision. What is federated learning? How to use it? Is it possible to deploy federated learning solutions in the real world? The main focus of this talk will be to demonstrate why, where, and how to use federated learning in computer vision.&lt;/p&gt;
&lt;p&gt;#PWC2022 attracted nearly 375 attendees from 36 countries and 21 time zones making it the biggest and best year yet. The highly engaging format featured 90 speakers, 6 tracks (including 80 talks and 4 tutorials) and took place virtually on March 21-25, 2022 on LoudSwarm by Six Feet Up.&lt;/p&gt;
&lt;p&gt;More information about the conference can be found at: &lt;a class="reference external" href="https://2022.pythonwebconf.com"&gt;https://2022.pythonwebconf.com&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aditya Lohia</dc:creator><pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2022-03-22:/python-web-conf-2022/federated-learning-in-computer-vision.html</guid><category>Python Web Conf 2022</category><category>PythonWebConf</category><category>PythonWebConf2022</category></item></channel></rss>