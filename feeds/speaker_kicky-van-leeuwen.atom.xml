<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_kicky-van-leeuwen.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-05-26T00:00:00+00:00</updated><entry><title>Why AI in the Medical Field Both Sucks and Rocks...</title><link href="https://pyvideo.org/pydata-amsterdam-2018/why-ai-in-the-medical-field-both-sucks-and-rocks.html" rel="alternate"></link><published>2018-05-26T00:00:00+00:00</published><updated>2018-05-26T00:00:00+00:00</updated><author><name>Kicky van Leeuwen</name></author><id>tag:pyvideo.org,2018-05-26:pydata-amsterdam-2018/why-ai-in-the-medical-field-both-sucks-and-rocks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deep learning is hot and happening, also in the medical field, however implementation is slow. Why is that? How do you approach such problems and how to make this a success? Where do you get the privacy-sensitive data from? Do pre-trained networks work? Can we make it scalable in the cloud? I will address these issues with a case study: segmentation of 4D heart MRI for heart function analysis.&lt;/p&gt;
</summary></entry></feed>