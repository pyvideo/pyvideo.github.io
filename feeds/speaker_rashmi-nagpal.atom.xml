<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Rashmi Nagpal</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_rashmi-nagpal.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2024-09-18T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Building and Deploying Fair and Unbiased ML Systems: An Art, Not Science</title><link href="https://pyvideo.org/europython-2023/building-and-deploying-fair-and-unbiased-ml-systems-an-art-not-science.html" rel="alternate"></link><published>2023-07-17T00:00:00+00:00</published><updated>2023-07-17T00:00:00+00:00</updated><author><name>Rashmi Nagpal</name></author><id>tag:pyvideo.org,2023-07-17:/europython-2023/building-and-deploying-fair-and-unbiased-ml-systems-an-art-not-science.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[EuroPython 2023 — Terrace 2B on 2023-07-21]&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://ep2023.europython.eu/session/building-and-deploying-fair-and-unbiased-ml-systems-an-art-not-science"&gt;https://ep2023.europython.eu/session/building-and-deploying-fair-and-unbiased-ml-systems-an-art-not-science&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There has been a renaissance around Artificial Intelligence systems in recent years. However, despite the hype, only a small percentage, i.e. 13% of Machine Learning models see the light of day!&lt;/p&gt;
&lt;p&gt;Well, effectively building and deploying …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[EuroPython 2023 — Terrace 2B on 2023-07-21]&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://ep2023.europython.eu/session/building-and-deploying-fair-and-unbiased-ml-systems-an-art-not-science"&gt;https://ep2023.europython.eu/session/building-and-deploying-fair-and-unbiased-ml-systems-an-art-not-science&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There has been a renaissance around Artificial Intelligence systems in recent years. However, despite the hype, only a small percentage, i.e. 13% of Machine Learning models see the light of day!&lt;/p&gt;
&lt;p&gt;Well, effectively building and deploying machine learning models is more of an art than science! ML models are indeed inherently complex, have fuzzy boundaries, and rely heavily on data distribution. But what if they are trained on biased data? Then they’ll generate highly biased decisions! As the famous saying goes by,  “Garbage in, garbage out,” so if the model is trained on skewed and unfair data distribution, they are bound to produce fuzzy output!&lt;/p&gt;
&lt;p&gt;So, join me in this talk as I will share my learnings in developing effective practices to build and deploy ethical, fair and unbiased machine learning models into production.&lt;/p&gt;
&lt;p&gt;This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License &lt;a class="reference external" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;http://creativecommons.org/licenses/by-nc-sa/4.0/&lt;/a&gt;&lt;/p&gt;
</content><category term="EuroPython 2023"></category></entry><entry><title>Unlocking the Enigma: Crafting Unbiased, Transparent, and Explainable Large Language Models</title><link href="https://pyvideo.org/pytorch-conference-2024/unlocking-the-enigma-crafting-unbiased-transparent-and-explainable-large-language-models.html" rel="alternate"></link><published>2024-09-18T00:00:00+00:00</published><updated>2024-09-18T00:00:00+00:00</updated><author><name>Rashmi Nagpal</name></author><id>tag:pyvideo.org,2024-09-18:/pytorch-conference-2024/unlocking-the-enigma-crafting-unbiased-transparent-and-explainable-large-language-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In an era where artificial intelligence reigns supreme, the statistics are both perplexing and thought-provoking – only a mere 13% of large language models manage to transcend the realms of research and enter the practical world of production. Who bears the responsibility when these models err, spewing out biased or …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In an era where artificial intelligence reigns supreme, the statistics are both perplexing and thought-provoking – only a mere 13% of large language models manage to transcend the realms of research and enter the practical world of production. Who bears the responsibility when these models err, spewing out biased or discriminatory outputs? It's time to demystify the complex landscape of machine learning ethics and carve a path towards a brighter, more accountable future! In this talk, firstly, we will navigate the profound impacts of large language models across diverse domains, from the lifesaving advances in medicine to safeguarding our nations through enhanced security protocols. Secondly, as we marvel at data-driven decisions laid by these models, we will confront the darker shadows cast by – the looming spectre of bias in the data. Finally, we will delve deep into the art of building interpretable models and navigating the maze of ethical considerations. Through a live demonstration in PyTorch, we will witness how to craft unbiased, transparent, and explainable models.&lt;/p&gt;
</content><category term="PyTorch Conference 2024"></category></entry></feed>