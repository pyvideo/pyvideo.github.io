<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_luciano-resende.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-12-07T00:00:00+00:00</updated><entry><title>AI pipelines powered by Jupyter notebooks</title><link href="https://pyvideo.org/pydata-austin-2019/ai-pipelines-powered-by-jupyter-notebooks.html" rel="alternate"></link><published>2019-12-07T00:00:00+00:00</published><updated>2019-12-07T00:00:00+00:00</updated><author><name>Luciano Resende</name></author><id>tag:pyvideo.org,2019-12-07:pydata-austin-2019/ai-pipelines-powered-by-jupyter-notebooks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Jupyter Notebook has become the de-facto platform used by data scientists to develop their AI/ML models. In this scenario, it’s very common to decompose various phases of the development into multiple notebooks to simplify the development and management of the model lifecycle. This session will detail different approaches to compose notebook based AI pipelines and running in different runtimes&lt;/p&gt;
</summary><category term="data pipelines"></category><category term="ai"></category><category term="artificial intelligence"></category><category term="jupyter notebooks"></category></entry><entry><title>Customizing JupyterLab using extensions</title><link href="https://pyvideo.org/pydata-austin-2019/customizing-jupyterlab-using-extensions.html" rel="alternate"></link><published>2019-12-07T00:00:00+00:00</published><updated>2019-12-07T00:00:00+00:00</updated><author><name>Alex Bozarth</name></author><id>tag:pyvideo.org,2019-12-07:pydata-austin-2019/customizing-jupyterlab-using-extensions.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;JupyterLab provides data scientists a singular work environment for notebooks, file editing, and more. Designed to be extendable, JupyterLab allows developers to create new features and improve upon built-in functionality. In this session we will go over JupyterLab extensions and how they can be used to customize JupyterLab for your use case.&lt;/p&gt;
</summary><category term="jupyter lab"></category></entry><entry><title>Scaling your Python interactive applications with Jupyter</title><link href="https://pyvideo.org/scipy-japan-2019/scaling-your-python-interactive-applications-with-jupyter.html" rel="alternate"></link><published>2019-04-23T00:00:00+00:00</published><updated>2019-04-23T00:00:00+00:00</updated><author><name>Luciano Resende</name></author><id>tag:pyvideo.org,2019-04-23:scipy-japan-2019/scaling-your-python-interactive-applications-with-jupyter.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter Notebooks have become the &amp;quot;de facto&amp;quot; platform used by scientists and engineers to build Python interactive applications to tackle scientific and machine learning problems. However, with the popularity of big data analytics and complex deep learning workloads, there is a growing requirement to extend the computation across a cluster of computers in a parallel fashion. In this talk, we will describe how to use multiple Jupyter Notebook components to enable the orchestration and distribution of interactive machine learning and deep learning workloads across different types of computing clusters including Apache Spark and Kubernetes. This talk is intended to attendees interested in distributed platforms and scientists experiencing difficulties on scaling their scientific workloads across multiple machines.
​
Bio: Luciano Resende is an STSM and Open Source Data Science/AI Platform Architect at IBM CODAIT (formerly Spark Technology Center). He has been contributing to open source at The ASF for over 10 years, he is a member of ASF and is currently contributing to various big data related Apache projects around the Apache Spark ecosystem. Currently, Luciano is contributing to Jupyter Ecosystem projects building scalable, secure and flexible Enterprise Data Science platform.&lt;/p&gt;
&lt;div class="section" id="connect-with-us"&gt;
&lt;h4&gt;Connect with us!&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="https://twitter.com/enthought"&gt;https://twitter.com/enthought&lt;/a&gt;
&lt;a class="reference external" href="https://www.facebook.com/Enthought/"&gt;https://www.facebook.com/Enthought/&lt;/a&gt;
&lt;a class="reference external" href="https://www.linkedin.com/company/enthought"&gt;https://www.linkedin.com/company/enthought&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</summary></entry></feed>