<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_harald-bosch.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-10-09T00:00:00+00:00</updated><entry><title>Creating an Interactive ML Conference Showcase</title><link href="https://pyvideo.org/pydata-berlin-2019/creating-an-interactive-ml-conference-showcase.html" rel="alternate"></link><published>2019-10-09T00:00:00+00:00</published><updated>2019-10-09T00:00:00+00:00</updated><author><name>Harald Bosch</name></author><id>tag:pyvideo.org,2019-10-09:pydata-berlin-2019/creating-an-interactive-ml-conference-showcase.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Speaker: Harald Bosch&lt;/p&gt;
&lt;p&gt;Track:PyData
Our goal is to create a simple yet interactive showcase for computer vision using a Python notebook. In a trade fair setup, we want to learn new object classes quickly using very few training examples. Thus, we rely on pretrained neural networks for&lt;/p&gt;
&lt;p&gt;Recorded at the PyConDE &amp;amp; PyData Berlin 2019 conference.
&lt;a class="reference external" href="https://pycon.de"&gt;https://pycon.de&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More details at the conference page: &lt;a class="reference external" href="https://de.pycon.org/program/MMXQUC"&gt;https://de.pycon.org/program/MMXQUC&lt;/a&gt;
Twitter:  &lt;a class="reference external" href="https://twitter.com/pydataberlin"&gt;https://twitter.com/pydataberlin&lt;/a&gt;
Twitter:  &lt;a class="reference external" href="https://twitter.com/pyconde"&gt;https://twitter.com/pyconde&lt;/a&gt;&lt;/p&gt;
</summary></entry></feed>