<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Thu, 31 Aug 2017 00:00:00 +0000</lastBuildDate><item><title>Bayesian Optimization - Can you do better than randomly guessing parameters?</title><link>https://pyvideo.org/euroscipy-2017/bayesian-optimization-can-you-do-better-than-randomly-guessing-parameters.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Choosing the right hyper-parameters for a deep neural network, configuring a fluid dynamics simulation or finding the recipe of the next prize winning beer have three things in common: each trial is expensive, you don't have an analytic function you can minimise with &lt;cite&gt;scipy.minimize&lt;/cite&gt; and you only get noisy observations from each trial.&lt;/p&gt;
&lt;p&gt;Bayesian optimisation (BO) to the rescue! BO is a clever piece of math designed to solve exactly these kinds of problems. This talk is for people who have to find the best configuration for an &amp;quot;algorithm&amp;quot; that is expensive to run. Currently you might be performing a grid search or trying settings at random. Neither of these learn from observations they have already made. The fundamental idea of BO is to use previous observations to make a prediction about which settings to try next. By doing this you can reduce the number of evaluations needed to find the optimal settings.&lt;/p&gt;
&lt;p&gt;In this talk you will learn about bayesian optimisation, how to implement the basics yourself, some tricks of the trade, and I will introduce you to the scikit-optimize library: a simple and efficient library to minimize (very) expensive and noisy black-box functions. It implements several methods for BO and attempts to be accessible and easy to use in many different contexts.&lt;/p&gt;
&lt;p&gt;We will start by looking at some simple examples in depth, discuss when BO is the right tool and when not, and then use scikit-optimize to find the best hyper-parameters for a neural network.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tim Head</dc:creator><pubDate>Thu, 31 Aug 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-08-31:euroscipy-2017/bayesian-optimization-can-you-do-better-than-randomly-guessing-parameters.html</guid><category>bayesian optimization</category></item></channel></rss>