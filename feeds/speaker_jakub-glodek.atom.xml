<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Jakub Glodek</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_jakub-glodek.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2024-05-16T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Avoid the top 5 web data pitfalls when developing AI models (Sponsor: Bright Data)</title><link href="https://pyvideo.org/pycon-us-2024/avoid-the-top-5-web-data-pitfalls-when-developing-ai-models-sponsor-bright-data.html" rel="alternate"></link><published>2024-05-16T00:00:00+00:00</published><updated>2024-05-16T00:00:00+00:00</updated><author><name>Jakub Glodek</name></author><id>tag:pyvideo.org,2024-05-16:/pycon-us-2024/avoid-the-top-5-web-data-pitfalls-when-developing-ai-models-sponsor-bright-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Data Bias:&lt;/strong&gt; ensuring that the training data is not biased. Biased
data can lead to AI models that are unfair or discriminatory. For
example, if a dataset for facial recognition software predominantly
contains images of people from certain ethnic groups, the model may
perform poorly on faces from underrepresented â€¦&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Data Bias:&lt;/strong&gt; ensuring that the training data is not biased. Biased
data can lead to AI models that are unfair or discriminatory. For
example, if a dataset for facial recognition software predominantly
contains images of people from certain ethnic groups, the model may
perform poorly on faces from underrepresented groups. &lt;strong&gt;Insufficient
Data Variety:&lt;/strong&gt; AI models require diverse data to understand different
scenarios and variations. If the training data is too homogeneous or
lacks variety, the model might not perform well in real-world, diverse
conditions. &lt;strong&gt;Overfitting and Underfitting:&lt;/strong&gt; Overfitting occurs when a
model is too complex and learns to fit the training data so closely that
it fails to generalize to new data. Underfitting happens when the model
is too simple to capture the underlying patterns in the data. &lt;strong&gt;Poor
Data Quality:&lt;/strong&gt; If the training data is full of errors, inconsistencies,
or is poorly labeled, the AI model will likely inherit these flaws.
Ensuring high data quality is essential for developing reliable and
accurate AI models. &lt;strong&gt;Ignoring Data Drift:&lt;/strong&gt; Over time, the real-world
data that an AI model encounters may change or 'drift' from the data on
which it was trained. This can happen due to evolving trends, behaviors,
or environments. Failing to monitor and adapt to these changes can
render an AI model less effective or even obsolete.&lt;/p&gt;
</content><category term="PyCon US 2024"></category></entry></feed>