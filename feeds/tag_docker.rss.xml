<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - docker</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 15 Dec 2023 00:00:00 +0000</lastBuildDate><item><title>Containerize all the things</title><link>https://pyvideo.org/caipyra-2016/containerize-all-the-things.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Palestra do Andrews Medina no Caipyra 2016:&lt;/p&gt;
&lt;p&gt;Containerize all the things&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="http://talks.godoc.org/github.com/andrewsmedina/containerize-all-the-things/sample.slide#1"&gt;http://talks.godoc.org/github.com/andrewsmedina/containerize-all-the-things/sample.slide#1&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrews Medina</dc:creator><pubDate>Sat, 25 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-06-25:/caipyra-2016/containerize-all-the-things.html</guid><category>Caipyra 2016</category><category>docker</category><category>devops</category></item><item><title>Docker meets Python - A look on the Docker SDK for Python</title><link>https://pyvideo.org/europython-2019/docker-meets-python-a-look-on-the-docker-sdk-for-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;My talk aims to introduce and have a closer look on the Docker SDK for
Python.&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;I will cover:&lt;/div&gt;
&lt;div class="line"&gt;- How and where to get the SDK&lt;/div&gt;
&lt;div class="line"&gt;- How it works and how to use it in general&lt;/div&gt;
&lt;div class="line"&gt;- Possible use-cases like: Processing Container-Logs, Testing with
pytest on different Python Versions, Deploy via Python Script, etc..&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;For my talk, you should know what Docker is and how to use it.&lt;/div&gt;
&lt;div class="line"&gt;A basic idea of pytest and server administration is nice to have, but
not necessarily needed to follow my talk.&lt;/div&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jan Wagner</dc:creator><pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-12:/europython-2019/docker-meets-python-a-look-on-the-docker-sdk-for-python.html</guid><category>EuroPython 2019</category><category>Deployment/Continuous Integration and Delivery</category><category>DevOps general</category><category>Docker</category><category>Testing</category><category>Virtualization</category></item><item><title>How we run GraphQL APIs in production on our Kubernetes cluster</title><link>https://pyvideo.org/europython-2019/how-we-run-graphql-apis-in-production-on-our-kubernetes-cluster.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk I would like to share the workflow and tools we use to
build, deploy and operate GraphQL APIs on our on-premise Kubernetes
cluster.&lt;/p&gt;
&lt;p&gt;I will share code and command examples explaining how we are operating
our applications since our recent transition from REST APIs on Web
servers to GraphQL APIs containers on Kubernetes.&lt;/p&gt;
&lt;p&gt;This talk will not be about the difference between REST and GraphQL but
focus on the workflow, tools and experience we gained in switching our
run time environments and API models.&lt;/p&gt;
&lt;p&gt;At Numberly, we have built and are operating our own on-premise
Kubernetes cluster so we will also be talking about its capabilities and
share some of the experience we gained in doing so.&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Proposed agenda:&lt;/div&gt;
&lt;div class="line"&gt;- Our previous workflow and its limitations&lt;/div&gt;
&lt;div class="line"&gt;- How we designed our Kubernetes cluster, its capabilities and the
choices we made&lt;/div&gt;
&lt;div class="line"&gt;- Developer workflow, environments management and deployment&lt;/div&gt;
&lt;div class="line"&gt;- Our GraphQL stack, featuring a sample application&lt;/div&gt;
&lt;div class="line"&gt;- What we're still working on to improve&lt;/div&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexys Jacob</dc:creator><pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-12:/europython-2019/how-we-run-graphql-apis-in-production-on-our-kubernetes-cluster.html</guid><category>EuroPython 2019</category><category>APIs</category><category>Best Practice</category><category>Case Study</category><category>Docker</category><category>Infrastructure</category></item><item><title>Optimizing Docker builds for Python applications</title><link>https://pyvideo.org/europython-2019/optimizing-docker-builds-for-python-applications.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Do you deploy Python applications in Docker? Then this session is for
you!&lt;/div&gt;
&lt;div class="line"&gt;We will start by reviewing a simple Dockerfile to package a Python
application and move to more complex examples which speed up the build
process and reduce the size of the resulting Docker image for both
development and production builds.&lt;/div&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dmitry Figol</dc:creator><pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-12:/europython-2019/optimizing-docker-builds-for-python-applications.html</guid><category>EuroPython 2019</category><category>Deployment/Continuous Integration and Delivery</category><category>Docker</category></item><item><title>Best practices for production-ready Docker packaging</title><link>https://pyvideo.org/europython-2020/best-practices-for-production-ready-docker-packaging.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;An iterative packaging plan for your Python application&lt;/p&gt;
&lt;p&gt;You know the basics of packaging your Python application for Docker, but do you know enough to run that image in production? Bad packaging can result in security and production problems, not to mention wasted time try to debug unreproducible errors.&lt;/p&gt;
&lt;p&gt;And even if you figure out the best practices, there's still a huge number of details to get right, many of which interact with each other in unexpected ways. My personal list includes over 60 Docker packaging best practices, and it keeps growing. So where do you start? What should you do first?&lt;/p&gt;
&lt;p&gt;To help you quickly package your application in a production-ready way, this talk will give you a plan to help you prioritize and iteratively implement these best practices, by starting with the highest priority best practices (security, automation), moving on the correctness and reproducibility, and finally focusing on optimization.&lt;/p&gt;
&lt;p&gt;To make this process more concrete, along the way you'll also learn some of the techniques needed to build production-ready images:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Running as a non-root, for increased security.&lt;/li&gt;
&lt;li&gt;Debugging C crashes with faulthandler.&lt;/li&gt;
&lt;li&gt;Faster startup with pre-compiled .pycs.&lt;/li&gt;
&lt;li&gt;Smaller images by disabling pip caching.&lt;/li&gt;
&lt;li&gt;Avoiding Alpine Linux.&lt;/li&gt;
&lt;li&gt;And more!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At the end of the talk you'll also get some resources to teach you even more best practices that can't be fit in a 30-minute talk.&lt;/p&gt;
&lt;p&gt;This talk is for Python programmers who know the basics of Docker packaging, and need to run the resulting images in a production environment.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Itamar Turner-Trauring</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/best-practices-for-production-ready-docker-packaging.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>Deployment/Continuous Integration and Delivery</category><category>DevOps general</category><category>Docker</category><category>Packaging</category><category>Security</category></item><item><title>Extending Python with Rust</title><link>https://pyvideo.org/europython-2020/extending-python-with-rust.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Introduction and a hands-on demo of writing Python extension in Rust&lt;/p&gt;
&lt;p&gt;Rust is a rising star of the programming language world. I'd like to discuss it from a Python developer perspective. Obviously, Rust is not a replacement for Python, but in case you're seeking better performance it may be a good idea to build an extension. This is safer and arguably easier to do in Rust than in C.
In this talk we will take a look at existing crates that provide interface to Python and see how easy it is to use them.
Then we go through the demo and see it in action.
Run some benchmarks against pure Python and also Cython.
Write a Dockerfile to build it all together.
Discuss CI/CD for mixed Rust/Python projects.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mikhail Medvedev</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/extending-python-with-rust.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>All Other Programming Languages</category><category>Compiler and Interpreters</category><category>Deployment/Continuous Integration and Delivery</category><category>Docker</category><category>Rust</category></item><item><title>Aplicações web com Flask e Docker</title><link>https://pyvideo.org/flask-conf-2018/aplicacoes-web-com-flask-e-docker.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Aplicações web com Flask e Docker - Palestra de Felipe Alcantara na Flask Conf 2018.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Felipe Alcantara</dc:creator><pubDate>Sat, 25 Aug 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-08-25:/flask-conf-2018/aplicacoes-web-com-flask-e-docker.html</guid><category>Flask Conf 2018</category><category>flask</category><category>docker</category></item><item><title>Debugging flask application within a docker container using VSCode</title><link>https://pyvideo.org/flaskcon-2021/debugging-flask-application-within-a-docker-container-using-vscode.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We all love Docker which helps us a lot in deploying our applications without worrying about what OS we are using and what software versions we have. As a developer you come across a bug every now and then. To solve a bug debug comes very handy. In this talk, I would love to show you one of the ways to debug your flask application within a docker container using VSCode. To do that first, we will build a small flask application and write a Dockerfile for that and run the application. When we want to debug that application we need debugpy package which I don't want to put it in my final docker image so instead of building a different Dockerfile for each purpose we will get to know a bit about Docker multistage build concept and update the current Dockerfile and debug our flask application.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ashok Tankala</dc:creator><pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2021-12-01:/flaskcon-2021/debugging-flask-application-within-a-docker-container-using-vscode.html</guid><category>FlaskCon 2021</category><category>flask</category><category>docker</category><category>debugging</category></item><item><title>Containerization 101 with Docker and Flask</title><link>https://pyvideo.org/flaskcon-2023/containerization-101-with-docker-and-flask.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;An interactive workshop recorded for Flaskcon2023. Covers an introduction to Docker (containers/images/registries), containerizing a Flask app with a Dockerfile, and using databases with Docker compose.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Pamela Fox</dc:creator><pubDate>Fri, 15 Dec 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-12-15:/flaskcon-2023/containerization-101-with-docker-and-flask.html</guid><category>FlaskCon 2023</category><category>flask</category><category>docker</category></item><item><title>Introduction To Docker / Python Microservices</title><link>https://pyvideo.org/hsvpy-huntsvilles-python-meetup/introduction-to-docker-python-microservices.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Two talks: 1) How Docker helped save a company time and money by automated environment setup / A look at Python Microservices using celery&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kyle Galloway</dc:creator><pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-08:/hsvpy-huntsvilles-python-meetup/introduction-to-docker-python-microservices.html</guid><category>HSV.py - Huntsville's Python Meetup</category><category>Docker</category><category>microservices</category></item><item><title>Automate Your Integration Tests Using pytest-docker-compose</title><link>https://pyvideo.org/kiwi-pycon-2019/automate-your-integration-tests-using-pytest-docker-compose.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Sometimes unit tests aren't enough, and you need to actually deploy your solution to see how it behaves as a whole. Utilities like docker-compose make it easy to stand up an entire environment, but the actual testing part still has to be done manually... or does it? Learn how to automate your integration tests using pytest-docker-compose today!&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Phoenix Zerin</dc:creator><pubDate>Sat, 24 Aug 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-08-24:/kiwi-pycon-2019/automate-your-integration-tests-using-pytest-docker-compose.html</guid><category>Kiwi PyCon 2019</category><category>docker</category><category>docker-compose</category><category>pytest</category><category>testing</category></item><item><title>Extend Docker using Python</title><link>https://pyvideo.org/pycon-israel-2017/extend-docker-using-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Docker is the most popular platform to run Python applications within containers. Many companies are using this platform to either deploy micro-services or test the code changes before merging it to production. Docker has 3 extension points: Drivers, Plugins and user-facing API. I am going to focus on the latter (user-facing API) and by the end of the talk, you will learn Docker's REST API and know how to extend Docker capabilities using Python.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Boaz Shuster</dc:creator><pubDate>Tue, 13 Jun 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-06-13:/pycon-israel-2017/extend-docker-using-python.html</guid><category>PyCon Israel 2017</category><category>docker</category></item><item><title>Launch Jupyter to the Cloud with Docker and Terraform</title><link>https://pyvideo.org/pycon-israel-2018/launch-jupyter-to-the-cloud-with-docker-and-terraform.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Launch Jupyter to the Cloud: an example of using Docker and Terraform&lt;/p&gt;
&lt;p&gt;In this talk, we will use a task: hiring a GPU on Google Cloud Platform to train neural network, as an example to show how an application can be deployed on a cloud platform with Docker and Terraform. The goal is to have Jupyter Notebook running in an environment with Tensorflow (GPU version) and other libraries installed on a Google Compute Engine.&lt;/p&gt;
&lt;p&gt;This talk is for people with no experience in application deployment on cloud service but would benefit form computational reproducibility and cloud service, potentially data scientists/ analysts or tech practitioners who didn't have a software developing background. We will use an example that is simple but useful in data science to demonstrate basic usage of Docker and Terraform which would be beneficial to beginners who would like to simplify their work flow with those tools.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Cheuk Ting Ho</dc:creator><pubDate>Tue, 05 Jun 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-06-05:/pycon-israel-2018/launch-jupyter-to-the-cloud-with-docker-and-terraform.html</guid><category>PyCon Israel 2018</category><category>jupyter</category><category>docker</category><category>terraform</category></item><item><title>Sparking Pandas: an experiment</title><link>https://pyvideo.org/pycon-italia-2017/sparking-pandas-an-experiment.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas is a good library to deal with tabular data. What if you need to
manage an amount of data that doesn’t fit into memory? What if you want
to “distribute” your computations among multiple machines?&lt;/p&gt;
&lt;p&gt;Starting from a real scenario, Apache Spark will be presented as the
main tool to read and process collected data. It will be shown how a
Pandas-like syntax will come in handy to run aggregations, filtering and
grouping using a Spark Dataframe.&lt;/p&gt;
&lt;p&gt;A previous knowledge of Docker and Docker Compose will be very useful
while knowing MongoDB (where data will be fetched from) is not
mandatory. Basics of functional programming will help to understand
Spark inner logic.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Francesco Bruni</dc:creator><pubDate>Fri, 07 Apr 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-04-07:/pycon-italia-2017/sparking-pandas-an-experiment.html</guid><category>PyCon Italia 2017</category><category>microservices</category><category>Jupyter</category><category>mongodb</category><category>data-visualization</category><category>data-analysis</category><category>spark</category><category>docker</category></item><item><title>DevOps di applicazioni Python (e non solo) su OpenShift</title><link>https://pyvideo.org/pycon-italia-2018/devops-di-applicazioni-python-e-non-solo-su-openshift.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="section" id="abstract"&gt;
&lt;h4&gt;Abstract&lt;/h4&gt;
&lt;p&gt;OpenShift Origin è la Platform-as-a-Service opensource di riferimento.
Basata su Kubernetes e Docker, contiene features aggiuntive e
integrazioni con altri componenti che semplificano le pratiche di
DevOps.&lt;/p&gt;
&lt;p&gt;Dopo una breve introduzione ad Openshift ed alla sua architettura,
vedremo come:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;fare il setup di infrastrutture applicative microservice-based (es.
microservizi Python Flask/Django, single page application Angular,
ecc…)&lt;/li&gt;
&lt;li&gt;creare una piattaforma di Continuous Integration e Continuous
Delivery&lt;/li&gt;
&lt;li&gt;implementare e gestire la CI/CD di microservice-based application
sfruttando l’integrazione con Git e Jenkins&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="agenda"&gt;
&lt;h4&gt;Agenda&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;architettura di base di OpenShift&lt;/li&gt;
&lt;li&gt;come costruire un &lt;em&gt;project&lt;/em&gt; OpenShift: &lt;em&gt;builds&lt;/em&gt; e &lt;em&gt;deployments&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;automatizzare il setup mediante &lt;em&gt;template&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;utilizzare Git, Jenkins e Openshift per creare una semplice pipeline
di CI/CD&lt;/li&gt;
&lt;li&gt;strategie di deployment avanzate: &lt;em&gt;blue-green deployment&lt;/em&gt; , &lt;em&gt;A/B
deployment&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="prerequisiti"&gt;
&lt;h4&gt;Prerequisiti&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;conoscenza base di Git e Jenkins&lt;/li&gt;
&lt;li&gt;conoscenza base dei concetti CI/CD e DevOps&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;in __on &lt;strong&gt;venerdì 20 aprile&lt;/strong&gt; at 11:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Francesco Fiore</dc:creator><pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-20:/pycon-italia-2018/devops-di-applicazioni-python-e-non-solo-su-openshift.html</guid><category>PyCon Italia 2018</category><category>microservices</category><category>continuous-integration</category><category>git</category><category>continuous-delivery</category><category>kubernetes</category><category>devops</category><category>jenkins</category><category>docker</category><category>OpenShift</category></item><item><title>PaaS per tutti i gusti: CI/CD sotto controllo con Kubernetes e Dokku</title><link>https://pyvideo.org/pycon-italia-2018/paas-per-tutti-i-gusti-cicd-sotto-controllo-con-kubernetes-e-dokku.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In questo talk saranno illustrati processi e workflow tipici dei
paradigmi del DevOp e delle metodologie Agile. Vedremo quali
&lt;strong&gt;accorgimenti&lt;/strong&gt; devono essere presi con le applicazioni pacchettizzate
con &lt;strong&gt;Docker&lt;/strong&gt; , in particolare le applicazioni Django e come &lt;strong&gt;evitare
le problematiche principali che portano frustrazione e impediscono
un’adozione reale della CI/CD&lt;/strong&gt;. Saranno presentati degli esempi pratici
&lt;strong&gt;workflow&lt;/strong&gt; implementati con successo, in modo snello, versionato e
ripetibile, in ambienti che vanno dal test fino alla produzione. In
ultimo faremo una carrellata dei sistemi di &lt;strong&gt;PaaS&lt;/strong&gt; più in voga del
momento concentrandoci quindi su &lt;strong&gt;Dokku&lt;/strong&gt; e &lt;strong&gt;Kubernetes&lt;/strong&gt; , che
coprono tutto il ventaglio delle necessità di deploy, dal piccolo sito
fino al sistema ultra scalabile e ridondato.&lt;/p&gt;
&lt;p&gt;Prerequisito per il talk è conoscere i concetti base di Docker e
dell’uso di git. Durante il talk con 3 distinti esempi e demo di
complessità crescente esploreremo il mondo della CI/CD.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;venerdì 20 aprile&lt;/strong&gt; at 12:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Claudio Mignanti</dc:creator><pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-20:/pycon-italia-2018/paas-per-tutti-i-gusti-cicd-sotto-controllo-con-kubernetes-e-dokku.html</guid><category>PyCon Italia 2018</category><category>paas</category><category>continuous-integration</category><category>gitlab</category><category>kubernetes</category><category>testing</category><category>git</category><category>docker</category></item><item><title>Scaling your Data infrastructure</title><link>https://pyvideo.org/pycon-italia-2018/scaling-your-data-infrastructure.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;This talk aims to answer a few questions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;What do you do when you need to move your model from your laptop to
production?&lt;/li&gt;
&lt;li&gt;Is &lt;tt class="docutils literal"&gt;big data == I need to use JVM&lt;/tt&gt; the right assumption?&lt;/li&gt;
&lt;li&gt;How can I put my jupyter notebook in production?&lt;/li&gt;
&lt;li&gt;How do you apply the best software engineering practices (testing and
ci for example) inside your data science process?&lt;/li&gt;
&lt;li&gt;How do you “decouple” your data scientists, developers and devops
teams?&lt;/li&gt;
&lt;li&gt;How do you guarantee the reproducibility of your models?&lt;/li&gt;
&lt;li&gt;How do you scale your training process when does not fit in memory
anymore?&lt;/li&gt;
&lt;li&gt;How do you serve your models and provide an easy rollback system?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Agenda:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The Data Science workflow&lt;/li&gt;
&lt;li&gt;Scaling is not just a matter of the size of your Data&lt;/li&gt;
&lt;li&gt;Scaling when the size of your Data matters&lt;/li&gt;
&lt;li&gt;DDS, Dockerized Data Science&lt;/li&gt;
&lt;li&gt;Cassiny&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ll share my experience highlighting some of the challenges I faced and
the solutions I came up to answer these questions.&lt;/p&gt;
&lt;p&gt;During this presentation I will mention libraries like jupyter, atom,
scikit- learn, dask, ray, parquet, arrow and many others.&lt;/p&gt;
&lt;p&gt;The principles and best practices I will share are something that you
can apply, more or less easily, if you are running or in the process to
run a production system based on the Python stack.&lt;/p&gt;
&lt;p&gt;This talk will focus on (my) best practices to run the Python Data stack
together and I will also talk about Cassiny, an open source project I
started, that aims to simplify your life if you want to use a completely
Python based solution in your data science workflow.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 20 April&lt;/strong&gt; at 11:00 &lt;a class="reference external" href="/en/sprints/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Christian Barra</dc:creator><pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-20:/pycon-italia-2018/scaling-your-data-infrastructure.html</guid><category>PyCon Italia 2018</category><category>Jupyter</category><category>CloudComputing</category><category>pydata</category><category>#lessonslearned</category><category>Big-Data</category><category>S3</category><category>Data-Scientist</category><category>#amicodialessia</category><category>java</category><category>docker</category><category>cloud</category></item><item><title>Basta problemi con tensorflow usando Docker &amp; Nvidia Docker</title><link>https://pyvideo.org/pycon-italia-2019/basta-problemi-con-tensorflow-usando-docker-nvidia-docker.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Di sicuro vi sarà capitato che condividendo o effettuando un progetto
tensorflow questo non funzioni correttamente. Soprattutto non riesco a
far scalare la mia app perchè non ho abbastanza macchine con GPU e
eseguire lo scale su macchine con solo CPU è costoso per poi ottenere
scarsi benefici. La soluzione è utilizzare Docker e Nvidia Docker.
Vedremo perchè Docker è migliore di una macchina virtuale e come
cambiano le prestazioni rispetto ad andare direttamente sulla macchina.
Vedremo trucchi su come strutturare dei docker-compose file senza
duplicazione per poter sviluppare agilmente sia con GPU che senza, poter
effettuare un deploy con tranquillità e poter scalare facilmente anche
senza GPU. Slide Link: &amp;lt;&lt;a class="reference external" href="https://www.slideshare.net/NicolaLandro/basta"&gt;https://www.slideshare.net/NicolaLandro/basta&lt;/a&gt;-
problemicontensorflowusandodockernvidiadocker&amp;gt;&lt;/p&gt;
&lt;p&gt;Feedback form: &lt;a class="reference external" href="https://python.it/feedback-1528"&gt;https://python.it/feedback-1528&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Saturday 4 May&lt;/strong&gt; at 10:45 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Nicola Landro</dc:creator><pubDate>Sat, 04 May 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-04:/pycon-italia-2019/basta-problemi-con-tensorflow-usando-docker-nvidia-docker.html</guid><category>PyCon Italia 2019</category><category>OSX</category><category>windows</category><category>devops</category><category>Machine Learning</category><category>GNU/Linux</category><category>cuda</category><category>tensorflow</category><category>docker</category></item><item><title>Geospatial analysis with Python</title><link>https://pyvideo.org/pycon-italia-2019/geospatial-analysis-with-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Due to its effectiveness and simplicity, Python is spreading as a choice
for handling geospatial data. From running algorithms capable of
extracting geo- referred insights or processing geo archives, Python
could represent a powerful tool to handle geo-related problems thanks to
an extensive set of libraries. The training will give an overview about
processing geospatial data with Python. An approximate agenda will
include:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Introduction&lt;ul&gt;
&lt;li&gt;setting up the the environment&lt;/li&gt;
&lt;li&gt;an introduction to geospatial world&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Working with geospatial data&lt;ul&gt;
&lt;li&gt;playing with geo archives (vector/rasters)&lt;/li&gt;
&lt;li&gt;extracting geo analytics&lt;/li&gt;
&lt;li&gt;Vector tiles big vector data&lt;/li&gt;
&lt;li&gt;Apache Spark for geospatial raster analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Python for Earth observation&lt;ul&gt;
&lt;li&gt;Classifying earth observation images&lt;/li&gt;
&lt;li&gt;Extracting insights from Copernicus products&lt;/li&gt;
&lt;li&gt;Use SNAP from Python&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;No tools are required for attending this training. Bring your PC with
Docker installed. Further instructions will be provided.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1674"&gt;https://python.it/feedback-1674&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 10:30 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt; in __on &lt;strong&gt;Saturday 4
May&lt;/strong&gt; at 18:00 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Francesco Bruni</dc:creator><pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-03:/pycon-italia-2019/geospatial-analysis-with-python.html</guid><category>PyCon Italia 2019</category><category>Jupyter</category><category>pyspark</category><category>geospatial</category><category>geopynotebook</category><category>spark</category><category>docker</category></item><item><title>PostgreSQL on the kube</title><link>https://pyvideo.org/pycon-italia-2019/postgresql-on-the-kube.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Kubernetes è un sistema di orchestrazione di container che permette di
gestire il deploy, lo scaling e l’aggiornamento di una applicazione e di
tutti i suoi componenti.&lt;/p&gt;
&lt;p&gt;In questo talk parleremo di quali strumenti sono a disposizione per
effettuare un deploy di un database PostgreSQL in un cluster Kubernetes.
Inoltre vedremo come sia implementabile l’alta disponibilità e la
disaster recovery, in maniera da avere i propri dati al sicuro e sempre
accessibili.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1784"&gt;https://python.it/feedback-1784&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 10:30 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marco Nenciarini</dc:creator><pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-03:/pycon-italia-2019/postgresql-on-the-kube.html</guid><category>PyCon Italia 2019</category><category>postgresql</category><category>postgres</category><category>kubernetes</category><category>storage</category><category>containers</category><category>docker</category><category>k8s</category><category>cloud</category></item><item><title>Da crontab a Celery senza rimpianti</title><link>https://pyvideo.org/pycon-italia-2022/da-crontab-a-celery-senza-rimpianti.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Da crontab a Celery senza rimpianti - PyCon Italia 2022&lt;/p&gt;
&lt;p&gt;Eseguire i backup, controllare le email, cancellare i log .. ci sono un
sacco di cose utili che si possono automatizzare con i cron jobs ma dopo
un po’ di tempo i vostri file di crontab diventano ingestibili. In
questo caso Celery può diventare il vostro migliore amico. I cont jobs
sono fantastici, possono salvarti la vita e il matrimonio, lavorano di
giorno e di notte con qualsiasi tempo e non sbagliano mai orario. Ma
quando diventano troppi diventa davvero difficile gestirli e poi avete
mai provato ad eseguire un cron job in un container?&lt;/p&gt;
&lt;p&gt;la prima volta che ho provato Celery è stato abbastanza frustrante, il
setup iniziale non è semplice ma se non ci si arrende il risultato è
sorprendente e il potere che ti può dare Celery una volta installato è
gigantesco.&lt;/p&gt;
&lt;p&gt;Speaker: Marco Pavanelli&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marco Pavanelli</dc:creator><pubDate>Fri, 03 Jun 2022 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2022-06-03:/pycon-italia-2022/da-crontab-a-celery-senza-rimpianti.html</guid><category>PyCon Italia 2022</category><category>django</category><category>docker</category><category>infrastructure</category></item><item><title>Managing large-scale ML pipelines with MLflow and serverless computing.</title><link>https://pyvideo.org/pycon-italia-2022/managing-large-scale-ml-pipelines-with-mlflow-and-serverless-computing.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Managing large-scale Machine Learning pipelines with MLflow and
serverless computing. - PyCon Italia 2022&lt;/p&gt;
&lt;p&gt;MLOps aims to manage the machine learning (ML) lifecycle including
experimentation, reproducibility, deployment, and model registry. Come
to discover how in Vedrai - one of the top AI startups in Europe - we
enhance and maintain ML pipelines models in production reliably and
efficiently using MLOps. Problem:&lt;/p&gt;
&lt;p&gt;One difficulty of employing Machine Learning (ML) within organizations
is managing the model’s lifecycle. Moving from experimenting to
deployment in production environments is operated by different steps:
Preparing and Analysing Data, Training, Deployment, Monitoring, and
Governance of ML models. So, it is crucial to possess a platform to
manage and organize the ML lifecycle.&lt;/p&gt;
&lt;p&gt;Solution:&lt;/p&gt;
&lt;p&gt;In Vedrai, we combined the strength of the MLflow framework and the
resilience of AWS serverless services to manage, deploy, and scale our
ML models in production. MLflow is an open-source framework for tracking
the entire ML lifecycle from training to deployment. Among the
functions, it offers model tracking, packaging, and serving. Whereas,
deploying ML applications is an infrastructure affair that needs to be
scalable with minimum server management, which makes AWS serverless
services a great choice.&lt;/p&gt;
&lt;p&gt;Value:&lt;/p&gt;
&lt;p&gt;MLflow enforces the model’s reproducibility and robustness at the same
time allowing more centralized experimentation. AWS serverless services
allow training and inferencing pipelines to run without provisioning or
managing servers while only paying for the time it takes to run.&lt;/p&gt;
&lt;p&gt;Summary:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;State of the art of MLOps.&lt;/li&gt;
&lt;li&gt;Record and query experiments with MLflow Tracking.&lt;/li&gt;
&lt;li&gt;Package data science code with MLflow Projects.&lt;/li&gt;
&lt;li&gt;Store ML models with MLflow Models Registry.&lt;/li&gt;
&lt;li&gt;Deploy ML models in the AWS environment.&lt;/li&gt;
&lt;li&gt;Future MLOps challenges.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Speaker: ilyas chaoua&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">ilyas chaoua</dc:creator><pubDate>Fri, 03 Jun 2022 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2022-06-03:/pycon-italia-2022/managing-large-scale-ml-pipelines-with-mlflow-and-serverless-computing.html</guid><category>PyCon Italia 2022</category><category>architecture</category><category>aws</category><category>best practice</category><category>deep learning</category><category>devops</category><category>docker</category><category>infrastructure</category><category>machine learning</category><category>open source</category><category>operations</category><category>packaging</category><category>performance</category><category>scaling</category></item><item><title>/metrics, a must have</title><link>https://pyvideo.org/pycon-italia-2022/metrics-a-must-have.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;/metrics, a must have - PyCon Italia 2022&lt;/p&gt;
&lt;p&gt;With modern applications being distributed, only testing is enough to
ensure your apps are healthy? The web is wild and users are
unpredictable. Having a good strategy of observability in place is
essential. In this talk, I’ll demo how to setup extensible metrics in
your app using open-source tools With the advent of microservices and
all that jazz, the complexity of monitoring applications increased quite
a lot. How many instances of my app do I have running? Are they all
healthy? How is it performing under heavy load? Questions like that can
not be answered by guesses only, but you need data to be more assertive.&lt;/p&gt;
&lt;p&gt;In this talk, we will create a sample web application and instrument it
using Prometheus (and potentially other tools such as Grafana, Jaeger,
Alert Manager, etc) and see in practice how we can monitor web
applications in real-time.&lt;/p&gt;
&lt;p&gt;Speaker: Luiz Marques&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Luiz Marques</dc:creator><pubDate>Fri, 03 Jun 2022 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2022-06-03:/pycon-italia-2022/metrics-a-must-have.html</guid><category>PyCon Italia 2022</category><category>apis</category><category>asyncio</category><category>debugging</category><category>docker</category><category>open source</category><category>performance</category><category>tooling</category></item><item><title>Patti chiari, amicizia lunga. Disaccoppiamo lo sviluppo con test di contratto</title><link>https://pyvideo.org/pycon-italia-2022/patti-chiari-amicizia-lunga-disaccoppiamo-lo-sviluppo-con-test-di-contratto.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Patti chiari amicizia lunga. Come disaccoppiamo lo sviluppo tramite i
test di contratto - PyCon Italia 2022&lt;/p&gt;
&lt;p&gt;Front-end, vi è mai capitato che nonostante vi siate messi d’accordo con
il back-end l’endpoint non vi espone qualcosa? Noi abbiamo risolto
utilizzando il Contract testing, vi mostrerò i vantaggi e alcuni casi
reali di come scrivere un patto aiuta a rendere più semplice lo sviluppo
per tutti. Quando sono entrato in 20tab l’azienda seguiva già le
metodologie Lean e Agile ed era composta principalmente da sviluppatori
Python/Django. Quando abbiamo deciso di disaccoppiare i servizi
(back-end in Django e front-end in React JS) siamo andati incontro a
difficoltà dovute ai differenti tempi di sviluppo o limiti tecnici. Come
prima soluzione avevamo provato con alternare lo sviluppo dei due
servizi prima iniziava il back-end, una volta completato partiva lo
sviluppo front-end. Questo ci rendeva inefficienti a volte i dati che
arrivavano al front-end erano insufficienti o eccessivi rispetto
all’interfaccia che doveva costruire. Quindi abbiamo provato a
dettagliare con maggior rigore tutti i requisiti tecnici necessari per
partire in parallelo, ma lato front-end dovevamo sempre costruirci un
server finto per procedere con lo sviluppo. In questo ci è venuto
incontro il contract testing, entrambi i rappresentanti dei servizi si
riuniscono prendono il design lo analizzano insieme e il front-end
scrive un test di contratto dopo di che entrambi i servizi possono
procedere con i rispettivi sviluppi in maniera svincolata tra di loro.
Il front-end può sfruttare il pact-stub-server per scrivere test
funzionali con cypress e per lavorare senza neanche tirare su il
servizio back-end. Questo ha portato il front-end a riorganizzare il
proprio template, ora abbiamo 3 tipi di test diversi, quelli unitari sui
componenti, quelli funzionali con cypress e quelli di contratto con Pact
JS. Tutti questi test tramite Docker vengono eseguiti nelle nostre
pipeline e bloccano il nostro processo di deploy in caso di fallimento.&lt;/p&gt;
&lt;p&gt;Slide:&lt;/p&gt;
&lt;p&gt;Speaker: Daniele Pompa&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Daniele Pompa</dc:creator><pubDate>Fri, 03 Jun 2022 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2022-06-03:/pycon-italia-2022/patti-chiari-amicizia-lunga-disaccoppiamo-lo-sviluppo-con-test-di-contratto.html</guid><category>PyCon Italia 2022</category><category>apis</category><category>django</category><category>docker</category><category>javascript</category><category>testing</category></item><item><title>DIY Serverless Platform with Python3 and Docker</title><link>https://pyvideo.org/pycon-jamaica-2016/diy-serverless-platform-with-python3-and-docker.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A walkthrough on how I built my own serverless platform to run both ephemeral and long-lasting functions in Python on top of Docker, capable of handling REST and websocket connections. Will go over architecture, show code, and discuss pain points as well as next steps.  #pyconjamaica2016&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joir-dan Gumbs</dc:creator><pubDate>Fri, 18 Nov 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-11-18:/pycon-jamaica-2016/diy-serverless-platform-with-python3-and-docker.html</guid><category>PyCon Jamaica 2016</category><category>Serverless</category><category>Docker</category></item><item><title>Docker for Data Science</title><link>https://pyvideo.org/pycon-us-2018/docker-for-data-science.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter notebooks simplify the process of developing and sharing Data Science projects across groups and organizations. However, when we want to deploy our work into production, we need to extract the model from the notebook and package it up with the required artifacts (data, dependencies, configurations, etc) to ensure it works in other environments. Containerization technologies such as Docker can be used to streamline this workflow.&lt;/p&gt;
&lt;p&gt;This hands-on tutorial presents Docker in the context of Reproducible Data Science - from idea to application deployment. You will get a thorough introduction to the world of containers; learn how to incorporate Docker into various Data Science projects; and walk through the process of building a Machine Learning model in Jupyter and deploying it as a containerized Flask REST API.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aly Sivji</dc:creator><pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-05-10:/pycon-us-2018/docker-for-data-science.html</guid><category>PyCon US 2018</category><category>jupyter</category><category>docker</category><category>data science</category></item><item><title>Running jupyter notebook remotely in a docker swarm cluster</title><link>https://pyvideo.org/pydata-barcelona-2017/running-jupyter-notebook-remotely-in-a-docker-swarm-cluster.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The current version of Jupyter Notebook computes the document state at the browser side, this is a problem if you run long jobs in a remote notebook from a laptop. If you close the browser you lose all the output of the current running cell. I will explain how we solved this problem in our lab. This solution it also allows a &amp;quot;walkie-talkie&amp;quot; like real-time collaboration.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The solution is based on running a docker container with a browser and a VNC server. All the remote access to the notebooks is done using Apache Guacamole a clientless remote desktop gateway. Everything is running on a dynamic docker swarm cluster of 20 nodes. As a lateral effect, this solution it also allows a real-time collaboration between users in a way that multiple users can access at the same time the same desktop (but they have to fight for the mouse and the keyboard).&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/jordeu/pytalks/tree/master/20170520_pydata_jupyter_in_a_docker_cluster"&gt;https://github.com/jordeu/pytalks/tree/master/20170520_pydata_jupyter_in_a_docker_cluster&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jordi Deu-Pons</dc:creator><pubDate>Sat, 20 May 2017 15:00:00 +0200</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-05-20:/pydata-barcelona-2017/running-jupyter-notebook-remotely-in-a-docker-swarm-cluster.html</guid><category>PyData Barcelona 2017</category><category>jupyter notebook</category><category>docker</category><category>swarm</category></item><item><title>Setting up predictive analytics services with Palladium</title><link>https://pyvideo.org/pydata-berlin-2016/setting-up-predictive-analytics-services-with-palladium.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Description&lt;/p&gt;
&lt;p&gt;We will introduce Palladium, an open source framework for setting up predictive analytics services. It supports tasks like fitting, evaluating, storing, and distributing (predictive) models. Core ML processes are compatible with scikit-learn and a large number of scikit-learn’s features can be used. Besides the use of Palladium we will also show how to use it with Docker and Mesos / Marathon.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;In this talk, we will introduce Palladium, an open source framework for easily setting up predictive analytics services (&lt;a class="reference external" href="https://github.com/ottogroup/palladium"&gt;https://github.com/ottogroup/palladium&lt;/a&gt;). It supports tasks like fitting, evaluating, storing, distributing, and updating (predictive) models. Core machine learning processes are compatible with the open source machine learning library scikit-learn and thus, a large number of scikit-learn’s features can be used with Palladium. Although being implemented in Python, Palladium provides support for other languages and is shipped with examples how to integrate and expose R and Julia models. For an efficient deployment of services based on Palladium, a script to create Docker images automatically is provided. This talk will cover the use of Palladium including an example where a simple classification service is set up. We will also show how Docker and Mesos / Marathon can be used to deploy and scale Palladium-based services. Having basic knowledge about Machine Learning and/or scikit-learn would be an advantage when attending this talk.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andreas Lattner</dc:creator><pubDate>Tue, 07 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-06-07:/pydata-berlin-2016/setting-up-predictive-analytics-services-with-palladium.html</guid><category>PyData Berlin 2016</category><category>palladium</category><category>scikit-learn</category><category>docker</category><category>mesos</category><category>marathon</category><category>machine learning</category></item><item><title>Dev Ops meets Data Science Taking models from prototype to production with Docker</title><link>https://pyvideo.org/pydata-dc-2016/dev-ops-meets-data-science-taking-models-from-prototype-to-production-with-docker.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;We present the evolution of a model to a production API that can scale to large e-commerce needs. On the journey we discuss metrics of success and how to use the Kubernetes cluster manager and associated tools for deploy. In addition to the use of these tools we highlight how to make use of the cluster management system for further testing and experimentation with your models.&lt;/p&gt;
&lt;p&gt;The chasm between data science and dev ops is often wide and impenetrable, but the two fields have more in common than meets the eye. Every data scientist will be able to lean in and help their career by investing in a basic understanding the basic principles of dev ops. In this talk I present the notions of service level indicators, objectives, and agreements. I cover the rigorous monitoring and testing of services. Finally we demonstrate how to build a basic data science workflow and push to production level APIs with Docker and Kubernetes.&lt;/p&gt;
&lt;p&gt;Kubernetes is an opinionated container cluster manager with an easy to use, robust interface. It can be use on very small and very large clusters. Docker is a container system that allows one to build code in an isolated environment. Paired with a container manager such as Kubernetes we are able to manage millions of instances as needed for a production deployment. These tools are two of many different options but are considered among the best open source solutions available.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andy Terrel</dc:creator><pubDate>Sun, 09 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-09:/pydata-dc-2016/dev-ops-meets-data-science-taking-models-from-prototype-to-production-with-docker.html</guid><category>PyData DC 2016</category><category>Data</category><category>data science</category><category>docker</category><category>models</category><category>science</category></item><item><title>Building Python apps with Docker</title><link>https://pyvideo.org/pytexas-2015/building-python-apps-with-docker.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you haven't heard of Docker yet, its a great tool that allows you
wrap up your app and everything it needs to run: code, runtime, and even
system libraries and guarantee that it will always run the same,
regardless of the environment (local machine, server, or even the
cloud). Whether you're deploying a web app, performing data analysis, or
creating local environments for your dev team or CI builds, Docker can
help.&lt;/p&gt;
&lt;p&gt;I'll give an introduction to Docker, an overview of some of the current
tools in the Docker ecosystem (Docker Machine and Docker Compose) and
demonstrate how to create, build, and deploy Python applications using
Docker.&lt;/p&gt;
&lt;p&gt;This talk is targeted towards web developers, data scientists, or really
anyone who develops using Python that would like to learn more about
Docker and how it can help their projects.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mark Adams</dc:creator><pubDate>Fri, 09 Oct 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-10-09:/pytexas-2015/building-python-apps-with-docker.html</guid><category>PyTexas 2015</category><category>Docker</category></item><item><title>Dockerizing the Python</title><link>https://pyvideo.org/pycon-se-2017/dockerizing-the-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The focus of this talk will be on building and running python programs in a docker container. A major chunk of the talk will also concentrate on the docker setup &amp;amp; it’s complete echo system. The purpose behind the talk is the demonstrate the usage of docker in everyday python development &amp;amp; deployment environment.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ambreen Sheikh</dc:creator><pubDate>Wed, 06 Sep 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-09-06:/pycon-se-2017/dockerizing-the-python.html</guid><category>PyCon SE 2017</category><category>docker</category></item></channel></rss>