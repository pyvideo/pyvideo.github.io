<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Lukas Michel</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 03 Aug 2020 00:00:00 +0000</lastBuildDate><item><title>Finite-Memory Near-Optimal Learning for Markov Decision Processes with Long-Run Average Reward</title><link>https://pyvideo.org/uai-2020/finite-memory-near-optimal-learning-for-markov-decision-processes-with-long-run-average-reward.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Finite-Memory Near-Optimal Learning for Markov Decision Processes with Long-Run Average Reward&lt;/p&gt;
&lt;p&gt;Jan Kretinsky (TU Munich)*; Fabian Michel (TU Munich); Lukas Michel (TU Munich); Guillermo Perez (UAntwerpen)&lt;/p&gt;
&lt;p&gt;We consider learning policies online in Markov decision processes with the long-run average reward (a.k.a. mean payoff). To ensure implementability of the policies, we focus on policies with finite memory. Firstly, we show that near optimality can be achieved almost surely, using an unintuitive gadget we call forgetfulness. Secondly, we extend the approach to a setting with partial knowledge of the system topology, introducing two optimality measures and providing near-optimal algorithms also for these cases.&amp;quot;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jan Kretinsky</dc:creator><pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-08-03:/uai-2020/finite-memory-near-optimal-learning-for-markov-decision-processes-with-long-run-average-reward.html</guid><category>UAI 2020</category></item></channel></rss>