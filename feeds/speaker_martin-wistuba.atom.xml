<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Martin Wistuba</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_martin-wistuba.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2023-04-17T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Hyperparameter optimization for the impatient</title><link href="https://pyvideo.org/pydata-berlin-2023/hyperparameter-optimization-for-the-impatient.html" rel="alternate"></link><published>2023-04-17T00:00:00+00:00</published><updated>2023-04-17T00:00:00+00:00</updated><author><name>Martin Wistuba</name></author><id>tag:pyvideo.org,2023-04-17:/pydata-berlin-2023/hyperparameter-optimization-for-the-impatient.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the last years, Hyperparameter Optimization (HPO) became a fundamental step in the training of Machine Learning (ML) models and in the creation of automatic ML pipelines.
Unfortunately, while HPO improves the predictive performance of the final model, it comes with a significant cost both in terms of computational â€¦&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the last years, Hyperparameter Optimization (HPO) became a fundamental step in the training of Machine Learning (ML) models and in the creation of automatic ML pipelines.
Unfortunately, while HPO improves the predictive performance of the final model, it comes with a significant cost both in terms of computational resources and waiting time.
This leads many practitioners to try to lower the cost of HPO by employing unreliable heuristics.&lt;/p&gt;
&lt;p&gt;In this talk we will provide simple and practical algorithms for users that want to train models
with almost-optimal predictive performance, while incurring in a significantly lower cost and waiting time. The presented algorithms are agnostic to the application and the model being trained so they can be useful in a wide range of scenarios.&lt;/p&gt;
&lt;p&gt;We provide results from an extensive experimental activity on public benchmarks, including comparisons with well-known techniques like Bayesian Optimization (BO), ASHA, Successive Halving. We will describe in which scenarios the biggest gains are observed (up to 30x) and provide examples for how to use these algorithms in a real-world environment.&lt;/p&gt;
&lt;p&gt;All the code used for this talk is available on [GitHub](&lt;a class="reference external" href="https://github.com/awslabs/syne-tune"&gt;https://github.com/awslabs/syne-tune&lt;/a&gt;).&lt;/p&gt;
</content><category term="PyData Berlin 2023"></category></entry></feed>