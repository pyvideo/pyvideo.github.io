<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 15 Jul 2016 00:00:00 +0000</lastBuildDate><item><title>3D Drawing in Python: Reviving Visual</title><link>https://pyvideo.org/scipy-2016/3d-drawing-in-python-reviving-visual-scipy-2016-catherine-holloway.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In 2000 David Scherer created Visual, a python package with a simple interface for drawing 3D objects to the screen. Visual abstracted away calls to OpenGL vertex drawing, textures, and transformations, and allowed primitive geometric objects to be placed on the screen in an intuitive manner. Visual was subsequently adopted by many researchers and university instructors, primarily in physics, to visualize scientific results and simulation assignments. The original Visual module used C++ to make OpenGL calls, and compatibility with Linux was never implemented. Python and OpenGL have come a long way in the past sixteen years, and now Visual can be made cross-platform by removing the C++ backend. I will present my attempt to re-implement Visual using pyglet, as well as demonstrate its API and usage in education and research visualization.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Catherine Holloway</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/3d-drawing-in-python-reviving-visual-scipy-2016-catherine-holloway.html</guid><category>SciPy 2016</category></item><item><title>A BLAS for Tensors with Portable High Performance</title><link>https://pyvideo.org/scipy-2016/a-blas-for-tensors-with-portable-high-performance-scipy-2016-devin-matthews.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Devin Matthews</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/a-blas-for-tensors-with-portable-high-performance-scipy-2016-devin-matthews.html</guid><category>SciPy 2016</category></item><item><title>A Whirlwind Tour of UC Berkeley’s Data Science Education Program</title><link>https://pyvideo.org/scipy-2016/a-whirlwind-tour-of-uc-berkeleys-data-science-education-program-scipy-2016-cathryn-carson-sam.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Cathryn Carson, Sam</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/a-whirlwind-tour-of-uc-berkeleys-data-science-education-program-scipy-2016-cathryn-carson-sam.html</guid><category>SciPy 2016</category></item><item><title>Automatic Machine Learning?</title><link>https://pyvideo.org/scipy-2016/automatic-machine-learning-scipy-2016-andreas-mueller.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andreas Mueller</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/automatic-machine-learning-scipy-2016-andreas-mueller.html</guid><category>SciPy 2016</category></item><item><title>Community-Powered Packaging with conda-forge (BoF Session)</title><link>https://pyvideo.org/scipy-2016/community-powered-packaging-with-conda-forge-bof-session-scipy-2016-phillip-elson.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Phillip Elson</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/community-powered-packaging-with-conda-forge-bof-session-scipy-2016-phillip-elson.html</guid><category>SciPy 2016</category><category>conda</category><category>conda-forge</category></item><item><title>Computational Supply Chain Risk Management for Open Source Software</title><link>https://pyvideo.org/scipy-2016/computational-supply-chain-risk-management-for-open-source-software-scipy-2016-sebastian-benthall.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We address the cybersecurity problems of supply chain risk management in open source software. How does one detect high-risk components in a deployed software system that includes many open source components? As a complement to software assurance approaches based on static source code analysis, we propose a technique based on an analysis of the entire open source ecosystem, inclusive of its technical products and contributor activity. we show how dependency topology, community activity, and exogenous vulnerability and exposure information can be integrated to detect high risk &amp;quot;hot spots&amp;quot; requiring additional investment. We demonstrate this technique using the Python dependency topology extracted from PyPi and data from GitHub. We will dicuss how our analysis prototype has been implemented with SciPy tools.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sebastian Benthall</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/computational-supply-chain-risk-management-for-open-source-software-scipy-2016-sebastian-benthall.html</guid><category>SciPy 2016</category></item><item><title>Conduit: A Scientific Data Exchange Library for HPC Simulations</title><link>https://pyvideo.org/scipy-2016/conduit-a-scientific-data-exchange-library-for-hpc-simulations-scipy-2016-cyrus-harrison.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Conduit (&lt;a class="reference external" href="http://software.llnl.gov/conduit"&gt;http://software.llnl.gov/conduit&lt;/a&gt;) is a new open source project from Lawrence Livermore National Laboratory. It provides an intuitive model for describing hierarchical scientific data in C++, C, Fortran, and Python. Conduit supports in-core data coupling between packages, serialization, and I/O tasks.&lt;/p&gt;
&lt;p&gt;Conduit leverages ideas from JSON and NumPy to provide a cross-language data access API that simplifies sharing data in the HPC ecosystem. For SciPy 2016, an important focus of our talk will be Python support in Conduit and how positive experiences using Python motivated our approach to build a sane cross-language data description solution.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Cyrus Harrison</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/conduit-a-scientific-data-exchange-library-for-hpc-simulations-scipy-2016-cyrus-harrison.html</guid><category>SciPy 2016</category></item><item><title>Constructing Models to Deal with Missing Data</title><link>https://pyvideo.org/scipy-2016/constructing-models-to-deal-with-missing-data-scipy-2016-deborah-hanus.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Deborah Hanus</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/constructing-models-to-deal-with-missing-data-scipy-2016-deborah-hanus.html</guid><category>SciPy 2016</category><category>data science</category></item><item><title>Democratizing Geostats</title><link>https://pyvideo.org/scipy-2016/democratizing-geostats-scipy-2016-nicholas-ronnei.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Error and uncertainty are a fact of life, however they often go unaccounted for in geospatial models that rely on Digital Elevation Models (DEMs). Our work focuses on mitigating that problem as it relates to SRTM and ASTER GDEM. This is a discussion about how Python works within a broader system that enables researchers to work around this uncertainty without being geostatistics experts. The talk will cover how we use Python for advanced raster processing (including a vertical datum correction), calculating error statistics, and interacting with our spatial database as well as what we're doing with the end product, including a live demo.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Nicholas Ronnei</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/democratizing-geostats-scipy-2016-nicholas-ronnei.html</guid><category>SciPy 2016</category></item><item><title>Diffing and Merging Jupyter Notebooks with nbdime</title><link>https://pyvideo.org/scipy-2016/diffing-and-merging-jupyter-notebooks-with-nbdime-scipy-2016-min-ragan-kelley.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Min Ragan Kelley</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/diffing-and-merging-jupyter-notebooks-with-nbdime-scipy-2016-min-ragan-kelley.html</guid><category>SciPy 2016</category><category>jupyter</category><category>jupyter notebook</category></item><item><title>DyND Callables</title><link>https://pyvideo.org/scipy-2016/dynd-callables-scipy-2016-mark-wiebe.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mark Wiebe</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/dynd-callables-scipy-2016-mark-wiebe.html</guid><category>SciPy 2016</category></item><item><title>Emperor, Interactive Beta diversity Exploration</title><link>https://pyvideo.org/scipy-2016/emperor-interactive-beta-diversity-exploration-scipy-2016-yoshiki-vazquez-baeza.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yoshiki Vazquez Baeza</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/emperor-interactive-beta-diversity-exploration-scipy-2016-yoshiki-vazquez-baeza.html</guid><category>SciPy 2016</category></item><item><title>Generalized Earthquake Focal Mechanism Classification</title><link>https://pyvideo.org/scipy-2016/generalized-earthquake-focal-mechanism-classification-scipy-2016-ben-lasscock.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We present a novel classification technique for identifying earthquake focal mechanism type and fault plane orientation using a robust classification technique rather than the least squares based (HASH) algorithm. The  goal was to support a system capable of automatically classifying earthquakes, for applications such as microseismic monitoring. In this context, classification of both shear or/and tensile failure (mixed double-couple and CLVD sources) was required, so a generalized system was developed. More generally  though, we see applications of this algorithm in hazard monitoring, particularly for early classification of tsunamigenic. The project was implemented in Python, the classification was made easy using scikit-learn and SciPy special functions, and 3-D visualization was done using Mayavi.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ben Lasscock</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/generalized-earthquake-focal-mechanism-classification-scipy-2016-ben-lasscock.html</guid><category>SciPy 2016</category></item><item><title>GR: Plotting with Python or Julia</title><link>https://pyvideo.org/scipy-2016/gr-plotting-with-python-or-julia-scipy-2016-josef-heinen.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;GR is a plotting package for the creation of two- and three-dimensional graphics in Python or Julia, offering unique plotting functions to visualize static or dynamic data with minimal overhead. In addition, GR can be used as a backend for other plotting interfaces or wrappers, in particular when being used in interactive notebooks. This presentation shows how visualization applications with special performance requirements can be designed on the basis of simple and easy-to-use functions as known from the MATLAB plotting library. Using quick practical examples, this talk is going to present the special features and capabilities provided by the GR framework both as a self-contained graphics library or as a fast backend for other packages. Slides may be found here: &lt;a class="reference external" href="http://pgi-jcns.fz-juelich.de/pub/doc/SciPy_2016/GR-Plotting_with_Python_or_Julia.pdf"&gt;http://pgi-jcns.fz-juelich.de/pub/doc/SciPy_2016/GR-Plotting_with_Python_or_Julia.pdf&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Josef Heinen</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/gr-plotting-with-python-or-julia-scipy-2016-josef-heinen.html</guid><category>SciPy 2016</category></item><item><title>Hacking the CPython Interpreter</title><link>https://pyvideo.org/scipy-2016/hacking-the-cpython-interpreter-scipy-2016-james-powell.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">James Powell</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/hacking-the-cpython-interpreter-scipy-2016-james-powell.html</guid><category>SciPy 2016</category></item><item><title>HistomicsTK: Seamless Analytics for Biomedical Microscopy</title><link>https://pyvideo.org/scipy-2016/histomicstk-seamless-analytics-for-biomedical-microscopy-scipy-2016-brian-helba.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We present the architecture of HistomicsTK, an open-source library for the processing and analysis of biomedical microscopy images. HistomicsTK leverages multiple SciPy libraries, and contains an innovative parameter serialization model to expose arbitrary CLI algorithms via a web GUI.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brian Helba</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/histomicstk-seamless-analytics-for-biomedical-microscopy-scipy-2016-brian-helba.html</guid><category>SciPy 2016</category></item><item><title>HyperSpy: How to Easily Bend Multi-dimensional Data to your Analytical Will</title><link>https://pyvideo.org/scipy-2016/hyperspy-how-to-easily-bend-multi-dimensional-data-to-your-analytical-will-scipy-2016-tomas-osta.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;HyperSpy is an open-source Python library that aims at easing the task of visualizing, analyzing, accessing and storing multi-dimensional signals. Such data structures arise in many scientific and engineering fields, from astronomy to electron microscopy. In addition, common non-linear optimization problems and our suggested new solutions will be presented.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomas Osta</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/hyperspy-how-to-easily-bend-multi-dimensional-data-to-your-analytical-will-scipy-2016-tomas-osta.html</guid><category>SciPy 2016</category></item><item><title>Integrating Scripting into Commercial Applications</title><link>https://pyvideo.org/scipy-2016/integrating-scripting-into-commercial-applications-scipy-2016-eric-jones.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Eric Jones</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/integrating-scripting-into-commercial-applications-scipy-2016-eric-jones.html</guid><category>SciPy 2016</category></item><item><title>JupyterLab: Building Blocks for Interactive Computing</title><link>https://pyvideo.org/scipy-2016/jupyterlab-building-blocks-for-interactive-computing-scipy-2016-brian-granger.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Project Jupyter provides building blocks for interactive and exploratory computing. These building blocks make science and data science reproducible across over 40 programming language (Python, Julia, R, etc.). Central to the project is the Jupyter Notebook, a web-based interactive computing platform that allows users to author data- and code-driven narratives - computational narratives - that combine live code, equations, narrative text, visualizations, interactive dashboards and other media.&lt;/p&gt;
&lt;p&gt;While the Jupyter Notebook has proved to be an incredibly productive way of working with code and data interactively, it is helpful to decompose notebooks into more primitive building blocks: kernels for code execution, input areas for typing code, markdown cells for composing narrative content, output areas for showing results, terminals, etc. The fundamental idea of JupyterLab is to offer a user interface that allows users to assemble these building blocks in different ways to support interactive workflows that include, but go far beyond, Jupyter Notebooks.&lt;/p&gt;
&lt;p&gt;JupyterLab accomplishes this by providing a modular and extensible user interface that exposes these building blocks in the context of a powerful work space. Users can arrange multiple notebooks, text editors, terminals, output areas, etc. on a single page with multiple panels, tabs, splitters, and collapsible sidebars with a file browser, command palette and integrated help system. The codebase and UI of JupyterLab is based on a flexible plugin system that makes it easy to extend with new components.&lt;/p&gt;
&lt;p&gt;In this talk, we will demonstrate the JupyterLab interface, its codebase, and describe how it fits within the overall roadmap of the project.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brian Granger</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/jupyterlab-building-blocks-for-interactive-computing-scipy-2016-brian-granger.html</guid><category>SciPy 2016</category><category>jupyter</category><category>jupyterlab</category><category>jupyter notebook</category></item><item><title>Keynote: Machine Learning for Social Science</title><link>https://pyvideo.org/scipy-2016/keynote-machine-learning-for-social-science-scipy-2016-hanna-wallach.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, I will introduce the audience to the emerging area of
computational social science, focusing on how machine learning for social science differs from machine learning in other contexts. I will present two related models -- both based on Bayesian Poisson tensor decomposition -- for uncovering latent structure from count data. The first is for uncovering topics in previously classified government documents, while the second is for uncovering multilateral relations from country-to-country interaction data. Finally, I will talk briefly about the broader ethical implications of analyzing social data.&lt;/p&gt;
&lt;p&gt;Hanna Wallach is a Senior Researcher at Microsoft Research New York City and an Adjunct Associate Professor in the College of Information and Computer Sciences at the University of Massachusetts Amherst. She is also a member of UMass's Computational Social Science Institute. Hanna develops machine learning methods for analyzing the structure, content, and dynamics of social processes. Her work is inherently interdisciplinary: she collaborates with political scientists, sociologists, and journalists to understand how organizations work by analyzing publicly available interaction data, such as email networks, document collections, press releases, meeting transcripts, and news articles. To complement this agenda, she also studies issues of fairness, accountability, and transparency as they relate to machine learning. Hanna's research has had broad impact in machine learning, natural language processing, and computational social science. In 2010, her work on infinite belief networks won the best paper award at the Artificial Intelligence and Statistics conference; in 2014, she was named one of Glamour magazine's &amp;quot;35 Women Under 35 Who Are Changing the Tech Industry&amp;quot;; in 2015, she was elected to the International Machine Learning Society's Board of Trustees; and in 2016, she was named co-winner of the 2016 Borg Early Career Award. She is the recipient of several National Science Foundation grants, an Intelligence Advanced Research Projects Activity grant, and a grant from the Office of Juvenile Justice and Delinquency Prevention. Hanna is committed to increasing diversity and has worked for over a decade to address the underrepresentation of women in computing. She co-founded two projects---the first of their kind---to increase women's involvement in free and open source software development: Debian Women and the GNOME Women's Summer Outreach Program. She also co-founded the annual Women in Machine Learning Workshop, which is now in its eleventh year. Hanna holds a BA in computer science from the University of Cambridge, an MSc in cognitive science and machine learning from the University of Edinburgh, and a PhD in machine learning from the University of Cambridge.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Hanna Wallach</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/keynote-machine-learning-for-social-science-scipy-2016-hanna-wallach.html</guid><category>SciPy 2016</category></item><item><title>Keynote: Project Jupyter</title><link>https://pyvideo.org/scipy-2016/keynote-project-jupyter-scipy-2016-brian-granger.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Brian Granger is an Associate Professor of Physics at Cal Poly State University in San Luis Obispo, CA. He has a background in theoretical physics, with a Ph.D from the University of Colorado. His current research interests include quantum computing, parallel and distributed computing and interactive computing environments for scientific computing and data science. He is a leader of the IPython project, co-founder of Project Jupyter and is an active contributor to a number of other open source projects focused on data science in Python. He is a board member of the NumFocus Foundation and a fellow at Cal Poly’s Center for Innovation and Entrepreneurship. He is &amp;#64;ellisonbg on Twitter and GitHub.&lt;/p&gt;
&lt;p&gt;Announcement of Altair, Altair is a declarative statistical visualization library for Python. Altair is developed by Brian Granger and Jake Vanderplas in close collaboration with the UW Interactive Data Lab.&lt;/p&gt;
&lt;p&gt;With Altair, you can spend more time understanding your data and its meaning. Altair's API is simple, friendly and consistent and built on top of the powerful Vega-Lite JSON specification. This elegant simplicity produces beautiful and effective visualizations with a minimal amount of code.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brian Granger</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/keynote-project-jupyter-scipy-2016-brian-granger.html</guid><category>SciPy 2016</category><category>altair</category><category>jupyter</category><category>jupyter notebook</category></item><item><title>Labs in the Wild: Teaching Signal Processing Using Wearables &amp; Jupyter Notebooks</title><link>https://pyvideo.org/scipy-2016/labs-in-the-wild-teaching-signal-processing-using-wearables-jupyter-notebooks-scipy-2016.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter notebooks and the Python ecosystem provide a unique opportunity for interactive, web-based, teaching of content that has not traditionally leveraged scientific computing resources. We discuss the design and implementation of a new biological signal processing course at Harvard, ES155, which fuses Wearable technology and cloud-based analysis of data. ES155 bridges the gap that has traditionally existed between Electrical Engineering and Computer Science education, in a framework that we term “Labs in the Wild”. In the process of designing the course, we have had to solve the problem of serving Jupyter notebooks on the cloud reliably using AWS EC2 instances. This is a challenging problem because a successful approach must be scalable, cost-effective, reliable, and address the privacy concerns associated with cloud-based technologies. We describe our system in this talk, and perform a live demo of how students in our class interact with the system, and give examples of ingenious final projects put together by students. Being cloud-based, our system lowers the barrier of entry for students to begin using Python for scientific computing.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Demba Ba</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/labs-in-the-wild-teaching-signal-processing-using-wearables-jupyter-notebooks-scipy-2016.html</guid><category>SciPy 2016</category><category>jupyter notebook</category><category>wearable</category><category>education</category></item><item><title>Launching Python Applications on Peta scale Massively Parallel Systems</title><link>https://pyvideo.org/scipy-2016/launching-python-applications-on-peta-scale-massively-parallel-systems-scipy-2016-yu-feng.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yu Feng</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/launching-python-applications-on-peta-scale-massively-parallel-systems-scipy-2016-yu-feng.html</guid><category>SciPy 2016</category></item><item><title>Machine Learning for Time Series Data in Python</title><link>https://pyvideo.org/scipy-2016/machine-learning-for-time-series-data-in-python-scipy-2016-brett-naul.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The analysis of time series data is a fundamental part of many scientific disciplines, but there are few resources meant to help domain scientists to easily explore time course datasets: traditional statistical models of time series are often too rigid to explain complex time domain behavior, while popular machine learning packages deal almost exclusively with 'fixed-width' datasets containing a uniform number of features. Cesium is a time series analysis framework, consisting of a Python library as well as a web front-end interface, that allows researchers to apply modern machine learning techniques to time series data in a way that is simple, easily reproducible, and extensible.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brett Naul</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/machine-learning-for-time-series-data-in-python-scipy-2016-brett-naul.html</guid><category>SciPy 2016</category></item><item><title>Modeling Rate and State Friction with Python</title><link>https://pyvideo.org/scipy-2016/modeling-rate-and-state-friction-with-python-scipy-2016-modeling-rate-and-state-friction-with-py.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Friction plays a crucial role in a broad spectrum of natural and technological applications ranging from earthquakes to materials handling. Researchers working to understand frictional dynamics often develop their own software to solve specific problems with constitutive laws that include history and strain rate dependence, which has limited interdisciplinary comparison and community standards. We address these shortcomings with a Python implementation of the rate-and-state friction constitutive laws, including tools to handle multiple state variables, dynamic instability, and variations in friction rate dependence with slip velocity.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">John Leeman</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/modeling-rate-and-state-friction-with-python-scipy-2016-modeling-rate-and-state-friction-with-py.html</guid><category>SciPy 2016</category></item><item><title>Proselint: The Linting of Science Prose, and the Science of Prose Linting</title><link>https://pyvideo.org/scipy-2016/proselint-the-linting-of-science-prose-and-the-science-of-prose-linting-scipy-2016-michael-pac.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Writing is notoriously hard, even for the best writers, and it's not for lack of good advice — a tremendous amount of knowledge is strewn across usage guides, dictionaries, technical manuals, essays, pamphlets, websites, and the hearts and minds of great authors and editors. But this knowledge is trapped, waiting to be extracted and transformed.&lt;/p&gt;
&lt;p&gt;We built Proselint, a Python-based linter for prose. Proselint identifies violations of expert style and usage guidelines. Proselint is open-source software released under the BSD license and works with Python 2 and 3. It runs as a command-line utility or editor plugin (e.g., Sublime Text, Atom, Vim, Emacs) and outputs advice in standard formats (e.g., JSON). Though in its infancy – perhaps 2% of what it could be – Proselint already includes modules addressing: redundancy, jargon, illogic, clichés, sexism, misspelling, inconsistency, misuse of symbols, malapropisms, oxymorons, security gaffes, hedging, apologizing, pretension.     Proselint can be seen as both a language tool for scientists and a tool for language science. On the one hand, it includes modules that promote clear and consistent prose in science writing. On the other, it measures language usage and explores the factors relevant to creating a useful linter.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Michael Pacer</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/proselint-the-linting-of-science-prose-and-the-science-of-prose-linting-scipy-2016-michael-pac.html</guid><category>SciPy 2016</category><category>lint</category><category>prose</category><category>jupyter</category></item><item><title>QCDB Database Tools for Managing and Harmonizing Quantum Chemistry</title><link>https://pyvideo.org/scipy-2016/qcdb-database-tools-for-managing-and-harmonizing-quantum-chemistry-scipy-2016-lori-burns.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Workflows in computational chemistry must manage large quantities of expensively computed and metadata-laden data, each to be accessed in its own right or recycled into complex methodologies. QCDB manages such datasets in collection, application of recognized and exploratory work-up procedures through Pandas, visualization through matplotlib, and facilitation of open-access. It is demonstrated applied to a set of nonbonded structures from the protein databank (PDB).&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lori Burns</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/qcdb-database-tools-for-managing-and-harmonizing-quantum-chemistry-scipy-2016-lori-burns.html</guid><category>SciPy 2016</category></item><item><title>Reinventing the whl: New Developments in the Upstream Python Packaging Ecosystem</title><link>https://pyvideo.org/scipy-2016/reinventing-the-whl-new-developments-in-the-upstream-python-packaging-ecosystem-scipy-2016-nath.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pip, wheels, and setuptools are the standard tools for installing, distributing, and building Python packages -- which means that if you're a user or package author then you're probably using them at least some of the time, even though when it comes to handling scientific packages, they've traditionally been a major source of pain. Fortunately, things have been getting better! In this talk, I'll describe how members of the scientific Python community have been working with upstream Python to solve some of the worst issues, and show you how to build and distribute binary wheels for Linux users, build Windows packages without MSVC, use wheels to handle dependencies on non-Python libraries like BLAS or libhdf5, plus give the latest updates on our effort to drive a stake through the heart of setup.py files and replace them with something better.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Nath</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/reinventing-the-whl-new-developments-in-the-upstream-python-packaging-ecosystem-scipy-2016-nath.html</guid><category>SciPy 2016</category></item><item><title>Scaling Up and Out Programming GPU Clusters with Numba and Dask</title><link>https://pyvideo.org/scipy-2016/scaling-up-and-out-programming-gpu-clusters-with-numba-and-dask-scipy-2016-siu-kwan-lam.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, we show how Python, Numba, and Dask can be used for GPU programming that easily scales from your workstation to a cluster, and can be controlled entirely from a Jupyter notebook. We will describe how the Numba JIT compiler can be used to create and compile GPU calculations entirely from the Python interpreter, and how the Dask task scheduling system can be used to farm these calculations out to a GPU cluster. Using an image processing example application, we will show how these two projects make it easy to iterate and experiment with algorithms on large data sets. Finally, we will conclude with tips and tricks for working with GPUs and distributed computing.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Siu Kwan Lam</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/scaling-up-and-out-programming-gpu-clusters-with-numba-and-dask-scipy-2016-siu-kwan-lam.html</guid><category>SciPy 2016</category></item><item><title>SymEngine A Fast Symbolic Manipulation Library</title><link>https://pyvideo.org/scipy-2016/symengine-a-fast-symbolic-manipulation-library-scipy-2016-ondrej-certik-isuru-fernando.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The goal of &lt;a class="reference external" href="https://github.com/symengine/symengine"&gt;SymEngine&lt;/a&gt; is to be the fastest C++ symbolic manipulation library (opensource or commercial), compatible with SymPy, that can be used from many languages (Python, Ruby, Julia, ...). We will present the current status of development, how things are implemented internally, why we chose C++, benchmarks, and examples of usage from Python (SymPy and Sage), Ruby and Julia.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ondřej Čertík</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/symengine-a-fast-symbolic-manipulation-library-scipy-2016-ondrej-certik-isuru-fernando.html</guid><category>SciPy 2016</category><category>symengine</category></item><item><title>SymPy Code Generation</title><link>https://pyvideo.org/scipy-2016/sympy-code-generation-scipy-2016-aaron-meurer.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aaron Meurer</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/sympy-code-generation-scipy-2016-aaron-meurer.html</guid><category>SciPy 2016</category><category>sympy</category></item><item><title>Tell Me Something I Don't Know: Analyzing OkCupid Profiles</title><link>https://pyvideo.org/scipy-2016/tell-me-something-i-dont-know-analyzing-okcupid-profiles-scipy-2016-matar-haller-juan-shishid.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, we present an approach for combining natural language processing with machine learning in order to explore the relationship between free text self-descriptions and demographics in OkCupid profile data. We discuss feature representation, clustering and topic modeling approaches, as well as feature selection and modeling strategies. We find that we can predict a user's demographic makeup based on their user essays, and we conclude by sharing some unexpected insights into deception.&lt;/p&gt;
&lt;p&gt;Additional talk materials here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/juanshishido/okcupid"&gt;https://github.com/juanshishido/okcupid&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/juanshishido/scipy_proceedings"&gt;https://github.com/juanshishido/scipy_proceedings&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Matar Haller</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/tell-me-something-i-dont-know-analyzing-okcupid-profiles-scipy-2016-matar-haller-juan-shishid.html</guid><category>SciPy 2016</category></item><item><title>The FOSSEE Python Project</title><link>https://pyvideo.org/scipy-2016/the-fossee-python-project-scipy-2016-prabhu-ramachandran.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Prabhu Ramachandran</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/the-fossee-python-project-scipy-2016-prabhu-ramachandran.html</guid><category>SciPy 2016</category></item><item><title>What's new in Spyder 3.0</title><link>https://pyvideo.org/scipy-2016/whats-new-in-spyder-30-scipy-2016-carlos-cordoba.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Our aim in this talk is to present the new features available in the next major version of Spyder, the Scientific PYthon DEvelopment EnviRonment. This version (Spyder 3.0) represents almost two years of development and brings important characteristics that we would like to introduce to the SciPy community. Among them we can find: the ability to
create and install third-party plugins, improved projects support, syntax highlighting and code completion for all programming languages supported by Pygments, a new file switcher
(similar to the one present in Sublime Text), code folding for the Editor, Emacs keybindings for the entire application, a Numpy array graphical builder, and a fully dark theme for the interface.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Carlos Cordoba</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/whats-new-in-spyder-30-scipy-2016-carlos-cordoba.html</guid><category>SciPy 2016</category></item><item><title>Working towards all the Geophysics, but Backwards</title><link>https://pyvideo.org/scipy-2016/working-towards-all-the-geophysics-but-backwards-scipy-2016-rowan-cockett.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Geophysical inversions are tools for constructing models of the subsurface (images) given a finite amount of data. SimPEG (&lt;a class="reference external" href="http://simpeg.xyz"&gt;http://simpeg.xyz&lt;/a&gt;) is an effort to synthesize geophysical forward and inverse methodologies into a consistent framework. We will show seven geophysical methods based around a diamond exploration case study, combining the results to drive a more informed decision. Slides may be found here: &lt;a class="reference external" href="https://docs.google.com/presentation/d/1O6A85QwnnAibm7CsV2_VZ95HcRsnLyvPQIRYIz_K5xg/edit#slide=id.g15d5208fb1_2_246"&gt;https://docs.google.com/presentation/d/1O6A85QwnnAibm7CsV2_VZ95HcRsnLyvPQIRYIz_K5xg/edit#slide=id.g15d5208fb1_2_246&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rowan Cockett</dc:creator><pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-15:scipy-2016/working-towards-all-the-geophysics-but-backwards-scipy-2016-rowan-cockett.html</guid><category>SciPy 2016</category></item><item><title>A String Theorist's Journey with Python</title><link>https://pyvideo.org/scipy-2016/a-string-theorists-journey-with-python-scipy-2016-chan-park.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Chan Park</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/a-string-theorists-journey-with-python-scipy-2016-chan-park.html</guid><category>SciPy 2016</category></item><item><title>Analysis and Visualization of 3D Data with yt</title><link>https://pyvideo.org/scipy-2016/analysis-and-visualization-of-3d-data-with-yt-scipy-2016-matthew-turk.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;yt is a Python package designed for domain-specific inquiry of volumetric data, licensed under the BSD license and available at yt-project.org. Utilizing numerous components of the scientific Python ecosystem, it is able to ingest data from numerous different sources from domains such as astrophysics, nuclear engineering, weather and climate, oceanography, and seismology. Building on top of a parallelized framework for data selection, analysis, processing and visualization, inquiry can be driven based on relevant, physical quantities rather than those specific to data formats. I will describe recent advances in the yt 3.0 series, including support for particle, octree, patch and unstructured mesh datasets; interactive and batch volume rendering using both software and OpenGL backends; semantically-rich ontologies of fields, derived quantities and affiliated units (powered by sympy); user-defined kernel estimates for density; support for visualization in non-Cartesian domains; and a flexible chunking system for data IO. I will describe some of the non-astrophysics domains that yt has been applied to, and the infrastructure implemented to support that. Finally, I will describe the community-driven approach taken to designing, developing and implementing new features, and describe some of the challenges this has presented in the context of scientific software developers.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Matthew Turk</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/analysis-and-visualization-of-3d-data-with-yt-scipy-2016-matthew-turk.html</guid><category>SciPy 2016</category></item><item><title>Communicating Model Results</title><link>https://pyvideo.org/scipy-2016/communicating-model-results-scipy-2016-bargava-subramanian.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;For a data scientist building predictive models, the following are important:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;How good is the model ?&lt;/li&gt;
&lt;li&gt;How good is it compared to competing/alternate models?&lt;/li&gt;
&lt;li&gt;Is there a way to identify what worked in the models built so far, to leverage it to build something even better?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The stakeholder/end-user who finally uses the output from the model, for whom the ML process is mostly black-box, is concerned with the following:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;How to trust the model output?&lt;/li&gt;
&lt;li&gt;How to understand the drivers?&lt;/li&gt;
&lt;li&gt;How to do what-if analysis?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The unifying theme that could answer most of the above questions is visualization. The biggest challenge is to find a way to visualize the model, the model fitting process and the impact of drivers. This talk summarizes the learnings and key takeaways when communicating model results.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bargava Subramanian</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/communicating-model-results-scipy-2016-bargava-subramanian.html</guid><category>SciPy 2016</category></item><item><title>Composable Multi Threading for Python Libraries</title><link>https://pyvideo.org/scipy-2016/composable-multi-threading-for-python-libraries-scipy-2016-anton-malakhov.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Multi-processing parallelism in Python might be unacceptable due to cache-inefficiency and memory overhead. On the other hand, multi-threaded parallelism with Python suffers from the GIL but when it comes to numeric computations, most of the time is spent in native codes where the GIL can easily be released. This is why modules such as Dask and Numba use multi-threading to greatly speed up the computations. But being used together in a nested way, e.g. when a Dask task calls Numba's threaded ufunc, it leads to the situation where there are more active software threads than available hardware resources. This situation is called over-subscription and it leads to inefficient execution due to frequent context switches, thread migration, broken cache-efficiency, and finally to a load imbalance when some threads finished their work but others are stuck along with the overall progress.&lt;/p&gt;
&lt;p&gt;Another example is Numpy/Scipy when they are accelerated using Intel Math Kernels Library (MKL) like the ones shipped as part of Intel Distribution for Python. MKL is usually threaded using OpenMP which is known for not easily co-existing even with itself. In particular, OpenMP threads keep spin-waiting after the work is done -- which is usually necessary to reduce work distribution overhead for the next possible parallel region. But it plays badly with another thread pool because while OpenMP worker threads keep consuming CPU time in spin-waiting, the other parallel work like Numba's ufunc cannot start until OpenMP threads stop spinning or are preempted by the OS.&lt;/p&gt;
&lt;p&gt;And the worst case is also connected to usage of OpenMP when a program starts multiple parallel tasks and each of these tasks ends up executing an OpenMP parallel region. This is quadratic over-subscription which ruins multi-threaded performance.&lt;/p&gt;
&lt;p&gt;Our approach to solve these co-existence problems is to share one thread pool among all the necessary modules and native libraries so that one task scheduler will take care of this composability issue. Intel Threading Building Blocks (TBB) library works as such a task scheduler in our solution. TBB is a wide-spread and recognized C++ library for enabling multi-core parallelism. It was designed for composability, nested parallelism support, and avoidance of over-subscription from its early days. Thus we implemented a Python module which integrates TBB with Python, it is already available as part of Intel Distribution for Python and on Intel channel for conda users. I will show how to enable it for Numpy/Scipy, Dask, Numba, Joblib, and other threaded modules and demonstrate the performance benefits it brings.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Anton Malakhov</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/composable-multi-threading-for-python-libraries-scipy-2016-anton-malakhov.html</guid><category>SciPy 2016</category></item><item><title>Dask Parallel and Distributed Computing</title><link>https://pyvideo.org/scipy-2016/dask-parallel-and-distributed-computing-scipy-2016-matthew-rocklin.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dask is a pure Python library for parallel and distributed computing. Last year Dask parallelized NumPy and Pandas computations on multi-core workstations. This year we discuss using Dask to design custom algorithms and execute those algorithms efficiently on a cluster. This talk discusses Pythonic APIs for parallel algorithm development as well as strategies for intuitive and efficient distributed computing. We discuss recent results in machine learning and novel scientific applications.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Matthew Rocklin</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/dask-parallel-and-distributed-computing-scipy-2016-matthew-rocklin.html</guid><category>SciPy 2016</category><category>dask</category><category>parallel computing</category></item><item><title>datreant: Persistent, Pythonic Trees for Heterogeneous Data</title><link>https://pyvideo.org/scipy-2016/datreant-persistent-pythonic-trees-for-heterogeneous-data-scipy-2016-sean-seyler-et-al.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In science the file system often serves as a de facto database, with directory trees being the zeroth-order scientific data structure. But it can be tedious and error prone to work directly with the file system to retrieve and store heterogeneous data sets. datreant makes working with directory structures and files Pythonic with Treants: specially marked directories with distinguishing characteristics that can be discovered, queried, and filtered. Treants can be manipulated individually and in aggregate, with mechanisms for granular access to the directories and files in their trees. Disparate data sets stored in any format (CSV, HDF5, NetCDF, Feater, etc.) scattered throughout a file system can thus be manipulated as meta-data sets of Treants. datreant is modular and extensible by design to allow specialized applications to be built on top of it, with MDSynthesis as an example for working with molecular dynamics simulation data. &lt;a class="reference external" href="http://datreant.org/"&gt;http://datreant.org/&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sean Seyler</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/datreant-persistent-pythonic-trees-for-heterogeneous-data-scipy-2016-sean-seyler-et-al.html</guid><category>SciPy 2016</category></item><item><title>Experiments as Iterators asyncio in Science</title><link>https://pyvideo.org/scipy-2016/experiments-as-iterators-asyncio-in-science-scipy-2016-daniel-allan-and-thomas-caswell-et-al.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;nA key challenge to reproducible data collection is capturing and organizing metadata without constraining flexibility and improvisation. u201cBlueskyu201d is a data collection framework designed to solve this problem. It communicates with hardware through a high-level interface and performs data collection, capturing data and rich metadata for streaming, live analysis.n n The project is developed at the National Synchrotron Light Source II --- a Dept. of Energy X-ray user facility. The X-ray beam is used by internal scientific staff and external visitors from academia and industry. These users employ bluesky in a broad range of experiments, ranging from well-defined, established techniques to ad hoc, improvised experiments.n n Bluesky expresses an experimental procedure as an iterable. Each element in the iterable specifies a granular step: u201cMove motor X; read detector Y; ...u201d. Bluesky supervises the execution of each step, handling common supervisory tasks: monitoring for problems, recovering from interruptions, safely cleaning up. In hardware control, the devil is in the details. Bluesky handles many of these details for the user, separating them from the scientific logic of the experimental procedure.n n While executing the procedure, bluesky collates all measurements and metadata into Python dictionaries with a flexible schema. These data u201cdocumentsu201d are created in a streaming fashion during the experiment and dispatched to user-defined functions. They can be printed, plotted, written into a database, broadcast as JSON documents, or fed into a real-time processing pipeline.n n Bluesky employs Python language features not as commonly used in the scipy community: generators, coroutines, and the asyncio event loop. For example, generators provide a parsimonious syntax for expressing sequential steps of an experiment. Coroutines can express adaptive logic, such as spacing measurements adaptively in response to the local slope, concentrating on regions of high variability. The asyncio event loop manages hardware control, data collection, visualization, and light-weight analysis in a single process. Wherever possible, bluesky relies on core language features and built-in data structures, avoiding a proliferation of special classes or a sprawling vocabulary.n n By integrating cleanly with the scipy stack, bluesky empowers scientists to build sophisticated experimental control logic. While currently deployed for X-ray experiments at NSLS-II, bluesky is developed in the open and should be useful for scientific experiment control in any context. It is thoroughly documented at nsls-ii.github.io/bluesky. The source code is available at github.com/NSLS-II/bluesky.n nTalk co-authers: Thomas Caswell, Brookhaven National Lab, Kenneth Lauer, Brookaven National Lab.&amp;quot;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Daniel Allan</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/experiments-as-iterators-asyncio-in-science-scipy-2016-daniel-allan-and-thomas-caswell-et-al.html</guid><category>SciPy 2016</category></item><item><title>Getting More from Your Core: Processing &amp; Analysis of Well Core CT Data</title><link>https://pyvideo.org/scipy-2016/getting-more-from-your-core-processing-analysis-of-well-core-ct-data-scipy-2016-brendon-hall.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A Python-based platform for processing and analyzing data from core CT scans will be presented. This dataset is a high resolution 3D dataset of compositional and textural information. In raw form, this data contains artifacts and is in a form unsuitable for analysis. Once the data has been cleaned, it can be processed to detect features such as beds, laminae and dip angle. It can be combined with high resolution core photographs and well logs. Machine learning algorithms can use the CT data as a feature set to perform facies classification.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brendon Hall</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/getting-more-from-your-core-processing-analysis-of-well-core-ct-data-scipy-2016-brendon-hall.html</guid><category>SciPy 2016</category></item><item><title>Governing Open Source Projects at Scale: Lessons from Wikipedia's Growing Pains</title><link>https://pyvideo.org/scipy-2016/governing-open-source-projects-at-scale-lessons-from-wikipedias-growing-pains-staurt-geiger-sc.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Stuart Geiger</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/governing-open-source-projects-at-scale-lessons-from-wikipedias-growing-pains-staurt-geiger-sc.html</guid><category>SciPy 2016</category><category>wikipedia</category></item><item><title>GT Py : Accelerating NumPy programs on CPU&amp;GPU w/ Minimal Programming Effort</title><link>https://pyvideo.org/scipy-2016/gt-py-accelerating-numpy-programs-on-cpugpu-w-minimal-programming-effort-scipy-2016-chi-luk.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;GT-Py is a newly developed just-in-time compiler that can offload NumPy code to hardware accelerators with relatively little programming effort. It lets programmers add pragmas to a Python program to specify what need to be offloaded, without writing the actual offloading code. By generating OpenCL code, GT-Py can run on a variety of accelerators including GPUs from different vendors, multicore CPUs, and potentially FPGAs. Experimental results demonstrate that significant performance gains, as much as over 9000x faster than the Python interpreter execution, can be obtained by adding only a couple of pragmas to the NumPy program. GT-Py supports both Python 2.7 and Python 3.4+. It will be available to public use for free.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Chi Luk</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/gt-py-accelerating-numpy-programs-on-cpugpu-w-minimal-programming-effort-scipy-2016-chi-luk.html</guid><category>SciPy 2016</category></item><item><title>High Quality, High Performance Clustering with HDBSCAN</title><link>https://pyvideo.org/scipy-2016/high-quality-high-performance-clustering-with-hdbscan-scipy-2016-leland-mcinnes.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Data clustering is a powerful tool for data analysis. It can be particularly useful in exploratory data analysis for helping to summarize and give intuition about a dataset. Despite it's power clustering is used for this task far less frequently than it could be. A plethora of options for clustering algorithms exist, and we will provide a survey of some of the more popular options, discussing their strengths and weaknesses, particularly with regard to exploratory data analysis. Our focus, however, is on a relatively new algorithm that appears to be the best equipped to meet the needs of exploratory data analysis: HDBSCAN* has the strengths of density based algorithms, has a small robust set of parameters, and with suitable implementation can be made highly scalable to large datasets. We will discuss how the algorithm works, taking a few different perspectives, and explain the techniques used for a high performance implementation. Finally we'll discuss ways to extend the algorithm, drawing on ideas from topological data analysis.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Leland McInnes</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/high-quality-high-performance-clustering-with-hdbscan-scipy-2016-leland-mcinnes.html</guid><category>SciPy 2016</category></item><item><title>HoloViews Let your Data Reveal Itself</title><link>https://pyvideo.org/scipy-2016/holoviews-let-your-data-reveal-itself-scipy-2016-phllip-rudiger-and-jean-luc-stevens-et-al.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Phllip Rudiger</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/holoviews-let-your-data-reveal-itself-scipy-2016-phllip-rudiger-and-jean-luc-stevens-et-al.html</guid><category>SciPy 2016</category></item><item><title>HOPE: A Python Just-In-Time Compiler for Astrophysical Computations</title><link>https://pyvideo.org/scipy-2016/hope-a-python-just-in-time-compiler-for-astrophysical-computations-scipy-2016-joel-akeret.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joel Akeret</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/hope-a-python-just-in-time-compiler-for-astrophysical-computations-scipy-2016-joel-akeret.html</guid><category>SciPy 2016</category></item><item><title>JupyterHub as an Interactive Supercomputing Gateway</title><link>https://pyvideo.org/scipy-2016/jupyterhub-as-an-interactive-supercomputing-gateway-scipy-2016-michael-milligan.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At the Minnesota Supercomputing Institute we are exploring ways to provide the immediacy and flexibility of interactive computing within the batch-scheduled, tightly controlled world of traditional cluster supercomputing. As Jupyter Notebook has gained in popularity, the steps needed to use it within such an environment have proven to be a barrier to entry even as increasingly powerful Python tools have developed to take advantage of large computational resources. JupyterHub to the rescue! Except out of the box, it doesn't know anything about resource types, job submission, and so on. We developed BatchSpawner and friends as a general JupyterHub backend for batch-scheduled environments. In this talk I will walk through how we have deployed JupyterHub to provide a user-friendly gateway to interactive supercomputing.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Michael Milligan</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/jupyterhub-as-an-interactive-supercomputing-gateway-scipy-2016-michael-milligan.html</guid><category>SciPy 2016</category><category>hpc</category><category>jupyterhub</category><category>jupyter</category><category>jupyter notebook</category><category>supercomputing</category></item><item><title>Large Scale Geospatial Analytics with Python, Spark, and Impala</title><link>https://pyvideo.org/scipy-2016/large-scale-geospatial-analytics-with-python-spark-and-impala-scipy-2016-evan-wyse.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We harnessed the power of three different computing platforms, Spark, Impala, and scientific python, to perform geospatial analysis on mobile phone users. We will discuss data processing techniques for comparing billions of user locations per day with millions of places of interest, easily extractible insights, and methodologies for estimating impacts of treatment on these movement patterns. Our workflow has potential for application for other use cases involving geospatial movement of populations.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Evan Wyse</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/large-scale-geospatial-analytics-with-python-spark-and-impala-scipy-2016-evan-wyse.html</guid><category>SciPy 2016</category></item><item><title>Lightning Talks 2016-07-13</title><link>https://pyvideo.org/scipy-2016/lightning-talks-scipy-2016-20160713.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Various speakers</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/lightning-talks-scipy-2016-20160713.html</guid><category>SciPy 2016</category><category>lightning talks</category></item><item><title>MONTE Python for Deep Space Navigation</title><link>https://pyvideo.org/scipy-2016/monte-python-for-deep-space-navigation-scipy-2016-jonathon-smith.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Mission Analysis, Operations, and Navigation Toolkit Environment (MONTE) is the Jet Propulsion Laboratory's (JPL) signature astrodynamic computing platform. It was built to support JPL's deep space exploration program, and has been used to fly robotic spacecraft to Mars, Jupiter, Saturn, Ceres, and many solar system small bodies. At its core, MONTE consists of low-level astrodynamic libraries that are written in C++ and presented to the end user as an importable Python language module. These libraries form the basis on which Python-language applications are built for specific astrodynamic applications, like trajectory design and optimization, orbit determination, flight path control, and more. This talk gives a brief history of the project, shows some examples of MONTE in action, and relates the stories of its greatest successes.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jonathon Smith</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/monte-python-for-deep-space-navigation-scipy-2016-jonathon-smith.html</guid><category>SciPy 2016</category></item><item><title>Processing a Petabyte of Planetary Pixels with Python</title><link>https://pyvideo.org/scipy-2016/processing-a-petabyte-of-planetary-pixels-with-python-samuel-skillman-scipy-2016.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the last 40 years over a petabyte of publicly available earth observation imagery has been produced. In the near future, many petabytes of imagery per year will become available from a combination of public satellite missions and private satellite constellations. At the same time, commercial cloud providers are competing to provide the lowest cost alternative to on-premise compute capabilities. By combining the dramatic rise in available imagery with low cost of high performance storage, network, and compute capabilities, we have a unique opportunity to combine analysis techniques from remote sensing, machine learning algorithms, and scalable compute infrastructure. Combined, they allow for global scale investigations into how our planet is changing.&lt;/p&gt;
&lt;p&gt;Here we will report on how we leverage the commercial cloud to generate a tiled spatio-temporal mosaic of the Earth and how it enables fast iteration for the development of both traditional model based predictions and machine learning algorithms. As part of our effort, we have processed, in less than 24 hours, over a petabyte of compressed raw data from the combination of the US Landsat and MODIS programs, totalling nearly 3 petapixels. We will detail the challenges and benefits to moving from traditional remote sensing workbenches to the commercial cloud, with particular emphasis on the benefits for researchers.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Samuel Skillman</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/processing-a-petabyte-of-planetary-pixels-with-python-samuel-skillman-scipy-2016.html</guid><category>SciPy 2016</category></item><item><title>PyTeCK: A Python-based automatic testing package for chemical kinetic models</title><link>https://pyvideo.org/scipy-2016/pyteck-a-python-based-automatic-testing-package-for-chemical-kinetic-models-scipy-2016-kyle-nie.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Combustion simulations require detailed chemical kinetic models to predict fuel oxidation, heat release, and pollutant emissions.&lt;/p&gt;
&lt;p&gt;These models are typically validated using qualitative rather than quantitative comparisons with limited sets of experimental data.&lt;/p&gt;
&lt;p&gt;This work introduces PyTeCK, an open-source Python-based package for automatic testing of chemical kinetic models. Given a model of interest, PyTeCK automatically parses experimental datasets encoded in an XML format, validates the self-consistency of each dataset, and performs simulations for each experimental datapoint. It then reports a quantitative metric of the model's performance, based on the discrepancy between experimental and simulated values and weighted by experimental variance. The initial version of PyTeCK supports shock tube and rapid compression machine experiments that measure autoignition delay. PyTeCK relies on several packages in the SciPy stack and greater scientific Python ecosystem. In addition to providing an easy-to-use, automated tool for evaluating chemical kinetic model performance, a secondary objective of PyTeCK is to encourage greater openness and reproducibility in combustion research.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kyle Nie</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/pyteck-a-python-based-automatic-testing-package-for-chemical-kinetic-models-scipy-2016-kyle-nie.html</guid><category>SciPy 2016</category></item><item><title>Python and R Together at Last: Writing Cross Language Tools</title><link>https://pyvideo.org/scipy-2016/python-and-r-together-at-last-writing-cross-language-tools-scipy-2016-bill-lattner.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Both Python and R boast large data science communities. Each have developed a fantastic collection of packages from reading/writing data to plotting and visualization. Unfortunately, some tools are only available in one language or the other, but not both. Python and R provide relatively simple mechanisms for interacting with C, C++, and Fortran. There are many tools that take advantage of this interoperability. While not a simple matter, developing data science tools in these low level languages and providing Python and R wrappers allows code reuse between languages, speed benefits notwithstanding. In this talk we will discuss strategies and lessons learned from porting existing packages to Python from R and writing cross language tools from scratch.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bill Lattner</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/python-and-r-together-at-last-writing-cross-language-tools-scipy-2016-bill-lattner.html</guid><category>SciPy 2016</category></item><item><title>Reproducible, One Button Workflows with the Jupyter Notebook &amp; Scons</title><link>https://pyvideo.org/scipy-2016/reproducible-one-button-workflows-with-the-jupyter-notebook-scons-scipy-2016-jessica-hamrick.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;What is the best way to develop analysis code in the Jupyter notebook, while managing complex dependencies between analyses? In this talk, I will introduce nbflow, which is a project that integrates a Python-based build system (SCons) with the Jupyter notebook, enabling researchers to easily build sophisticated,
complex analysis pipelines entirely within notebooks while still maintaining a &amp;quot;one-button workflow&amp;quot; in which all analyses can be executed, in the correct order, from a single command. I will show how nbflow can be applied to existing analyses and how it can be used to construct an analysis pipeline stretching the entire way from data cleaning, to computing statistics, to generating figures,
and even to automatically generating LaTeX commands that can be used in publications to format results without the risk of copy-and-paste error.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jessica Hamrick</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/reproducible-one-button-workflows-with-the-jupyter-notebook-scons-scipy-2016-jessica-hamrick.html</guid><category>SciPy 2016</category><category>jupyter</category><category>jupyter notebook</category><category>workflow</category><category>nbflow</category></item><item><title>Sharing Reproducible Environments with Binder</title><link>https://pyvideo.org/scipy-2016/sharing-reproducible-environments-with-binder-scipy-2016-andrew-osheroff.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Binder (&lt;a class="reference external" href="http://mybinder.org"&gt;http://mybinder.org&lt;/a&gt;) is a service that bundles GitHub repositories with code, Jupyter notebooks, and data into reproducible, executable environments that can be launched instantaneously in the browser with the click of a button. Under the hood, Binder uses simple and flexible dependency specifications to build Docker images on demand, and then launches and schedules them across a public Kubernetes cluster. In this talk, I’ll describe in detail how Binder works, and highlight some exciting use cases. I’ll then describe several future directions for the project, including handling larger datasets, lowering barriers for environment specification, and supporting custom deployments with user-provided computing resources.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Osheroff</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/sharing-reproducible-environments-with-binder-scipy-2016-andrew-osheroff.html</guid><category>SciPy 2016</category><category>binder</category><category>jupyter notebook</category></item><item><title>UConnRCMPy: Python-based Data Analysis for Rapid Compression Machines</title><link>https://pyvideo.org/scipy-2016/uconnrcmpy-python-based-data-analysis-for-rapid-compression-machines-scipy-2016-bryan-weber.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The ignition delay of a fuel/air mixture is an important quantity in designing combustion devices, and these data are also used to validate computational kinetic models for combustion. One of the typical experimental devices used to measure the ignition delay is called a Rapid Compression Machine (RCM). This work presents UConnRCMPy, an open-source Python package to process experimental data from the RCM at the University of Connecticut. Given an experimental measurement, UConnRCMPy computes the thermodynamic conditions in the reactor of the RCM during an experiment along with the ignition delay. UConnRCMPy relies on several packages from the SciPy stack and the broader scientific Python community. UConnRCMPy implements an extensible framework, so that alternative experimental data formats can be incorporated easily. In this way, UConnRCMPy improves the consistency of RCM data processing and enables reproducible analysis of the data.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bryan Weber</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/uconnrcmpy-python-based-data-analysis-for-rapid-compression-machines-scipy-2016-bryan-weber.html</guid><category>SciPy 2016</category></item><item><title>Using Open Source Tools to Refactor Geoscience Education</title><link>https://pyvideo.org/scipy-2016/using-open-source-tools-to-refactor-geoscience-education-scipy-2016-lindsey-heagy.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;How do we communicate fundamental concepts in a reproducible, actionable form? How do we put numerical simulation tools in the hands of undergraduate students? These are questions we have been exploring in the development of &lt;a class="reference external" href="http://geosci.xyz/"&gt;http://geosci.xyz/&lt;/a&gt;, a web-based resource in geophysics that leverages the geophysical software package SimPEG, Sphinx documentation, Jupyter notebooks and Binders to make examples and explanations that are reproducible and interactive.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lindsey Heagy</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/using-open-source-tools-to-refactor-geoscience-education-scipy-2016-lindsey-heagy.html</guid><category>SciPy 2016</category></item><item><title>Symbolic Computation with Python using SymPy (Beginner)</title><link>https://pyvideo.org/scipy-2016/symbolic-compution-with-python-using-sympy-beginner-scipy-2016-tutorial-ondrej-certik-et-al.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Materials for this tutorial are found here: &lt;a class="reference external" href="https://github.com/sympy/scipy-2016-tutorial"&gt;https://github.com/sympy/scipy-2016-tutorial&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ondřej Čertík</dc:creator><pubDate>Mon, 11 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-11:scipy-2016/symbolic-compution-with-python-using-sympy-beginner-scipy-2016-tutorial-ondrej-certik-et-al.html</guid><category>SciPy 2016</category><category>tutorial</category><category>SymPy</category></item></channel></rss>