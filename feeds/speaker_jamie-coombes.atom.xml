<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Jamie Coombes</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_jamie-coombes.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2023-07-17T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Language Model Zen</title><link href="https://pyvideo.org/europython-2023/language-model-zen.html" rel="alternate"></link><published>2023-07-17T00:00:00+00:00</published><updated>2023-07-17T00:00:00+00:00</updated><author><name>Jamie Coombes</name></author><id>tag:pyvideo.org,2023-07-17:/europython-2023/language-model-zen.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[EuroPython 2023 — Terrace 2A on 2023-07-21]&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://ep2023.europython.eu/session/language-model-zen"&gt;https://ep2023.europython.eu/session/language-model-zen&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Beautiful is better than ugly.&lt;/p&gt;
&lt;p&gt;The frontier of AI Language Models awaits exploration.&lt;/p&gt;
&lt;blockquote&gt;
We, Pythonistas, face choices on how to use these tools.&lt;/blockquote&gt;
&lt;p&gt;Advanced models like GPT-4, BARD, and LLaMa generate human-like responses.&lt;/p&gt;
&lt;p&gt;The nature of Language …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[EuroPython 2023 — Terrace 2A on 2023-07-21]&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://ep2023.europython.eu/session/language-model-zen"&gt;https://ep2023.europython.eu/session/language-model-zen&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Beautiful is better than ugly.&lt;/p&gt;
&lt;p&gt;The frontier of AI Language Models awaits exploration.&lt;/p&gt;
&lt;blockquote&gt;
We, Pythonistas, face choices on how to use these tools.&lt;/blockquote&gt;
&lt;p&gt;Advanced models like GPT-4, BARD, and LLaMa generate human-like responses.&lt;/p&gt;
&lt;p&gt;The nature of Language Models is fear,&lt;/p&gt;
&lt;p&gt;But tools like TransformerLens show The Way.&lt;/p&gt;
&lt;p&gt;Understanding The Model is possible.&lt;/p&gt;
&lt;p&gt;The nature of Language Models is excitement.&lt;/p&gt;
&lt;p&gt;Using them out of the box is one option.&lt;/p&gt;
&lt;p&gt;Prompt engineering is another.&lt;/p&gt;
&lt;p&gt;ChatGPT plugins and LangChain offer a third choice.&lt;/p&gt;
&lt;p&gt;Fine-tuning them presents a fourth.&lt;/p&gt;
&lt;p&gt;Training them from scratch is the fifth option.&lt;/p&gt;
&lt;p&gt;Not using them at all is the final option. It may be safer.&lt;/p&gt;
&lt;p&gt;The output for one LM is the prompt for another.&lt;/p&gt;
&lt;p&gt;While openai is an excellent library, and&lt;/p&gt;
&lt;p&gt;LangChain composes language models and utilities.&lt;/p&gt;
&lt;p&gt;GPT's plugin system also composes language models and utilities, and&lt;/p&gt;
&lt;p&gt;There should be one-- and preferably only one --obvious way to do it.&lt;/p&gt;
&lt;p&gt;This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License &lt;a class="reference external" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;http://creativecommons.org/licenses/by-nc-sa/4.0/&lt;/a&gt;&lt;/p&gt;
</content><category term="EuroPython 2023"></category></entry></feed>