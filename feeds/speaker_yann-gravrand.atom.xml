<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_yann-gravrand.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2017-02-05T00:00:00+00:00</updated><entry><title>Hacking midi devices with StepPya step sequencer in Python</title><link href="https://pyvideo.org/fosdem-2017/hacking-midi-devices-with-steppya-step-sequencer-in-python.html" rel="alternate"></link><published>2017-02-05T00:00:00+00:00</published><updated>2017-02-05T00:00:00+00:00</updated><author><name>Yann Gravrand</name></author><id>tag:pyvideo.org,2017-02-05:fosdem-2017/hacking-midi-devices-with-steppya-step-sequencer-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you're making electronic music in 2017, you're likely to have seen or used one of Native Instrument's &amp;quot;Maschine&amp;quot;, &amp;quot;Maschine Jam&amp;quot;, Novation's &amp;quot;Circuit&amp;quot;, or Ableton's &amp;quot;Push&amp;quot;...These pad-based devices allow musicians to trigger samples, and create rhythms intuitively by the means of a &amp;quot;step sequencer&amp;quot;.The said step sequencer is implemented in the box and stays in it...Thanks to &amp;quot;mido&amp;quot; and &amp;quot;portmidi&amp;quot; libraries, I designed a lightweight open source software sequencer (without a GUI), exposing abstractions for python programmers to use their existing MIDI-enabled hardware. My MiniNova, Launch Control and Quneo devices were hacked this way to create new functionality together.The talk starts with a quick explanation of MIDI and step sequencing, then describes the benefits and challenges of using Python in this context, as well as the choice of gevent against other async frameworks. It ends of course with a live demo!&lt;/p&gt;
</summary></entry><entry><title>Visuellement correct - tests de non régression visuels automatisés</title><link href="https://pyvideo.org/pycon-fr-2015/visuellement-correct-tests-de-non-regression-visuels-automatises.html" rel="alternate"></link><published>2015-10-18T00:00:00+00:00</published><updated>2015-10-18T00:00:00+00:00</updated><author><name>Yann Gravrand</name></author><id>tag:pyvideo.org,2015-10-18:pycon-fr-2015/visuellement-correct-tests-de-non-regression-visuels-automatises.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Les tests de différences visuelles constituent un moyen efficace pour se
prémunir des régressions au sein des applications web. Cette
présentation décrit les types d’application pour lesquelles ces tests
présentent de l’intérêt, les outils que nous avons adoptés, et des
retours d’expérience sur les avantages et inconvénients de ces outils.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Après avoir écrit des tests unitaires pour les parties métier de notre
code, nous avons souhaité ajouter un autre niveau de vérifications
automatisées : les tests de différences visuelles. Ce vieux rêve des
développeurs web consiste à comparer visuellement les pages web d'une
source reconnue comme fiable (baseline) avec la version que l'on
s'apprête à déployer. Il est ainsi possible de vérifier l'impact des
nouvelles fonctionnalités sur une nouvelle version, s'assurer de la non
régression, et une fois l'impact visuel éventuel accepté, établir une
nouvelle baseline pour non régression future. Cette présentation décrit
des cas concrets dans lesquels ces types de vérifications présentent de
l’intérêt. Nous verrons ensuite l’architecture et le workflow que nous
avons adoptés afin de relever le défi, à l’aide d’une librairie python
nommée dpxdt développée chez Google. Nous terminerons par un retour
d’expérience sur les interactions avec notre système d’intégration
continue, des pistes d'amélioration, et les limites du procédé.&lt;/p&gt;
</summary></entry><entry><title>Informatique musicale : créer un séquenceur pas-à-pas avec Python</title><link href="https://pyvideo.org/pycon-fr-2016/informatique-musicale-creer-un-sequenceur-pas-a-pas-avec-python.html" rel="alternate"></link><published>2016-10-16T00:00:00+00:00</published><updated>2016-10-16T00:00:00+00:00</updated><author><name>Yann Gravrand</name></author><id>tag:pyvideo.org,2016-10-16:pycon-fr-2016/informatique-musicale-creer-un-sequenceur-pas-a-pas-avec-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Aujourd’hui, que ce soit via «&amp;nbsp;Maschine&amp;nbsp;» de Native Instruments, «&amp;nbsp;Push&amp;nbsp;» de Ableton, ou encore via des machines à l’esprit plus vintage comme le «&amp;nbsp;Dark Time&amp;nbsp;» de Doepfer ou des émulations de vieilles boites à rythmes, les musiciens retrouvent le goût du séquencement pas à pas ou «&amp;nbsp;Step Sequencing&amp;nbsp;».
Le bidouilleur que je suis avait envie de détourner son matériel pour reproduire ce type d’outil de création…
Après une introduction au MIDI et aux principes d’un séquenceur, nous verrons comment nous pouvons, avec Python et la librairie mido, «&amp;nbsp;hacker&amp;nbsp;» un certain synthétiseur hardware pour en faire un séquenceur pas à pas, à l’aide d’une boucle d’événements. Nous essaierons même de l’interfacer avec Ableton Live pour contrôler non plus les sons du synthétiseur, mais des samples !
Disclaimer : bien que pratiquant la M.A.O depuis longtemps, je ne suis pas expert en séquenceurs mais plutôt bidouilleur et pythoniste… Ainsi je laisserai une bonne place aux échanges avec vous pendant l’intervention !&lt;/p&gt;
</summary></entry></feed>