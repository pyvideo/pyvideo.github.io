<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_xiao-li.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-08-17T00:00:00+00:00</updated><entry><title>Koalas: Easy Transition from pandas to Apache Spark</title><link href="https://pyvideo.org/pybay-2019/koalas-easy-transition-from-pandas-to-apache-spark.html" rel="alternate"></link><published>2019-08-17T00:00:00+00:00</published><updated>2019-08-17T00:00:00+00:00</updated><author><name>Xiao Li</name></author><id>tag:pyvideo.org,2019-08-17:pybay-2019/koalas-easy-transition-from-pandas-to-apache-spark.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk was presented at PyBay2019 - 4th annual Bay Area Regional Python conference. See pybay.com for more details about PyBay and click SHOW MORE for more information about this talk.&lt;/p&gt;
&lt;p&gt;Description
In this talk, we present Koalas, a new open source project that was announced at the Spark + AI Summit in April. Koalas is a Python package that implements the pandas API on top of Apache Spark, to make the pandas API scalable to big data. Using Koalas, data scientists can make the transition from a single machine to a distributed environment without needing to learn a new framework.&lt;/p&gt;
&lt;p&gt;Abstract
Pandas is the standard tool for data science in python, and it is typically the first step to explore and manipulate a data set by data scientists. The problem is that pandas does not scale well to big data. It was designed for small data sets that a single machine could handle.. When data scientists work today with very large data sets, they either have to migrate to PySpark to leverage Spark or downsample their data so that they can use pandas.&lt;/p&gt;
&lt;p&gt;This presentation will give a deep dive into the conversion between Spark and pandas dataframes. Through live demonstrations and code samples, you will understand: - how to effectively leverage both pandas and Spark inside the same code base - how to leverage powerful pandas concepts such as lightweight indexing with Spark - technical considerations for unifying the different behaviors of Spark and pandas&lt;/p&gt;
&lt;p&gt;About the speaker
Xiao Li is an engineering manager, Apache Spark Committer, and PMC member at Databricks. His main interests are on Spark SQL, data replication and data integration. Previously, he was an IBM master inventor and an expert on asynchronous database replication and consistency verification. He received his Ph.D. from University of Florida in 2011.&lt;/p&gt;
&lt;p&gt;Sponsor Acknowledgement
This and other PyBay2019 videos are via the help of our media partner AlphaVoice (&lt;a class="reference external" href="https://www.alphavoice.io/"&gt;https://www.alphavoice.io/&lt;/a&gt;)!&lt;/p&gt;
&lt;p&gt;#pybay #pybay2019 #python #python3 #gdb&lt;/p&gt;
</summary></entry></feed>