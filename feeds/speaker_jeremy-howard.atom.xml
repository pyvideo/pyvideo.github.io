<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Jeremy Howard</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_jeremy-howard.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2023-09-17T00:00:00+00:00</updated><subtitle></subtitle><entry><title>A hacker's guide to open source LLMs</title><link href="https://pyvideo.org/positconf-2023/a-hackers-guide-to-open-source-llms.html" rel="alternate"></link><published>2023-09-17T00:00:00+00:00</published><updated>2023-09-17T00:00:00+00:00</updated><author><name>Jeremy Howard</name></author><id>tag:pyvideo.org,2023-09-17:/positconf-2023/a-hackers-guide-to-open-source-llms.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this deeply informative video, Jeremy Howard, co-founder of fast.ai and creator of the ULMFiT approach on which all modern language models (LMs) are based, takes you on a comprehensive journey through the fascinating landscape of LMs. Starting with the foundational concepts, Jeremy introduces the architecture and mechanics â€¦&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this deeply informative video, Jeremy Howard, co-founder of fast.ai and creator of the ULMFiT approach on which all modern language models (LMs) are based, takes you on a comprehensive journey through the fascinating landscape of LMs. Starting with the foundational concepts, Jeremy introduces the architecture and mechanics that make these AI systems tick. He then delves into critical evaluations of GPT-4, illuminates practical uses of language models in code writing and data analysis, and offers hands-on tips for working with the OpenAI API. The video also provides expert guidance on technical topics such as fine-tuning, decoding tokens, and running private instances of GPT models.&lt;/p&gt;
&lt;p&gt;As we move further into the intricacies, Jeremy unpacks advanced strategies for model testing and optimization, utilizing tools like GPTQ and Hugging Face Transformers. He also explores the potential of specialized datasets like Orca and Platypus for fine-tuning and discusses cutting-edge trends in Retrieval Augmented Generation and information retrieval. Whether you're new to the field or an established professional, this presentation offers a wealth of insights to help you navigate the ever-evolving world of language models.&lt;/p&gt;
&lt;p&gt;(The above summary was, of course, created by an LLM!)&lt;/p&gt;
&lt;p&gt;For the notebook used in this talk, see &lt;a class="reference external" href="https://github.com/fastai/lm-hackers"&gt;https://github.com/fastai/lm-hackers&lt;/a&gt;.&lt;/p&gt;
</content><category term="Posit:Conf 2023"></category></entry></feed>