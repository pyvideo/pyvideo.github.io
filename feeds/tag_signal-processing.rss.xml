<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 03 May 2019 00:00:00 +0000</lastBuildDate><item><title>Deep learning: the final frontier for time series analysis and signal processing?</title><link>https://pyvideo.org/pycon-italia-2019/deep-learning-the-final-frontier-for-time-series-analysis-and-signal-processing.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deep neural networks are becoming irreplaceable for analyzing most kinds
of data that humans supposed to exceed in - images, video, sounds,
texts. They can not only predict something based on some input but also
generate new images or sounds. Meanwhile, we are forgetting about
another very important source of data - signals (or time series, which
will be interchangeably here), that gets less hype in public but
benefits a lot from applying deep learning comparing to classical
approaches.&lt;/p&gt;
&lt;p&gt;In this talk, we will review what are sources of time series and what
business goals are we solving while analyzing them, what are “old” tools
for analysis and how deep neural nets overcome them, we will learn the
latest trends and ruin some myths and, moreover, we will see how
generative models can be applied to the signal processing as well.&lt;/p&gt;
&lt;p&gt;After this talk, you’ll be able to boost your current solutions in
signal processing or time series analysis with deep learning. It will be
also interesting for practitioners in other areas, like computer vision
or NLP since we will discuss some concepts that are widely applicable.
Previous experience with time series is not required, but some
theoretical or practical experience with machine learning and/or neural
networks is preferred.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1716"&gt;https://python.it/feedback-1716&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 18:00 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexandr Honchar</dc:creator><pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-03:pycon-italia-2019/deep-learning-the-final-frontier-for-time-series-analysis-and-signal-processing.html</guid><category>machine-learning</category><category>deep learning</category><category>biomedical-data-science</category><category>TimeSeries</category><category>signal-processing</category><category>neural network</category><category>finance</category></item><item><title>Machine Learning con Python: algoritmi NILM e real-time processing</title><link>https://pyvideo.org/pycon-italia-2017/machine-learning-con-python-algoritmi-nilm-e-real-time-processing.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Le tecniche di Machine Learning sono sempre più pervasive nelle
applicazioni analitiche odierne. In questo talk l’attenzione verte sul
problema del &lt;strong&gt;NILM&lt;/strong&gt; (Not Intrusive Load Monitoring) per cui
l’obiettivo è la disaggregazione real-time dei consumi di energia
elettrica. Gli algoritmi, permettono di riconoscere in realtime i
dispositivi attivi in base alle sole caratteristiche del segnale
aggregato.&lt;/p&gt;
&lt;p&gt;L’obiettivo del talk è dimostrare come sia possibile implementare
rapidamente un prototipo hardware e software grazie alle potenzialità di
Arduino e Python rispettivamente.&lt;/p&gt;
&lt;p&gt;Con degli &lt;em&gt;esempi hardware e software pratici&lt;/em&gt; (4 devices collegati ad
una multipresa), verrà dimostrata la capacità di Arduino di acquisire le
misura di corrente elettrica e la capacità di Python di riconoscere i
dispositivi attivi. Verranno fornite informazioni sulle logiche alla
base di tali algoritmi, con riferimento all’ecosistema Python e alle
relative librerie utilizzate.&lt;/p&gt;
&lt;p&gt;Per la comprensione del talk non sono necessari particolari requisiti se
non una conoscenza di base di programmazione in Python e di Machine
Learning.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Felice Tuosto</dc:creator><pubDate>Sat, 08 Apr 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-04-08:pycon-italia-2017/machine-learning-con-python-algoritmi-nilm-e-real-time-processing.html</guid><category>signal-processing</category><category>arduino</category><category>nilm</category><category>machine-learning</category><category>realtime</category></item><item><title>Machine Learning con Python: previsione in real-time della richiesta di energia elettrica</title><link>https://pyvideo.org/pycon-italia-2017/machine-learning-con-python-previsione-in-real-time-della-richiesta-di-energia-elettrica.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Nel talk si parlerà di come attraverso il linguaggio Python sia
possibile risolvere un problema reale e complesso relativamente alla
trasmissione di energia elettrica. Verrà spiegato il progetto
&lt;strong&gt;RealtimeLoadForecast&lt;/strong&gt; che è stato sviluppato per un importante TSO
(Transmission System Operator). Si tratta di sistema predittivo che
permette di fornire in tempo reale ogni 15 minuti ed entro 5 minuti, le
previsioni delle serie storiche dei consumi di energia elettrica
relativi a circa 500 nodi elettrici.&lt;/p&gt;
&lt;p&gt;Si parlerà dei passi che occorre seguire per ottenere da un semplice
prototipo, un sistema &lt;em&gt;ingegnerizzato&lt;/em&gt; che lavori in tempo reale e di
come sono state utilizzate le librerie di Python per l’acquisizione,
manipolazione e processamento dei dati elettrici ed ambientali.&lt;/p&gt;
&lt;p&gt;Saranno descritte alcune tecniche algoritmiche e di Machine Learning per
ottenere dei modelli predittivi capaci di fornire previsioni accurate ma
con tempi di risposta sfidanti.&lt;/p&gt;
&lt;p&gt;Verrà mostrato un &lt;em&gt;esempio concreto&lt;/em&gt; di implementazione di un algoritmo
predittivo basato sulla libreria Deep Learning &lt;strong&gt;Keras&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Per la comprensione del talk non sono necessari particolari requisiti se
non una conoscenza di base di programmazione in Python e di Machine
Learning.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Felice Tuosto</dc:creator><pubDate>Sat, 08 Apr 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-04-08:pycon-italia-2017/machine-learning-con-python-previsione-in-real-time-della-richiesta-di-energia-elettrica.html</guid><category>Forecasting</category><category>Genetic Algorithms</category><category>Keras</category><category>Data Mining</category><category>programming-paradigms</category><category>scikit-learn</category><category>bigdata</category><category>scalability</category><category>Deep-Learning</category><category>threading</category><category>realtime</category><category>Data-Scientist</category><category>database</category><category>machine-learning</category><category>mysql</category><category>signal-processing</category><category>LoadForecasting</category><category>cassandra</category></item><item><title>Signal Processing and Communications Hands On Using scikit dsp comm</title><link>https://pyvideo.org/scipy-2017/signal-processing-and-communications-hands-on-using-scikit-dsp-comm.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this tutorial I intend to start with a basic review of discrete-time signals and systems using a module I developed for my book Signals and Systems for Dummies. Once a basic foundation is provided, all using hands-on Python code examples in a Jupyter notebook, I will move to more advanced topics relative to statistical signal processing, digital communications and software defined radio. Digital communication transmitter and receiver simulations will be explored using Python code modules found in the newly posted scikit-dsp-comm as well as data acquisition code used in conjunction with a popular $20 software-defined radio USB dongle (RTL-SDR).
The capstone portion of the tutorial will have the students write code to recover FM stereo radio broadcasts from a raw complex signal file obtained from the output of a popular $20 software defined radio module (the RTLSDR).  Hardware will be provided for small groups to work together.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mark Wic</dc:creator><pubDate>Thu, 13 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-13:scipy-2017/signal-processing-and-communications-hands-on-using-scikit-dsp-comm.html</guid><category>signal processing</category><category>software defined radio</category><category>tutorial</category></item><item><title>A Simulation Framework for Studying the Code Acquisition and Tracking Functions of a Global Positioning System (GPS) Receiver</title><link>https://pyvideo.org/scipy-2016/a-simulation-framework-for-studying-the-code-acquisition-and-tracking-functions-of-a-global-position.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk a Python-based simulation framework is described that implements the waveform level signal processing needed to acquire and track the ranging signal of a global positioning system (GPS) satellite. This framework was developed Fall 2015 as an end-of-semester project for a digital signal processing course taken by electrical engineers. By design, GPS signals lie on top of one another, but are separable by virtue of a unique code and nearly orthogonal code assigned to each satellite. The key to position determination is the time difference of arrival (TDOA) of each of the satellite signals at the user receiver. A high precision clock maintains timing accuracy among the satellites. One of the most important tasks of the user receiver is to acquire and track the ranging code of three or more satellites in view at a given time. The framework allows the user to first explore a receiver for a single satellite signal. Object oriented Python then makes it easy to extend the receiver to processing multiple satellite signals in parallel. The source of signals used in the framework is either simulation or a low-cost (~$20) software defined radio dongle known as the RTL-SDR. With the RTL-SDR signals are captured from a GPS patch antenna, fed to the RTL-SDR, and then via USB captured into Python as a complex ndarray. The computer simulation project that utilizes the framework has the students performing a variety of simulation tasks, start from a single channel receiver building up to a four channel receiver with signal impairments present. As developed Fall 2015 the project utilizing this framework is entirely computer simulation based, but the ability to use real signals captured from the RTL-SDR, opens additional capability options. Making use of these signals is non-trival, as additional signal processing is needed to estimate the Doppler frequency error and if the data bits are to be recovered, the L1 signal carrier phase needs to be tracked. These aspects of the framework as currently under development (mid Spring 2016) for a communications theory course.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mark Wickert</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/a-simulation-framework-for-studying-the-code-acquisition-and-tracking-functions-of-a-global-position.html</guid><category>gps</category><category>signal processing</category></item></channel></rss>