<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_varun-kochar.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-12-12T00:00:00+00:00</updated><entry><title>Automation: Build A Training Pipeline</title><link href="https://pyvideo.org/pydata-warsaw-2019/automation-build-a-training-pipeline.html" rel="alternate"></link><published>2019-12-12T00:00:00+00:00</published><updated>2019-12-12T00:00:00+00:00</updated><author><name>Varun Kochar</name></author><id>tag:pyvideo.org,2019-12-12:pydata-warsaw-2019/automation-build-a-training-pipeline.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Many of us knows how to train &amp;amp; deploy ML models in cloud, but doing so
have we become redundant. Running multiple experiments in single machine
&amp;amp; waiting for tasks to complete cannot be time-efficient for big
datasets. Hence, we need an automation which can take over repetitive
manual tasks &amp;amp; spare us the time to do other important stuff. Aim is to
show how to deploy ML architecture in 60 SECONDS&lt;/p&gt;
&lt;p&gt;ML pipeline consists of many manual tasks such as Data collection, Data
cleaning, training environment setup, training configuration, monitoring
progress or model evaluation gig, all these components should be
automated &amp;amp; what you should be left with is just a single CONFIGURATION
document with information of different set of experiments.&lt;/p&gt;
</summary></entry></feed>