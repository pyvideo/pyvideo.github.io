<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Luciano Resende</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Wed, 10 May 2023 00:00:00 +0000</lastBuildDate><item><title>Elyra an AI development workspace based on Jupyter Notebooks</title><link>https://pyvideo.org/jupytercon-2023/elyra-an-ai-development-workspace-based-on-jupyter-notebooks.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Do you love Jupyter Notebooks, but are getting tired of the Wild Wild West of external tools and devOps tasks that consumes a lot of your time away from model development? In this talk, we will introduce you to Elyra, an open-source AI development workspace that enables data scientists, Machine Learning Engineers, and AI developers to be more productive. It provides support for low code/no code AI Pipelines integrated with Apache Airflow and Kubeflow runtimes, integrated Python, Scala, and R editors, collaboration support via git integration, code reusability via code snippets, etc all without having to leave your Notebook workspace. After a quick introduction to Elyra's capabilities, we will dive into a live demo, showcasing how to build and execute a data pipeline in a few minutes.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Luciano Resende</dc:creator><pubDate>Wed, 10 May 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-05-10:/jupytercon-2023/elyra-an-ai-development-workspace-based-on-jupyter-notebooks.html</guid><category>JupyterCon 2023</category></item><item><title>AI pipelines powered by Jupyter notebooks</title><link>https://pyvideo.org/pydata-austin-2019/ai-pipelines-powered-by-jupyter-notebooks.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Jupyter Notebook has become the de-facto platform used by data scientists to develop their AI/ML models. In this scenario, it’s very common to decompose various phases of the development into multiple notebooks to simplify the development and management of the model lifecycle. This session will detail different approaches to compose notebook based AI pipelines and running in different runtimes&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Luciano Resende</dc:creator><pubDate>Sat, 07 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-07:/pydata-austin-2019/ai-pipelines-powered-by-jupyter-notebooks.html</guid><category>PyData Austin 2019</category><category>data pipelines</category><category>ai</category><category>artificial intelligence</category><category>jupyter notebooks</category></item><item><title>Customizing JupyterLab using extensions</title><link>https://pyvideo.org/pydata-austin-2019/customizing-jupyterlab-using-extensions.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;JupyterLab provides data scientists a singular work environment for notebooks, file editing, and more. Designed to be extendable, JupyterLab allows developers to create new features and improve upon built-in functionality. In this session we will go over JupyterLab extensions and how they can be used to customize JupyterLab for your use case.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alex Bozarth</dc:creator><pubDate>Sat, 07 Dec 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-12-07:/pydata-austin-2019/customizing-jupyterlab-using-extensions.html</guid><category>PyData Austin 2019</category><category>jupyter lab</category></item><item><title>Scaling your Python interactive applications with Jupyter</title><link>https://pyvideo.org/scipy-japan-2019/scaling-your-python-interactive-applications-with-jupyter.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter Notebooks have become the &amp;quot;de facto&amp;quot; platform used by scientists and engineers to build Python interactive applications to tackle scientific and machine learning problems. However, with the popularity of big data analytics and complex deep learning workloads, there is a growing requirement to extend the computation across a cluster of computers in a parallel fashion. In this talk, we will describe how to use multiple Jupyter Notebook components to enable the orchestration and distribution of interactive machine learning and deep learning workloads across different types of computing clusters including Apache Spark and Kubernetes. This talk is intended to attendees interested in distributed platforms and scientists experiencing difficulties on scaling their scientific workloads across multiple machines.
​
Bio: Luciano Resende is an STSM and Open Source Data Science/AI Platform Architect at IBM CODAIT (formerly Spark Technology Center). He has been contributing to open source at The ASF for over 10 years, he is a member of ASF and is currently contributing to various big data related Apache projects around the Apache Spark ecosystem. Currently, Luciano is contributing to Jupyter Ecosystem projects building scalable, secure and flexible Enterprise Data Science platform.&lt;/p&gt;
&lt;div class="section" id="connect-with-us"&gt;
&lt;h4&gt;Connect with us!&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="https://twitter.com/enthought"&gt;https://twitter.com/enthought&lt;/a&gt;
&lt;a class="reference external" href="https://www.facebook.com/Enthought/"&gt;https://www.facebook.com/Enthought/&lt;/a&gt;
&lt;a class="reference external" href="https://www.linkedin.com/company/enthought"&gt;https://www.linkedin.com/company/enthought&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Luciano Resende</dc:creator><pubDate>Tue, 23 Apr 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-04-23:/scipy-japan-2019/scaling-your-python-interactive-applications-with-jupyter.html</guid><category>Scipy Japan 2019</category></item></channel></rss>