<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_michael-beyeler.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2017-07-12T00:00:00+00:00</updated><entry><title>pulse2percept - A Python based Simulation Framework for Bionic Vision</title><link href="https://pyvideo.org/scipy-2017/pulse2percept-a-python-based-simulation-framework-for-bionic-vision.html" rel="alternate"></link><published>2017-07-12T00:00:00+00:00</published><updated>2017-07-12T00:00:00+00:00</updated><author><name>Michael Beyeler</name></author><id>tag:pyvideo.org,2017-07-12:scipy-2017/pulse2percept-a-python-based-simulation-framework-for-bionic-vision.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;By 2020 roughly 200 million people worldwide will suffer from photoreceptor diseases such as retinitis pigmentosa and age-related macular degeneration, and a variety of retinal sight restoration technologies are being developed to target these diseases. Two brands of retinal prostheses are already being implanted in patients. Analogous to cochlear implants, these devices use a grid of electrodes to stimulate remaining retinal cells. However, clinical experience with these implants has made it apparent that the vision restored by these devices differs substantially from normal sight. To better understand the current state-of-the-art in prosthetic vision, we developed a computational model based on human behavioral data that can predict the perceptual experience of retinal prosthesis patients. The model is implemented as an open-source Python package (&lt;a class="reference external" href="https://github.com/uwescience/pulse2percept"&gt;https://github.com/uwescience/pulse2percept&lt;/a&gt;), which provides a modular and extensible user interface, making it straightforward for users to simulate novel implants, stimuli, and retinal models. We will give an overview of the software, review our solutions to various technical challenges, and discuss the broader impact of this work for the computational neuroscience community.&lt;/p&gt;
</summary></entry></feed>