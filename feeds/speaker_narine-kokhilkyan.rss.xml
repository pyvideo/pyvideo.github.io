<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Narine Kokhilkyan</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Wed, 16 Oct 2019 00:00:00 +0000</lastBuildDate><item><title>Model Interpretability with Captum</title><link>https://pyvideo.org/pytorch-conference-2019/model-interpretability-with-captum.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As models become ever more complex, it is increasingly important to develop new methods for model interpretability. Learn about Captum, a new tool for helping developers working in PyTorch understand why their model generates a specific output. Captumâ€™s algorithms include integrated gradients, conductance, SmoothGrad and VarGrad, and DeepLift.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Narine Kokhilkyan</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/model-interpretability-with-captum.html</guid><category>PyTorch Conference 2019</category></item></channel></rss>