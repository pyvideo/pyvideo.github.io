<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - machine learning</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_machine-learning.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-07-23T00:00:00+00:00</updated><subtitle></subtitle><entry><title>How do I create dummy variables in pandas?</title><link href="https://pyvideo.org/data-school/pandas-24-dummy-variables.html" rel="alternate"></link><published>2016-07-12T00:00:00+00:00</published><updated>2016-07-12T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-07-12:/data-school/pandas-24-dummy-variables.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you want to include a categorical feature in your machine learning model, one common solution is to create dummy variables. In this video, I'll demonstrate three different ways you can create dummy variables from your existing DataFrame columns. I'll also show you a trick for simplifying your code ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you want to include a categorical feature in your machine learning model, one common solution is to create dummy variables. In this video, I'll demonstrate three different ways you can create dummy variables from your existing DataFrame columns. I'll also show you a trick for simplifying your code that was introduced in pandas 0.18.&lt;/p&gt;
&lt;p&gt;This is video 24 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</content><category term="Data School"></category><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="machine learning"></category></entry><entry><title>How do I use pandas with scikit-learn to create Kaggle submissions?</title><link href="https://pyvideo.org/data-school/pandas-22-prepare-for-machine-learning.html" rel="alternate"></link><published>2016-06-28T00:00:00+00:00</published><updated>2016-06-28T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-06-28:/data-school/pandas-22-prepare-for-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you been using scikit-learn for machine learning, and wondering whether pandas could help you to prepare your data and export your predictions? In this video, I'll demonstrate the simplest way to integrate pandas into your machine learning workflow, and will create a submission for Kaggle's Titanic competition in ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you been using scikit-learn for machine learning, and wondering whether pandas could help you to prepare your data and export your predictions? In this video, I'll demonstrate the simplest way to integrate pandas into your machine learning workflow, and will create a submission for Kaggle's Titanic competition in just a few lines of code!&lt;/p&gt;
&lt;p&gt;This is video 22 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</content><category term="Data School"></category><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="scikit-learn"></category><category term="machine learning"></category></entry><entry><title>How to evaluate a classifier in scikit-learn</title><link href="https://pyvideo.org/data-school/scikit-learn-09-evaluating-classification-models.html" rel="alternate"></link><published>2015-10-23T00:00:00+00:00</published><updated>2015-10-23T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2015-10-23:/data-school/scikit-learn-09-evaluating-classification-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, you'll learn how to properly evaluate a classification model using a variety of common tools and metrics, as well as how to adjust the performance of a classifier to best match your business objectives. I'll start by demonstrating the weaknesses of classification accuracy as an evaluation ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, you'll learn how to properly evaluate a classification model using a variety of common tools and metrics, as well as how to adjust the performance of a classifier to best match your business objectives. I'll start by demonstrating the weaknesses of classification accuracy as an evaluation metric. I'll then discuss the confusion matrix, the ROC curve and AUC, and metrics such as sensitivity, specificity, and precision. By the end of the video, you will have a solid foundation for intelligently evaluating your own classification model.&lt;/p&gt;
&lt;p&gt;This is the ninth video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</content><category term="Data School"></category><category term="machine learning"></category><category term="data science"></category><category term="scikit-learn"></category><category term="tutorial"></category><category term="Data School"></category><category term="model evaluation"></category><category term="classification"></category><category term="confusion matrix"></category><category term="ROC curve"></category><category term="AUC"></category></entry><entry><title>How to find the best model parameters in scikit-learn</title><link href="https://pyvideo.org/data-school/scikit-learn-08-parameter-tuning-with-grid-search.html" rel="alternate"></link><published>2015-07-15T00:00:00+00:00</published><updated>2015-07-15T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2015-07-15:/data-school/scikit-learn-08-parameter-tuning-with-grid-search.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, you'll learn how to efficiently search for the optimal tuning parameters (or &amp;quot;hyperparameters&amp;quot;) for your machine learning model in order to maximize its performance. I'll start by demonstrating an exhaustive &amp;quot;grid search&amp;quot; process using scikit-learn's GridSearchCV class, and then I'll compare it with RandomizedSearchCV, which can ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, you'll learn how to efficiently search for the optimal tuning parameters (or &amp;quot;hyperparameters&amp;quot;) for your machine learning model in order to maximize its performance. I'll start by demonstrating an exhaustive &amp;quot;grid search&amp;quot; process using scikit-learn's GridSearchCV class, and then I'll compare it with RandomizedSearchCV, which can often achieve similar results in far less time.&lt;/p&gt;
&lt;p&gt;This is the eighth video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</content><category term="Data School"></category><category term="machine learning"></category><category term="data science"></category><category term="scikit-learn"></category><category term="tutorial"></category><category term="Data School"></category><category term="cross-validation"></category><category term="model evaluation"></category><category term="parameter tuning"></category><category term="grid search"></category></entry><entry><title>Selecting the best model in scikit-learn using cross-validation</title><link href="https://pyvideo.org/data-school/scikit-learn-07-model-evaluation-with-cross-validation.html" rel="alternate"></link><published>2015-06-28T00:00:00+00:00</published><updated>2015-06-28T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2015-06-28:/data-school/scikit-learn-07-model-evaluation-with-cross-validation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, we'll learn about K-fold cross-validation and how it can be used for selecting optimal tuning parameters, choosing between models, and selecting features. We'll compare cross-validation with the train/test split procedure, and we'll also discuss some variations of cross-validation that can result in more accurate estimates ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, we'll learn about K-fold cross-validation and how it can be used for selecting optimal tuning parameters, choosing between models, and selecting features. We'll compare cross-validation with the train/test split procedure, and we'll also discuss some variations of cross-validation that can result in more accurate estimates of model performance.&lt;/p&gt;
&lt;p&gt;This is the seventh video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</content><category term="Data School"></category><category term="machine learning"></category><category term="data science"></category><category term="scikit-learn"></category><category term="tutorial"></category><category term="Data School"></category><category term="cross-validation"></category><category term="model evaluation"></category><category term="feature selection"></category><category term="parameter tuning"></category></entry><entry><title>Data science in Python: pandas, seaborn, scikit-learn</title><link href="https://pyvideo.org/data-school/scikit-learn-06-data-science-pipeline.html" rel="alternate"></link><published>2015-05-28T00:00:00+00:00</published><updated>2015-05-28T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2015-05-28:/data-school/scikit-learn-06-data-science-pipeline.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, we'll cover the data science pipeline from data ingestion (with pandas) to data visualization (with seaborn) to machine learning (with scikit-learn). We'll learn how to train and interpret a linear regression model, and then compare three possible evaluation metrics for regression problems. Finally, we'll apply the ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, we'll cover the data science pipeline from data ingestion (with pandas) to data visualization (with seaborn) to machine learning (with scikit-learn). We'll learn how to train and interpret a linear regression model, and then compare three possible evaluation metrics for regression problems. Finally, we'll apply the train/test split procedure to decide which features to include in our model.&lt;/p&gt;
&lt;p&gt;This is the sixth video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</content><category term="Data School"></category><category term="machine learning"></category><category term="data science"></category><category term="scikit-learn"></category><category term="tutorial"></category><category term="Data School"></category><category term="pandas"></category><category term="seaborn"></category><category term="linear regression"></category><category term="model evaluation"></category><category term="feature selection"></category><category term="visualization"></category></entry><entry><title>Comparing machine learning models in scikit-learn</title><link href="https://pyvideo.org/data-school/scikit-learn-05-comparing-machine-learning-models.html" rel="alternate"></link><published>2015-05-14T00:00:00+00:00</published><updated>2015-05-14T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2015-05-14:/data-school/scikit-learn-05-comparing-machine-learning-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We've learned how to train different machine learning models and make predictions, but how do we actually choose which model is &amp;quot;best&amp;quot;? We'll cover the train/test split process for model evaluation, which allows you to avoid &amp;quot;overfitting&amp;quot; by estimating how well a model is likely to perform on ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We've learned how to train different machine learning models and make predictions, but how do we actually choose which model is &amp;quot;best&amp;quot;? We'll cover the train/test split process for model evaluation, which allows you to avoid &amp;quot;overfitting&amp;quot; by estimating how well a model is likely to perform on new data. We'll use that same process to locate optimal tuning parameters for a KNN model, and then we'll re-train our model so that it's ready to make real predictions.&lt;/p&gt;
&lt;p&gt;This is the fifth video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</content><category term="Data School"></category><category term="machine learning"></category><category term="data science"></category><category term="scikit-learn"></category><category term="tutorial"></category><category term="Data School"></category><category term="model evaluation"></category><category term="overfitting"></category></entry><entry><title>Training a machine learning model with scikit-learn</title><link href="https://pyvideo.org/data-school/scikit-learn-04-training-a-machine-learning-model.html" rel="alternate"></link><published>2015-04-29T00:00:00+00:00</published><updated>2015-04-29T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2015-04-29:/data-school/scikit-learn-04-training-a-machine-learning-model.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Now that we're familiar with the famous iris dataset, let's actually use a classification model in scikit-learn to predict the species of an iris! We'll learn how the K-nearest neighbors (KNN) model works, and then walk through the four steps for model training and prediction in scikit-learn. Finally, we'll ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Now that we're familiar with the famous iris dataset, let's actually use a classification model in scikit-learn to predict the species of an iris! We'll learn how the K-nearest neighbors (KNN) model works, and then walk through the four steps for model training and prediction in scikit-learn. Finally, we'll see how easy it is to try out a different classification model, namely logistic regression.&lt;/p&gt;
&lt;p&gt;This is the fourth video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</content><category term="Data School"></category><category term="machine learning"></category><category term="data science"></category><category term="scikit-learn"></category><category term="tutorial"></category><category term="Data School"></category><category term="classification"></category><category term="KNN"></category></entry><entry><title>Getting started in scikit-learn with the famous iris dataset</title><link href="https://pyvideo.org/data-school/scikit-learn-03-getting-started-with-machine-learning.html" rel="alternate"></link><published>2015-04-21T00:00:00+00:00</published><updated>2015-04-21T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2015-04-21:/data-school/scikit-learn-03-getting-started-with-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Now that we've set up Python for machine learning, let's get started by loading an example dataset into scikit-learn! We'll explore the famous &amp;quot;iris&amp;quot; dataset, learn some important machine learning terminology, and discuss the four key requirements for working with data in scikit-learn.&lt;/p&gt;
&lt;p&gt;This is the third video in ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Now that we've set up Python for machine learning, let's get started by loading an example dataset into scikit-learn! We'll explore the famous &amp;quot;iris&amp;quot; dataset, learn some important machine learning terminology, and discuss the four key requirements for working with data in scikit-learn.&lt;/p&gt;
&lt;p&gt;This is the third video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</content><category term="Data School"></category><category term="machine learning"></category><category term="data science"></category><category term="scikit-learn"></category><category term="tutorial"></category><category term="Data School"></category><category term="NumPy"></category></entry><entry><title>Setting up Python for machine learning: scikit-learn and IPython Notebook</title><link href="https://pyvideo.org/data-school/scikit-learn-02-machine-learning-setup.html" rel="alternate"></link><published>2015-04-15T00:00:00+00:00</published><updated>2015-04-15T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2015-04-15:/data-school/scikit-learn-02-machine-learning-setup.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Want to get started with machine learning in Python? I'll discuss the pros and cons of the scikit-learn library, show how to install my preferred Python distribution, and demonstrate the basic functionality of the IPython Notebook. If you don't yet know any Python, I'll also provide four recommended resources ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Want to get started with machine learning in Python? I'll discuss the pros and cons of the scikit-learn library, show how to install my preferred Python distribution, and demonstrate the basic functionality of the IPython Notebook. If you don't yet know any Python, I'll also provide four recommended resources for learning Python.&lt;/p&gt;
&lt;p&gt;This is the second video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</content><category term="Data School"></category><category term="machine learning"></category><category term="data science"></category><category term="scikit-learn"></category><category term="tutorial"></category><category term="Data School"></category><category term="IPython notebook"></category><category term="Jupyter notebook"></category></entry><entry><title>What is machine learning, and how does it work?</title><link href="https://pyvideo.org/data-school/scikit-learn-01-what-is-machine-learning.html" rel="alternate"></link><published>2015-04-07T00:00:00+00:00</published><updated>2015-04-07T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2015-04-07:/data-school/scikit-learn-01-what-is-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you heard of &amp;quot;machine learning&amp;quot;, and you're trying to figure out exactly what that means? I'll give you my definition, provide some examples of machine learning, and explain at a high level how machine learning &amp;quot;works&amp;quot;.&lt;/p&gt;
&lt;p&gt;This is the first video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning ‚Ä¶&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you heard of &amp;quot;machine learning&amp;quot;, and you're trying to figure out exactly what that means? I'll give you my definition, provide some examples of machine learning, and explain at a high level how machine learning &amp;quot;works&amp;quot;.&lt;/p&gt;
&lt;p&gt;This is the first video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</content><category term="Data School"></category><category term="machine learning"></category><category term="data science"></category><category term="scikit-learn"></category><category term="tutorial"></category><category term="Data School"></category><category term="supervised learning"></category><category term="unsupervised learning"></category></entry><entry><title>Introduction to machine learning using Python tools</title><link href="https://pyvideo.org/europython-2013/introduction-to-machine-learning-using-python-tools.html" rel="alternate"></link><published>2013-07-02T00:00:00+00:00</published><updated>2013-07-02T00:00:00+00:00</updated><author><name>Satish Shankar</name></author><id>tag:pyvideo.org,2013-07-02:/europython-2013/introduction-to-machine-learning-using-python-tools.html</id><content type="html"></content><category term="EuroPython 2013"></category><category term="statistics"></category><category term="machine-learning"></category><category term="datamining"></category><category term="Algorithms"></category><category term="data-analysis"></category><category term="scientific-computing"></category><category term="sklearn"></category></entry><entry><title>Audio Classification with Machine Learning</title><link href="https://pyvideo.org/europython-2019/audio-classification-with-machine-learning.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Jon Nordby</name></author><id>tag:pyvideo.org,2019-07-11:/europython-2019/audio-classification-with-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Sound is a rich source of information about the world around us.&lt;/div&gt;
&lt;div class="line"&gt;Modern deep learning approaches can give human-like performance on a
range of sound classifiction tasks.&lt;/div&gt;
&lt;div class="line"&gt;This makes it possible to build systems that use sound to for example:&lt;/div&gt;
&lt;div class="line"&gt;understand speech, to analyze music, to assist in medical ‚Ä¶&lt;/div&gt;&lt;/div&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Sound is a rich source of information about the world around us.&lt;/div&gt;
&lt;div class="line"&gt;Modern deep learning approaches can give human-like performance on a
range of sound classifiction tasks.&lt;/div&gt;
&lt;div class="line"&gt;This makes it possible to build systems that use sound to for example:&lt;/div&gt;
&lt;div class="line"&gt;understand speech, to analyze music, to assist in medical diagnostics,
detect quality problems in manufacturing, and to study the behavior of
animals.&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;This talk will show you how to build practical machine learning models
that can classify sound.&lt;/div&gt;
&lt;div class="line"&gt;We will convert sound into spectrograms, a visual representation of
sound over time,&lt;/div&gt;
&lt;div class="line"&gt;and apply machine learning models similar to what is used to for image
classification.&lt;/div&gt;
&lt;div class="line"&gt;The focus will be on Convolutional Neural Networks, which have been
shown to work very well for this task.&lt;/div&gt;
&lt;div class="line"&gt;The Keras and Tensorflow deep learning frameworks will be used. Some
tricks for getting usable results with small amounts of data will be
covered, including transfer learning, audio embeddings and data
augmentation.&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;A basic understanding of machine learning is recommended.&lt;/div&gt;
&lt;div class="line"&gt;Familiarity with digital sound is a bonus.&lt;/div&gt;
&lt;/div&gt;
</content><category term="EuroPython 2019"></category><category term="Data Science"></category><category term="Deep Learning"></category><category term="Machine-Learning"></category></entry><entry><title>Building Data-Driven Client Relationship Management in Banking with Python</title><link href="https://pyvideo.org/europython-2019/building-data-driven-client-relationship-management-in-banking-with-python.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Paul Hughes</name></author><id>tag:pyvideo.org,2019-07-11:/europython-2019/building-data-driven-client-relationship-management-in-banking-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This is a case study that documents how a small data science team in a
big bank took on the challenge to transform a fragmented sales process
into a data-driven one using Python and machine learning.&lt;/p&gt;
&lt;p&gt;This talk outlines the various ways Python has been instrumental in
delivering a ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This is a case study that documents how a small data science team in a
big bank took on the challenge to transform a fragmented sales process
into a data-driven one using Python and machine learning.&lt;/p&gt;
&lt;p&gt;This talk outlines the various ways Python has been instrumental in
delivering a production solution that serves advisers and relationship
manager on a continuous basis.&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;The Challenge&lt;/div&gt;
&lt;div class="line"&gt;- A bank has many clients with diverse needs and cost pressures mean
fewer advisers resulting in reduced client coverage.&lt;/div&gt;
&lt;div class="line"&gt;- Multiple sales channels and mixed service levels meant sales
processes were uncoordinated and driven by heuristics and often very
subjective.&lt;/div&gt;
&lt;div class="line"&gt;- And... Excel sheets everywhere!&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Solution&lt;/div&gt;
&lt;div class="line"&gt;- Go data-driven!&lt;/div&gt;
&lt;div class="line"&gt;- Learn from clients and understand product usage&lt;/div&gt;
&lt;div class="line"&gt;- Empower and inform advisers and call centre agents&lt;/div&gt;
&lt;div class="line"&gt;- Build a front-to-back sales process (no more Excels!)&lt;/div&gt;
&lt;div class="line"&gt;- How? With Python!&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;The Python Bits&lt;/div&gt;
&lt;div class="line"&gt;- Scikit learn machine learning pipelines that implement two distinct
approaches to product affinity in banking and wealth management&lt;/div&gt;
&lt;div class="line"&gt;- SQL Alchemy based API for data engineering and rapid prototyping of
analytics&lt;/div&gt;
&lt;div class="line"&gt;- Pandas and Jupyter for development and collaboration&lt;/div&gt;
&lt;div class="line"&gt;- Luigi pipeline for daily processing of millions of transactions and
engineering features&lt;/div&gt;
&lt;div class="line"&gt;- Extracting features from text with NLP (Spacy)&lt;/div&gt;
&lt;div class="line"&gt;- Delivering machine learning interpretability in production, e.g.
with Random Forests and treeinterpreter&lt;/div&gt;
&lt;div class="line"&gt;- A Python module that we built with all the reusable bits: building
training and prediction datasets, developing pipelines, generating
monitoring data and enabling explainability&lt;/div&gt;
&lt;/div&gt;
</content><category term="EuroPython 2019"></category><category term="Business Cases"></category><category term="Data Science"></category><category term="Machine-Learning"></category><category term="Scientific Libraries (Numpy/Pandas/SciKit/...)"></category><category term="Windows"></category></entry><entry><title>Deep Learning with TensorFlow 2.0</title><link href="https://pyvideo.org/europython-2019/deep-learning-with-tensorflow-20.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Brad Miro</name></author><id>tag:pyvideo.org,2019-07-11:/europython-2019/deep-learning-with-tensorflow-20.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Learn about the updates being made to TensorFlow in its 2.0 version.
We‚Äôll give an overview of what‚Äôs available in the new version as well as
do a deep dive into an example using its central high-level API, Keras.
You‚Äôll walk away with a better ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Learn about the updates being made to TensorFlow in its 2.0 version.
We‚Äôll give an overview of what‚Äôs available in the new version as well as
do a deep dive into an example using its central high-level API, Keras.
You‚Äôll walk away with a better understanding of how you can get started
building machine learning models in Python with TensorFlow 2.0 as well
as the other exciting available features!&lt;/p&gt;
</content><category term="EuroPython 2019"></category><category term="Data Science"></category><category term="Deep Learning"></category><category term="Machine-Learning"></category><category term="Scientific Libraries (Numpy/Pandas/SciKit/...)"></category></entry><entry><title>How software can feed the world üå±</title><link href="https://pyvideo.org/europython-2019/how-software-can-feed-the-world.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Christian Barra</name></author><id>tag:pyvideo.org,2019-07-11:/europython-2019/how-software-can-feed-the-world.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Infarm is a FaaS, Farming as a Service, and whether you believe it or
not, our business is in-house farming at scale.&lt;/p&gt;
&lt;p&gt;We design and build our farms, grow vegetables and sell them, and the
backbone of our infrastructure is based on Python.&lt;/p&gt;
&lt;p&gt;You can check this video to ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Infarm is a FaaS, Farming as a Service, and whether you believe it or
not, our business is in-house farming at scale.&lt;/p&gt;
&lt;p&gt;We design and build our farms, grow vegetables and sell them, and the
backbone of our infrastructure is based on Python.&lt;/p&gt;
&lt;p&gt;You can check this video to see what we do -&amp;gt;
&lt;a class="reference external" href="https://twitter.com/christianbarra/status/1096399602159439874"&gt;https://twitter.com/christianbarra/status/1096399602159439874&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More than 10 million observations are recorded from our farms, feeding
our farm management system that allows operators, plant scientists, and
supervisors to monitor each farm in real-time.&lt;/p&gt;
&lt;p&gt;During this talk I will briefly introduce the world's problems we are
trying to resolve at Infarm and then talk about our IoT farms,
infrastructure, how we use Python and how we plan to improve the
capabilities of our farms by adding edge machine learning.&lt;/p&gt;
&lt;p&gt;Agenda&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;- What are the problems we are trying to solve at Infarm&lt;/div&gt;
&lt;div class="line"&gt;- Our 4 tech pillars&lt;/div&gt;
&lt;div class="line"&gt;- How we started with Python&lt;/div&gt;
&lt;div class="line"&gt;- Issues we are facing while scaling our Python infrastructure to
support &amp;gt; 400 farms&lt;/div&gt;
&lt;div class="line"&gt;- How we plan to evolve our software and infrastructure on 4 different
levels: consolidate, architecture, cloud native and observability&lt;/div&gt;
&lt;div class="line"&gt;- How Python is going to support our automated farms and its role in
making the farms smarter (edge computing with AI)&lt;/div&gt;
&lt;/div&gt;
</content><category term="EuroPython 2019"></category><category term="Big Data"></category><category term="Hardware/IoT"></category><category term="Internet of Things (IoT)"></category><category term="Machine-Learning"></category><category term="Python general"></category></entry><entry><title>Machine learning on non curated data</title><link href="https://pyvideo.org/europython-2019/machine-learning-on-non-curated-data.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Gael Varoquaux</name></author><id>tag:pyvideo.org,2019-07-11:/europython-2019/machine-learning-on-non-curated-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;According to industry surveys [1], the number one hassle of data
scientists is cleaning the data to analyze it. Textbook statistical
modeling is sufficient for noisy signals, but errors of a discrete
nature break standard tools of machine learning. I will discuss how to
easily run machine learning on ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;According to industry surveys [1], the number one hassle of data
scientists is cleaning the data to analyze it. Textbook statistical
modeling is sufficient for noisy signals, but errors of a discrete
nature break standard tools of machine learning. I will discuss how to
easily run machine learning on data tables with two common dirty-data
problems: missing values and non-normalized entries. On both problems, I
will show how to run standard machine-learning tools such as
scikit-learn in the presence of such errors. The talk will be didactic
and will discuss simple software solutions. It will build on the latest
improvements to scikit-learn for missing values and the DirtyCat package
[2] for non normalized entries. I will also summarize theoretical
analyses in recent machine learning publications.&lt;/p&gt;
&lt;p&gt;This talk targets data practitioners. Its goal are to help data
scientists to be more efficient analysing data with such errors and
understanding their impacts.&lt;/p&gt;
&lt;p&gt;With missing values, I will use simple arguments and examples to outline
how to obtain asymptotically good predictions [3]. Two components are
key: imputation and adding an indicator of missingness. I will explain
theoretical guidelines for these, and I will show how to implement these
ideas in practice, with scikit-learn as a learner, or as a preprocesser.&lt;/p&gt;
&lt;p&gt;For non-normalized categories, I will show that using their string
representations to ‚Äúvectorize‚Äù them, creating vectorial representations
gives a simple but powerful solution that can be plugged in standard
statistical analysis tools [4].&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;[1] Kaggle, the state of ML and data science 2017
&lt;a class="reference external" href="https://www.kaggle.com/surveys/2017"&gt;https://www.kaggle.com/surveys/2017&lt;/a&gt;&lt;/div&gt;
&lt;div class="line"&gt;[2] &lt;a class="reference external" href="https://dirty-cat.github.io/stable/"&gt;https://dirty-cat.github.io/stable/&lt;/a&gt;&lt;/div&gt;
&lt;div class="line"&gt;[3] Josse Julie, Prost Nicolas, Scornet Erwan, and Varoquaux Ga√´l
(2019). ‚ÄúOn the consistency of supervised learning with missing
values‚Äù. &lt;a class="reference external" href="https://arxiv.org/abs/1902.06931"&gt;https://arxiv.org/abs/1902.06931&lt;/a&gt;&lt;/div&gt;
&lt;div class="line"&gt;[4] Cerda Patricio, Varoquaux Ga√´l, and K√©gl Bal√°zs. &amp;quot;Similarity
encoding for learning with dirty categorical variables.&amp;quot; Machine
Learning 107.8-10 (2018): 1477 &lt;a class="reference external" href="https://arxiv.org/abs/1806.00979"&gt;https://arxiv.org/abs/1806.00979&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;
</content><category term="EuroPython 2019"></category><category term="Big Data"></category><category term="Data"></category><category term="Data Science"></category><category term="Machine-Learning"></category><category term="Scientific Libraries (Numpy/Pandas/SciKit/...)"></category></entry><entry><title>Natural language processing with neural networks.</title><link href="https://pyvideo.org/europython-2019/natural-language-processing-with-neural-networks.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Hubert Bry≈Çkowski</name></author><id>tag:pyvideo.org,2019-07-11:/europython-2019/natural-language-processing-with-neural-networks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Getting started with a natural language processing and neural networks
is easier nowadays thanks to the numerous talks and tutorials. The
goal is to dive deeper for those who already know the basics, or want
to expand their knowledge in a machine learning field.&lt;/div&gt;
&lt;div class="line"&gt;The talk will start with ‚Ä¶&lt;/div&gt;&lt;/div&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Getting started with a natural language processing and neural networks
is easier nowadays thanks to the numerous talks and tutorials. The
goal is to dive deeper for those who already know the basics, or want
to expand their knowledge in a machine learning field.&lt;/div&gt;
&lt;div class="line"&gt;The talk will start with the common use cases that can be generalized
to the specific problems in a NLP world. Then I will present an
overview of possible features that we can use as input to our network,
and show that even simple feature engineering can change our results.&lt;/div&gt;
&lt;div class="line"&gt;Furthermore, I will compare different network architectures - starting
with the fully connected networks, through convolution neural networks
to recursive neural networks. I will not only considering the good
parts, but also - what is usually overlooked - pitfalls of every
solution.&lt;/div&gt;
&lt;div class="line"&gt;All of these will be done considering number of parameters, which
transfers into training and prediction costs and time. I will also
share a number of ‚Äútricks‚Äù that enables getting the best results even
out of the simple architectures, as these are usually the fastest and
quite often hard to beat, at the same time being the easiest to
interpret.&lt;/div&gt;
&lt;/div&gt;
</content><category term="EuroPython 2019"></category><category term="Data Science"></category><category term="Deep Learning"></category><category term="Machine-Learning"></category><category term="Natural Language Processing"></category></entry><entry><title>The state of Machine Learning Operations in 2019</title><link href="https://pyvideo.org/europython-2019/the-state-of-machine-learning-operations-in-2019.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Alejandro Saucedo</name></author><id>tag:pyvideo.org,2019-07-11:/europython-2019/the-state-of-machine-learning-operations-in-2019.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will provide an overview of the key challenges and trends in
the productization of machine learning systems, including concepts such
as reproducibility, explainability and orchestration. The talk will also
provide a high level overview of several key open source tools and
frameworks available to tackle these issues ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will provide an overview of the key challenges and trends in
the productization of machine learning systems, including concepts such
as reproducibility, explainability and orchestration. The talk will also
provide a high level overview of several key open source tools and
frameworks available to tackle these issues, which have been identifyed
putting together the Awesome Machine Learning Operations list
(&lt;a class="reference external" href="https://github.com/EthicalML/awesome-machine-learning-operations"&gt;https://github.com/EthicalML/awesome-machine-learning-operations&lt;/a&gt;).&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;The key concepts that will be covered are:&lt;/div&gt;
&lt;div class="line"&gt;* Reproducibility&lt;/div&gt;
&lt;div class="line"&gt;* Explainability&lt;/div&gt;
&lt;div class="line"&gt;* Orchestration of models&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The reproducibility piece will cover key motivations as well as
practical requirements for model versioning, together with tools that
allow data scientists to achieve version control of model+config+data to
ensure full model lineage.&lt;/p&gt;
&lt;p&gt;The explainability piece will contain a high level overview of why this
has become an important topic in machine learning, including the high
profile incidents that tech companies have experienced where undesired
biases have slipped into data. This will also include a high level
overview of some of the tools available.&lt;/p&gt;
&lt;p&gt;Finally, the orchestration piece will cover some of the fundamental
challenges with large scale serving of models, together with some of the
key tools that are available to ensure this challenge can be tackled.&lt;/p&gt;
</content><category term="EuroPython 2019"></category><category term="Architecture"></category><category term="Data"></category><category term="Data Science"></category><category term="Deep Learning"></category><category term="Machine-Learning"></category></entry><entry><title>Building a Powerful Pet Detector in Notebooks</title><link href="https://pyvideo.org/europython-2019/building-a-powerful-pet-detector-in-notebooks.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Katherine Kampf</name></author><id>tag:pyvideo.org,2019-07-10:/europython-2019/building-a-powerful-pet-detector-in-notebooks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Ever wondered what breed that dog or cat is? Let‚Äôs build a pet detector
service to recognize them in pictures! In this talk, we will walk
through the training, optimizing, and deploying of a deep learning model
using Azure Notebooks. We will use transfer learning to retrain a ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Ever wondered what breed that dog or cat is? Let‚Äôs build a pet detector
service to recognize them in pictures! In this talk, we will walk
through the training, optimizing, and deploying of a deep learning model
using Azure Notebooks. We will use transfer learning to retrain a
MobileNet model using TensorFlow to recognize dog and cat breeds using
the Oxford IIIT Pet Dataset. Next, we‚Äôll optimize the model and tune our
hyperparameters to improve the model accuracy. Finally, we will deploy
the model as a web service in. Come to learn how you can quickly create
accurate image recognition models with a few simple techniques!&lt;/p&gt;
</content><category term="EuroPython 2019"></category><category term="Data"></category><category term="Data Science"></category><category term="Deep Learning"></category><category term="Jupyter"></category><category term="Machine-Learning"></category></entry><entry><title>Dissecting tf.function to discover AutoGraph strengths and subtleties</title><link href="https://pyvideo.org/europython-2019/dissecting-tffunction-to-discover-autograph-strengths-and-subtleties.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Paolo Galeone</name></author><id>tag:pyvideo.org,2019-07-10:/europython-2019/dissecting-tffunction-to-discover-autograph-strengths-and-subtleties.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;AutoGraph is one of the most exciting new features of Tensorflow 2.0: it
allows transforming a subset of Python syntax into its portable, high-
performance and language agnostic graph representation bridging the gap
between Tensorflow 1.x and the 2.0 release based on eager execution.&lt;/p&gt;
&lt;p&gt;Using AutoGraph ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;AutoGraph is one of the most exciting new features of Tensorflow 2.0: it
allows transforming a subset of Python syntax into its portable, high-
performance and language agnostic graph representation bridging the gap
between Tensorflow 1.x and the 2.0 release based on eager execution.&lt;/p&gt;
&lt;p&gt;Using AutoGraph with the &lt;tt class="docutils literal"&gt;&amp;#64;tf.fuction&lt;/tt&gt; decorator seems easy, but in
practice, writing efficient and correctly graph-convertible code
requires to know in detail how AutoGraph and tf.function work.&lt;/p&gt;
&lt;p&gt;In particular, knowing how:&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;- A graph is created and when it is re-used;&lt;/div&gt;
&lt;div class="line"&gt;- To deal with functions that create a state;&lt;/div&gt;
&lt;div class="line"&gt;- To correctly use the Tensorflow &lt;tt class="docutils literal"&gt;tf.Tensor&lt;/tt&gt; object instead of
using the Python native types to speed-up the computation;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;defines the minimum skill-set required to write correct
graph-accelerable code.&lt;/p&gt;
&lt;p&gt;The talk will guide you trough AutoGraph and &lt;tt class="docutils literal"&gt;tf.function&lt;/tt&gt;
highlighting all the peculiarities that are worth knowing to build the
right skill-set.&lt;/p&gt;
</content><category term="EuroPython 2019"></category><category term="Data-Structures"></category><category term="Machine-Learning"></category><category term="New Features"></category><category term="Software Design"></category></entry><entry><title>How to train an image classifier using PyTorch</title><link href="https://pyvideo.org/europython-2019/how-to-train-an-image-classifier-using-pytorch.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Rogier van der Geer</name></author><id>tag:pyvideo.org,2019-07-10:/europython-2019/how-to-train-an-image-classifier-using-pytorch.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Neural networks are everywhere nowadays. But while it seems everyone is
using them, training your first neural network can be quite a hurdle to
overcome.&lt;/p&gt;
&lt;p&gt;In this talk I will take you by the hand, and following an example image
classifier I trained, I will take you through the ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Neural networks are everywhere nowadays. But while it seems everyone is
using them, training your first neural network can be quite a hurdle to
overcome.&lt;/p&gt;
&lt;p&gt;In this talk I will take you by the hand, and following an example image
classifier I trained, I will take you through the steps of making an
image classifier in PyTorch. I will show you code snippets and explain
the more intricate parts. Also, I will tell you about my experience, and
about what mistakes to prevent. After this all you need to start
training your first classifier is a data set!&lt;/p&gt;
&lt;p&gt;Of course I will provide a link to the full codebase at the end. The
talk will focus on the practical aspect of training a neural network,
and will only touch the theoretical side very briefly. Some basic prior
knowledge of neural networks is beneficial, but not required, to follow
this talk.&lt;/p&gt;
</content><category term="EuroPython 2019"></category><category term="Deep Learning"></category><category term="Fun and Humor"></category><category term="Image Processing"></category><category term="Machine-Learning"></category><category term="Scientific Libraries (Numpy/Pandas/SciKit/...)"></category></entry><entry><title>30 Golden Rules of Deep Learning Performance</title><link href="https://pyvideo.org/europython-2020/30-golden-rules-of-deep-learning-performance.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Siddha Ganju</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/30-golden-rules-of-deep-learning-performance.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;‚ÄúWatching paint dry is faster than training my deep learning model.‚Äù
‚ÄúIf only I had ten more GPUs, I could train my model in time.‚Äù
‚ÄúI want to run my model on a cheap smartphone, but it‚Äôs probably too heavy and slow.‚Äù&lt;/p&gt;
&lt;p&gt;If this sounds like you, then ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;‚ÄúWatching paint dry is faster than training my deep learning model.‚Äù
‚ÄúIf only I had ten more GPUs, I could train my model in time.‚Äù
‚ÄúI want to run my model on a cheap smartphone, but it‚Äôs probably too heavy and slow.‚Äù&lt;/p&gt;
&lt;p&gt;If this sounds like you, then you might like this talk.&lt;/p&gt;
&lt;p&gt;Exploring the landscape of training and inference, we cover a myriad of tricks that step-by-step improve the efficiency of most deep learning pipelines, reduce wasted hardware cycles, and make them cost-effective. We identify and fix inefficiencies across different parts of the pipeline, including data preparation, reading and augmentation, training, and inference.&lt;/p&gt;
&lt;p&gt;With a data-driven approach and easy-to-replicate TensorFlow examples, finely tune the knobs of your deep learning pipeline to get the best out of your hardware. And with the money you save, demand a raise!&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Deep Learning"></category><category term="Machine-Learning"></category></entry><entry><title>Building quantum applications with D-Wave's Leap</title><link href="https://pyvideo.org/europython-2020/building-quantum-applications-with-d-waves-leap.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Alexander Condello</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/building-quantum-applications-with-d-waves-leap.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Get started coding on a quantum computer using D-Wave's Python-based Leap cloud service.&lt;/p&gt;
&lt;p&gt;In the past, quantum computing was largely reserved for researchers, physicists, and scientists with direct access to physical quantum computing systems. But the game has changed, thanks to the cloud. Barriers to quantum computing are coming ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Get started coding on a quantum computer using D-Wave's Python-based Leap cloud service.&lt;/p&gt;
&lt;p&gt;In the past, quantum computing was largely reserved for researchers, physicists, and scientists with direct access to physical quantum computing systems. But the game has changed, thanks to the cloud. Barriers to quantum computing are coming down quickly.&lt;/p&gt;
&lt;p&gt;Today, cloud access (like D-Wave‚Äôs Leap 2 quantum application environment) and improvements in quantum computing hardware, software, and developer tools are allowing programmers around the world to code on live quantum computers in real-time. Developers, students, and researchers around the world can now tap into the power of a quantum via their browser ‚Äî quantum mechanical knowledge not required. Users and private companies have already built over 200 early applications on D-Wave‚Äôs computers in industries ranging from automotive to machine learning, aerospace, finance, and beyond. The quantum application era is here, and the growing quantum developer community is making it a reality.&lt;/p&gt;
&lt;p&gt;In this session, Alex Condello, Manager of Applications Development Technology and Tools at D-Wave Systems, will talk about the burgeoning quantum application development ecosystem, and how developers can start learning to code on a quantum computer today. This includes a walkthrough of Leap 2, D-Wave's new quantum cloud service equipped with hybrid solvers, and D-Wave's Ocean SDK. Alex will also explore some of the early applications that developers and companies have built to-date.&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Community"></category><category term="Jupyter"></category><category term="Machine-Learning"></category><category term="Other Hardware"></category><category term="Python general"></category></entry><entry><title>Building smarter solutions with no expertise in machine learning</title><link href="https://pyvideo.org/europython-2020/building-smarter-solutions-with-no-expertise-in-machine-learning.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Laurent PICARD</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/building-smarter-solutions-with-no-expertise-in-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;ML? API? AutoML? Python is the language of choice to solve problems with machine learning, but what can we build in only a few hours or days and without any expertise? In this session, we'll see how to benefit from existing ML models and how to create a custom ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;ML? API? AutoML? Python is the language of choice to solve problems with machine learning, but what can we build in only a few hours or days and without any expertise? In this session, we'll see how to benefit from existing ML models and how to create a custom model with AutoML techniques. We‚Äôll also be active players of a live demo, so don't put your smartphone on airplane mode!&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Computer Vision"></category><category term="Human-Machine-Interaction"></category><category term="Machine-Learning"></category><category term="Natural Language Processing"></category><category term="Public Cloud (AWS/Google/...)"></category></entry><entry><title>Building The Perfect Personalised Menu Using Python</title><link href="https://pyvideo.org/europython-2020/building-the-perfect-personalised-menu-using-python.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Irene Iriarte</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/building-the-perfect-personalised-menu-using-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;How Gousto is building an algorithm to offer personalised menus to their customers using python&lt;/p&gt;
&lt;p&gt;This talk will describe how Gousto, a leading recipe box service based in the UK, is using python to build a personalisation ecosystem. Our menu planning optimisation algorithm allows us to create the perfect ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;How Gousto is building an algorithm to offer personalised menus to their customers using python&lt;/p&gt;
&lt;p&gt;This talk will describe how Gousto, a leading recipe box service based in the UK, is using python to build a personalisation ecosystem. Our menu planning optimisation algorithm allows us to create the perfect mix of recipes, ensuring a variety of dish types, cuisines and ingredients. Our recommendation engine sitting on top of this can then offer each customer a personally curated menu, making sure that users have meaningful choice. All this while ensuring that we are also optimising for maximum performance from the operations point of view!&lt;/p&gt;
&lt;p&gt;To build this, we have used a range of Python packages, such as DEAP for implementing genetic algorithms, and integrations, such as the one for graph database neo4j.&lt;/p&gt;
&lt;p&gt;The talk will give an overview of our methods, our infrastructure, our results and everything that we have learnt along the way!&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Algorithms"></category><category term="Case Study"></category><category term="Data Science"></category><category term="E-Commerce"></category><category term="Machine-Learning"></category></entry><entry><title>Deceptive Security using Python</title><link href="https://pyvideo.org/europython-2020/deceptive-security-using-python.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Gajendra Deshpande</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/deceptive-security-using-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deceiving hackers to protect your resources&lt;/p&gt;
&lt;p&gt;Imagine you are passing through an unknown street at midnight and you find that some anti-social elements are following you. To save yourself from them you start running and look for a safe place to hide. On the way, you will find a ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deceiving hackers to protect your resources&lt;/p&gt;
&lt;p&gt;Imagine you are passing through an unknown street at midnight and you find that some anti-social elements are following you. To save yourself from them you start running and look for a safe place to hide. On the way, you will find a good person and requests him to help you. He hides you in his place to protect you. When these anti-social elements visit a good person‚Äôs place and enquire about you, the good person misguides them and redirects them to some other place in order to protect you. This is exactly how deception works. In this analogy, YOU are the resources to be protected, anti-social elements are the hackers who want to gain access to the resources, and a good person is a deception technique that protects the resources from hackers by making them fall in the trap.&lt;/p&gt;
&lt;p&gt;The talk begins with an introduction to deception technology, deception types, and methods, a deceptive security life cycle. In this talk, we will demonstrate the following deception tools implemented using python language:
‚Ä¢       WebTrap (&lt;a class="reference external" href="https://github.com/IllusiveNetworks-Labs/WebTrap"&gt;https://github.com/IllusiveNetworks-Labs/WebTrap&lt;/a&gt;): is designed to create deceptive webpages to deceive and redirect attackers away from real websites. The deceptive webpages are generated by cloning real websites, specifically their login pages.
‚Ä¢       DemonHunter (&lt;a class="reference external" href="https://github.com/RevengeComing/DemonHunter"&gt;https://github.com/RevengeComing/DemonHunter&lt;/a&gt;):  is a distributed low interaction honeypot with Agent/Master design
Finally, we will conclude the talk with how built a deception tool and demonstrate its working.&lt;/p&gt;
&lt;p&gt;How we implemented a deception tool in python using machine learning:
We designed a deception tool in python language using PyBRAIN package to model and mitigate XPath injection attacks for web services. It is known that XML can be used to store the data and this data can be queried using XPath query language. XPath is a query language, it has injection issues similar to SQL. To handle this issue, we proposed a solution, which uses a count-based validation technique and Long Short-Term Memory (LSTM) modular neural networks to identify and classify atypical behavior in user input. Once the atypical user input is identified, the attacker is redirected to fake resources to protect the critical data. Our experiment resulted in over 90% accuracy in the classification of input vectors.&lt;/p&gt;
&lt;p&gt;Outline
1. Introduction to deception, Deception types, Deception technology applicable methods and Deception Life cycle(08 Minutes)
2. Demonstration of WebTrap deception tool(04 Minutes)
3. Demonstration of DemonHunter deception tool(04 Minutes)
4. Discussion of our deception tool and demonstration(06 Minutes)
5. Conclusion and Questions(03 Minutes)&lt;/p&gt;
&lt;p&gt;Audience
No experience level of Python is needed. In general, anyone can attend this talk and learn about applying deception techniques and machine learning to application security.&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Beginners"></category><category term="Machine-Learning"></category><category term="Security"></category><category term="python"></category></entry><entry><title>Deploy your Machine Learning Bots like a boss with CI/CD</title><link href="https://pyvideo.org/europython-2020/deploy-your-machine-learning-bots-like-a-boss-with-cicd.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>William Arias</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/deploy-your-machine-learning-bots-like-a-boss-with-cicd.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Using Gitlab Open Source tools to automate NLP models deployment&lt;/p&gt;
&lt;p&gt;Context: Today is relatively easy to create and train a conversational agent using Machine Learning Techniques, fire it up and showcase it in your computer&lt;/p&gt;
&lt;p&gt;Problem: Sharing your chatbot with the outside world is not as easy as training ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Using Gitlab Open Source tools to automate NLP models deployment&lt;/p&gt;
&lt;p&gt;Context: Today is relatively easy to create and train a conversational agent using Machine Learning Techniques, fire it up and showcase it in your computer&lt;/p&gt;
&lt;p&gt;Problem: Sharing your chatbot with the outside world is not as easy as training your models. Load Balancer, Unit Test, Integration Tests, Differential Tests ... Text Analytics and retrain the models to better serve your audience goes way beyond the simple agent that runs in the developer environment&lt;/p&gt;
&lt;p&gt;Solution: I want to show how from my experience of deploying bots to production, leveraging DevOps + DataScience skills along with an entry level knowledge of Databases, CI/CD and distributed systems you can take your prototypes to a next level, deploy, iterate  and re-train your models faster.&lt;/p&gt;
&lt;p&gt;Pre-reqs: Entry level understanding of CI/CD Pipelines, NLP, jupyterhub, Version Control, Rasa&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Deep Learning"></category><category term="Deployment/Continuous Integration and Delivery"></category><category term="Ipython"></category><category term="Machine-Learning"></category><category term="Open-Source"></category></entry><entry><title>Detecting and Analyzing Solar Panels in Switzerland using Aerial Imagery</title><link href="https://pyvideo.org/europython-2020/detecting-and-analyzing-solar-panels-in-switzerland-using-aerial-imagery.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Adrian Meyer</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/detecting-and-analyzing-solar-panels-in-switzerland-using-aerial-imagery.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A novel method for detecting solar panels and its geometry on aerial imagery is presented. Deep Learning with PyTorch is being used for segmentation. The goal is to know the exact locations, dimensions and potential of every solar installation in Switzerland. It is shown how we labelled the data ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A novel method for detecting solar panels and its geometry on aerial imagery is presented. Deep Learning with PyTorch is being used for segmentation. The goal is to know the exact locations, dimensions and potential of every solar installation in Switzerland. It is shown how we labelled the data and how we found a solution to distinguish different solar panel types.&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Deep Learning"></category><category term="Machine-Learning"></category></entry><entry><title>Developing a match-making algorithm between customers and Go-Jek products!</title><link href="https://pyvideo.org/europython-2020/developing-a-match-making-algorithm-between-customers-and-go-jek-products.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Gunjan Dewan</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/developing-a-match-making-algorithm-between-customers-and-go-jek-products.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;GoJek has millions of monthly active users in Indonesia across our 20+ products and services. A major problem we faced was targeting these customers with promos and vouchers that were relevant to them. We developed a generalized model that takes into account the transaction history of users and gives ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;GoJek has millions of monthly active users in Indonesia across our 20+ products and services. A major problem we faced was targeting these customers with promos and vouchers that were relevant to them. We developed a generalized model that takes into account the transaction history of users and gives a ranked list of our services that they are most likely to use next. From here on, we are able to determine the vouchers that we can target these customers with.
In this poster, I will be presenting our process while developing the model, the challenges we faced during the time, how we used PySpark to tackle these challenges and the impact it had on our conversion rates.&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Data"></category><category term="Data Science"></category><category term="Machine-Learning"></category></entry><entry><title>Diffprivlib: Privacy-preserving machine learning with Scikit-learn</title><link href="https://pyvideo.org/europython-2020/diffprivlib-privacy-preserving-machine-learning-with-scikit-learn.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Naoise Holohan</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/diffprivlib-privacy-preserving-machine-learning-with-scikit-learn.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Train machine learning models with differential privacy guarantees&lt;/p&gt;
&lt;p&gt;Data privacy is having an ever-increasing impact on the way data is stored, processed, accessed and utilised, as the legal and ethical effects of data protection regulations take effect around the globe. Differential privacy, considered by many to be the strongest ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Train machine learning models with differential privacy guarantees&lt;/p&gt;
&lt;p&gt;Data privacy is having an ever-increasing impact on the way data is stored, processed, accessed and utilised, as the legal and ethical effects of data protection regulations take effect around the globe. Differential privacy, considered by many to be the strongest privacy guarantee currently available, gives robust, provable guarantees on protecting privacy, and allows tasks to be completed on data with guarantees on the privacy of individuals in that data. This naturally extends to machine learning, where training datasets can contain sensitive personal information, that are vulnerable to privacy attacks on trained models.
By using differential privacy in the training process, a machine learning model can be trained to accurately represent the dataset at large, but without inadvertently revealing sensitive information about an individual. Diffprivlib is the first library of its kind to leverage the power of differential privacy with scikit-learn and numpy to give data scientists and researchers access to the tools to train accurate, portable models with robust, provable privacy guarantees built-in.
In this talk, we will introduce attendees to the idea of differential privacy, why it is necessary in today's world, and how diffprivlib can be seamlessly integrated within existing scripts to protect your trained models from privacy vulnerabilities. Attendees will be expected to have a basic understanding of sklearn (i.e., how to initialise, fit and predict a model). No knowledge of data privacy or differential privacy will be assumed or required.&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Data Privacy"></category><category term="Data Protection"></category><category term="Machine-Learning"></category><category term="Open-Source"></category><category term="Scientific Libraries (Numpy/Pandas/SciKit/...)"></category></entry><entry><title>Docker and Python: making them play nicely and securely for Data Science and ML</title><link href="https://pyvideo.org/europython-2020/docker-and-python-making-them-play-nicely-and-securely-for-data-science-and-ml.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Tania Allard</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/docker-and-python-making-them-play-nicely-and-securely-for-data-science-and-ml.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Docker has become a standard tool for developers around the world to deploy applications in a reproducible and robust manner. The existence of Docker and Docker compose have reduced the time needed to set up new software and implementing complex technology stacks for our applications. Now, six years after ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Docker has become a standard tool for developers around the world to deploy applications in a reproducible and robust manner. The existence of Docker and Docker compose have reduced the time needed to set up new software and implementing complex technology stacks for our applications. Now, six years after the initial release of Docker, we can say with confidence that containers and containers orchestration have become some of the defaults in the current technology stacks.&lt;/p&gt;
&lt;p&gt;There are thousands of tutorials and getting started documents for those wanting to adopt Docker for apps deployment. However, if you are a Data Scientist, a researcher or someone working on scientific computing wanting to adopt Docker, the story is quite different. There are very few tutorials (in comparison to app/web) and documents focused on Docker best practices for DS and scientific computing. If you are working on DS, ML or scientific computing, this talk is for you. We'll cover best practices when building Docker containers for data-intensive applications, from optimising your image build, to ensuring your containers are secure and efficient deployment workflows. We will talk about the most common problems faced while using Docker with data intensive applications and how you can overcome most of them. Finally I'll give some practical and useful tips for you to improve your Docker workflows and practises.&lt;/p&gt;
&lt;p&gt;Attendees will leave the talk feeling confident about adopting Docker across a range of DS, ML and research projects.&lt;/p&gt;
&lt;p&gt;Who and Why (audience)
This talk is designed for folks working in data-intensive environments (i.e. Machine Learning, Data Science, research and scientific computing) and that are either using Docker or want to learn more about how to use Docker in these environments. Attendees will leave the talk feeling confident about adopting Docker in their workflows as well as have acquired several best practices and guidelines to do this robustly.
Introduction (5 minutes)
About me
When is Docker the right choice?
Docker for all Python users: introduction to Docker in Machine Learning (ML), Data Science (DS) and research contexts
The usual culprits
Optimising for data-oriented application (10 minutes)
Creating a data-oriented Docker image - how is this different from an app/web image?
Choosing the right base image - set yourself for success
Dependencies, volumes and code best practices
Security and performance (10 minutes)
Finding vulnerabilities in your images
Image consistency and reproducibility
Optimising image building - cache and image size considerations
Do not reinvent the wheel - automate! (10 minutes)
Consider tools to assist with Dockerfile generation - e.g. repo2docker, dokta
Creating templates for projects
Automating image build and publishing - e.g. GitHub actions
Automated deployment strategies - going from local to deploying your containerised application
Conclusions (5 minutes)
Top 10 best practices when working with Docker and Python for DS/ML and research
Additional resources
Thanks and getting in touch&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Conda / conda forge"></category><category term="Data Science"></category><category term="Deep Learning"></category><category term="Machine-Learning"></category><category term="Scientific Libraries (Numpy/Pandas/SciKit/...)"></category></entry><entry><title>Machine Learning for Everyone</title><link href="https://pyvideo.org/europython-2020/machine-learning-for-everyone.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Aaron Ma</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/machine-learning-for-everyone.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Machine learning (ML) is becoming an essential technology for our day to day life. Stop taking ML as a threat and learn it today as not learning it is a HUGE LOSS! Get started today with ML in Aaron's remarkable 45-mins talk. We will begin by talking about the ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Machine learning (ML) is becoming an essential technology for our day to day life. Stop taking ML as a threat and learn it today as not learning it is a HUGE LOSS! Get started today with ML in Aaron's remarkable 45-mins talk. We will begin by talking about the paradigm of ML, then taking a deep dive into Neural Networks and building a Neural Network from scratch with Keras and TensorFlow (the hottest machine learning framework). You'll master the magic of neural networks that are powering incredible advances both in AI, self-driving cars, and much more! Finally, we will finish off by talking about Reinforcement learning and how it is empowering YouTube suggestions along with tips-and-tricks from a specialist plus a grand finale mind-blowing demo. Ready to master the paradigm of ML? Let's get started.&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Beginners"></category><category term="Deep Learning"></category><category term="General"></category><category term="Machine-Learning"></category></entry><entry><title>Meditations on First Deployment: A Practical Guide to Responsible Development</title><link href="https://pyvideo.org/europython-2020/meditations-on-first-deployment-a-practical-guide-to-responsible-development.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Alejandro Saucedo</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/meditations-on-first-deployment-a-practical-guide-to-responsible-development.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Keynote&lt;/p&gt;
&lt;p&gt;As the impact of software increasingly reaches farther and wider, our professional responsibility as developers becomes more critical to society. The production systems we design, build and maintain often bring inherent adversities with complex technical, societal and even ethical challenges. The skillsets required to tackle these challenges require ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Keynote&lt;/p&gt;
&lt;p&gt;As the impact of software increasingly reaches farther and wider, our professional responsibility as developers becomes more critical to society. The production systems we design, build and maintain often bring inherent adversities with complex technical, societal and even ethical challenges. The skillsets required to tackle these challenges require us to go beyond the algorithms, and require cross-functional collaboration that often goes beyond a single developer. In this talk we introduce intuitive and practical insights from a few of the core ethics themes in software including Privacy, Equity, Trust and Transparency. We cover their importance, the growing societal challenges, and how organisations such as The Institute for Ethical AI, The Linux Foundation, the Association for Computer Machinery, NumFocus, the IEEE and the Python Software Foundation are contributing to these critical themes through standards, policy advise and open source software initiatives. We finally will wrap up the talk with practical steps that any individual can take to get involved and contribute to some of these great open initiatives, and contribute to these critical ongoing discussions.&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Ethics"></category><category term="Machine-Learning"></category></entry><entry><title>NLPeasy - a Workflow to Analyse, Enrich, and Explore Textual Data</title><link href="https://pyvideo.org/europython-2020/nlpeasy-a-workflow-to-analyse-enrich-and-explore-textual-data.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Philipp Thomann</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/nlpeasy-a-workflow-to-analyse-enrich-and-explore-textual-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Use pre-trained NLP-models, ingest into Elastic Search, and enjoy auto-generated Kibana dashboards!&lt;/p&gt;
&lt;p&gt;Ever wanted to try out NLP methods but it felt it too cumbersome to set up a workflow for textual data? How to enrich your data based on textual features and explore the results?&lt;/p&gt;
&lt;p&gt;NLPeasy (&lt;a class="reference external" href="https://github.com/d-one/NLPeasy"&gt;https://github ‚Ä¶&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Use pre-trained NLP-models, ingest into Elastic Search, and enjoy auto-generated Kibana dashboards!&lt;/p&gt;
&lt;p&gt;Ever wanted to try out NLP methods but it felt it too cumbersome to set up a workflow for textual data? How to enrich your data based on textual features and explore the results?&lt;/p&gt;
&lt;p&gt;NLPeasy (&lt;a class="reference external" href="https://github.com/d-one/NLPeasy"&gt;https://github.com/d-one/NLPeasy&lt;/a&gt;) does that: Enrich the data using well-known pre-trained models (Word embeddings, Sentiment Analysics, POS, Dependency Parsing). Then start the Elastic Stack on your Docker. Set-up indices and ingest it in bulk. And finally generate Kibana dashboards to explore the results.&lt;/p&gt;
&lt;p&gt;Complicated? Not at all! Just do it in a simple Jupyter Notebook.&lt;/p&gt;
&lt;p&gt;In this presentation we will give an architecture overview of the different components and demonstrate the capabilities of this Python package.&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Data Science"></category><category term="Elastic Search"></category><category term="Machine-Learning"></category><category term="Natural Language Processing"></category></entry><entry><title>Painless Machine Learning in Production</title><link href="https://pyvideo.org/europython-2020/painless-machine-learning-in-production.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Chase Stevens</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/painless-machine-learning-in-production.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Developing machine learning models is easy; training, deploying, monitoring, scaling, and maintaining them in an automated fashion - all while maintaining your sanity - is hard.&lt;/p&gt;
&lt;p&gt;In this session, I'll discuss the infrastructure and tooling my small team of data science practitioners and engineers is using to manage and orchestrate the ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Developing machine learning models is easy; training, deploying, monitoring, scaling, and maintaining them in an automated fashion - all while maintaining your sanity - is hard.&lt;/p&gt;
&lt;p&gt;In this session, I'll discuss the infrastructure and tooling my small team of data science practitioners and engineers is using to manage and orchestrate the machine learning model lifecycle, including pitfalls we've encountered along the way. Particular attention will be paid to where we've opted to use off-the-shelf solutions versus developing our own, the importance of developer ergonomics, and how to maximally empower data scientists to get their work into production without the need for a dedicated MLOps team.&lt;/p&gt;
&lt;p&gt;The talk will cover our ML stack as it exists in production today, and will touch on our application of a number of technologies and techniques, including:
- AWS SageMaker
- Airflow
- Docker
- Cookiecutter
- Property-based testing
- Jsonschema
- Linting
- Slack integration
- Model artifacts and diagnostics
- Automated deployments and rollbacks
- Healthchecks
- Autoscaling
- DBT&lt;/p&gt;
&lt;p&gt;At the end of the session, attendees should expect to leave with new insights that they can apply immediately to their own ML systems and infrastructure, as well as a better understanding of how to minimize engineering and ops overhead, in the real world, across data science teams of any size and composition.&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Case Study"></category><category term="Data Science"></category><category term="DevOps general"></category><category term="Infrastructure"></category><category term="Machine-Learning"></category></entry><entry><title>Painting with GANs: Challenges and Technicalities of Neural Style Transfer</title><link href="https://pyvideo.org/europython-2020/painting-with-gans-challenges-and-technicalities-of-neural-style-transfer.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Anmol Krishan Sachdeva</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/painting-with-gans-challenges-and-technicalities-of-neural-style-transfer.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Building Artistic Artefacts using Generative Networks&lt;/p&gt;
&lt;p&gt;A lot of advancements are happening in the field of Deep Learning and Generative Adversarial Networks are one of them. We have seen GANs being applied for photo editing and in-painting, generating new image datasets and realistic photographs, increasing resolution of images (Super ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Building Artistic Artefacts using Generative Networks&lt;/p&gt;
&lt;p&gt;A lot of advancements are happening in the field of Deep Learning and Generative Adversarial Networks are one of them. We have seen GANs being applied for photo editing and in-painting, generating new image datasets and realistic photographs, increasing resolution of images (Super Resolution), and many more things. Some people have also exploited GANs for generating fake content. All the above-mentioned examples are result of a technique where the focus is to generate uncommon yet original samples from scratch. However, these examples have very less commercial applications and GANs are capable of doing much more. The focus of this talk is a technique called &amp;quot;Neural Style Transfer (NST)&amp;quot; which has numerous commercial applications in the gaming world, fashion/design industry, mobile applications, and many more fields. Challenges and technicalities of NSTs will be covered in great detail. We will teach the machines on how to paint images and utilize Style Transfer networks to generate artistic artefacts.&lt;/p&gt;
&lt;p&gt;The flow of the talk will be as follows:
~ Self Introduction [1 minute]
~ A Succinct Prelude to GANs [10 minutes]
~ Understanding Style Transfer [5 minutes]
~ Learning about Neural Style Transfer Networks [5 minutes]
~ Loss Functions: Content, Style, Total Variantion [10 minutes]
~ Code Walkthrough and Result Analysis [5 minutes]
~ Challenges and Applications [5 minutes]
~ Questions and Answers Session [3-4 minutes]&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Computer Vision"></category><category term="Deep Learning"></category><category term="Generative Adversarial Networks"></category><category term="Image Processing"></category><category term="Machine-Learning"></category></entry><entry><title>Probabilistic Forecasting with DeepAR and AWS SageMaker</title><link href="https://pyvideo.org/europython-2020/probabilistic-forecasting-with-deepar-and-aws-sagemaker.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Nicolas Kuhaupt</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/probabilistic-forecasting-with-deepar-and-aws-sagemaker.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In time series forecasting we are interested in how the time series is going to continue in the future. This is of high importance in areas like forecasting energy production from renewable resources, forecasting demand of customers or the price of products. Many forecasting algorithms provide only the prediction ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In time series forecasting we are interested in how the time series is going to continue in the future. This is of high importance in areas like forecasting energy production from renewable resources, forecasting demand of customers or the price of products. Many forecasting algorithms provide only the prediction. However, oftentimes we are also interested in the likelihood of the prediction and how much it may vary. This is what probabilistic forecasting is for. With every forecast, we also obtain an upper and lower bound with certain probabilities. For a long time, probabilistic forecasting was limited to traditional techniques like ARIMA. DeepAR is an algorithm that allows us to combine Deep Learning techniques with probabilistic forecasting. Additionally, in contrast to training a model for each time series individually, DeepAR suggests training one large forecasting model for all related time series. The algorithm was developed by Amazon and is also provided in AWS SageMaker.
In this talk, we will understand the theoretical basics of DeepAR, have a look at a practical time series example and will demonstrate an implementation. In the end, you will be prepared to get started with your own forecasts.&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Data Science"></category><category term="Deep Learning"></category><category term="Machine-Learning"></category><category term="Predictions"></category><category term="Public Cloud (AWS/Google/...)"></category></entry><entry><title>Radio Astronomy with Python</title><link href="https://pyvideo.org/europython-2020/radio-astronomy-with-python.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Priscila Gutierres</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/radio-astronomy-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Gaussian Processes and Neural Networks applied to photometric redshift reconstruction&lt;/p&gt;
&lt;p&gt;Looking at higher redshifts is equivalent to looking back in time: they improve the studies of cosmology, expanding our knowledge of the universe. It allows us to study various physical phenomena like the power spectrum of galaxies which describes ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Gaussian Processes and Neural Networks applied to photometric redshift reconstruction&lt;/p&gt;
&lt;p&gt;Looking at higher redshifts is equivalent to looking back in time: they improve the studies of cosmology, expanding our knowledge of the universe. It allows us to study various physical phenomena like the power spectrum of galaxies which describes the distribution of galaxies on a range of scales, galaxy clustering, and large scales, the detection of the Baryon Acoustic Oscillation feature.
As a result,  a significant amount of work has been done to increase the efficiency and accuracy of the process via new algorithms and optimization of existing ones.
Astronomical datasets are undergoing a rapid growth in size and complexity as past, ongoing and future surveys produce massive multi-temporal and multi-wavelength datasets, with huge information to be extracted and analyzed.
The alternative to a full spectroscopic survey is to obtain multi-color images of the sky and perform photometric redshift estimates for the galaxies we have available.
When dealing with this problem, there are two main approaches: model-driven data analysis (template fitting methods) and data-driven analysis, which can use machine learning methods.
To solve this problem, we use data-driven analysis, more specifically GPz (which uses Gaussian processes)  and  ANNz2 (which mainly uses neural networks), both python software.&lt;/p&gt;
&lt;p&gt;Prerequisites: machine learning and basic math knowledge&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Big Data"></category><category term="Data"></category><category term="Machine-Learning"></category><category term="Physics"></category></entry><entry><title>The Painless Route in Python to Fast and Scalable Machine Learning</title><link href="https://pyvideo.org/europython-2020/the-painless-route-in-python-to-fast-and-scalable-machine-learning.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>David Liu</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/the-painless-route-in-python-to-fast-and-scalable-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python is the lingua franca for data analytics and machine learning. Its superior productivity makes it the preferred tool for prototyping. However, traditional Python packages are not necessarily designed to provide high performance and scalability for large datasets.
We start our tutorial with a short introduction on how to ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python is the lingua franca for data analytics and machine learning. Its superior productivity makes it the preferred tool for prototyping. However, traditional Python packages are not necessarily designed to provide high performance and scalability for large datasets.
We start our tutorial with a short introduction on how to get close-to-native performance with Intel-optimized packages, such as numpy, scipy, and scikit-learn. The next part of the tutorial is focused on getting high performance and scalability from multi-cores on a single machine to large clusters of workstations. We will demonstrate that with Python it is possible to achieve the same performance and scalability as with hand-tuned C++/MPI code:
-       Scalable Dataframe Compiler (SDC) is used to compile analytics code using pandas/Python and scale it to bare-metal cluster performance. It compiles a subset of Python code into efficient parallel binaries that use message passing to perform collective communications.
-       A convenient Python API to data analytics and machine learning primitives (daal4py). While its interface is scikit-learn-like, its MPI-based engine allows to scale machine learning algorithms to bare-metal cluster performance.
-       In the tutorial, we will use SDC and daal4py together to build an end-to-end analytics pipeline that scales to clusters, requiring only minimal code changes.&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Analytics"></category><category term="Big Data"></category><category term="Distributed Systems"></category><category term="Machine-Learning"></category><category term="Scientific Libraries (Numpy/Pandas/SciKit/...)"></category></entry><entry><title>Train. Serve. Deploy! Story of a NLP Model ft. PyTorch, Docker, Uwsgi and Nginx</title><link href="https://pyvideo.org/europython-2020/train-serve-deploy-story-of-a-nlp-model-ft-pytorch-docker-uwsgi-and-nginx.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Shreya Khurana</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/train-serve-deploy-story-of-a-nlp-model-ft-pytorch-docker-uwsgi-and-nginx.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Quickly prototype a machine translation model from scratch and learn how to serve it in production&lt;/p&gt;
&lt;p&gt;Natural language processing has seen leaps of technology progress with Machine Learning becoming the norm of solving the major problems in this area, with Machine translation being one of the major problems in ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Quickly prototype a machine translation model from scratch and learn how to serve it in production&lt;/p&gt;
&lt;p&gt;Natural language processing has seen leaps of technology progress with Machine Learning becoming the norm of solving the major problems in this area, with Machine translation being one of the major problems in this area. Neural machine translation systems are now used to convert sentences or phrases from one language to another, or in general, for sequence to sequence modeling. In this talk, we‚Äôll be covering the steps from scratch to preprocess, train and serve a NMT model using PyTorch. While building a highly accurate model is a prerequisite to getting good quality translations, often in industry, we also need to make sure we can serve the model to customers without getting timeouts or delays. The practice of serving models requires creating a web app to get client requests and process them in a way the model would understand. For this, we‚Äôll use  the various components of the application server environment - Flask, Docker, uwsgi and nginx. This talk is suitable for audience who is working in general with ML models and want to learn how to serve them or working specifically with NMT and want to learn about some quick prototyping tips.&lt;/p&gt;
&lt;p&gt;Prerequisites: Audience should be comfortable with the basic ML terminology and procedure of training models. NLP knowledge will be good, but is not a necessity as the focus will be on quick prototyping in production.&lt;/p&gt;
&lt;p&gt;By the end of the talk, the audience will have:
- Learnt how to preprocess data for NLP systems
- Learnt how to quickly prototype and train a translation model
- Learnt how to create a web app for the NLP model using Flask
- Learnt how to containerize a pytorch model using Docker
- Learnt how to serve the model as an app using uwsgi, nginx and&lt;/p&gt;
&lt;p&gt;Outline:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Introduction to translation systems, machine translation framework&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ML Modelling
- Preprocessing data
- Training
- Generating new translations&lt;/p&gt;
&lt;p&gt;Serving and prototyping
- Flask app
- Docker container
- Nginx + uwsgi + supervisord configurations
- Putting it all together&lt;/p&gt;
&lt;p&gt;Good practices
Q/A (optional?)&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Data Science"></category><category term="Deep Learning"></category><category term="Machine-Learning"></category><category term="Natural Language Processing"></category><category term="Web Servers and MicroFWs (Flask/Tornado/Nginx/...)"></category></entry><entry><title>Aircraft predictive maintenance using Python/ML</title><link href="https://pyvideo.org/kiwi-pycon-2019/aircraft-predictive-maintenance-using-pythonml.html" rel="alternate"></link><published>2019-08-24T00:00:00+00:00</published><updated>2019-08-24T00:00:00+00:00</updated><author><name>Amar Verma</name></author><id>tag:pyvideo.org,2019-08-24:/kiwi-pycon-2019/aircraft-predictive-maintenance-using-pythonml.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Applied machine learning for predictive maintenance (PdM) with objectives to reduce aircraft downtime &amp;amp; in-workshop costs.&lt;/p&gt;
</content><category term="Kiwi PyCon 2019"></category><category term="machine learning"></category></entry><entry><title>An introduction to PyMC3</title><link href="https://pyvideo.org/pycon-de-2017/an-introduction-to-pymc3.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>Adrian Seyboldt</name></author><id>tag:pyvideo.org,2017-10-25:/pycon-de-2017/an-introduction-to-pymc3.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Adrian Seyboldt&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I studied Mathematics and Bioinformatics in Bonn and T√ºbingen and I am a core developer of pymc3 since Feb 2017. Currently, I work for Quantopian on the development of Bayesian Methods for portfolio allocation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;PyMC3 allows you to build statistical models for a wide range of ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Adrian Seyboldt&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I studied Mathematics and Bioinformatics in Bonn and T√ºbingen and I am a core developer of pymc3 since Feb 2017. Currently, I work for Quantopian on the development of Bayesian Methods for portfolio allocation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;PyMC3 allows you to build statistical models for a wide range of datasets, use those models to estimate underlying parameters, and compute the uncertainty about those parameters. In this talk I will try to give a gentle introduction to PyMC3, and help avoid common pitfalls for new users.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Some of the problems that are discussed in the context of the reproducibility crisis in science and statistics can be solved or alleviated by tools like PyMC3 or Stan. They allow users to build much more realistic models and get a full distribution of the possible values for parameters as output ‚Äì instead of p-values that are often hard to interpret correctly. Thanks to Hamiltonian and Variational methods, they are more flexible and can be applied to larger problems than predecessors like JAGS and BUGS. However, these new methods also come with challenges. Writing good models isn't easy, and when inference algorithms cry out in pain, they need someone who listens to them. This talk uses some real-world applications to give an introduction to PyMC3, without requiring a lot of background in math, statistics or programming.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</content><category term="PyCon DE 2017"></category><category term="python"></category><category term="data-science"></category><category term="machine learning"></category><category term="analysis"></category></entry><entry><title>Data Science Best Practices : From Proof of Concepts to Production</title><link href="https://pyvideo.org/pycon-de-2017/data-science-best-practices-from-proof-of-concepts-to-production.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>Yasir Khan</name></author><id>tag:pyvideo.org,2017-10-25:/pycon-de-2017/data-science-best-practices-from-proof-of-concepts-to-production.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Yasir Khan&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Yasir Khan is working as a Data Science Manager. He has nearly 12 years of experience in consulting and R&amp;amp;D domains. He obtained his PhD in Applied Machine Learning and has been invited as a speaker at several leading international forums and conferences. He has nearly ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Yasir Khan&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Yasir Khan is working as a Data Science Manager. He has nearly 12 years of experience in consulting and R&amp;amp;D domains. He obtained his PhD in Applied Machine Learning and has been invited as a speaker at several leading international forums and conferences. He has nearly 12 research articles and journals to his credit and book chapters published by Cambridge University Press.&lt;/p&gt;
&lt;p&gt;In his spare time he loves flying WWII aircrafts at a local aeroclub and is an avid scuba diver. He is also an investor in 2 technology startups.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This presentation will benefit the audience as it brings forward the practical issues in the industry today as we move towards industrializing data science algorithms. We will discuss the best practices around organization, methodology and tools to integrate a data science project into production.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As the industry understands the importance of Data Science for transforming businesses an interesting trend is arising. We have started seeing a widening gap &amp;amp; increasing difficulty to move teams from Proof of Concepts to Production. Apart from searching for the best data scientists, the industry is now looking for answers to organize &amp;amp; federate the data teams around practical business use cases. In this talk, Yasir Khan will provide an overview of the bottlenecks, and hurdles involved in a practical data project. While citing lessons learned from industry, this presentation will focus on important aspects such as business centric, data culture, data pipelines, organization, methodology &amp;amp; tools all of which are important but seldom ignored in large corporations.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</content><category term="PyCon DE 2017"></category><category term="use-case"></category><category term="analytics"></category><category term="python"></category><category term="machine learning"></category><category term="ai"></category><category term="business"></category></entry><entry><title>Data Science Project for Beginners</title><link href="https://pyvideo.org/pycon-de-2017/data-science-project-for-beginners.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>Natalie Speiser</name></author><id>tag:pyvideo.org,2017-10-25:/pycon-de-2017/data-science-project-for-beginners.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Natalie Speiser,Jens Beyer&lt;/strong&gt; (&amp;#64;natalie_lavrio)&lt;/p&gt;
&lt;p&gt;Natalie is a psychologist focused on statistics and machine learning for predictions. Jens is a pyhsicist turned consultant for IBM and d-fine and helped big companies with statistical models since 2009. Together, we founded LAVRIO.solutions and help our clients to make the most ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Natalie Speiser,Jens Beyer&lt;/strong&gt; (&amp;#64;natalie_lavrio)&lt;/p&gt;
&lt;p&gt;Natalie is a psychologist focused on statistics and machine learning for predictions. Jens is a pyhsicist turned consultant for IBM and d-fine and helped big companies with statistical models since 2009. Together, we founded LAVRIO.solutions and help our clients to make the most out of their data. In our recent data science projects, we faced specific hurdles which seem to be typical.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;AI and Machine Learning are taking over the world - but how do you actually start with understanding your data and predicting events? And what kind of &amp;quot;political&amp;quot; trouble could you run into? With examples from real projects, we try to give you a feeling for data science projects.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We will be talking about examples from projects we did as data science consultants. What should be organized before you go to a client (internal or external). How should the data look like. What are problems you have to face while working with the clients IT department. You get to see a rough draft of our code. It won't be a thorough manual, just our experiences and how we dealt with problems.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</content><category term="PyCon DE 2017"></category><category term="business"></category><category term="data-science"></category><category term="use-case"></category><category term="python"></category><category term="machine learning"></category></entry><entry><title>Deep Learning for Computer Vision</title><link href="https://pyvideo.org/pycon-de-2017/deep-learning-for-computer-vision.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>Alex Conway</name></author><id>tag:pyvideo.org,2017-10-25:/pycon-de-2017/deep-learning-for-computer-vision.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Alex Conway&lt;/strong&gt; (&amp;#64;alxcnwy)
Alex is the founder &amp;amp; CTO of NumberBoost, a startup that builds deep learning applications. He previously worked as a quant for a hedge fund and as a data scientist for an e-commerce company. He has an honours degree in actuarial science and a MSc in statistics ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Alex Conway&lt;/strong&gt; (&amp;#64;alxcnwy)
Alex is the founder &amp;amp; CTO of NumberBoost, a startup that builds deep learning applications. He previously worked as a quant for a hedge fund and as a data scientist for an e-commerce company. He has an honours degree in actuarial science and a MSc in statistics. He is one of the organizers of the Cape Town Deep Learning meet-up and has built numerous computer vision systems that run at scale in production predicting labels for millions of images per day.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The state-of-the-art in image classification has skyrocketed thanks to the development of deep convolutional neural networks and increases in the amount of data and computing power available to train them. The top-5 error rate in the ImageNet competition to predict which of 1000 classes an image belongs to has plummeted from 28% error in 2010 to just 2.25% in 2017 (human level error is around 5%).&lt;/p&gt;
&lt;p&gt;In addition to being able to classify objects in images (including not hotdogs), deep learning can be used to automatically generate captions for images, convert photos into paintings, detect cancer in pathology slide images, and help self-driving cars ‚Äòsee‚Äô.&lt;/p&gt;
&lt;p&gt;The talk will give an overview of the cutting edge and some of the core mathematical concepts and will also include a short code-first tutorial to show how easy it is to get started using deep learning for computer vision in python‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This talk is a crash course on convolutional neural networks and how to use them to solve 2 real-world applications at scale. The first is an image moderation system and the second is a visual similarity system where a user uploads an image of an item and the system returns visually similar items.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</content><category term="PyCon DE 2017"></category><category term="business"></category><category term="data-science"></category><category term="use-case"></category><category term="deep learning"></category><category term="ai"></category><category term="machine learning"></category></entry><entry><title>Effective Data Analysis with Pandas Indexes</title><link href="https://pyvideo.org/pycon-de-2017/effective-data-analysis-with-pandas-indexes.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>Alexander Hendorf</name></author><id>tag:pyvideo.org,2017-10-25:/pycon-de-2017/effective-data-analysis-with-pandas-indexes.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas is the Swiss-Multipurpose Knife for Data Analysis in Python. In this talk we will look deeper into how to gain productivity utilizing Pandas powerful indexing and make advanced analytics a piece of cake. Pandas features multiple index types. This talk will give you a deep insight into the ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas is the Swiss-Multipurpose Knife for Data Analysis in Python. In this talk we will look deeper into how to gain productivity utilizing Pandas powerful indexing and make advanced analytics a piece of cake. Pandas features multiple index types. This talk will give you a deep insight into the Pandas indexes and showcase the handiness of special Indexes as the TimeSeriesIndex.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</content><category term="PyCon DE 2017"></category><category term="machine learning"></category><category term="analytics"></category><category term="data-science"></category><category term="business analytics"></category></entry><entry><title>Getting Scikit-Learn To Run On Top Of Pandas</title><link href="https://pyvideo.org/pycon-de-2017/getting-scikit-learn-to-run-on-top-of-pandas.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>Ami Tavory</name></author><id>tag:pyvideo.org,2017-10-25:/pycon-de-2017/getting-scikit-learn-to-run-on-top-of-pandas.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Ami Tavory&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Ami is a data scientist at Facebook Research's Core Data Science group. He previously worked as a machine learning researcher in the fields of bioinformatics and algorithmic trading. In 2010 he received a Ph.D in Electrical Engineering from Tel Aviv University, in the field of financial ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Ami Tavory&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Ami is a data scientist at Facebook Research's Core Data Science group. He previously worked as a machine learning researcher in the fields of bioinformatics and algorithmic trading. In 2010 he received a Ph.D in Electrical Engineering from Tel Aviv University, in the field of financial information theory. His bachelor's and master's are from Tel Aviv University too.&lt;/p&gt;
&lt;p&gt;Ami uses Python and C++ for data analysis. He contributed to various open source projects, and is the author of a libstd C++ extension shipped with g++ (pb_ds: policy-based data structures).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Scikit-Learn is built directly over numpy, Python's numerical array library. Pandas adds to numpy metadata and higher-level munging capabilities. This talk describes how to intelligently auto-wrap Scikit-Learn for creating a version that can leverage pandas's added features.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Scikit-Learn is the de-facto standard Python library for general-purpose machine learning. It operates over NumPy, an efficient, but low-level, homogeneic array library. Pandas adds to NumPy metadata, heterogeneity, and higher-leve munging capabilities.&lt;/p&gt;
&lt;p&gt;In the field of visualization, newer generation libraries, e.g., Seaborn and Bokeh, are providing safer, more readable, and higher-level functionality, by operating over Pandas data structures. Some of these are implemented using Matplotlib, a lower-level NumPy-based plotting library.&lt;/p&gt;
&lt;p&gt;This talk describes a library for a Pandas-based version of sickit-learn. Here, too, giving a Pandas interface to a machine-learning library, provides code which is safer to use, more readable, and allows direct integration with Pandas's higher-level munging capabilities.&lt;/p&gt;
&lt;p&gt;Due to the large-scale, and evolving nature, of sicikit-learn's codebase, it is infeasible to manually wrap it. Except for a small number of intentional deviations from sickit-learn, the library wraps Scikit-Learn modules lazily through module and class introspection, and dynamic module loading.&lt;/p&gt;
&lt;p&gt;Following a short review of the relevant points of Pandas and Scikit-Learn, the talk is roughly divided into two aspects:     Scikit-Learn And Pandas User Perspective     Safety Advantages Of Pandas-Based Estimators     Using Metadata For Inter-Instance Aggregated Features And Cross-Validation     Using Metadata For Advanced Meta-Algorithms: Stacking, Nested Labeled And Stratified Cross-Valdiation     Python Develop Perspective     Unique Challenges Of Scikit-Learn Introspection And Decoration     Two Approaches For Wrapping Scikit-Learn Estimators     Lazy Dynamic Module Loading&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</content><category term="PyCon DE 2017"></category><category term="code-introspection"></category><category term="scikit-learn"></category><category term="pandas"></category><category term="data-science"></category><category term="python"></category><category term="machine learning"></category></entry><entry><title>Large-scale machine learning pipelines using Luigi, PySpark and scikit-learn</title><link href="https://pyvideo.org/pycon-de-2017/large-scale-machine-learning-pipelines-using-luigi-pyspark-and-scikit-learn.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>Alexander Bauer</name></author><id>tag:pyvideo.org,2017-10-25:/pycon-de-2017/large-scale-machine-learning-pipelines-using-luigi-pyspark-and-scikit-learn.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Alexander Bauer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Alexander Bauer holds a Ph.D. in computer science. He has around 10 years industry experience, currently leading a team of data scientists at Lidl, one of the largest global discount supermarket chains. He is a Kaggle Master and regular speaker at the Frankfurt Predictive Analytics Meetup ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Alexander Bauer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Alexander Bauer holds a Ph.D. in computer science. He has around 10 years industry experience, currently leading a team of data scientists at Lidl, one of the largest global discount supermarket chains. He is a Kaggle Master and regular speaker at the Frankfurt Predictive Analytics Meetup. He believes in agile software development practices and promotes Python as a primary language for data science applications in production.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For prescriptive analytics applications, data science teams need to design, build and maintain complex machine learning pipelines. In this talk, we demonstrate how such pipelines can be implemented in a robust, scalable and extensible manner using Python, Luigi, PySpark and scikit-learn.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Data science teams working on real-world prescriptive analytics applications face the challenge to design, build and maintain considerably complex machine learning pipelines on a daily basis. Such pipelines include parsing data from multiple data sources, extracting relevant predictive features, executing training, validation, prediction steps and finally optimizing actions to meet desired business outcome so that they can be shared and visualized to business users. In this talk, we demonstrate how such pipelines can be implemented end-to-end in a robust, scalable and extensible manner using Python, Luigi, PySpark and scikit-learn. We will share our lessons learned from using this framework in a real-world demand forecasting use case.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</content><category term="PyCon DE 2017"></category><category term="data-science"></category><category term="analytics"></category><category term="python"></category><category term="machine learning"></category></entry><entry><title>Rasa: open source conversational AI to build next generation chatbots</title><link href="https://pyvideo.org/pycon-de-2017/rasa-open-source-conversational-ai-to-build-next-generation-chatbots.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>Joey Faulkner</name></author><id>tag:pyvideo.org,2017-10-25:/pycon-de-2017/rasa-open-source-conversational-ai-to-build-next-generation-chatbots.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Joey Faulkner&lt;/strong&gt; (&amp;#64;JoeyMFaulkner)&lt;/p&gt;
&lt;p&gt;I am a PhD student in machine learning/astronomy, and an AI researcher at Rasa. We make open source libraries for conversational AI.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Soon you will primarily communicate with your computer through conversation. At Rasa, we believe that this revolution in user experience should be ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Joey Faulkner&lt;/strong&gt; (&amp;#64;JoeyMFaulkner)&lt;/p&gt;
&lt;p&gt;I am a PhD student in machine learning/astronomy, and an AI researcher at Rasa. We make open source libraries for conversational AI.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Soon you will primarily communicate with your computer through conversation. At Rasa, we believe that this revolution in user experience should be available to everyone. In this spirit we have developed open source tools that use machine learning to make chatbots in a developer-friendly interface.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The revolution-in-waiting for user experience is conversational AI, and this revolution should be available to everyone. The ability to communicate with your computer via a fulfilling and useful conversation will change the way we approach user interaction. Recent advances in machine learning have made this goal not only possible to reach, but possible to bring to the developer community at large. At Rasa we have developed a set of open-source Python libraries which can comprehend natural language and handle complex, interesting conversations. We utilise deep learning to bypass existing rigid conversational norms (state machines, if/else statements, etc.) and allow developers to make awesome bots simply by talking to them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</content><category term="PyCon DE 2017"></category><category term="python"></category><category term="machine learning"></category><category term="deep learning"></category><category term="open source"></category><category term="chatbot"></category><category term="natural language"></category><category term="ai"></category><category term="business"></category></entry><entry><title>Really Deep Neural Networks with PyTorch</title><link href="https://pyvideo.org/pycon-de-2017/really-deep-neural-networks-with-pytorch.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>David Dao</name></author><id>tag:pyvideo.org,2017-10-25:/pycon-de-2017/really-deep-neural-networks-with-pytorch.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;David Dao&lt;/strong&gt; (&amp;#64;dwddao)&lt;/p&gt;
&lt;p&gt;David is a PhD student at ETH Zurich, working on Deep Reinforcement Learning. Before joining ETH Zurich, he was an autonomous driving researcher at Mercedes-Benz Research in Silicon Valley and a graduate student at the Broad Institute of MIT and Harvard.&lt;/p&gt;
&lt;p&gt;David is a firm believer ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;David Dao&lt;/strong&gt; (&amp;#64;dwddao)&lt;/p&gt;
&lt;p&gt;David is a PhD student at ETH Zurich, working on Deep Reinforcement Learning. Before joining ETH Zurich, he was an autonomous driving researcher at Mercedes-Benz Research in Silicon Valley and a graduate student at the Broad Institute of MIT and Harvard.&lt;/p&gt;
&lt;p&gt;David is a firm believer in open source and is organising Germany's largest deep learning meetup series, and Silicon Valley's self-driving AI series. He is a contributor to popular machine intelligence frameworks such as TensorFlow and PyTorch and speaks chinese with swabian accent.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Modern neural networks have hundreds of layers! How can we train such deep networks? Simply stacking layers on top doesn't work! This talk introduces the deep learning library PyTorch by explaining the exciting math, cool ideas and simple code behind what makes really deep neural networks work.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Modern neural networks consist of hundreds of computation layers! These very deep architectures consistently outperform shallower networks in a variety of tasks. However just simply stacking layers on top of each other won't work because the gradients are either vanishing or exploding during optimisation procedure. This talk explains the exciting math, cool ideas and elegant code that modern neural network architectures such as ResNets, HighwayNets and DenseNets are applying to circumvent the problem using PyTorch. PyTorch is a relatively new deep learning framework that is deeply integrated into Python. Unlike other frameworks such as TensorFlow and Theano, it uses tape-based automatic differentiation to run computation immediately, supports dynamic neural networks and provides a powerful GPU-accelerated Tensor library. The talk concludes with some real-world use-cases for very deep neural networks in chemical-genetic profiling and autonomous driving.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</content><category term="PyCon DE 2017"></category><category term="deep learning"></category><category term="ai"></category><category term="machine learning"></category><category term="python"></category><category term="autonomous-driving"></category><category term="pytorch"></category></entry><entry><title>Synthetic Data for Machine Learning Applications</title><link href="https://pyvideo.org/pycon-de-2017/synthetic-data-for-machine-learning-applications.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>Hendrik Niemeyer</name></author><id>tag:pyvideo.org,2017-10-25:/pycon-de-2017/synthetic-data-for-machine-learning-applications.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Dr. Hendrik Niemeyer&lt;/strong&gt; (&amp;#64;hniemeye)&lt;/p&gt;
&lt;p&gt;Data Scientist working on predictive analytics with data from pipeline inspection measurements.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this talk I will show how we use real and synthetic data to create successful models for risk assessing pipeline anomalies. The main focus is the estimation of the difference in ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Dr. Hendrik Niemeyer&lt;/strong&gt; (&amp;#64;hniemeye)&lt;/p&gt;
&lt;p&gt;Data Scientist working on predictive analytics with data from pipeline inspection measurements.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this talk I will show how we use real and synthetic data to create successful models for risk assessing pipeline anomalies. The main focus is the estimation of the difference in the statistical properties of real and generated data by machine learning methods.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ROSEN provides predictive analytics for pipelines by detecting and risk assessing anomalies from data gathered by inline inspection measurement devices. Due to budget reasons (pipelines need to be dug up to get acess) ground truth data for machine learning applications in this field are usually scarce, imbalanced and not available for all existing configurations of measurement devices. This creates the need for synthetic data (using FEM simulations and unsupervised learning algorithms) in order to be able to create successful models.&lt;/p&gt;
&lt;p&gt;But a naive mixture of real-world and synthetic samples in a model does not necessarily yield to an increased predictive performance because of differences in the statistical distributions in feature space. I will show how we evaluate the use of synthetic data besides simple visual inspection. Manifold learning (e.g. TSNE) can be used to gain an insight whether real and generated data are inherently different.
Quantitative approaches like classifiers trained to discriminate between these types of data provide a non visual insight whether a &amp;quot;synthetic gap&amp;quot; in the feature distributions exists.&lt;/p&gt;
&lt;p&gt;If the synthetic data is useful for model building careful considerations have to be applied when constructing cross validation folds and test sets to prevent biased estimates of the model performance.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</content><category term="PyCon DE 2017"></category><category term="data-science"></category><category term="python"></category><category term="machine learning"></category><category term="ai"></category></entry><entry><title>The Mustache Movement</title><link href="https://pyvideo.org/pycon-de-2017/the-mustache-movement.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>Heidi Thorpe</name></author><id>tag:pyvideo.org,2017-10-25:/pycon-de-2017/the-mustache-movement.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Heidi Thorpe&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Heidi graduated with Honors in Chemistry from the University of Leeds before taking up a position as an Industrial Chemist with ICI (ORICA). This led to a career in software development working in UK, Aus and USA. In 2000 she became an author by the publication by ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Heidi Thorpe&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Heidi graduated with Honors in Chemistry from the University of Leeds before taking up a position as an Industrial Chemist with ICI (ORICA). This led to a career in software development working in UK, Aus and USA. In 2000 she became an author by the publication by Addison Wesley of Oracle8i tuning and administration: the essential reference ASIN: B007EIZGOG this was a sales success and translated into German. In her spare time she uses python to write software that allows her to train object classifiers to steal mens' mustaches and put them on the face of Taylor Swift. For this talk she will give a simple introduction to Generative Adversarial Networks using learned &amp;quot;mustache-ness&amp;quot; as an example, implemented with existing python modules&lt;/p&gt;
&lt;p&gt;PyconAu 2016 and PyconHK 2016 is her speaking experience &lt;a class="reference external" href="https://www.youtube.com/watch?v=70JAm03IBFI"&gt;https://www.youtube.com/watch?v=70JAm03IBFI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Generative Adversarial Networks (GANs) are a class of neural networks which are powerful and flexible tools. A common application is image generation. I would like to give a simple introduction to GANs using existing python modules and an example of how &amp;quot;mustache-ness&amp;quot; can be learned and applied.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The objective is to showcase the power and flexibility of combining preexisting python modules and applying them to the field of image processing and machine learning. Learning what constitutes &amp;quot;Mustache-ness&amp;quot; in a straight forward and fun example of applying the technology in a 30 min presentation&lt;/p&gt;
&lt;p&gt;Attendees will learn tips on image processing, as well as training their own neural network.&lt;/p&gt;
&lt;p&gt;An analogy can be considered as a relation between forger and detective. The task of the forger is to create fake examples of original paintings by famous artists. If the fake can pass as an original the the forger can exchange the fake for money. The task of the detective is to catch the forgers. He does this by knowing what are the properties that set the original artist apart and what sort of picture he would create. The detective uses this knowledge to determine whether or not the image is real or fake. From an introduction of what a Generative Adversarial Network is, how they work and how they can be used to generate fake images of mustaches by determining what constitutes &amp;quot;mustache-ness&amp;quot;&lt;/p&gt;
&lt;p&gt;You will learn that there are two main components of a GAN ‚Äì Generator Neural Network and Discriminator Neural Network.&lt;/p&gt;
&lt;p&gt;The Generator Network takes an random input and tries to generate a sample of data.&lt;/p&gt;
&lt;p&gt;It then generates data which is subsequently fed into a discriminator network D(x). The task of Discriminator Network is to take input either from the real data or from the generator and try to predict whether the input is real or generated.&lt;/p&gt;
&lt;p&gt;D(x) solves a binary classification problem using sigmoid function giving output in the range 0 to 1.&lt;/p&gt;
&lt;p&gt;You will learn how to define the problem. Do you want to generate fake images or fake text. Having defined the problem you can then collect data for it. You will define how your GAN should look. In our example of &amp;quot;mustache-ness&amp;quot; you will choose a convolutional neural network.&lt;/p&gt;
&lt;p&gt;You will see the effect of training the Discriminator on real data for n epochs. Using examples of real mustaches we will generate fake ones. We will see generated fake inputs for the generator and the effect of training the discriminator on fake data. The discriminator will correctly predict them as fake. Subsequently we will see how to train the generator with the output of discriminator. Now we can see a trained generator that can fool the discriminator. Generating fake mustaches that are indistinguishable from real.&lt;/p&gt;
&lt;p&gt;Attendees will learn tips on image processing, as well as training your own convolutional neural network.&lt;/p&gt;
&lt;p&gt;Showcasing the power of python in a fun, lighthearted way. Hopefully, being informative and entertaining&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</content><category term="PyCon DE 2017"></category><category term="python"></category><category term="machine learning"></category><category term="torch"></category><category term="scikit-learn"></category><category term="numpy"></category><category term="neural networks"></category></entry><entry><title>The Python Ecosystem for Data Science: A Guided Tour</title><link href="https://pyvideo.org/pycon-de-2017/the-python-ecosystem-for-data-science-a-guided-tour.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>Christian Staudt</name></author><id>tag:pyvideo.org,2017-10-25:/pycon-de-2017/the-python-ecosystem-for-data-science-a-guided-tour.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Christian Staudt&lt;/strong&gt; (&amp;#64;C_L_Staudt)&lt;/p&gt;
&lt;p&gt;I am an independent data scientist with a background in computer science, in-depth in algorithms, data analysis, high-performance computing and software engineering. My current interests include machine learning and data visualization.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Pythonistas have access to an extensive collection of tools for data analysis. The space ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Christian Staudt&lt;/strong&gt; (&amp;#64;C_L_Staudt)&lt;/p&gt;
&lt;p&gt;I am an independent data scientist with a background in computer science, in-depth in algorithms, data analysis, high-performance computing and software engineering. My current interests include machine learning and data visualization.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Pythonistas have access to an extensive collection of tools for data analysis. The space of tools is best understood as an ecosystem: Libraries build upon each other, and a good library fills an ecological niche by doing certain jobs well. This is a guided tour of the Python data science ecosystem.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Python Ecosystem for Data Science: A Guided Tour&lt;/p&gt;
&lt;p&gt;Python is on its way to becoming the lingua franca of data science, and Pythonistas have access to an impressive and extensive collection of tools for data analysis. Here, a data scientist needs to see the forest for the trees: The space of tools is best understood as an ecosystem, where libraries build upon each other, and where a good library fills an ecological niche by doing certain jobs well. This talk is a guided tour of the Python data science ecosystem. More than a list of libraries, it aims to provide some structure, classing tools by type of data, size of data, and type of analysis. In our tour, we visit a number of areas, including working with tabular data (numpy, pandas, dask, ...) and graph data (e.g. networkx), statistics (e.g. statsmodels), machine learning (scikit-learn, ...), data visualization (matplotlib, seaborn, bokeh, ...). Aspiring data scientists, and everyone else working with data, should find this useful for selecting the right tools for their next data-driven project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</content><category term="PyCon DE 2017"></category><category term="use-case"></category><category term="business"></category><category term="ai"></category><category term="analytics"></category><category term="data-science"></category><category term="python"></category><category term="machine learning"></category></entry><entry><title>Time series feature extraction with tsfresh - ‚Äúget rich or die overfitting‚Äù</title><link href="https://pyvideo.org/pycon-de-2017/time-series-feature-extraction-with-tsfresh-get-rich-or-die-overfitting.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>Nils Braun</name></author><id>tag:pyvideo.org,2017-10-25:/pycon-de-2017/time-series-feature-extraction-with-tsfresh-get-rich-or-die-overfitting.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Nils Braun&lt;/strong&gt; (&amp;#64;_nilsbraun)&lt;/p&gt;
&lt;p&gt;Currently I am doing my PhD in Particle Physics - which mainly involves development of software in a large collaboration. I love working with Python and C++ to process large amounts of data. Of course it needs to be processed as quickly as possible. I am working ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Nils Braun&lt;/strong&gt; (&amp;#64;_nilsbraun)&lt;/p&gt;
&lt;p&gt;Currently I am doing my PhD in Particle Physics - which mainly involves development of software in a large collaboration. I love working with Python and C++ to process large amounts of data. Of course it needs to be processed as quickly as possible. I am working on the core reconstruction algorithms for our experiment, which are steered and controlled using Python. Apart from that, I was working as a Data Science Engineer for Blue Yonder, a leading machine learning company, where the idea for tsfresh was born. I am still heavily involved in the project. When I am not writing code, I am updating myself on the newest technical geek stuff (mostly cloud computing and deep learning) or play the guitar.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Have you ever thought about developing a time series model to predict stock prices? Or do you consider log time series from the operation of cloud resources as being more compelling? In this case you really should consider using the time series feature extraction package tsfresh for your project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Trends such as the Internet of Things (IoT), Industry 4.0, and precision medicine are driven by the availability of cheap sensors and advancing connectivity, which among others increases the availability of temporally annotated data. The resulting time series are the basis for manifold machine learning applications. Examples are the classification of hard drives into risk classes concerning specific defect, the log analysis of server farms for detecting intruders, or regression tasks like the prediction of the remaining lifespan of machinery. Tsfresh also allows to easily setup a machine learning pipeline that predicts stock prices, which we will demonstrate live during the presentation ;). The problem of extracting and selecting relevant features for classification or regression is these domains is especially hard to solve, if each label or regression target is associated with several time series and meta-information simultaneously ‚Äì which is a common pattern in industrial applications. This talk introduces a distributed and parallel feature extraction and selection algorithm ‚Äì the recently published Python library tsfresh. The fully automated extraction and importance selection does not only allow to reach better machine learning classification scores, but in combination with the speed of the package, also allows to incorporate tsfresh into automated AI-pipelines.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</content><category term="PyCon DE 2017"></category><category term="pydata"></category><category term="time series"></category><category term="data-science"></category><category term="machine learning"></category><category term="python"></category><category term="ai"></category></entry><entry><title>Build text classification models ( CBOW and Skip-gram) with FastText in python</title><link href="https://pyvideo.org/pycon-de-2018/build-text-classification-models-cbow-and-skip-gram-with-fasttext-in-python.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Kajal Puri</name></author><id>tag:pyvideo.org,2018-10-26:/pycon-de-2018/build-text-classification-models-cbow-and-skip-gram-with-fasttext-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;FastText has been open-sourced by Facebook in 2016 and with its release,
it became the fastest and most accurate library in Python for text
classification and word representation. It is to be seen as a substitute
for gensim package's word2vec. It includes the implementation of two
extremely important methodologies ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;FastText has been open-sourced by Facebook in 2016 and with its release,
it became the fastest and most accurate library in Python for text
classification and word representation. It is to be seen as a substitute
for gensim package's word2vec. It includes the implementation of two
extremely important methodologies in NLP i.e Continuous Bag of Words and
Skip-gram model. Fasttext performs exceptionally well with supervised as
well as unsupervised learning.&lt;/p&gt;
&lt;p&gt;The tutorial will be divided in following four segments :&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Artificial Intelligence"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Data Science"></category><category term="NLP"></category><category term="Machine Learning"></category></entry><entry><title>Building your own conversational AI with open source tools</title><link href="https://pyvideo.org/pycon-de-2018/building-your-own-conversational-ai-with-open-source-tools.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Justina Petraitytƒó</name></author><id>tag:pyvideo.org,2018-10-26:/pycon-de-2018/building-your-own-conversational-ai-with-open-source-tools.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Conversational AI is far from being a solved problem, but you don‚Äôt need
to rely on third-party APIs to build great chat and voice apps.&lt;/p&gt;
&lt;p&gt;In this talk we will live-code a useful, engaging conversational AI bot
based entirely on machine learning. We‚Äôll be using Rasa NLU ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Conversational AI is far from being a solved problem, but you don‚Äôt need
to rely on third-party APIs to build great chat and voice apps.&lt;/p&gt;
&lt;p&gt;In this talk we will live-code a useful, engaging conversational AI bot
based entirely on machine learning. We‚Äôll be using Rasa NLU &amp;amp; Rasa Core,
which are open source libraries for building machine learning-based
chatbots and voice assistants. We will teach our system how to hold
multi-turn conversations by creating some initial training data, and
then refine its behaviour by interacting with the system and providing
feedback. We will cover the fundamentals of conversational AI, including
the most important algorithms for intent classification, entity
extraction, and dialogue management.&lt;/p&gt;
&lt;p&gt;What will attendees learn:&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Artificial Intelligence"></category><category term="NLP"></category><category term="Machine Learning"></category><category term="Python"></category></entry><entry><title>From exploration to deployment - combining PyTorch and TensorFlow for Deep Learning</title><link href="https://pyvideo.org/pycon-de-2018/from-exploration-to-deployment-combining-pytorch-and-tensorflow-for-deep-learning.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Marcel Kurovski</name></author><id>tag:pyvideo.org,2018-10-26:/pycon-de-2018/from-exploration-to-deployment-combining-pytorch-and-tensorflow-for-deep-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Despite the many deep learning frameworks out in the wild few have
achieved widespread adoption. Two of them are TensorFlow and PyTorch.
Where PyTorch relies on a dynamic computation graph TensorFlow goes for
a static graph. Where TensorFlow shows greater adoption and additional
useful extensions with TensorFlow Serving and ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Despite the many deep learning frameworks out in the wild few have
achieved widespread adoption. Two of them are TensorFlow and PyTorch.
Where PyTorch relies on a dynamic computation graph TensorFlow goes for
a static graph. Where TensorFlow shows greater adoption and additional
useful extensions with TensorFlow Serving and TensorBoard, Pytorch
proves useful trough its easy and more pythonic API.&lt;/p&gt;
&lt;p&gt;Data scientists are confronted with explorative challenges, but also
need to be aware of model deployment and production. Do we need to
single out frameworks until we end up with the only one or is there a
case for joint usage of two deep learning frameworks? Can we leverage
the strengths of the frameworks for different tasks along the path from
exploration to production?&lt;/p&gt;
&lt;p&gt;In my talk, I want to present a case combining the benefits of PyTorch
and TensorFlow using the first for explorative and latter for deployment
tasks. Therefore, I will choose a common deep learning challenge and
discuss the strengths and weaknesses of both frameworks along a demo
that brings a model from development into production.&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Artificial Intelligence"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Data Science"></category><category term="Machine Learning"></category></entry><entry><title>Prototyping to tested code</title><link href="https://pyvideo.org/pycon-de-2018/prototyping-to-tested-code.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Christopher Prohm</name></author><id>tag:pyvideo.org,2018-10-26:/pycon-de-2018/prototyping-to-tested-code.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter notebooks are a great environment to prototype solutions and
explore their design. Turning these solutions into reusable components
usually requires moving them out of the notebook environment into
external python packages. Often, at this stage, the code is refactored
and test are written.&lt;/p&gt;
&lt;p&gt;In this talk, I will ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter notebooks are a great environment to prototype solutions and
explore their design. Turning these solutions into reusable components
usually requires moving them out of the notebook environment into
external python packages. Often, at this stage, the code is refactored
and test are written.&lt;/p&gt;
&lt;p&gt;In this talk, I will demo
&lt;tt class="docutils literal"&gt;`ipytest&lt;/tt&gt; &amp;lt;&lt;a class="reference external" href="https://github.com/chmp/ipytest"&gt;https://github.com/chmp/ipytest&lt;/a&gt;&amp;gt;`__, a small tool to run
tests inside notebooks. It supports &lt;tt class="docutils literal"&gt;`pytest&lt;/tt&gt; &amp;lt;&lt;a class="reference external" href="http://pytest.org/"&gt;http://pytest.org/&lt;/a&gt;&amp;gt;`__
as well as the standard
&lt;tt class="docutils literal"&gt;`unittest&lt;/tt&gt; &amp;lt;&lt;a class="reference external" href="https://docs.python.org/3/library/unittest.html"&gt;https://docs.python.org/3/library/unittest.html&lt;/a&gt;&amp;gt;`__
framework. It allows to start prototypes in a notebook and to develop
the tests with the code in an highly interactive environment. As the
code grows, it can be transparently moved outside notebooks and
transformed into reusable components. By bringing support for tests to
the notebook environment,
&lt;tt class="docutils literal"&gt;`ipytest&lt;/tt&gt; &amp;lt;&lt;a class="reference external" href="https://github.com/chmp/ipytest"&gt;https://github.com/chmp/ipytest&lt;/a&gt;&amp;gt;`__ bridges the artificial
gap between notebooks and reusable components.&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Data Science"></category><category term="Machine Learning"></category></entry><entry><title>Satellite data is for everyone: insights into modern remote sensing research with open data and Python</title><link href="https://pyvideo.org/pycon-de-2018/satellite-data-is-for-everyone-insights-into-modern-remote-sensing-research-with-open-data-and-python.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Felix M. Riese</name></author><id>tag:pyvideo.org,2018-10-26:/pycon-de-2018/satellite-data-is-for-everyone-insights-into-modern-remote-sensing-research-with-open-data-and-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The largest earth observation programme Copernicus
(&lt;a class="reference external" href="http://copernicus.eu"&gt;http://copernicus.eu&lt;/a&gt;) makes it possible to perform terrestrial
observations providing data for all kinds of purposes. One important
objective is to monitor the land-use and land-cover changes with the
Sentinel-2 satellite mission. These satellites measure the sun
reflectance on the earth surface ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The largest earth observation programme Copernicus
(&lt;a class="reference external" href="http://copernicus.eu"&gt;http://copernicus.eu&lt;/a&gt;) makes it possible to perform terrestrial
observations providing data for all kinds of purposes. One important
objective is to monitor the land-use and land-cover changes with the
Sentinel-2 satellite mission. These satellites measure the sun
reflectance on the earth surface with multispectral cameras (13 channels
between 440 nm to 2190 nm). Machine learning techniques like
convolutional neural networks (CNN) are able to learn the link between
the satellite image (spectrum) and the ground truth (land use class). In
this talk, we give an overview about the state-of-the-art land-use
classification with CNNs based on an open dataset.&lt;/p&gt;
&lt;p&gt;The EuroSAT benchmark dataset (&lt;a class="reference external" href="http://madm.dfki.de/downloads"&gt;http://madm.dfki.de/downloads&lt;/a&gt;) is freely
provided by German Research Center for Artificial Intelligence (DFKI).
It consists of 27.000 image patches for ten different land use/cover
classes, e.g. industrial and residential areas, different crop and
vegetation types and forests. All samples have 64 by 64 pixel dimension
and include either only the RGB images or all 13 bands.&lt;/p&gt;
&lt;p&gt;We will use different out-of-box CNNs for the Keras deep learning
library (&lt;a class="reference external" href="https://keras.io/"&gt;https://keras.io/&lt;/a&gt;). All networks are either included in Keras
itself or are available from Github repositories. We will show the
process of transfer learning for the RGB datasets. Furthermore, the
minimal changes required to apply commonly used CNNs to multispectral
data are demonstrated. Thus, the interested audience will be able to
perform their own classification of remote sensing data within a very
short time. Results of different network structures are visually
compared. Especially the differences of transfer learning and learning
from scratch are demonstrated. This also includes the amount of
necessary training epochs, progress of training and validation error and
visual comparison of the results of the trained networks.&lt;/p&gt;
&lt;p&gt;Finally, we give a quick overview about the current research topics
including recurrent neural networks for spatio-temporal land-use
classification and further applications of multi- and hyperspectral
data, e.g. for the estimation of water parameters and soil
characteristics. Additionally, we provide links to the code and dataset
used in this talk.&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Artificial Intelligence"></category><category term="Computer Vision"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Data Science"></category><category term="Machine Learning"></category><category term="Science"></category></entry><entry><title>Beyond Jupyter Notebooks - Building your own Data Science platform with Python &amp; Docker</title><link href="https://pyvideo.org/pycon-de-2018/beyond-jupyter-notebooks-building-your-own-data-science-platform-with-python-docker.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Joshua G√∂rner</name></author><id>tag:pyvideo.org,2018-10-25:/pycon-de-2018/beyond-jupyter-notebooks-building-your-own-data-science-platform-with-python-docker.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Interactive notebooks like Jupyter have become more and more popular in
the recent past and build the core of many data scientist's workplace.
Being accessed via web browser they allow scientists to easily structure
their work by combining code and documentation.&lt;/p&gt;
&lt;p&gt;Yet notebooks often lead to isolated and disposable ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Interactive notebooks like Jupyter have become more and more popular in
the recent past and build the core of many data scientist's workplace.
Being accessed via web browser they allow scientists to easily structure
their work by combining code and documentation.&lt;/p&gt;
&lt;p&gt;Yet notebooks often lead to isolated and disposable analysis artefacts.
Keeping the computation inside those notebooks does not allow for
convenient concurrent model training, model exposure or scheduled model
retraining.&lt;/p&gt;
&lt;p&gt;Those issues can be addressed by taking advantage of recent developments
in the discipline of software engineering. Over the past years
containerization became the technology of choice for crafting and
deploying applications. Building a data science platform that allows for
easy access (via notebooks), flexibility and reproducibility (via
containerization) combines the best of both worlds and addresses Data
Scientist's hidden needs.&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Artificial Intelligence"></category><category term="Algorithms"></category><category term="Data Science"></category><category term="DevOps"></category><category term="Infrastructure"></category><category term="Jupyter"></category><category term="Machine Learning"></category><category term="Programming"></category><category term="Python"></category></entry><entry><title>Data science complexity and solutions in real industrial projects</title><link href="https://pyvideo.org/pycon-de-2018/data-science-complexity-and-solutions-in-real-industrial-projects.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Artur Miller</name></author><id>tag:pyvideo.org,2018-10-25:/pycon-de-2018/data-science-complexity-and-solutions-in-real-industrial-projects.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As data scientists we usually like to apply fancy machine learning
models to well-groomed datasets. Everyone working on industrial problems
will eventually learn, that this does not reflect reality. The amount of
time spent on modeling is small compared to data gathering, -warehousing
and -cleaning. Even after training and ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As data scientists we usually like to apply fancy machine learning
models to well-groomed datasets. Everyone working on industrial problems
will eventually learn, that this does not reflect reality. The amount of
time spent on modeling is small compared to data gathering, -warehousing
and -cleaning. Even after training and deployment of the model, the work
is not done. Continuous monitoring of the performance and input data is
still necessary.&lt;/p&gt;
&lt;p&gt;In this talk I discuss how important data handling is for successful
data science projects. Each milestone, from finding the business case to
continuously monitoring the performance of the solution, is addressed.
This is exemplary shown on a project, with the goal of improving a
productive system.&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Algorithms"></category><category term="Big Data"></category><category term="Data Science"></category><category term="Infrastructure"></category><category term="Machine Learning"></category></entry><entry><title>Introduction to Docker for Pythonistas</title><link href="https://pyvideo.org/pycon-de-2018/introduction-to-docker-for-pythonistas.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Jan Wagner</name></author><id>tag:pyvideo.org,2018-10-25:/pycon-de-2018/introduction-to-docker-for-pythonistas.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="line-block"&gt;
&lt;div class="line"&gt;My Talk aims to introduce you to Docker and how it works, how you can
use prebuild Images from the Docker-Hub and how you can make your own
Images.&lt;/div&gt;
&lt;div class="line"&gt;In more Detail, the following Points will be covered:&lt;/div&gt;
&lt;/div&gt;
</content><category term="PyCon DE 2018"></category><category term="Big Data"></category><category term="Data Science"></category><category term="DevOps"></category><category term="Jupyter"></category><category term="Machine Learning"></category></entry><entry><title>Machine Learning as a Service: How to deploy ML Models as APIs without going nuts</title><link href="https://pyvideo.org/pycon-de-2018/machine-learning-as-a-service-how-to-deploy-ml-models-as-apis-without-going-nuts.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Anand Chitipothu</name></author><id>tag:pyvideo.org,2018-10-25:/pycon-de-2018/machine-learning-as-a-service-how-to-deploy-ml-models-as-apis-without-going-nuts.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Often, the most convenient way to deploy a machine model is an API. It
allows accessing it from various programming environments and also
decouples the development and deployment of the models from its use.&lt;/p&gt;
&lt;p&gt;However, building an good API is hard. It involves many nitty-gritties
and many of them ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Often, the most convenient way to deploy a machine model is an API. It
allows accessing it from various programming environments and also
decouples the development and deployment of the models from its use.&lt;/p&gt;
&lt;p&gt;However, building an good API is hard. It involves many nitty-gritties
and many of them need to repeated everytime an API is built. Also, it is
very important to have a client library so that the API can be easily
accessed. If you every plan to use it from Javascript directly, then you
need to worry about cross-origin-resource-sharing etc. All things add up
and building APIs for machine very tedious.&lt;/p&gt;
&lt;p&gt;In this talk demonstrates how deploying machine learning models an APIs
can be made fun by using right programming abstractions. This presents
couple of opensource libraries
&lt;a class="reference external" href="https://firefly-%20python.readthedocs.io/en/latest/"&gt;firefly&lt;/a&gt; and
&lt;a class="reference external" href="https://rorodata.github.io/rorolite/"&gt;rorolite&lt;/a&gt; which are built for
this very purpose.&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Machine Learning"></category><category term="Python"></category><category term="Web"></category></entry><entry><title>Reproducibility, and Selection Bias in Machine Learning</title><link href="https://pyvideo.org/pycon-de-2018/reproducibility-and-selection-bias-in-machine-learning.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Valerio Maggio</name></author><id>tag:pyvideo.org,2018-10-25:/pycon-de-2018/reproducibility-and-selection-bias-in-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Reproducibility&lt;/em&gt; - the ability to recompute results ‚Äî and
&lt;em&gt;replicability&lt;/em&gt; ‚Äî the chances other experimenters will achieve a
consistent result[1]- are among the main important beliefs of the
&lt;em&gt;scientific method&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Surprisingly, these two aspects are often underestimated or not even
considered when setting up scientific experimental pipelines. In this,
one of ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Reproducibility&lt;/em&gt; - the ability to recompute results ‚Äî and
&lt;em&gt;replicability&lt;/em&gt; ‚Äî the chances other experimenters will achieve a
consistent result[1]- are among the main important beliefs of the
&lt;em&gt;scientific method&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Surprisingly, these two aspects are often underestimated or not even
considered when setting up scientific experimental pipelines. In this,
one of the main threat to replicability is the &lt;em&gt;selection bias&lt;/em&gt; , that
is the error in choosing the individuals or groups to take part in a
study. Selection bias may come in different flavours: the selection of
the population of samples in the dataset ( &lt;em&gt;sample bias&lt;/em&gt; ); the
selection of features used by the learning models, particularly sensible
in case of high dimensionality; the selection of hyper parameter best
performing on specific dataset(s). If not properly considered, the
selection bias may strongly affect the validity of derived conclusions,
as well as the reliability of the learning model.&lt;/p&gt;
&lt;p&gt;In this talk I will provide a solid introduction to the topics of
reproducibility and selection bias, with examples taken from the
biomedical research, in which reliability is paramount.&lt;/p&gt;
&lt;p&gt;From a more technological perspective, to date the scientific Python
ecosystem still misses tools to consolidate the experimental pipelines
in in research, that can be used together with Machine and Deep learning
frameworks (e.g. &lt;tt class="docutils literal"&gt;sklearn&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;keras&lt;/tt&gt;). In this talk, I will
present &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;reproducible-lern&lt;/span&gt;&lt;/tt&gt;, a new Python frameworks for reproducible
research to be used for machine and deep learning.&lt;/p&gt;
&lt;p&gt;During the talk, the main features of the framework will be presented,
along with several examples, technical insights and implementation
choices to be discussed with the audience.&lt;/p&gt;
&lt;p&gt;The talk is intended for &lt;em&gt;intermediate&lt;/em&gt; PyData researchers and
practitioners. Basic prior knowledge of the main Machine Learning
concepts is assumed for the first part of the talk. On the other hand,
good proficiency with the Python language and with scientific python
libraries (e.g. &lt;tt class="docutils literal"&gt;numpy&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;sklearn&lt;/tt&gt;) are required for the second
part.&lt;/p&gt;
&lt;p&gt;-- &lt;a class="reference external" href="http://www.pnas.org/content/112/6/1645.full"&gt;1&lt;/a&gt; &lt;em&gt;Reproducible
research can still be wrong: Adopting a prevention approach&lt;/em&gt; by Jeffrey
T. Leek, and Roger D. Peng&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.cancer.gov/publications/dictionaries/cancer-terms?CdrID=44087"&gt;2&lt;/a&gt;
Dictionary of Cancer Terms -&amp;gt; &amp;quot;selection bias&amp;quot;&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Algorithms"></category><category term="Machine Learning"></category><category term="Science"></category></entry><entry><title>Satellite Image Segmentation Photovoltaic Potential Estimation</title><link href="https://pyvideo.org/pycon-de-2018/satellite-image-segmentation-photovoltaic-potential-estimation.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Johannes Oos</name></author><id>tag:pyvideo.org,2018-10-25:/pycon-de-2018/satellite-image-segmentation-photovoltaic-potential-estimation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The used technologies are python based and include: MongoDB tensorflow
Flask google.cloud python API&lt;/p&gt;
&lt;p&gt;A dataset of labelled satellite images is created. Several networks are
trained and tested on this dataset. The network is deployed on a
production server.&lt;/p&gt;
&lt;p&gt;The results of the classification/segmentaion are used to ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The used technologies are python based and include: MongoDB tensorflow
Flask google.cloud python API&lt;/p&gt;
&lt;p&gt;A dataset of labelled satellite images is created. Several networks are
trained and tested on this dataset. The network is deployed on a
production server.&lt;/p&gt;
&lt;p&gt;The results of the classification/segmentaion are used to feed python
based photovotlaic simulation libaries. The output is displayed and the
results (the potential) evaluated.&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Artificial Intelligence"></category><category term="Computer Vision"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Machine Learning"></category><category term="Science"></category></entry><entry><title>Solving Data Science Problems using a Jupyter Notebook and SAP HANA's in-database Machine Learning Libraries</title><link href="https://pyvideo.org/pycon-de-2018/solving-data-science-problems-using-a-jupyter-notebook-and-sap-hanas-in-database-machine-learning-libraries.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Dr Frank Gottfried</name></author><id>tag:pyvideo.org,2018-10-25:/pycon-de-2018/solving-data-science-problems-using-a-jupyter-notebook-and-sap-hanas-in-database-machine-learning-libraries.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Companies store their data in databases with highly restricted access
regulations. The latest regulatorily changes enforces the need to work
on the datasets in this controlled environment without created
additional external copies. However Data Scientists prefer to work with
tools they are most familiar like Python, R and Jupyter ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Companies store their data in databases with highly restricted access
regulations. The latest regulatorily changes enforces the need to work
on the datasets in this controlled environment without created
additional external copies. However Data Scientists prefer to work with
tools they are most familiar like Python, R and Jupyter Notebooks using
to a large amount of open- source packages (numpy, matplotlib, pandas,
..). SAP HANA provides highly optimized in-database machine learning
libraries. In this talk we will present how a Data Scientist can work in
an environment he/she is most familiar with and access the data stored
in SAP HANA using SAP HANA machine learning libraries with a
scikit-learn type interface. Data will remain in the database and will
be exposed as dataframes (similar to Pandas dataframes). We will explain
the software architecture and present a complete end-to-end use case by
using a Jupyter Notebook.&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Big Data"></category><category term="Data Science"></category><category term="Jupyter"></category><category term="Machine Learning"></category><category term="Visualisation"></category></entry><entry><title>Active Learning - Building Semi-supervised Classifiers when Labeled Data is not Available</title><link href="https://pyvideo.org/pycon-de-2018/active-learning-building-semi-supervised-classifiers-when-labeled-data-is-not-available.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Dr. Hendrik Niemeyer</name></author><id>tag:pyvideo.org,2018-10-24:/pycon-de-2018/active-learning-building-semi-supervised-classifiers-when-labeled-data-is-not-available.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In many situations large datasets are available but unfortunately
labeling is expensive and time consuming. Active Learning is a concept
for building classifiers by letting the algorithm choose the training
data it uses. This achieves greater accuracy than just labeling a random
subset of the available dataset.&lt;/p&gt;
&lt;p&gt;The active ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In many situations large datasets are available but unfortunately
labeling is expensive and time consuming. Active Learning is a concept
for building classifiers by letting the algorithm choose the training
data it uses. This achieves greater accuracy than just labeling a random
subset of the available dataset.&lt;/p&gt;
&lt;p&gt;The active learning algorithm selects some unlabeled data instances
which are then labeled by a human annotator. Given this information a
classifier is trained and new instances for the human annotator to label
are selected. This iterative process tries to label as few instances as
possible while achieving high classification accuracy.&lt;/p&gt;
&lt;p&gt;In this talk I will give a general overview of the core concepts and
techniques of active learning like algorithms for selecting the queries
and convergence criteria.&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Artificial Intelligence"></category><category term="Algorithms"></category><category term="Data Science"></category><category term="Machine Learning"></category><category term="Python"></category></entry><entry><title>Distributed Hyperparameter search with sklearn and kubernetes</title><link href="https://pyvideo.org/pycon-de-2018/distributed-hyperparameter-search-with-sklearn-and-kubernetes.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Jakob Karalus</name></author><id>tag:pyvideo.org,2018-10-24:/pycon-de-2018/distributed-hyperparameter-search-with-sklearn-and-kubernetes.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While sklearn provides a good interface to do hyperparameter search on
large &amp;amp; complex model (pipelines), doing these can take up a lot of
time. The traditional way usually includes one beefy machine and a lot
of waiting. In other cases, people tend to ‚Äúmanually‚Äù schedule parameter
ranges between nodes ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While sklearn provides a good interface to do hyperparameter search on
large &amp;amp; complex model (pipelines), doing these can take up a lot of
time. The traditional way usually includes one beefy machine and a lot
of waiting. In other cases, people tend to ‚Äúmanually‚Äù schedule parameter
ranges between nodes, but that can also be problematic since these won't
talk to each other. Kubernetes itself is currently the most prominent
scheduler and shines at distributing task, but is a pretty complex
system in itself.&lt;/p&gt;
&lt;p&gt;In this talk, I will show how you can harness the scheduling of
kubernetes for distributing hyperparameter search with sklearn onto a
cluster of nodes. This can be achieved quite easily and with just a few
changes to the original code, so the Data Scientist won't be bothered by
complex kubernetes internals.&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Algorithms"></category><category term="Big Data"></category><category term="Data Science"></category><category term="DevOps"></category><category term="Infrastructure"></category><category term="Machine Learning"></category></entry><entry><title>Experiences from applying Convolutional Neural Networks for classifying 2D sensor data</title><link href="https://pyvideo.org/pycon-de-2018/experiences-from-applying-convolutional-neural-networks-for-classifying-2d-sensor-data.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Matthias Peussner</name></author><id>tag:pyvideo.org,2018-10-24:/pycon-de-2018/experiences-from-applying-convolutional-neural-networks-for-classifying-2d-sensor-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When being the first in your company to apply a deep learning algorithm
on your data you often have to overcome several obstacles. One challenge
is to understand your data and to form a training and test dataset.
Another one is to get your algorithms and its performance accepted ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When being the first in your company to apply a deep learning algorithm
on your data you often have to overcome several obstacles. One challenge
is to understand your data and to form a training and test dataset.
Another one is to get your algorithms and its performance accepted and
integrated in your existing processing workflow.&lt;/p&gt;
&lt;p&gt;Convolutional Neural Networks have become a standard tool in processing
image data. They have shown to reach human-level classification
performance on some object recognition tasks.&lt;/p&gt;
&lt;p&gt;In this talk I will present my experiences in getting started using a
convolutional neural network for classification of 2D sensor data. I
will point out the importance of understanding your data and give hints
of how to select your train and test datasets according to the
requirements. Furthermore, I will show how to get a feature extractor
out of the classifier and how to visualize it.&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Artificial Intelligence"></category><category term="Computer Vision"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Machine Learning"></category></entry><entry><title>Germany's next topic model</title><link href="https://pyvideo.org/pycon-de-2018/germanys-next-topic-model.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Thomas Mayer</name></author><id>tag:pyvideo.org,2018-10-24:/pycon-de-2018/germanys-next-topic-model.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Identifying topic models for user generated content like hotel reviews
turns out to be difficult with the standard approach of LDA (Latent
Dirichlet Allocation; Blei et al., 2003). Hotel review texts usually
don't differ as much in the topics that are covered as is typical with
other genres such ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Identifying topic models for user generated content like hotel reviews
turns out to be difficult with the standard approach of LDA (Latent
Dirichlet Allocation; Blei et al., 2003). Hotel review texts usually
don't differ as much in the topics that are covered as is typical with
other genres such as Wikipedia or newsgroup articles where there is
commonly only a very small set of topics present in each document.&lt;/p&gt;
&lt;p&gt;To this end, we developed our own approach to topic modeling that is
especially tailored to non-edited texts like hotel reviews. The approach
can be divided into three major steps. First, using the concept of
second-order cooccurrences we define a contextual similarity score that
enables us to identify words that are similar with respect to certain
topics. This score allows us to build up a topic network where nodes are
words and edges the contextual similarity between the words. With the
help of algorithms from graph theory, like the Infomap algorithm
(Rosvall and Bergstrom, 2008), we are able to detect clusters of highly
connected words that can be identified as topics in our review texts. In
a further step, we use these clusters and the respective words to get a
topic similarity score for each word in the network. In other words, we
transform a hard clustering of words into topics into a probability
score of how likely a certain word belongs to a given topic/cluster.&lt;/p&gt;
&lt;p&gt;The presentation is structured as follows:&lt;/p&gt;
&lt;p&gt;References: David M. Blei, Andrew Y. Ng, Michael I. Jordan: Latent
dirichlet allocation. In: Journal of Machine Learning Research, Jg. 3
(2003), S. 993‚Äì1022, ISSN 1532-4435 M. Rosvall and C. T. Bergstrom, Maps
of information flow reveal community structure in complex networks, PNAS
105, 1118 (2008) &lt;a class="reference external" href="http://dx.doi.org/10.1073/pnas.0706851105"&gt;http://dx.doi.org/10.1073/pnas.0706851105&lt;/a&gt;,
&lt;a class="reference external" href="http://arxiv.org/abs/0707.0609"&gt;http://arxiv.org/abs/0707.0609&lt;/a&gt;&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Artificial Intelligence"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Data Science"></category><category term="Networks"></category><category term="NLP"></category><category term="Machine Learning"></category><category term="Visualisation"></category></entry><entry><title>Productionizing your ML code seamlessly</title><link href="https://pyvideo.org/pycon-de-2018/productionizing-your-ml-code-seamlessly.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Lauris Jullien</name></author><id>tag:pyvideo.org,2018-10-24:/pycon-de-2018/productionizing-your-ml-code-seamlessly.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Data science and Machine Learning are hot topics right now for Software
Engineers and beyond. There are a lot of python tools that allow you to
hack together a notebook to quickly get insight on your data, or train a
model to predict or classify. Or you might have ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Data science and Machine Learning are hot topics right now for Software
Engineers and beyond. There are a lot of python tools that allow you to
hack together a notebook to quickly get insight on your data, or train a
model to predict or classify. Or you might have inherited some data
wrangling and modeling {Jupyter/Zeppelin} notebook code from someone
else, like the resident data scientist.&lt;/p&gt;
&lt;p&gt;The code works on test data, when you run the cells in the right order
(skipping cell 22), and you believe that the insight gained from this
work would be a valuable game changer. But now how do you take this
experimental code into production, and keep it up-to-date with a regular
retraining schedule? And what do you need to do after that, to ensure
that it remains reliable and brings value in the long term?&lt;/p&gt;
&lt;p&gt;These will be the questions this talk will answer, focusing on 2 main
themes: What does running an ML model in production involve? How to
improve your development workflow to make the path to production easier?&lt;/p&gt;
&lt;p&gt;This talk will draw examples from real projects at Yelp, like migrating
a pandas/sklearn classification project into production with pyspark,
while aiming to give advice that is not dependent on specific
frameworks, or tools, and is useful for listeners from all backgrounds.&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Artificial Intelligence"></category><category term="Data Science"></category><category term="Machine Learning"></category></entry><entry><title>reticulate: R interface to Python</title><link href="https://pyvideo.org/pycon-de-2018/reticulate-r-interface-to-python.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Jens Bruno Wittek</name></author><id>tag:pyvideo.org,2018-10-24:/pycon-de-2018/reticulate-r-interface-to-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python and R are the preferred languages for data science. In 2018,
RStudio introduced its package reticulate and clearly demonstrates that
it favours to join forces. Both languages have strengths and weaknesses.
Tools to combine the strengths will enable easier collaboration in
projects and more possibilities to succeed. Using ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python and R are the preferred languages for data science. In 2018,
RStudio introduced its package reticulate and clearly demonstrates that
it favours to join forces. Both languages have strengths and weaknesses.
Tools to combine the strengths will enable easier collaboration in
projects and more possibilities to succeed. Using Python from R gives R
users wider access to functions and makes it easier for Python beginners
to just run scripts and being able to collaborate in Python projects.
The talk will show the possibilities of reticulate: The main part starts
with demonstrating the Python interpreter within R. It will show how to
source Python scripts as well as install and import modules. Then it
will deal with the most important types of Python objects, how they are
represented in R and how to further manipulate them. Thereby, a special
focus is on using Python for data science. In addition, it will be
presented how Conda environments can be created and used from R. A
further application will be the creation of reports with Markdown and
LaTeX where R and Python can be used within one document and share
objects. A last topic is about showing the possibilities for easier
development in RStudio (help regarding Python functions, auto
completion).&lt;/p&gt;
</content><category term="PyCon DE 2018"></category><category term="Artificial Intelligence"></category><category term="Algorithms"></category><category term="Big Data"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Data Science"></category><category term="NLP"></category><category term="Machine Learning"></category><category term="Visualisation"></category></entry><entry><title>Por qu√© Charles Xavier debe cambiar Cerebro por Python</title><link href="https://pyvideo.org/pycon-es-2014/por-que-charles-xavier-debe-cambiar-cerebro-por-python.html" rel="alternate"></link><published>2015-04-06T00:00:00+00:00</published><updated>2015-04-06T00:00:00+00:00</updated><author><name>Mayte Gimenez</name></author><id>tag:pyvideo.org,2015-04-06:/pycon-es-2014/por-que-charles-xavier-debe-cambiar-cerebro-por-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Los buenos de Marvel han liberado su API, ¬øqu√© quiere decir esto? ¬°Un mont√≥n de datos para jugar!&lt;/p&gt;
&lt;p&gt;La premisa que queremos estudiar mediante el an√°lisis de los datos disponibles a trav√©s de la API de Marvel es la variedad de personajes femeninos y de personajes de minor√≠as culturales ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Los buenos de Marvel han liberado su API, ¬øqu√© quiere decir esto? ¬°Un mont√≥n de datos para jugar!&lt;/p&gt;
&lt;p&gt;La premisa que queremos estudiar mediante el an√°lisis de los datos disponibles a trav√©s de la API de Marvel es la variedad de personajes femeninos y de personajes de minor√≠as culturales y raciales (en occidente) que hay en el mundo Marvel as√≠ como los roles en los que est√°n representados m√°s frecuentemente. ¬øDe qu√© color dir√≠as que tiene el pelo el personaje t√≠pico de Marvel? ¬øY cu√°l es su nacionalidad?&lt;/p&gt;
&lt;p&gt;El objetivo de la charla es ense√±ar las distintas herramientas de las que disponemos los cient√≠ficos para el an√°lisis de datos. Usando ipython Notebook veremos como cargar datos y extraer informaci√≥n de ellos usando pandas, c√≥mo dibujar gr√°ficas con matplotlib.&lt;/p&gt;
&lt;p&gt;Adem√°s aplicaremos Machine Learning para distinguir clases (iris, spam,...) aplicado a la muestra de personajes de Marvel que hay disponibles a trav√©s de la citada API, para ello utilizaremos el toolkit scikit-learn.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://nbviewer.ipython.org/github/mshopper/aurora/blob/master/Aurora.ipynb"&gt;http://nbviewer.ipython.org/github/mshopper/aurora/blob/master/Aurora.ipynb&lt;/a&gt;&lt;/p&gt;
</content><category term="PyCon ES 2014"></category><category term="marvel api"></category><category term="ipython"></category><category term="notebook"></category><category term="machine learning"></category></entry><entry><title>Machine Learning in production</title><link href="https://pyvideo.org/pycon-es-2017/machine-learning-in-production.html" rel="alternate"></link><published>2017-09-23T12:00:00+02:00</published><updated>2017-09-23T12:00:00+02:00</updated><author><name>Luis Mesas</name></author><id>tag:pyvideo.org,2017-09-23:/pycon-es-2017/machine-learning-in-production.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Una vez tenemos el modelo dise√±ado por los data scientists hay que ponerlo en pro, pero ninguna de las herramientas que han usado son viables en producci√≥n y tienen problemas de escalabilidad ¬øQue hacemos ahora?. En esta charla veremos arquitecturas aplicadas a 2 casos de uso t√≠picos: arquitectura de ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Una vez tenemos el modelo dise√±ado por los data scientists hay que ponerlo en pro, pero ninguna de las herramientas que han usado son viables en producci√≥n y tienen problemas de escalabilidad ¬øQue hacemos ahora?. En esta charla veremos arquitecturas aplicadas a 2 casos de uso t√≠picos: arquitectura de ejecuci√≥n √∫nica reutilizable y arquitectura de uso cont√≠nuo con bucle de feedback.&lt;/p&gt;
</content><category term="PyCon ES 2017"></category><category term="machine learning"></category></entry><entry><title>Machine Learning for developers</title><link href="https://pyvideo.org/pycon-es-2017/machine-learning-for-developers.html" rel="alternate"></link><published>2017-09-23T11:00:00+02:00</published><updated>2017-09-23T11:00:00+02:00</updated><author><name>Rodrigo Cabello</name></author><id>tag:pyvideo.org,2017-09-23:/pycon-es-2017/machine-learning-for-developers.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Siempre has escuchado el termino Machine learning y pones caras raras? En esta sesi√≥n explicaremos de una manera muy sencilla los principales conceptos. Tambi√©n veremos c√≥mo Azure Machine Learning Studio nos ayudar√° a crear nuestros experimentos de una manera f√°cil y sencilla. Adem√°s veremos c√≥mo Python nos puede echar ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Siempre has escuchado el termino Machine learning y pones caras raras? En esta sesi√≥n explicaremos de una manera muy sencilla los principales conceptos. Tambi√©n veremos c√≥mo Azure Machine Learning Studio nos ayudar√° a crear nuestros experimentos de una manera f√°cil y sencilla. Adem√°s veremos c√≥mo Python nos puede echar una mano a la hora de ejecutar algunos scripts que puedan ser necesarios para pre-procesar nuestros datos.&lt;/p&gt;
&lt;p&gt;Introducci√≥n a Machine Learning ¬øQu√© es?&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Principales conceptos:&lt;/li&gt;
&lt;li&gt;Aprendizaje supervisado y no supervisado&lt;/li&gt;
&lt;li&gt;Aprendizaje supervisado&lt;/li&gt;
&lt;li&gt;Clasificaci√≥n&lt;/li&gt;
&lt;li&gt;Regresi√≥n&lt;/li&gt;
&lt;li&gt;Detecci√≥n de anomal√≠as.&lt;/li&gt;
&lt;li&gt;Algoritmos de aprendizaje autom√°tico&lt;/li&gt;
&lt;li&gt;Tipos de algoritmos&lt;/li&gt;
&lt;li&gt;¬øC√≥mo puedo elegir el algoritmo adecuado?&lt;/li&gt;
&lt;li&gt;Python tools visual studio (¬°Soporte para Python en VS!)&lt;/li&gt;
&lt;li&gt;Probar nuestros scripts de python&lt;/li&gt;
&lt;li&gt;Azure Machine Learning Studio&lt;/li&gt;
&lt;li&gt;Obtener los datos&lt;/li&gt;
&lt;li&gt;Preprocesar los datos&lt;/li&gt;
&lt;li&gt;Definir las caracter√≠sticas&lt;/li&gt;
&lt;li&gt;Elegir y aplicar un algoritmos de aprendizaje&lt;/li&gt;
&lt;li&gt;Probar nuestro experimento y publicarlo&lt;/li&gt;
&lt;li&gt;Ejemplos adicionales de experimentos&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Por √∫ltimo, veremos una aplicaci√≥n desarrollada en Flask que realizar√° el proceso de cuantizaci√≥n de im√°genes haciendo uso de los Web services creados con Azure Machine Learning.&lt;/p&gt;
</content><category term="PyCon ES 2017"></category><category term="machine learning"></category></entry><entry><title>Predicting the past</title><link href="https://pyvideo.org/pycon-ireland-2017/predicting-the-past.html" rel="alternate"></link><published>2017-10-21T00:00:00+00:00</published><updated>2017-10-21T00:00:00+00:00</updated><author><name>Piotr Milian</name></author><id>tag:pyvideo.org,2017-10-21:/pycon-ireland-2017/predicting-the-past.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk I would like to present basic techniques in counter-factual predictions that are used for uplift analysis in marketing. The idea is to use time series prediction models to predict the past after certain intervention date (our marketing action) and compare what would have happened to what ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk I would like to present basic techniques in counter-factual predictions that are used for uplift analysis in marketing. The idea is to use time series prediction models to predict the past after certain intervention date (our marketing action) and compare what would have happened to what actually happened. With some basic black magic trickery (statistics) we can then draw conclusions about effectiveness of the marketing intervention. This basic talk would cover using simple off the shelf tools (fbprophet) and ML techniques.&lt;/p&gt;
</content><category term="PyCon Ireland 2017"></category><category term="fbprophet"></category><category term="machine learning"></category></entry><entry><title>Building a Fine Grained Image Classification System</title><link href="https://pyvideo.org/pycon-ireland-2018/building-a-fine-grained-image-classification-system.html" rel="alternate"></link><published>2018-11-10T00:00:00+00:00</published><updated>2018-11-10T00:00:00+00:00</updated><author><name>Fergal Walsh</name></author><id>tag:pyvideo.org,2018-11-10:/pycon-ireland-2018/building-a-fine-grained-image-classification-system.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At Fieldguide we are developing a digital field guide for all species of flora and fauna across the planet. We are using image recognition technology to enable species identification and to help with the curation of this massive catalogue. In this talk I will describe how we are building ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At Fieldguide we are developing a digital field guide for all species of flora and fauna across the planet. We are using image recognition technology to enable species identification and to help with the curation of this massive catalogue. In this talk I will describe how we are building an image recognition system with the aim of identifying all known species in the natural world. The system has gone through a number of iterations at this point using a variety of computer vision and machine learning techniques, from nearest neighbour search to classification with fine tuned deep convolutional networks. All of this has been implemented in Python using scikit-learn, Numpy, Caffe and Tensorflow. Aside from the obvious machine learning challenges in designing and training such a system we faced numerous technical challenges while implementing and scaling this system in a cost effective manner. I will discuss these challenges, our solutions and the remaining open problems. While this talk will be relatively high level with few code examples and no math (but lots moths), it will be of most interest to those who have some knowledge of machine learning concepts.&lt;/p&gt;
</content><category term="PyCon Ireland 2018"></category><category term="image-recognition"></category><category term="Computer Vision"></category><category term="machine learning"></category></entry><entry><title>Patient Data Made Real</title><link href="https://pyvideo.org/pycon-ireland-2018/patient-data-made-real.html" rel="alternate"></link><published>2018-11-10T00:00:00+00:00</published><updated>2018-11-10T00:00:00+00:00</updated><author><name>Lorenzo Trojan</name></author><id>tag:pyvideo.org,2018-11-10:/pycon-ireland-2018/patient-data-made-real.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we will present how python is used to develop a machine learning based 3D medical imaging processing pipeline in axial3D. We will provide a demo taking relevant scientific packages and develop a simple algorithm to detect bony anatomy. A 3D printable model will be produced at ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we will present how python is used to develop a machine learning based 3D medical imaging processing pipeline in axial3D. We will provide a demo taking relevant scientific packages and develop a simple algorithm to detect bony anatomy. A 3D printable model will be produced at the end of the demo. We will also show how we use existing 3D mesh python packages to adjust properties of the object for visualisation in screen and mixed reality platforms. The healthcare sector produces vast quantities of three dimensional images for the diagnosis and treatment of a large variety of medical conditions. Traditionally, the 3D images are reviewed by a highly qualified healthcare professional such as a radiologist or surgeon. As a result, the diagnosis and treatment of patient is time consuming, expensive and not scalable; moreover, this approach has limited efficacy as the medical doctor may not be able to obtain a general understanding of the anatomic three dimensional structure (e.g the shape and size of a tumor, the position of each bony fragment in a complex fracture, the location of an aneurysm together with surrounding vasculature, etc). The talk will focus on the advanced image processing techniques and Deep Learning approaches that are in active development developed both within academia and the private sector. These approaches aim to achieve a faster and better understanding of medical scans. They allow healthcare systems to provide a cheaper, faster and more effective medical service to patients. The results of the image analysis can then be rendered to the medical staff using a Virtual Reality, or an Augmented Reality system. 3D prints can also be employed to convey a very tangible experience as well as allow the medical staff to prepare for the operation by setting up a mock procedure on the 3D prints.&lt;/p&gt;
</content><category term="PyCon Ireland 2018"></category><category term="machine learning"></category></entry><entry><title>Prediction of risk factors for stroke</title><link href="https://pyvideo.org/pycon-ireland-2018/prediction-of-risk-factors-for-stroke.html" rel="alternate"></link><published>2018-11-10T00:00:00+00:00</published><updated>2018-11-10T00:00:00+00:00</updated><author><name>Olga Lyashevska</name></author><id>tag:pyvideo.org,2018-11-10:/pycon-ireland-2018/prediction-of-risk-factors-for-stroke.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Atrial fibrillation (AF) is the most common irregular heartbeat among the world‚Äôs population and is a major contributing factor to clot formation within the heart. When such a blood clot enters the cardiovascular system, it first must travel along the ascending aorta. The clot may travel along the ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Atrial fibrillation (AF) is the most common irregular heartbeat among the world‚Äôs population and is a major contributing factor to clot formation within the heart. When such a blood clot enters the cardiovascular system, it first must travel along the ascending aorta. The clot may travel along the aortic arch and travel towards the brain through the left and right common carotid arteries. If clot enters these vessels, it can become lodged within the smaller vessels of the brain and cause a stroke. We apply supervised machine learning classifiers (logit, SVM) for detecting stroke probability using simulation data. Various scenarios are implemented to examine the impact of variables such as shape of the aortic arch, varying clot dimensions and the entry point. Model selection tools (grid search, cross-validation) and classification probability are calculated for each classifier. Application will be shown using Jupyter notebooks.&lt;/p&gt;
</content><category term="PyCon Ireland 2018"></category><category term="machine learning"></category></entry><entry><title>Differential network analysis and graph classification: a glocal approach</title><link href="https://pyvideo.org/pycon-italia-2017/differential-network-analysis-and-graph-classification-a-glocal-approach.html" rel="alternate"></link><published>2017-04-09T00:00:00+00:00</published><updated>2017-04-09T00:00:00+00:00</updated><author><name>Giuseppe Jurman</name></author><id>tag:pyvideo.org,2017-04-09:/pycon-italia-2017/differential-network-analysis-and-graph-classification-a-glocal-approach.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We propose a novel solution in differential network analysis to both the
network comparison and the classification tasks by introducing the
glocal HIM metric for comparing graphs and a graph kernel induced by the
HIM measure. The HIM distance is defined as the one-parameter family of
product metrics linearly ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We propose a novel solution in differential network analysis to both the
network comparison and the classification tasks by introducing the
glocal HIM metric for comparing graphs and a graph kernel induced by the
HIM measure. The HIM distance is defined as the one-parameter family of
product metrics linearly combining the normalised Hamming distance H and
the normalised Ipsen- Mikhailov spectral distance IM. The combination of
the two components within a single metric allows overcoming their
drawbacks and obtaining a measure which is simultaneously global and
local. Furthermore, plugging the HIM kernel into a Support Vector
Machine gives us a classification algorithm based on the HIM distance.
Here we outline the underlying theoretical details of the metric
construction, and we present several applications of the HIM distance
and the HIM kernel to datasets belonging to different areas, including
socioeconomics, neuroscience, oncogenomics and developmental genomics,
supporting the adoption of the HIM family as a general analysis tool for
information extraction based on a quantitative evaluation of the
difference among diverse instances of a complex system. We conclude
introducing the Open Source implementation of the HIM metrics provided
in the R package nettols and in its web interface ReNette.&lt;/p&gt;
</content><category term="PyCon Italia 2017"></category><category term="mathematics"></category><category term="algebra"></category><category term="Network"></category><category term="Machine Learning"></category></entry><entry><title>Explore the brain with Nilearn</title><link href="https://pyvideo.org/pycon-italia-2017/explore-the-brain-with-nilearn.html" rel="alternate"></link><published>2017-04-09T00:00:00+00:00</published><updated>2017-04-09T00:00:00+00:00</updated><author><name>Darya Chyzhyk</name></author><id>tag:pyvideo.org,2017-04-09:/pycon-italia-2017/explore-the-brain-with-nilearn.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the past recent years, the Python programming language became popular
and widely used in many science areas, that you can notes from huge
amount of high quality &lt;strong&gt;scientific&lt;/strong&gt; libraries available in GitHub.
Python has already won the confidence in neuro-imaging community&lt;/p&gt;
&lt;p&gt;Analysis of different &lt;strong&gt;neuroimaging&lt;/strong&gt; modalities consists of ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the past recent years, the Python programming language became popular
and widely used in many science areas, that you can notes from huge
amount of high quality &lt;strong&gt;scientific&lt;/strong&gt; libraries available in GitHub.
Python has already won the confidence in neuro-imaging community&lt;/p&gt;
&lt;p&gt;Analysis of different &lt;strong&gt;neuroimaging&lt;/strong&gt; modalities consists of
identifying such a complex pipeline that include supporting specific
&lt;strong&gt;MRI&lt;/strong&gt; data acquisition, image processing, statistics and predictive
modeling, and visualization of the results. &lt;strong&gt;Nilearn&lt;/strong&gt; is a Python
package designed to face these challenges. It provides state-of-the-art
&lt;strong&gt;machine-learning&lt;/strong&gt; methods for analysis task fMRI, resting-state, or
anathomical data. In my talk, I would like to present general purpose of
Nilearn, focusing on &lt;strong&gt;functional connectivity&lt;/strong&gt; and &lt;strong&gt;connectome&lt;/strong&gt;
analysis in resting-state fMRI.&lt;/p&gt;
</content><category term="PyCon Italia 2017"></category><category term="computer-science"></category><category term="cognitive-science"></category><category term="Artificial Intelligence"></category><category term="Machine Learning"></category></entry><entry><title>Facial Analysis Techniques for Pythonista (and beyond!)</title><link href="https://pyvideo.org/pycon-italia-2017/facial-analysis-techniques-for-pythonista-and-beyond.html" rel="alternate"></link><published>2017-04-09T00:00:00+00:00</published><updated>2017-04-09T00:00:00+00:00</updated><author><name>Alex Casalboni</name></author><id>tag:pyvideo.org,2017-04-09:/pycon-italia-2017/facial-analysis-techniques-for-pythonista-and-beyond.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The ability to detect, track, and analyze faces opens up a wide range of
interesting use cases, ranging from interactive smart applications and
real- time video processing, all the way to biometric security and
augmented reality.&lt;/p&gt;
&lt;p&gt;This talk will showcase the available &lt;strong&gt;tools built by the Python
community&lt;/strong&gt; and ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The ability to detect, track, and analyze faces opens up a wide range of
interesting use cases, ranging from interactive smart applications and
real- time video processing, all the way to biometric security and
augmented reality.&lt;/p&gt;
&lt;p&gt;This talk will showcase the available &lt;strong&gt;tools built by the Python
community&lt;/strong&gt; and their corresponding pros &amp;amp; cons, limitations, and
complexity. While discussing the possible scenarios and what is actually
required to &lt;strong&gt;DIY with Python&lt;/strong&gt;, I will compare such handmade solutions
with &lt;strong&gt;Cloud-based products and APIs&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;: basic understanding of Python‚Äôs data science stack
(especially numpy).&lt;/p&gt;
</content><category term="PyCon Italia 2017"></category><category term="CloudComputing"></category><category term="aws"></category><category term="scikit-learn"></category><category term="scikit-image"></category><category term="google-cloud"></category><category term="Deep-Learning"></category><category term="opencv"></category><category term="scikits"></category><category term="cv"></category><category term="Machine Learning"></category><category term="Facial-Analysis"></category><category term="dlib"></category><category term="Artificial Intelligence"></category></entry><entry><title>Tensor decomposition with Python: Learning structures from multidimensional data</title><link href="https://pyvideo.org/pycon-italia-2017/tensor-decomposition-with-python-learning-structures-from-multidimensional-data.html" rel="alternate"></link><published>2017-04-09T00:00:00+00:00</published><updated>2017-04-09T00:00:00+00:00</updated><author><name>Andr√© Panisson</name></author><id>tag:pyvideo.org,2017-04-09:/pycon-italia-2017/tensor-decomposition-with-python-learning-structures-from-multidimensional-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Many problems in signal processing and machine learning generate massive
amounts of multidimensional data. Data sources from sensor networks and
Internet-of-Things applications promise a wealth of interaction data
that can be naturally represented as tensors. Tensor decompositions have
gained a steadily increasing popularity in data mining and machine
learning ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Many problems in signal processing and machine learning generate massive
amounts of multidimensional data. Data sources from sensor networks and
Internet-of-Things applications promise a wealth of interaction data
that can be naturally represented as tensors. Tensor decompositions have
gained a steadily increasing popularity in data mining and machine
learning, with applications in psychometrics, chemometrics, signal
processing, computer vision, neuroscience, graph analysis, and more. For
example, time-varying social networks collected from wearable proximity
sensors can be represented as 3-way tensors, and tensor decomposition
can be used to extract community structures with their structural and
temporal signatures.&lt;/p&gt;
&lt;p&gt;The current standard framework for working with tensors, however, is
Matlab. We will show how tensor decompositions can be carried out using
Python, how to obtain latent components and how they can be interpreted,
and what are some applications of this technique in the academy and
industry. We will see a use case where a Python implementation of tensor
decomposition is applied to a dataset that describes face-to-face social
interactions of people, collected using the
&lt;a class="reference external" href="http://www.sociopatterns.org/"&gt;SocioPatterns&lt;/a&gt; platform. This
platform was deployed in different settings such as conferences, schools
and hospitals, in order to support mathematical modelling and simulation
of airborne infectious diseases. Tensor decomposition has been used in
these scenarios to solve different types of problems: it is used for
data cleaning, where time-varying graph anomalies can be identified and
removed from data; it have been also used to assess the impact of
face-to-face interactions in the spreading of diseases. These examples
show the potential of this technique in data mining and machine learning
applications.&lt;/p&gt;
</content><category term="PyCon Italia 2017"></category><category term="mathematical-modelling"></category><category term="datamining"></category><category term="machine-learning"></category></entry><entry><title>AI, Machine Learning e Deep Learning: cosa cambia?</title><link href="https://pyvideo.org/pycon-italia-2017/ai-machine-learning-e-deep-learning-cosa-cambia.html" rel="alternate"></link><published>2017-04-08T00:00:00+00:00</published><updated>2017-04-08T00:00:00+00:00</updated><author><name>Antonio Spadaro</name></author><id>tag:pyvideo.org,2017-04-08:/pycon-italia-2017/ai-machine-learning-e-deep-learning-cosa-cambia.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Artificial Intelligence&lt;/strong&gt;, &lt;strong&gt;Machine Learning&lt;/strong&gt; e &lt;strong&gt;Deep Learning&lt;/strong&gt;:
cosa sono e qual‚Äô√® la loro storia? Ma soprattutto quali sono le
differenze tra questi tre?&lt;/p&gt;
&lt;p&gt;Questo talk √® orientato a coloro che non hanno alcuna base su nessuno di
questi argomenti&lt;/p&gt;
</content><category term="PyCon Italia 2017"></category><category term="Deep-Learning"></category><category term="machine-learning"></category><category term="Artificial Intelligence"></category><category term="Machine Learning"></category></entry><entry><title>AI, Machine Learning e Deep Learning: cosa cambia?</title><link href="https://pyvideo.org/pycon-italia-2017/ai-machine-learning-e-deep-learning-cosa-cambia.html" rel="alternate"></link><published>2017-04-08T00:00:00+00:00</published><updated>2017-04-08T00:00:00+00:00</updated><author><name>Antonio Spadaro</name></author><id>tag:pyvideo.org,2017-04-08:/pycon-italia-2017/ai-machine-learning-e-deep-learning-cosa-cambia.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Artificial Intelligence&lt;/strong&gt;, &lt;strong&gt;Machine Learning&lt;/strong&gt; e &lt;strong&gt;Deep Learning&lt;/strong&gt;:
cosa sono e qual‚Äô√® la loro storia? Ma soprattutto quali sono le
differenze tra questi tre?&lt;/p&gt;
&lt;p&gt;Questo talk √® orientato a coloro che non hanno alcuna base su nessuno di
questi argomenti&lt;/p&gt;
</content><category term="PyCon Italia 2017"></category><category term="Deep-Learning"></category><category term="machine-learning"></category><category term="Artificial Intelligence"></category><category term="Machine Learning"></category></entry><entry><title>Machine Learning con Python: algoritmi NILM e real-time processing</title><link href="https://pyvideo.org/pycon-italia-2017/machine-learning-con-python-algoritmi-nilm-e-real-time-processing.html" rel="alternate"></link><published>2017-04-08T00:00:00+00:00</published><updated>2017-04-08T00:00:00+00:00</updated><author><name>Felice Tuosto</name></author><id>tag:pyvideo.org,2017-04-08:/pycon-italia-2017/machine-learning-con-python-algoritmi-nilm-e-real-time-processing.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Le tecniche di Machine Learning sono sempre pi√π pervasive nelle
applicazioni analitiche odierne. In questo talk l‚Äôattenzione verte sul
problema del &lt;strong&gt;NILM&lt;/strong&gt; (Not Intrusive Load Monitoring) per cui
l‚Äôobiettivo √® la disaggregazione real-time dei consumi di energia
elettrica. Gli algoritmi, permettono di riconoscere in realtime i
dispositivi ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Le tecniche di Machine Learning sono sempre pi√π pervasive nelle
applicazioni analitiche odierne. In questo talk l‚Äôattenzione verte sul
problema del &lt;strong&gt;NILM&lt;/strong&gt; (Not Intrusive Load Monitoring) per cui
l‚Äôobiettivo √® la disaggregazione real-time dei consumi di energia
elettrica. Gli algoritmi, permettono di riconoscere in realtime i
dispositivi attivi in base alle sole caratteristiche del segnale
aggregato.&lt;/p&gt;
&lt;p&gt;L‚Äôobiettivo del talk √® dimostrare come sia possibile implementare
rapidamente un prototipo hardware e software grazie alle potenzialit√† di
Arduino e Python rispettivamente.&lt;/p&gt;
&lt;p&gt;Con degli &lt;em&gt;esempi hardware e software pratici&lt;/em&gt; (4 devices collegati ad
una multipresa), verr√† dimostrata la capacit√† di Arduino di acquisire le
misura di corrente elettrica e la capacit√† di Python di riconoscere i
dispositivi attivi. Verranno fornite informazioni sulle logiche alla
base di tali algoritmi, con riferimento all‚Äôecosistema Python e alle
relative librerie utilizzate.&lt;/p&gt;
&lt;p&gt;Per la comprensione del talk non sono necessari particolari requisiti se
non una conoscenza di base di programmazione in Python e di Machine
Learning.&lt;/p&gt;
</content><category term="PyCon Italia 2017"></category><category term="signal-processing"></category><category term="arduino"></category><category term="nilm"></category><category term="machine-learning"></category><category term="realtime"></category></entry><entry><title>Machine Learning con Python: previsione in real-time della richiesta di energia elettrica</title><link href="https://pyvideo.org/pycon-italia-2017/machine-learning-con-python-previsione-in-real-time-della-richiesta-di-energia-elettrica.html" rel="alternate"></link><published>2017-04-08T00:00:00+00:00</published><updated>2017-04-08T00:00:00+00:00</updated><author><name>Felice Tuosto</name></author><id>tag:pyvideo.org,2017-04-08:/pycon-italia-2017/machine-learning-con-python-previsione-in-real-time-della-richiesta-di-energia-elettrica.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Nel talk si parler√† di come attraverso il linguaggio Python sia
possibile risolvere un problema reale e complesso relativamente alla
trasmissione di energia elettrica. Verr√† spiegato il progetto
&lt;strong&gt;RealtimeLoadForecast&lt;/strong&gt; che √® stato sviluppato per un importante TSO
(Transmission System Operator). Si tratta di sistema predittivo che
permette di fornire ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Nel talk si parler√† di come attraverso il linguaggio Python sia
possibile risolvere un problema reale e complesso relativamente alla
trasmissione di energia elettrica. Verr√† spiegato il progetto
&lt;strong&gt;RealtimeLoadForecast&lt;/strong&gt; che √® stato sviluppato per un importante TSO
(Transmission System Operator). Si tratta di sistema predittivo che
permette di fornire in tempo reale ogni 15 minuti ed entro 5 minuti, le
previsioni delle serie storiche dei consumi di energia elettrica
relativi a circa 500 nodi elettrici.&lt;/p&gt;
&lt;p&gt;Si parler√† dei passi che occorre seguire per ottenere da un semplice
prototipo, un sistema &lt;em&gt;ingegnerizzato&lt;/em&gt; che lavori in tempo reale e di
come sono state utilizzate le librerie di Python per l‚Äôacquisizione,
manipolazione e processamento dei dati elettrici ed ambientali.&lt;/p&gt;
&lt;p&gt;Saranno descritte alcune tecniche algoritmiche e di Machine Learning per
ottenere dei modelli predittivi capaci di fornire previsioni accurate ma
con tempi di risposta sfidanti.&lt;/p&gt;
&lt;p&gt;Verr√† mostrato un &lt;em&gt;esempio concreto&lt;/em&gt; di implementazione di un algoritmo
predittivo basato sulla libreria Deep Learning &lt;strong&gt;Keras&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Per la comprensione del talk non sono necessari particolari requisiti se
non una conoscenza di base di programmazione in Python e di Machine
Learning.&lt;/p&gt;
</content><category term="PyCon Italia 2017"></category><category term="Forecasting"></category><category term="Genetic Algorithms"></category><category term="Keras"></category><category term="Data Mining"></category><category term="programming-paradigms"></category><category term="scikit-learn"></category><category term="bigdata"></category><category term="scalability"></category><category term="Deep-Learning"></category><category term="threading"></category><category term="realtime"></category><category term="Data-Scientist"></category><category term="database"></category><category term="machine-learning"></category><category term="mysql"></category><category term="signal-processing"></category><category term="LoadForecasting"></category><category term="cassandra"></category></entry><entry><title>A Gentle Introduction to Neural Networks (with Python)</title><link href="https://pyvideo.org/pycon-italia-2017/a-gentle-introduction-to-neural-networks-with-python.html" rel="alternate"></link><published>2017-04-07T00:00:00+00:00</published><updated>2017-04-07T00:00:00+00:00</updated><author><name>Tariq Rashid</name></author><id>tag:pyvideo.org,2017-04-07:/pycon-italia-2017/a-gentle-introduction-to-neural-networks-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A gentle introduction to neural networks, and making your own with
Python.&lt;/p&gt;
&lt;p&gt;This session is especially designed to be accessible to everyone,
including anyone with no expertise in mathematics, computer science or
Python.&lt;/p&gt;
&lt;p&gt;From this session you will have an intuitive understanding of what
neural networks are and how ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A gentle introduction to neural networks, and making your own with
Python.&lt;/p&gt;
&lt;p&gt;This session is especially designed to be accessible to everyone,
including anyone with no expertise in mathematics, computer science or
Python.&lt;/p&gt;
&lt;p&gt;From this session you will have an intuitive understanding of what
neural networks are and how they work. If you are more technically
capable, you will see how you could make your own with Python and numpy.&lt;/p&gt;
&lt;p&gt;Part 1 - Ideas:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;the search for AI, hard problems for computers easy for humans&lt;/li&gt;
&lt;li&gt;learning from examples (simple classifier)&lt;/li&gt;
&lt;li&gt;biologically inspired neurons and networks&lt;/li&gt;
&lt;li&gt;training a neural network&lt;/li&gt;
&lt;li&gt;the back propagation breakthrough&lt;/li&gt;
&lt;li&gt;matrix ways of working (good for computers)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Part 2 - Python:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Python is easy, and everywhere&lt;/li&gt;
&lt;li&gt;Python notebooks&lt;/li&gt;
&lt;li&gt;the MNIST data set&lt;/li&gt;
&lt;li&gt;a very simple neural network class&lt;/li&gt;
&lt;li&gt;focus on concise and efficient matrix calculations with numpy&lt;/li&gt;
&lt;li&gt;97.5% accuracy recognising handwritten numbers - with just a few lines of code!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Part 3 - Live Demo! ‚Ä¶ and Q&amp;amp;A&lt;/p&gt;
</content><category term="PyCon Italia 2017"></category><category term="image-processing"></category><category term="numpy"></category><category term="neural network"></category><category term="Artificial Intelligence"></category><category term="Machine Learning"></category></entry><entry><title>The unconventional Introduction to Deep Learning</title><link href="https://pyvideo.org/pycon-italia-2017/the-unconventional-introduction-to-deep-learning.html" rel="alternate"></link><published>2017-04-07T00:00:00+00:00</published><updated>2017-04-07T00:00:00+00:00</updated><author><name>Valerio Maggio</name></author><id>tag:pyvideo.org,2017-04-07:/pycon-italia-2017/the-unconventional-introduction-to-deep-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you are into Deep Learning, sooner or later, it inevitbly happens
that you‚Äôre asked at least once to explain what actually means &lt;strong&gt;Deep
Learning&lt;/strong&gt; , and what‚Äôs all the fuss about it.&lt;/p&gt;
&lt;p&gt;Indeed, answering this question in a proper way, may vary (and it has
to) depending ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you are into Deep Learning, sooner or later, it inevitbly happens
that you‚Äôre asked at least once to explain what actually means &lt;strong&gt;Deep
Learning&lt;/strong&gt; , and what‚Äôs all the fuss about it.&lt;/p&gt;
&lt;p&gt;Indeed, answering this question in a proper way, may vary (and it has
to) depending on the kind of audience you‚Äôve been talking to.&lt;/p&gt;
&lt;p&gt;If you are talking to a machine learning experts, you have to
concentrate on what &lt;em&gt;deep&lt;/em&gt; means, for the multiple learning models you
can come up with. Most importarly, you have to convince them that a deep
learning model would work by far better than a more standard and robust
Random Forest or Support Vector Machine.&lt;/p&gt;
&lt;p&gt;On the other hand, if your audience is made up of engineers, they
[STRIKEOUT:don‚Äôt give a damn..] are definitely more interested in how
you implement your Artificial Neural Networks (ANN) rather than
understanding what are the implications of different &lt;em&gt;activations&lt;/em&gt; and
&lt;em&gt;optimizers&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Finally, if your audience is made up of data scientists - who are a good
mixture of the previous two, according to &lt;a class="reference external" href="http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram"&gt;Drew
Conway&lt;/a&gt;
- they are more or less interested in both the two aspects.&lt;/p&gt;
&lt;p&gt;The other way, that is the &lt;em&gt;unconventional way&lt;/em&gt;, to explain what Deep
Learning means, is from the perspective of the computational model it
requires to be properly effective. Therefore, you may want to talk about
ANN in terms of matrix multiplications algorithms, running on a (series
of) GPUs in parallel. And this is &lt;strong&gt;exactly&lt;/strong&gt; the perspecitve I intend
to pursue in this talk.&lt;/p&gt;
&lt;p&gt;This talk is for PyData scientists who are interested in understanding
Deep Learning models from this unconventional perspective, learning what
are the libraries and tools they may leverage for their experiments on
GPUs. Experienced engineers may likely benefit from this talk as well,
learning how they can make their models run fast(er).&lt;/p&gt;
</content><category term="PyCon Italia 2017"></category><category term="Keras"></category><category term="rumba"></category><category term="Deep-Learning"></category><category term="machine-learning"></category><category term="Theano"></category><category term="GPU"></category><category term="tensorflow"></category></entry><entry><title>Where are you going? An overview on machine learning models for human mobility</title><link href="https://pyvideo.org/pycon-italia-2017/where-are-you-going-an-overview-on-machine-learning-models-for-human-mobility.html" rel="alternate"></link><published>2017-04-07T00:00:00+00:00</published><updated>2017-04-07T00:00:00+00:00</updated><author><name>Gianni Barlacchi</name></author><id>tag:pyvideo.org,2017-04-07:/pycon-italia-2017/where-are-you-going-an-overview-on-machine-learning-models-for-human-mobility.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The recent explosion of big mobility data, such as massive traces from
GPS devices and mobile phone networks, opened the door to the study of
the quantitative spatio-temporal patterns characterizing human mobility.
In this talk we will first introduce the audience in the world of human
mobility and related ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The recent explosion of big mobility data, such as massive traces from
GPS devices and mobile phone networks, opened the door to the study of
the quantitative spatio-temporal patterns characterizing human mobility.
In this talk we will first introduce the audience in the world of human
mobility and related challenges. Then, we will briefly show how to deal
in Python with geo- mobility dataset and finally, we will go trough the
recent advances in machine learning and deep learning in the context
human mobility (e.g. prediction of the next visited place).&lt;/p&gt;
</content><category term="PyCon Italia 2017"></category><category term="Deep-Learning"></category><category term="human-mobility"></category><category term="machine-learning"></category></entry><entry><title>Practical Machine Learning with Python and scikit-learn</title><link href="https://pyvideo.org/pycon-italia-2018/practical-machine-learning-with-python-and-scikit-learn.html" rel="alternate"></link><published>2018-04-22T00:00:00+00:00</published><updated>2018-04-22T00:00:00+00:00</updated><author><name>Andrea Grandi</name></author><id>tag:pyvideo.org,2018-04-22:/pycon-italia-2018/practical-machine-learning-with-python-and-scikit-learn.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A tutorial for intermediate Python developers with none or little
knowledge about Machine Learning.&lt;/p&gt;
&lt;p&gt;After presenting an existing dataset and giving a bit of context about
the problem, I will show step by step how to analyse it, train a
supervised classification model, optimise it and make predictions.&lt;/p&gt;
&lt;p&gt;During ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A tutorial for intermediate Python developers with none or little
knowledge about Machine Learning.&lt;/p&gt;
&lt;p&gt;After presenting an existing dataset and giving a bit of context about
the problem, I will show step by step how to analyse it, train a
supervised classification model, optimise it and make predictions.&lt;/p&gt;
&lt;p&gt;During the tutorial we will make use of the following libraries and
tools: pandas, jupyter, matplotlib, numpy, scikit-learn, scipy.&lt;/p&gt;
&lt;p&gt;Even if it won‚Äôt be possible to follow each singular attendee, it‚Äôs
strongly suggested to have a laptop ready with Python 3 installed and a
virtual environment properly configured and ready to be used. In this
way attendees will have the possibility to try the shown code and
examples.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;domenica 22 aprile&lt;/strong&gt; at 11:15 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</content><category term="PyCon Italia 2018"></category><category term="Python"></category><category term="Data-Scientist"></category><category term="scikit-learn"></category><category term="machine-learning"></category></entry><entry><title>What's going on there? Understanding cities with location data.</title><link href="https://pyvideo.org/pycon-italia-2018/whats-going-on-there-understanding-cities-with-location-data.html" rel="alternate"></link><published>2018-04-22T00:00:00+00:00</published><updated>2018-04-22T00:00:00+00:00</updated><author><name>Gianni Barlacchi</name></author><id>tag:pyvideo.org,2018-04-22:/pycon-italia-2018/whats-going-on-there-understanding-cities-with-location-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, the audience will learn how to build from scratch with
Python machine learning models for predicting spatiotemporal activities
in cities using location data.&lt;/p&gt;
&lt;p&gt;The growing availability of data from cities (e.g., traffic flow, human
mobility and geographical data) opens new opportunities for predicting
and thus ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, the audience will learn how to build from scratch with
Python machine learning models for predicting spatiotemporal activities
in cities using location data.&lt;/p&gt;
&lt;p&gt;The growing availability of data from cities (e.g., traffic flow, human
mobility and geographical data) opens new opportunities for predicting
and thus optimizing human activities. These may include human mobility,
land use classification, event detection and location recommendation.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;How do we characterize the main activity of an area (e.g. Business,
Commercial, Nightlife)?&lt;ul&gt;
&lt;li&gt;How to detect and forecast unusual spatiotemporal events (e.g.
protest, sport game, concert)?&lt;/li&gt;
&lt;li&gt;How to understand why people are moving between places?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This talk will try to answers these questions explaining how, making use
of Python, it is possible to (i) collect and aggregate geo-located data;
and (ii) build machine learning models to predict spatiotemporal
activities. For example, an unusual activity in a local area at a
specific time can be predicted by analyzing the text from geo-located
tweets.&lt;/p&gt;
&lt;p&gt;Firstly, we will present an organized picture of geo-located data such
as mobile phone data, geo-located texts from social networks (e.g.
Foursquare and Twitter), census and Open Street Map. Then, we will
briefly discuss how to collect and aggregate such data using Python
packages such as GeoPandas and OSMnx. Finally, we will cover topics
related to cities activities including event detection and forecasting,
human mobility, and location recommendation and prediction.&lt;/p&gt;
&lt;p&gt;As location data, we will mostly use samples from Open Street Map and
Foursquare. The example code will make use of (basics) Pandas and
GeoPandas. However, this is a beginner talk and it will be
self-contained as much as possible.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;domenica 22 aprile&lt;/strong&gt; at 12:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</content><category term="PyCon Italia 2018"></category><category term="geo-data-science"></category><category term="Machine Learning"></category><category term="open-data"></category><category term="location-data"></category></entry><entry><title>Hacking Your Way Into Machine Learning</title><link href="https://pyvideo.org/pycon-italia-2018/hacking-your-way-into-machine-learning.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Laksh Arora</name></author><id>tag:pyvideo.org,2018-04-21:/pycon-italia-2018/hacking-your-way-into-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;You might have heard of Machine Learning from your co-worker or in a local meetup and are enticed to get started but not sure how to take that first step. Confused between different sources, where to start from or how to proceed given a particular problem statement or dataset ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;You might have heard of Machine Learning from your co-worker or in a local meetup and are enticed to get started but not sure how to take that first step. Confused between different sources, where to start from or how to proceed given a particular problem statement or dataset, then this talk is for you. It is aimed at complete beginners ( maybe you? ) who are just starting in machine learning and are ready to commit.
The talk will go something like this - each of the following items will be explained how it‚Äôs useful and why we should use it. Then alongside showcase, that same step applied to the real example(dataset) of that particular item so that the audience will be able to grasp the idea. It will add to around 35 minutes leaving us with 10 minutes for Q&amp;amp;A.
1) Context ( 5 mins ):
Discuss why we need Machine Learning and how we can use Machine Learning in different domains.
2) Resources ( 3 mins):
Talks about the dataset availability, online competitions, and Open Source libraries such as Scikit-learn, Matplotlib, Keras.
3) Jupyter Notebook (25 mins):
This Jupyter notebook will be a great starting point for most Supervised Machine Learning projects that involve common tasks: a) Imports and data loading (2 mins )
b) Data Exploration (5 mins)
c) Data Cleaning (3 mins)
d) Feature Engineering (4 mins)
e) Model Exploration (6 mins)
f) Final Model Building and Prediction ( 5 mins)
4) Wrap up ( 2 mins ):
Finalizing my talk, sharing some tips etc.
5) Q&amp;amp;A ( 10 mins ):
Question and Answering with the Audience.
Hope to inspire the audience to get started with machine learning, explore different domains, to learn, to create and engage with the Machine Learning Community.&lt;/p&gt;
</content><category term="PyCon Italia 2018"></category><category term="data-analysis"></category><category term="data-visualization"></category><category term="Python"></category><category term="scikit-learn"></category><category term="matplotlib"></category><category term="analytics"></category><category term="scipy"></category><category term="machine-learning"></category><category term="data"></category><category term="Statistical Learning"></category></entry><entry><title>Predicting future states using High Order Markov Chains</title><link href="https://pyvideo.org/pycon-italia-2018/predicting-future-states-using-high-order-markov-chains.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Pietro Mascolo</name></author><id>tag:pyvideo.org,2018-04-21:/pycon-italia-2018/predicting-future-states-using-high-order-markov-chains.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In modern automated systems (Interactive Voice Response, help chatbots,
routing systems, etc.) it is very often important to be able to predict
what is the most likely next step for the current user. One way of
addressing this issue is using sequence algorithms such as Markov
Chains.&lt;/p&gt;
&lt;p&gt;After a ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In modern automated systems (Interactive Voice Response, help chatbots,
routing systems, etc.) it is very often important to be able to predict
what is the most likely next step for the current user. One way of
addressing this issue is using sequence algorithms such as Markov
Chains.&lt;/p&gt;
&lt;p&gt;After a quick introduction to the concept of Markov chains and Markov
processes, we will explore the basics and the implementation of a simple
High Order Markov chain to predict what the most likely next state in a
sequence, based on previous states. We will be using anonymized
real-life data of an automated system and we will try to come up with a
model that can give us the most probable next state using Markov chains
of different orders.&lt;/p&gt;
&lt;p&gt;Things we will see in detail: - Mathematics and rationale behind Markov
Chains; - Basic implementation of First Order Markov Chains; -
Implementation of High Order Markov Chains; - Real life application of
the developed model.&lt;/p&gt;
&lt;p&gt;An undergraduate level of understanding of Linear Algebra and basic
Python skills will be useful to follow the talk.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 15:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</content><category term="PyCon Italia 2018"></category><category term="pydata"></category><category term="Pyston"></category><category term="algebra"></category><category term="Machine Learning"></category><category term="scipy"></category><category term="data-analysis"></category><category term="mathematics"></category><category term="data"></category><category term="python3"></category></entry><entry><title>Recent advancements in NLP and Deep Learning: A Quant's Perspective</title><link href="https://pyvideo.org/pycon-italia-2018/recent-advancements-in-nlp-and-deep-learning-a-quants-perspective.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Umit Mert Cakmak</name></author><id>tag:pyvideo.org,2018-04-21:/pycon-italia-2018/recent-advancements-in-nlp-and-deep-learning-a-quants-perspective.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There is a gold-rush among hedge-funds for text mining algorithms to
quantify textual data and generate trading signals. Harnessing the power
of alternative data sources became crucial to find novel ways of
enhancing trading strategies.&lt;/p&gt;
&lt;p&gt;With the proliferation of new data sources, natural language data became
one of the ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There is a gold-rush among hedge-funds for text mining algorithms to
quantify textual data and generate trading signals. Harnessing the power
of alternative data sources became crucial to find novel ways of
enhancing trading strategies.&lt;/p&gt;
&lt;p&gt;With the proliferation of new data sources, natural language data became
one of the most important data sources which could represent the public
sentiment and opinion about market events, which then can be used to
predict financial markets.&lt;/p&gt;
&lt;p&gt;Talk is split into 5 parts;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Who is a quant and how do they use NLP?&lt;/li&gt;
&lt;li&gt;How deep learning has changed NLP?&lt;/li&gt;
&lt;li&gt;Let‚Äôs get dirty with word embeddings&lt;/li&gt;
&lt;li&gt;Performant deep learning layer for NLP: The Recurrent Layer&lt;/li&gt;
&lt;li&gt;Using all that to make money&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="who-is-a-quant-and-how-do-they-use-nlp"&gt;
&lt;h4&gt;1. Who is a quant and how do they use NLP?&lt;/h4&gt;
&lt;p&gt;Quants use mathematical and statistical methods to create algorithmic
trading strategies.&lt;/p&gt;
&lt;p&gt;Due to recent advances in available deep learning frameworks and
datasets (time series, text, video etc) together with decreasing cost of
parallelisable hardware, quants are experimenting with various NLP
methods which are applicable to quantitative trading.&lt;/p&gt;
&lt;p&gt;In this section, we will get familiar with the brief history of text
mining work that quants have done so far and recent advancements.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-deep-learning-has-changed-nlp"&gt;
&lt;h4&gt;2. How deep learning has changed NLP?&lt;/h4&gt;
&lt;p&gt;In recent years, data representation and modeling methods are vastly
improved. For example when it comes to textual data, rather than using
high dimensional sparse matrices and suffering from curse of
dimensionality, distributional vectors are more efficient to work with.&lt;/p&gt;
&lt;p&gt;In this section, I will talk about distributional vectors a.k.a. word
embeddings and recent neural network architectures used when building
NLP models.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="lets-get-dirty-with-word-embeddings"&gt;
&lt;h4&gt;3. Let‚Äôs get dirty with word embeddings&lt;/h4&gt;
&lt;p&gt;Models such as Word2vec or GloVe helps us create word embeddings from
large unlabeled corpus which represent the relation between words, their
contextual relationships in numerical vector spaces and these
representations not only work for words but also could be used for
phrases and sentences.&lt;/p&gt;
&lt;p&gt;In this section, I will talk about inner workings of these models and
important points when creating domain-specific embeddings (e.g. for
sentiment analysis in financial domain).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="performant-deep-learning-layer-for-nlp-the-recurrent-layer"&gt;
&lt;h4&gt;4. Performant deep learning layer for NLP: The Recurrent Layer&lt;/h4&gt;
&lt;p&gt;Recurrent Neural Networks (RNNs) can capture and hold the information
which was seen before (context), which is important for dealing with
unbounded context in NLP tasks.&lt;/p&gt;
&lt;p&gt;Long Short Term Memory (LSTM) networks, which is a special type of RNN,
can understand the context even if words have long term dependencies,
words which are far back in their sequence.&lt;/p&gt;
&lt;p&gt;In this talk, I will compare LSTMs with other deep learning
architectures and will look at LSTM unit from a technical point of view.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="using-all-that-to-make-money"&gt;
&lt;h4&gt;5. Using all that to make money&lt;/h4&gt;
&lt;p&gt;Financial news, especially if it‚Äôs major, can change the sentiment among
investors and affect the related asset price with immediate price
corrections.&lt;/p&gt;
&lt;p&gt;For example, what‚Äôs been communicated in quarterly earnings calls might
indicate whether the price of share will drop or increase based on the
language used. If the message of the company is not direct and featuring
complex sounding language, it usually indicates that there‚Äôs some shady
stuff going on and if this information extracted right, it‚Äôs a valuable
trading signal. For similar reasons, scanning announcements and
financial disclosures for trading signals became a common NLP practice
in investment industry.&lt;/p&gt;
&lt;p&gt;In this section, I will talk about the various data sources that
researchers can use and also explain common NLP workflows and deep
learning practices for quantifying textual data for generating trading
signals.&lt;/p&gt;
&lt;p&gt;I will end with summary with application architecture in case anyone
would like to implement similar systems for their own use.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 14:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</content><category term="PyCon Italia 2018"></category><category term="nlp"></category><category term="data-science"></category><category term="Keras"></category><category term="Python"></category><category term="Deep-Learning"></category><category term="machine-learning"></category><category term="spaCy"></category><category term="nltk"></category></entry><entry><title>Reproducibility, and Selection Bias in Learning: when just Cross Validation is not enough!</title><link href="https://pyvideo.org/pycon-italia-2018/reproducibility-and-selection-bias-in-learning-when-just-cross-validation-is-not-enough.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Valerio Maggio</name></author><id>tag:pyvideo.org,2018-04-21:/pycon-italia-2018/reproducibility-and-selection-bias-in-learning-when-just-cross-validation-is-not-enough.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Reproducibility&lt;/em&gt; - the ability to recompute results ‚Äî and
&lt;em&gt;replicability&lt;/em&gt; ‚Äî the chances other experimenters will achieve a
consistent result[1]- are among the main important beliefs of the
&lt;em&gt;scientific method&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Surprisingly, these two aspects are often underestimated or not even
considered when setting up scientific experimental pipelines. In this,
one of ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Reproducibility&lt;/em&gt; - the ability to recompute results ‚Äî and
&lt;em&gt;replicability&lt;/em&gt; ‚Äî the chances other experimenters will achieve a
consistent result[1]- are among the main important beliefs of the
&lt;em&gt;scientific method&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Surprisingly, these two aspects are often underestimated or not even
considered when setting up scientific experimental pipelines. In this,
one of the main threat to replicability is the &lt;em&gt;selection bias&lt;/em&gt; , that
is the error in choosing the individuals or groups to take part in a
study. Selection bias may come in different flavours: the selection of
the population of samples in the dataset ( &lt;em&gt;sample bias&lt;/em&gt; ); the
selection of features used by the learning models, particularly sensible
in case of high dimensionality; the selection of hyper parameter best
performing on specific dataset(s). If not properly considered, the
selection bias may strongly affect the validity of derived conclusions,
as well as the reliability of the learning model.&lt;/p&gt;
&lt;p&gt;In this talk I will provide a solid introduction to the topics of
reproducibility and selection bias, with examples taken from the
biomedical research, in which reliability is paramount.&lt;/p&gt;
&lt;p&gt;From a more technological perspective, to date the scientific Python
ecosystem still misses tools to consolidate the experimental pipelines
in in research, that can be used together with Machine and Deep learning
frameworks (e.g. &lt;tt class="docutils literal"&gt;sklearn&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;keras&lt;/tt&gt;). In this talk, I will
present &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;reproducible-learn&lt;/span&gt;&lt;/tt&gt;, a new Python frameworks for reproducible
research to be used for machine and deep learning.&lt;/p&gt;
&lt;p&gt;During the talk, the main features of the framework will be presented,
along with several examples, technical insights and implementation
choices to be discussed with the audience.&lt;/p&gt;
&lt;p&gt;The talk is intended for &lt;em&gt;intermediate&lt;/em&gt; PyData researchers and
practitioners. Basic prior knowledge of the main Machine Learning
concepts is assumed for the first part of the talk. On the other hand,
good proficiency with the Python language and with scientific python
libraries (e.g. &lt;tt class="docutils literal"&gt;numpy&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;sklearn&lt;/tt&gt;) are required for the second
part.&lt;/p&gt;
&lt;p&gt;‚Äì &lt;a class="reference external" href="http://www.pnas.org/content/112/6/1645.full"&gt;1&lt;/a&gt; &lt;em&gt;Reproducible
research can still be wrong: Adopting a prevention approach&lt;/em&gt; by Jeffrey
T. Leek, and Roger D. Peng&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.cancer.gov/publications/dictionaries/cancer-terms?CdrID=44087"&gt;2&lt;/a&gt;
Dictionary of Cancer Terms -&amp;gt; ‚Äúselection bias‚Äù&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 18:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</content><category term="PyCon Italia 2018"></category><category term="Deep-Learning"></category><category term="Reproducibility"></category><category term="Machine Learning"></category></entry><entry><title>Using Python to bring democracy to the A.I. age</title><link href="https://pyvideo.org/pycon-italia-2018/using-python-to-bring-democracy-to-the-ai-age.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Felipe Cabral</name></author><id>tag:pyvideo.org,2018-04-21:/pycon-italia-2018/using-python-to-bring-democracy-to-the-ai-age.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;TL;DR&lt;/p&gt;
&lt;div class="section" id="when-you-go-full-big-data-at-public-data-and-become-a-citzen"&gt;
&lt;h4&gt;When you go full Big Data at public data and become a citzen.&lt;/h4&gt;
&lt;p&gt;Audience type: developers, data scientists of any level of expertise.&lt;/p&gt;
&lt;p&gt;After a political coup Brazil drowned in scandals and political
disbelief. That was the final straw for us.&lt;/p&gt;
&lt;p&gt;We created a bot persona who ‚Ä¶&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;TL;DR&lt;/p&gt;
&lt;div class="section" id="when-you-go-full-big-data-at-public-data-and-become-a-citzen"&gt;
&lt;h4&gt;When you go full Big Data at public data and become a citzen.&lt;/h4&gt;
&lt;p&gt;Audience type: developers, data scientists of any level of expertise.&lt;/p&gt;
&lt;p&gt;After a political coup Brazil drowned in scandals and political
disbelief. That was the final straw for us.&lt;/p&gt;
&lt;p&gt;We created a bot persona who uses Machine Learning to analyze public
spending, launching our own data journalism investigations. As expected
we use the internet publicize our findings and icing on it was to use
Twitter to directly engage the public and politicians under the topic of
suspicious expenses.&lt;/p&gt;
&lt;p&gt;Come with me and I‚Äôll show some figures from Brazilian corruption, share
some code and cherry-pick the best of our toolbox to deal with public
data and machine learning. I‚Äôll introduce our public dashboard that
makes visualization and browsing government data easy peasy. And surely
we can take a look in some tweets from Rosie, the robot, and how some
politicians are now vociferating with a ROBOT on social media.&lt;/p&gt;
&lt;p&gt;And you guessed it right: everything is open-source and our mission is
to create a global community to bring democracy to the A.I. age.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 18:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</content><category term="PyCon Italia 2018"></category><category term="machine-learning"></category><category term="Python"></category><category term="agile"></category><category term="Data Mining"></category><category term="bigdata"></category><category term="data-visualization"></category><category term="OpenSource"></category><category term="data-analysis"></category><category term="e-gov"></category><category term="data"></category></entry><entry><title>Deep Learning from zero to hero</title><link href="https://pyvideo.org/pycon-italia-2018/deep-learning-from-zero-to-hero.html" rel="alternate"></link><published>2018-04-20T00:00:00+00:00</published><updated>2018-04-20T00:00:00+00:00</updated><author><name>Gianluca Carucci</name></author><id>tag:pyvideo.org,2018-04-20:/pycon-italia-2018/deep-learning-from-zero-to-hero.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Avete sentito parlare di Deep Learning ma credete che la teoria alla
base sia troppo complessa? Non avete una laurea in matematica e
statistica e pensate che il machine learning non faccia per voi? Niente
paura: avrete solo bisogno di una conoscenze di base di Python.&lt;/p&gt;
&lt;p&gt;Conoscete la regola ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Avete sentito parlare di Deep Learning ma credete che la teoria alla
base sia troppo complessa? Non avete una laurea in matematica e
statistica e pensate che il machine learning non faccia per voi? Niente
paura: avrete solo bisogno di una conoscenze di base di Python.&lt;/p&gt;
&lt;p&gt;Conoscete la regola dell‚Äô80/20? Con il 20% delle conoscenze potete
raggiungere l‚Äô80% dei risultati: in questo talk vi mostrer√≤ in modo
pratico tramite delle demo - alcuni trucchi per costruire dei buoni
modelli predittivi, evitando di perdere (tanto) tempo nella scelta dei
tools e delle librerie necessarie al vostro scopo.&lt;/p&gt;
&lt;p&gt;L‚Äôobbiettivo √® fornirvi le basi pratiche con cui scegliere un modello di
rete neurale, farne training e ottimizzarlo nel modo pi√π adatto alla
tipologia del problema che dovete affrontare.&lt;/p&gt;
&lt;p&gt;Agenda: - Introduzione al Deep Learning - Un esempio di training senza
scrivere codice - Sviluppare, testare e ottimizzare un modello reale -
Considerazioni finali&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;venerd√¨ 20 aprile&lt;/strong&gt; at 12:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</content><category term="PyCon Italia 2018"></category><category term="machine-learning"></category><category term="Keras"></category><category term="Deep-Learning"></category><category term="data-analysis"></category><category term="tensorflow"></category><category term="computer-science"></category><category term="neural network"></category></entry><entry><title>Python &amp; Industry 4.0: a real world case</title><link href="https://pyvideo.org/pycon-italia-2018/python-industry-40-a-real-world-case.html" rel="alternate"></link><published>2018-04-20T00:00:00+00:00</published><updated>2018-04-20T00:00:00+00:00</updated><author><name>Gianluca Emireni</name></author><id>tag:pyvideo.org,2018-04-20:/pycon-italia-2018/python-industry-40-a-real-world-case.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;IT Con l‚Äôavvento dell‚ÄôIndustry 4.0 sempre pi√π linee di produzione sono
in grado di generare informazioni di funzionamento ad alta frequenza. E‚Äô
quindi possibile raccogliere ed elaborare i dati provenienti dai sensori
(per es. consumi elettrici, numero di pezzi prodotti, allarmi, ecc.) per
ottimizzare i processi ‚Ä¶&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;IT Con l‚Äôavvento dell‚ÄôIndustry 4.0 sempre pi√π linee di produzione sono
in grado di generare informazioni di funzionamento ad alta frequenza. E‚Äô
quindi possibile raccogliere ed elaborare i dati provenienti dai sensori
(per es. consumi elettrici, numero di pezzi prodotti, allarmi, ecc.) per
ottimizzare i processi produttivi fino ad arrivare alla Manutenzione
Predittiva. In questo talk vedremo come poter sfruttare lo stack Python
per implementare la pipeline di attivit√† quali Data Cleansing, Data
Wrangling, Feature Engineering e Machine Learning modeling su un caso
reale.&lt;/p&gt;
&lt;p&gt;EN Thanks to the Industry 4.0 wave, an increasing number of production
lines are able to generate high frequency operational data. It is
possible to gather and process sensor data (e.g., power consumption,
processed items, alerts, etc.) in order to optimize production processes
and to realize the so called Predictive Maintenance. In this talk we
will show how we applied the Python stack to a real world scenario by
implementing data pipelines (i.e., Data Cleansing, Data Wrangling,
Feature Engineering, and Machine Learning modeling).&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 20 April&lt;/strong&gt; at 11:45 &lt;a class="reference external" href="/en/sprints/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</content><category term="PyCon Italia 2018"></category><category term="industry4.0"></category><category term="data-science"></category><category term="machine-learning"></category></entry></feed>