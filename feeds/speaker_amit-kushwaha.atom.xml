<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_amit-kushwaha.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-05-04T00:00:00+00:00</updated><entry><title>Defence Against the Dark Arts: Adversarial ML</title><link href="https://pyvideo.org/pycon-italia-2019/defence-against-the-dark-arts-adversarial-ml.html" rel="alternate"></link><published>2019-05-04T00:00:00+00:00</published><updated>2019-05-04T00:00:00+00:00</updated><author><name>Amit Kushwaha</name></author><id>tag:pyvideo.org,2019-05-04:pycon-italia-2019/defence-against-the-dark-arts-adversarial-ml.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Security and Privacy issues need no introduction. But how exactly is
this affecting the field of Machine Learning? This is what this talk
will cover. We first expose the attack surface of systems deploying
machine learning. We then describe how an attacker may force models to
make wrong predictions with very little information about the victim.
One such attack can be biometric recognition where fake biometric traits
may be exploited to impersonate a legitimate user. We demonstrate that
these attacks are practical against existing machine learning as a
service platform. Towards the end, we will discuss current research to
defend models from such attacks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1700"&gt;https://python.it/feedback-1700&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Saturday 4 May&lt;/strong&gt; at 11:30 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="security"></category><category term="Artificial Intelligence"></category><category term="privacy"></category></entry></feed>