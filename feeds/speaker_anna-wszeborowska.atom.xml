<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_anna-wszeborowska.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-05-05T00:00:00+00:00</updated><entry><title>Subwoofler: Create Your Own Musical Instrument</title><link href="https://pyvideo.org/pycon-italia-2019/subwoofler-create-your-own-musical-instrument.html" rel="alternate"></link><published>2019-05-05T00:00:00+00:00</published><updated>2019-05-05T00:00:00+00:00</updated><author><name>Anna Wszeborowska</name></author><id>tag:pyvideo.org,2019-05-05:pycon-italia-2019/subwoofler-create-your-own-musical-instrument.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you, like me, started your musical encounters with toys that made
animal sounds? Has the teenage you wondered how your favorite beat
makers turned field recordings into playable sounds? What would happen
if you combined the two? Let me take you on a journey through the world
of sampling instruments which inspired Subwoofler - a barking sampler
written completely in Python. We’ll go through all of its components and
learn a few concepts commonly used in music applications. Finally, we’ll
compare the performance of processing real-time audio on different
implementations of Python; the language which is not the most typical
choice for such a use case.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1801"&gt;https://python.it/feedback-1801&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Sunday 5 May&lt;/strong&gt; at 14:30 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>Processing music on the fly with Python</title><link href="https://pyvideo.org/pycon-de-2016/processing-music-on-the-fly-with-python.html" rel="alternate"></link><published>2016-10-29T00:00:00+00:00</published><updated>2016-10-29T00:00:00+00:00</updated><author><name>Anna Wszeborowska</name></author><id>tag:pyvideo.org,2016-10-29:pycon-de-2016/processing-music-on-the-fly-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Music transcription allows to convert an audio recording to musical notation through mathematical analysis. It is a very complex problem, especially for polyphonic music - currently existing solutions yield results with approx. 70% or less accuracy.
In the talk we will focus on transcribing a monophonic audio input and see how we can modify it on the fly. To achieve that, we need to determine pitch and duration of each note, and then use these parameters to create a sequence of MIDI events. MIDI stands for Musical Instrument Digital Interface and it encodes commands used to generate sounds by musical hardware or software.
Let’s see how to play around with sounds using Python and a handful of its powerful libraries. And let’s do it in real-time!&lt;/p&gt;
</summary></entry><entry><title>Music transcription with Python</title><link href="https://pyvideo.org/europython-2016/music-transcription-with-python.html" rel="alternate"></link><published>2016-08-04T00:00:00+00:00</published><updated>2016-08-04T00:00:00+00:00</updated><author><name>Anna Wszeborowska</name></author><id>tag:pyvideo.org,2016-08-04:europython-2016/music-transcription-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Anna Wszeborowska - Music transcription with Python
[EuroPython 2016]
[21 July 2016]
[Bilbao, Euskadi, Spain]
(&lt;a class="reference external" href="https://ep2016.europython.eu//conference/talks/music-transcription-with-python"&gt;https://ep2016.europython.eu//conference/talks/music-transcription-with-python&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Music transcription allows to convert an audio recording to musical
notation through mathematical analysis. In the talk we will focus on
transcribing a monophonic audio input and see how we can modify it on
the fly. To achieve that, we need to determine pitch and duration of
each note, and then use these parameters to create a sequence of MIDI
events.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Music transcription allows to convert an audio recording to musical
notation through mathematical analysis. It is a very complex problem,
especially for polyphonic music - currently existing solutions yield
results with approx. 70% or less accuracy.&lt;/p&gt;
&lt;p&gt;In the talk we will focus on transcribing a monophonic audio input and
see how we can modify it on the fly.
To achieve that, we need to determine pitch and duration of each note,
and then use these parameters to create a sequence of MIDI events.
MIDI stands for &lt;em&gt;Musical Instrument Digital Interface&lt;/em&gt; and it encodes
commands used to generate sounds by musical hardware or software.&lt;/p&gt;
&lt;p&gt;Let's see how to play around with sounds using Python and a handful of
its powerful libraries. And let's do it in real-time!&lt;/p&gt;
</summary></entry></feed>