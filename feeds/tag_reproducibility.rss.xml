<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Wed, 09 May 2018 00:00:00 +0000</lastBuildDate><item><title>Reproducibility, and Selection Bias in Learning: when just Cross Validation is not enough!</title><link>https://pyvideo.org/pycon-italia-2018/reproducibility-and-selection-bias-in-learning-when-just-cross-validation-is-not-enough.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Reproducibility&lt;/em&gt; - the ability to recompute results — and
&lt;em&gt;replicability&lt;/em&gt; — the chances other experimenters will achieve a
consistent result[1]- are among the main important beliefs of the
&lt;em&gt;scientific method&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Surprisingly, these two aspects are often underestimated or not even
considered when setting up scientific experimental pipelines. In this,
one of the main threat to replicability is the &lt;em&gt;selection bias&lt;/em&gt; , that
is the error in choosing the individuals or groups to take part in a
study. Selection bias may come in different flavours: the selection of
the population of samples in the dataset ( &lt;em&gt;sample bias&lt;/em&gt; ); the
selection of features used by the learning models, particularly sensible
in case of high dimensionality; the selection of hyper parameter best
performing on specific dataset(s). If not properly considered, the
selection bias may strongly affect the validity of derived conclusions,
as well as the reliability of the learning model.&lt;/p&gt;
&lt;p&gt;In this talk I will provide a solid introduction to the topics of
reproducibility and selection bias, with examples taken from the
biomedical research, in which reliability is paramount.&lt;/p&gt;
&lt;p&gt;From a more technological perspective, to date the scientific Python
ecosystem still misses tools to consolidate the experimental pipelines
in in research, that can be used together with Machine and Deep learning
frameworks (e.g. &lt;tt class="docutils literal"&gt;sklearn&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;keras&lt;/tt&gt;). In this talk, I will
present &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;reproducible-learn&lt;/span&gt;&lt;/tt&gt;, a new Python frameworks for reproducible
research to be used for machine and deep learning.&lt;/p&gt;
&lt;p&gt;During the talk, the main features of the framework will be presented,
along with several examples, technical insights and implementation
choices to be discussed with the audience.&lt;/p&gt;
&lt;p&gt;The talk is intended for &lt;em&gt;intermediate&lt;/em&gt; PyData researchers and
practitioners. Basic prior knowledge of the main Machine Learning
concepts is assumed for the first part of the talk. On the other hand,
good proficiency with the Python language and with scientific python
libraries (e.g. &lt;tt class="docutils literal"&gt;numpy&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;sklearn&lt;/tt&gt;) are required for the second
part.&lt;/p&gt;
&lt;p&gt;– &lt;a class="reference external" href="http://www.pnas.org/content/112/6/1645.full"&gt;1&lt;/a&gt; &lt;em&gt;Reproducible
research can still be wrong: Adopting a prevention approach&lt;/em&gt; by Jeffrey
T. Leek, and Roger D. Peng&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.cancer.gov/publications/dictionaries/cancer-terms?CdrID=44087"&gt;2&lt;/a&gt;
Dictionary of Cancer Terms -&amp;gt; “selection bias”&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 18:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Valerio Maggio</dc:creator><pubDate>Sat, 21 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-21:pycon-italia-2018/reproducibility-and-selection-bias-in-learning-when-just-cross-validation-is-not-enough.html</guid><category>Deep-Learning</category><category>Reproducibility</category><category>Machine Learning</category></item><item><title>Down the rabbit hole. A 101 on reproducible workflows with Python</title><link>https://pyvideo.org/pycon-us-2018/down-the-rabbit-hole-a-101-on-reproducible-workflows-with-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There has been a massive interest in reproducible research / data
analysis pipelines over the last few years.
But... how can I ensure that what I produce as a Python
user is reproducible?
In this tutorial we'll be taking you on a journey down the rabbit hole
of reproducibility.
We'll be taking a step by step approach to reproducible scientific development
in Python.
This means you get a crash course on version control, execution environments, testing,
and continuous integration. And a guide on how to integrate all of these in your
software projects.
By the end of the course we hope you will have the necessary tools to make your
Python workflows reproducible no matter if you're starting a brand new project
or if this is ready to be shared with the world.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tania  Sanchez Monroy</dc:creator><pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-05-09:pycon-us-2018/down-the-rabbit-hole-a-101-on-reproducible-workflows-with-python.html</guid><category>reproducibility</category></item><item><title>You got your engineering in my Data Science: Addressing the reproducibility crisis</title><link>https://pyvideo.org/pydata-dc-2016/you-got-your-engineering-in-my-data-science-addressing-the-reproducibility-crisis.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="http://www.slideshare.net/jonbodner/you-got-your-engineering-in-my-data-science-addressing-the-reproducibility-crisis-with-software-engineering"&gt;http://www.slideshare.net/jonbodner/you-got-your-engineering-in-my-data-science-addressing-the-reproducibility-crisis-with-software-engineering&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Data science is the backbone of modern scientific discovery and industry. Unfortunately, multiple recent studies have been found to be unreliable and non-reproducible. Adopting techniques from software engineering might help mitigate some of these problems.&lt;/p&gt;
&lt;p&gt;Data science is the backbone of modern scientific discovery and industry. It makes sense of everything from cancer trials to package delivery logistics. But all is not well with data science. Over the past decade, multiple studies have been found to be unreliable and non-reproducible when other scientists tried to recreate their results. This is due to a variety of factors, including fraud, pressure to publish, improper data handling practices, and bugs in analytic tools.&lt;/p&gt;
&lt;p&gt;The problems faced by data science mirror problems that software engineering has been trying to solve. While there are no silver bullets to guarantee quality software, techniques have been developed over time that have improved quality and reliability. Some of these techniques, including open source, version control, automation, and fuzzing could be adapted to the data science domain to improve reliability and help address the reproducibility crisis.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jon Bodner</dc:creator><pubDate>Sun, 09 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-09:pydata-dc-2016/you-got-your-engineering-in-my-data-science-addressing-the-reproducibility-crisis.html</guid><category>Data</category><category>data science</category><category>engineering</category><category>reproducibility</category></item><item><title>More of your pandas questions answered!</title><link>https://pyvideo.org/data-school/pandas-23-viewer-questions.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, I'm answering a few of the pandas questions I've received in the YouTube comments: Could you explain how to read the pandas documentation? What is the difference between ufo.isnull() and pd.isnull(ufo)? Why are DataFrame slices inclusive when using .loc, but exclusive when using .iloc? How do I randomly sample rows from a DataFrame?&lt;/p&gt;
&lt;p&gt;This is video 23 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kevin Markham</dc:creator><pubDate>Tue, 05 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-05:data-school/pandas-23-viewer-questions.html</guid><category>data science</category><category>data analysis</category><category>data wrangling</category><category>data processing</category><category>pandas</category><category>tutorial</category><category>Data School</category><category>reproducibility</category></item><item><title>MPCite: Continuous and High-throughput Allocation of Digital Object Identifiers for Calculated and Contributed Data in the Materials Project</title><link>https://pyvideo.org/scipy-2016/mpcite-continuous-and-high-throughput-allocation-of-digital-object-identifiers-for-calculated-and.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We introduce 'MPCite' which enables the continuous request, validation, and dissemination of Digital Object Identifiers (DOIs) for all inorganic materials currently available in the Materials Project (&lt;a class="reference external" href="https://www.materialsproject.org/"&gt;https://www.materialsproject.org/&lt;/a&gt;). It provides our users with the necessary software infrastructure to achieve a new level of reproducibility in their research: It allows for the convenient and persistent citation of our materials data in online and print publications and facilitates sharing amongst collaborators. We also demonstrate how we extend the use of MPCite to non-core database entries such as theoretical and experimental data contributed through 'MPContribs' or suggested by the user for calculation via the “MPComplete' service. We expect MPCite to be easily extendable to other scientific domains where the number of data records demands high-throughput and continuous allocation of DOIs.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Patrick Huck</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/mpcite-continuous-and-high-throughput-allocation-of-digital-object-identifiers-for-calculated-and.html</guid><category>reproducibility</category></item><item><title>A Portrait of One Scientist as a Graduate Student</title><link>https://pyvideo.org/scipy-2013/a-portrait-of-one-scientist-as-a-graduate-student.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;a focus on specific tools and techniques invaluable in doing research in
a reproducible manner.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Authors: Ivanov, Paul, UC Berkeley&lt;/p&gt;
&lt;p&gt;Track: General&lt;/p&gt;
&lt;p&gt;In this talk, I will focus on the how of reproducible research. I will
focus on specific tools and techniques I have found invaluable in doing
research in a reproducible manner. In particular, I will cover the
following general topics (with specific examples in parentheses):
version control and code provenance (git), code verification (test
driven development, nosetests), data integrity (sha1, md5, git-annex),
seed saving ( random seed retention ) distribution of datasets
(mirroring, git-annex, metalinks), light-weight analysis capture (
ttyrec, ipython notebook)&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Paul Ivanov</dc:creator><pubDate>Tue, 02 Jul 2013 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2013-07-02:scipy-2013/a-portrait-of-one-scientist-as-a-graduate-student.html</guid><category>git</category><category>reproducibility</category></item><item><title>Emacs + org-mode + python in reproducible research; SciPy 2013 Presentation</title><link>https://pyvideo.org/scipy-2013/emacs-org-mode-python-in-reproducible-researc.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;We discuss the use of emacs + org-mode + python in enabling reproducible
research.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Authors: Kitchin, John Carnegie Mellon University&lt;/p&gt;
&lt;p&gt;Track: Reproducible Science&lt;/p&gt;
&lt;p&gt;We will discuss the use of emacs + org-mode + python in enabling
reproducible research. This combination of software enables researchers
to intertwine narrative and mathematical text with figures and code that
is executable within a document, with capture of the output. Portions of
the document can be selectively exported to LaTeX, HTML, pdf and other
other formats. We have used this method to produce technical manuscripts
submitted for peer review in scientific journals, in the preparation of
two e-books (about 300 pages each) on using python in scientific and
engineering applications (&lt;a class="reference external" href="http://jkitchin.github.com/pycse"&gt;http://jkitchin.github.com/pycse&lt;/a&gt;), and in
using python in the modeling of the properties of materials with density
functional theory (&lt;a class="reference external" href="http://jkitchin.github.com/dft-book"&gt;http://jkitchin.github.com/dft-book&lt;/a&gt;), as well as a
python-powered blog at &lt;a class="reference external" href="http://jkitchin.github.com"&gt;http://jkitchin.github.com&lt;/a&gt;. Our experience
suggests all three components are critical for enabling reproducible
research in practice: an extensible editor, a markup language that
separates text, math, data and code, and an effective language such as
python. We will show examples of the pros and cons of this particular
implementation of editor/markup/code combination.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">John Kitchin</dc:creator><pubDate>Tue, 02 Jul 2013 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2013-07-02:scipy-2013/emacs-org-mode-python-in-reproducible-researc.html</guid><category>emacs</category><category>reproducibility</category></item><item><title>Using Sumatra to Manage Numerical Simulations</title><link>https://pyvideo.org/scipy-2013/using-sumatra-to-manage-numerical-simulations-sc.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Sumatra is a lightweight system for recording the history and provenance
data for numerical simulations. ... The speaker will provide an
introduction to Sumatra as well as demonstrate some typical usage
patterns and discuss achievable future goals.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Authors: Davison, Andrew, CNRS (principal developer); Wheeler, Daniel,
NIST (speaker)&lt;/p&gt;
&lt;p&gt;Track: Reproducible Science&lt;/p&gt;
&lt;p&gt;Sumatra is a lightweight system for recording the history and provenance
data for numerical simulations. It works particularly well for
scientists that are in the intermediate stage between developing a code
base and using that code base for active research. This is a common
scenario and often results in a mode of development that mixes branching
for both code development and production simulations. Using Sumatra
avoids this unintended use of the versioning system by providing a
lightweight design for recording the provenance data independently from
the versioning system used for the code development. The lightweight
design of Sumatra fits well with existing ad-hoc patterns of simulation
management contrasting with more pervasive workflow tools, which can
require a wholesale alteration of work patterns. Sumatra uses a
straightforward Django-based data model enabling persistent data storage
independently from the Sumatra installation. Sumatra provides a command
line utility with a rudimentary web interface, but has the potential to
become a full web-based simulation management solution. During the talk,
the speaker will provide an introduction to Sumatra as well as
demonstrate some typical usage patterns and discuss achievable future
goals.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Daniel Wheeler</dc:creator><pubDate>Tue, 02 Jul 2013 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2013-07-02:scipy-2013/using-sumatra-to-manage-numerical-simulations-sc.html</guid><category>numerical simulations</category><category>provenance</category><category>reproducibility</category><category>sumatra</category></item><item><title>SciPy 2013 Keynote: The New Scientific Publishers</title><link>https://pyvideo.org/scipy-2013/scipy-2013-keynote-the-new-scientific-publishers-0.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;...As software becomes increasingly important to the practice of
science, and data becomes larger and more complex, the conventional
scientific journal is no longer an adequate vehicle to communicate
scientific findings and ensure reproducibility. So who are the new
scientific publishers filling these needs, and what roles will they play
in the future of science?&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Presenter: William Schroeder, Kitware&lt;/p&gt;
&lt;p&gt;Track: Keynotes&lt;/p&gt;
&lt;p&gt;Scientific societies such as the Royal Society were formed in the 17th
century with the goals of sharing information and ensuring
reproducibility. Very quickly scientific letters and publications were
assembled into collected transactions and eventually journals. For
hundreds of years publishers served admirably as disseminators of
scientific knowledge. Publications, and the associated peer review
process, became central to the scientific process, greatly impacting how
science is practiced, knowledge disseminated, and careers made. However,
as software becomes increasingly important to the practice of science,
and data becomes larger and more complex, the conventional scientific
journal is no longer an adequate vehicle to communicate scientific
findings and ensure reproducibility. So who are the new scientific
publishers filling these needs, and what roles will they play in the
future of science?&lt;/p&gt;
&lt;p&gt;In this presentation we'll discuss the central mandate of
reproducibility, and the role of Open Science, in particular Open
Access, Open Source and Open Data, and how emerging communities and
organizations are filling the needs of the scientific community. We'll
also discuss the challenges of curating the avalanche of scientific
knowledge, whether it be software, data or publications, and how these
communities and organizations can work together to support science
progress, and ensure continued technological innovation.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">William Schroeder</dc:creator><pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2013-07-01:scipy-2013/scipy-2013-keynote-the-new-scientific-publishers-0.html</guid><category>open science</category><category>reproducibility</category></item></channel></rss>