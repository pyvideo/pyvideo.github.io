<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Dheeraj Peri</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_dheeraj-peri.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2023-10-16T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Lightning Talk: Accelerated Inference in PyTorch 2.X with Torch-TensorRT</title><link href="https://pyvideo.org/pytorch-conference-2023/lightning-talk-accelerated-inference-in-pytorch-2x-with-torch-tensorrt.html" rel="alternate"></link><published>2023-10-16T00:00:00+00:00</published><updated>2023-10-16T00:00:00+00:00</updated><author><name>George Stefanakis</name></author><id>tag:pyvideo.org,2023-10-16:/pytorch-conference-2023/lightning-talk-accelerated-inference-in-pytorch-2x-with-torch-tensorrt.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Torch-TensorRT accelerates the inference of deep learning models in PyTorch targeting NVIDIA GPUs. Torch-TensorRT now leverages Dynamo, the graph capture technology introduced in PyTorch 2.0, to offer a new and more pythonic user experience as well as to upgrade the existing compilation workflow. The new user experience includes …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Torch-TensorRT accelerates the inference of deep learning models in PyTorch targeting NVIDIA GPUs. Torch-TensorRT now leverages Dynamo, the graph capture technology introduced in PyTorch 2.0, to offer a new and more pythonic user experience as well as to upgrade the existing compilation workflow. The new user experience includes Just-In-Time compilation and support for arbitrary Python code (like dynamic control flow, complex I/O, and external libraries) used within your model, while still accelerating performance. A single line of code provides easy and robust acceleration of your model with full flexibility to configure the compilation process without ever leaving PyTorch: torch.compile(model, backend=”tensorrt”) The existing API has also been revamped to use Dynamo export under the hood, providing you with the same Ahead-of-Time whole-graph acceleration with fallback for custom operators and dynamic shape support as in previous versions: torch_tensorrt.compile(model, inputs=example_inputs) We will present descriptions of both paths as well as features coming soon. All of our work is open source and available at &lt;a class="reference external" href="https://github.com/pytorch/TensorRT"&gt;https://github.com/pytorch/TensorRT&lt;/a&gt;.&lt;/p&gt;
</content><category term="PyTorch Conference 2023"></category><category term="Lightning Talk"></category></entry></feed>