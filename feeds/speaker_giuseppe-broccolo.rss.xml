<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 15 Jun 2019 00:00:00 +0000</lastBuildDate><item><title>Data science with Python</title><link>https://pyvideo.org/pylondinium-2019/data-science-with-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There is a scenario that is quite common when doing data science at scale.
The Data Science team have developed a good algorithm that suits our purpose and the prototype works well on a test dataset. But how to transform it into a reliable, responsive service ready for production payload? We will got through the steps involved in the evolution of a Jupyter notebook into an auto-scaling service. These steps involve changes in data ingestion, asynchronous processing, dockerisation, kubernetes and cloud technologies.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Giuseppe Broccolo</dc:creator><pubDate>Sat, 15 Jun 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-06-15:pylondinium-2019/data-science-with-python.html</guid></item><item><title>Big Data con PostgreSQL</title><link>https://pyvideo.org/pycon-italia-2016/big-data-con-postgresql.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Francesco Canovai</dc:creator><pubDate>Mon, 20 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-06-20:pycon-italia-2016/big-data-con-postgresql.html</guid></item></channel></rss>