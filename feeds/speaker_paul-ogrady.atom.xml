<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_paul-ogrady.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2017-07-13T00:00:00+00:00</updated><entry><title>An introduction to PyTorch &amp; Autograd</title><link href="https://pyvideo.org/europython-2017/an-introduction-to-pytorch-autograd.html" rel="alternate"></link><published>2017-07-13T00:00:00+00:00</published><updated>2017-07-13T00:00:00+00:00</updated><author><name>Paul O'Grady</name></author><id>tag:pyvideo.org,2017-07-13:europython-2017/an-introduction-to-pytorch-autograd.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyTorch is an optimized tensor library for Deep Learning, and is a
recent newcomer to the growing list of GPU programming frameworks
available in Python. Like other frameworks it offers efficient tensor
representations and is agnostic to the underlying hardware. However,
unlike other frameworks it allows you to create &amp;quot;define-by-run&amp;quot;
neural networks resulting in dynamic computation graphs, where every
single iteration can be different---opening up a whole new world of
possibilities. Central to all neural networks in PyTorch is the
Autograd package, which performs Algorithmic Differentiation on the
defined model and generates the required gradients at each iteration.
In this talk I will present a gentle introduction to the PyTorch
library and overview its main features using some simple examples,
paying particular attention to the mechanics of the Autograd package.&lt;/p&gt;
&lt;p&gt;Keywords: GPU Processing, Algorithmic Differentiation, Deep Learning, Linear algebra.&lt;/p&gt;
</summary></entry><entry><title>An introduction to GPU programming using Theano</title><link href="https://pyvideo.org/pycon-ireland-2015/an-introduction-to-gpu-programming-using-theano.html" rel="alternate"></link><published>2015-10-24T00:00:00+00:00</published><updated>2015-10-24T00:00:00+00:00</updated><author><name>Paul O'Grady</name></author><id>tag:pyvideo.org,2015-10-24:pycon-ireland-2015/an-introduction-to-gpu-programming-using-theano.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Theano is a Python library that allows you to define, optimize, and evaluate matrix expressions efficiently.&lt;/p&gt;
&lt;p&gt;Theano is used to build large-scale Machine Learning systems ---in particular Deep Learning Networks---and targets operations to GPU hardware, which achieves significant performance improvements over the same operations performed on a CPU (say using Numpy).&lt;/p&gt;
&lt;p&gt;In this talk I will present an overview of the Theano library and introduce its main features using some simple examples.&lt;/p&gt;
</summary></entry><entry><title>Detection of Duplicate Records in Large-scale Multi-tenant Platforms</title><link href="https://pyvideo.org/pycon-ireland-2016/detection-of-duplicate-records-in-large-scale-multi-tenant-platforms.html" rel="alternate"></link><published>2016-11-06T00:00:00+00:00</published><updated>2016-11-06T00:00:00+00:00</updated><author><name>Paul O'Grady</name></author><id>tag:pyvideo.org,2016-11-06:pycon-ireland-2016/detection-of-duplicate-records-in-large-scale-multi-tenant-platforms.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Zalando's quest to create an open multi-tenant fashion platform has its
challenges. One of these is the detection of duplicate product records
within the platform, where different tenants input the same product
using different product descriptions. Commonly referred to as
the_Record Linkage_problem in Machine Learning, the task is to group
together similar product records under a single canonical identifier,
which is useful for business intelligence purposes and for product
search etc. The kernel of the solution is the computation of an
~O(n**2) all-pairs similarity join, where the runtime explodes
quadratically with an increase in input. At Zalando's Fashion Insight
Centre in Dublin we are looking at solutions to this problem that work
at scale (i.e., more than one million products). For our particular
problem, which involves Categorical Data (cosine similarity will not
work here), we employ a data-driven similarity measure and approximate
the similarity join using a two-step approach. In this talk we introduce
the standard approaches to the problem and illustrate our work-to-date
using Python.&lt;/p&gt;
</summary></entry></feed>