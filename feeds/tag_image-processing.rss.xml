<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Image Processing</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Thu, 23 Jul 2020 00:00:00 +0000</lastBuildDate><item><title>How to train an image classifier using PyTorch</title><link>https://pyvideo.org/europython-2019/how-to-train-an-image-classifier-using-pytorch.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Neural networks are everywhere nowadays. But while it seems everyone is
using them, training your first neural network can be quite a hurdle to
overcome.&lt;/p&gt;
&lt;p&gt;In this talk I will take you by the hand, and following an example image
classifier I trained, I will take you through the steps of making an
image classifier in PyTorch. I will show you code snippets and explain
the more intricate parts. Also, I will tell you about my experience, and
about what mistakes to prevent. After this all you need to start
training your first classifier is a data set!&lt;/p&gt;
&lt;p&gt;Of course I will provide a link to the full codebase at the end. The
talk will focus on the practical aspect of training a neural network,
and will only touch the theoretical side very briefly. Some basic prior
knowledge of neural networks is beneficial, but not required, to follow
this talk.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rogier van der Geer</dc:creator><pubDate>Wed, 10 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-10:/europython-2019/how-to-train-an-image-classifier-using-pytorch.html</guid><category>EuroPython 2019</category><category>Deep Learning</category><category>Fun and Humor</category><category>Image Processing</category><category>Machine-Learning</category><category>Scientific Libraries (Numpy/Pandas/SciKit/...)</category></item><item><title>Image processing with scikit-image and Dash</title><link>https://pyvideo.org/europython-2019/image-processing-with-scikit-image-and-dash.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Images are an ubiquitous form of data in various fields of science and&lt;/div&gt;
&lt;div class="line"&gt;industry. Images often need to be transformed and processed, for
example for helping medical diagnosis by extracting regions of
interest or measures, or for building training sets for machine
learning.&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;In this talk, I will present and discuss several tools for automatic
and&lt;/div&gt;
&lt;div class="line"&gt;interactive image processing with Python. I will start by a short&lt;/div&gt;
&lt;div class="line"&gt;introduction to scikit-image (&lt;a class="reference external" href="https://scikit-image.org/"&gt;https://scikit-image.org/&lt;/a&gt;), the
open-source&lt;/div&gt;
&lt;div class="line"&gt;image processing toolkit of the Pydata ecosystem, which aims at&lt;/div&gt;
&lt;div class="line"&gt;processing images from a large class of modalities (2-D, 3-D, etc.)
and&lt;/div&gt;
&lt;div class="line"&gt;strives to have a gentle learning curve with pedagogical example-based&lt;/div&gt;
&lt;div class="line"&gt;documentation. scikit-image provides users with a simple API based on
a large number of functions, which can be used to build pipelines of
image processing workflows.&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;In a second part, I will explain how to use Dash for building
interactive&lt;/div&gt;
&lt;div class="line"&gt;image processing operations. Dash (&lt;a class="reference external" href="https://dash.plot.ly/"&gt;https://dash.plot.ly/&lt;/a&gt;) is an&lt;/div&gt;
&lt;div class="line"&gt;open-source Python web application framework developed by Plotly.
Written on top of Flask, Plotly.js, and React.js, Dash is meant for
building data visualization apps with highly custom user interfaces in
pure Python. The dash-canvas component library of Dash
(&lt;a class="reference external" href="https://dash.plot.ly/canvas"&gt;https://dash.plot.ly/canvas&lt;/a&gt;) is an interactive component for
annotating images with several tools (freehand brush, lines, bounding
boxes, ...). It also provides utility functions for using
user-provided annotations for several image processing tasks such as
segmentation, transformation, measures, etc. The latter functions are
based on libraries such scikit-image and openCV. A gallery of examples
showcases some typical uses of Dash for image processing on&lt;/div&gt;
&lt;div class="line"&gt;&lt;a class="reference external" href="https://dash-canvas.plotly.host/"&gt;https://dash-canvas.plotly.host/&lt;/a&gt;. Also, other components of Dash can
be leveraged easily to build powerful image processing applications,
such as widgets to tune parameters or data tables for inspecting
object&lt;/div&gt;
&lt;div class="line"&gt;properties.&lt;/div&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Emmanuelle Gouillart</dc:creator><pubDate>Wed, 10 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-10:/europython-2019/image-processing-with-scikit-image-and-dash.html</guid><category>EuroPython 2019</category><category>Computer Vision</category><category>Data Science</category><category>Image Processing</category><category>JavaScript Web Frameworks (AngularJS/ReactJS/...)</category><category>Scientific Libraries (Numpy/Pandas/SciKit/...)</category></item><item><title>Corona-Net</title><link>https://pyvideo.org/europython-2020/corona-net.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Fighting COVID-19 with Machine Learning&lt;/p&gt;
&lt;p&gt;Identified in December 2019, the novel Coronavirus has infected 2.7 million worldwide, and claimed the lives of 0.2 million. Amidst this deadly pandemic, I started my open source project, Corona-Net, in the hopes of contributing to the global fight against the Coronavirus. Corona-Net is a 3-part project dedicated to the classification, binary segmentation and multi-class segmentation of COVID-19. I first leverage the EfficientNet model for COVID-19 diagnosis, then utilise and refine the U-Net architecture for both binary and 3-class (ground-glass, consolidation, pleural effusion) segmentation of COVID-19 symptoms, through inference on the COVID-19 CT segmentation (chest axial CT) dataset. Through Corona-Net, I aim to develop a reliable, visual-semantically balanced method for automatic COVID-19 diagnosis, as well as extend an invitation to all to collaborate and stand together against this pandemic. My PyTorch code is publicly available at &lt;a class="reference external" href="https://github.com/chinglamchoi/Corona-Net"&gt;https://github.com/chinglamchoi/Corona-Net&lt;/a&gt;.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ching Lam Choi</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/corona-net.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>Computer Vision</category><category>Data Science</category><category>Deep Learning</category><category>Image Processing</category><category>Scientific Libraries (Numpy/Pandas/SciKit/...)</category></item><item><title>Painting with GANs: Challenges and Technicalities of Neural Style Transfer</title><link>https://pyvideo.org/europython-2020/painting-with-gans-challenges-and-technicalities-of-neural-style-transfer.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Building Artistic Artefacts using Generative Networks&lt;/p&gt;
&lt;p&gt;A lot of advancements are happening in the field of Deep Learning and Generative Adversarial Networks are one of them. We have seen GANs being applied for photo editing and in-painting, generating new image datasets and realistic photographs, increasing resolution of images (Super Resolution), and many more things. Some people have also exploited GANs for generating fake content. All the above-mentioned examples are result of a technique where the focus is to generate uncommon yet original samples from scratch. However, these examples have very less commercial applications and GANs are capable of doing much more. The focus of this talk is a technique called &amp;quot;Neural Style Transfer (NST)&amp;quot; which has numerous commercial applications in the gaming world, fashion/design industry, mobile applications, and many more fields. Challenges and technicalities of NSTs will be covered in great detail. We will teach the machines on how to paint images and utilize Style Transfer networks to generate artistic artefacts.&lt;/p&gt;
&lt;p&gt;The flow of the talk will be as follows:
~ Self Introduction [1 minute]
~ A Succinct Prelude to GANs [10 minutes]
~ Understanding Style Transfer [5 minutes]
~ Learning about Neural Style Transfer Networks [5 minutes]
~ Loss Functions: Content, Style, Total Variantion [10 minutes]
~ Code Walkthrough and Result Analysis [5 minutes]
~ Challenges and Applications [5 minutes]
~ Questions and Answers Session [3-4 minutes]&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Anmol Krishan Sachdeva</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/painting-with-gans-challenges-and-technicalities-of-neural-style-transfer.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>Computer Vision</category><category>Deep Learning</category><category>Generative Adversarial Networks</category><category>Image Processing</category><category>Machine-Learning</category></item><item><title>The Phantom of Radon</title><link>https://pyvideo.org/europython-2020/the-phantom-of-radon.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A story of analytical sinograms&lt;/p&gt;
&lt;p&gt;This project contains an open source Python library for image reconstruction in Axial Computed Tomography (TAC), based on the analytical Radon transforms of some classes of phantoms.
The package is available on GitHub at the following address: &lt;a class="reference external" href="https://github.com/francescat93/Exact_sinogram"&gt;https://github.com/francescat93/Exact_sinogram&lt;/a&gt;.
The mathematical phantoms are fictitious images, composed of very simple geometric figures (ellipses, squares and rectangles) that, sampled with the Radon transform allows to build a fictitious signal, called (exact) sinogram.  Using a phantom gives the advantage to test the reconstruction algorithm on a zero-noise data so the error we get is only due to numerical inaccuracies in the algorithm itself. We want to calculate two reconstructed images from the approximated and exact sinograms, obtained applying the iradon function of the Python library scikit-image on both of them. We expect a smaller error on the exact reconstructed image. This turns to be true on continuous regions, but near the discontinuities of the phantom the Gibbs phenomenon prevents us to obtain the same enhancement.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Francesca Tedeschi</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/the-phantom-of-radon.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>Education</category><category>Image Processing</category><category>Open-Source</category><category>Science</category><category>Teaching</category></item><item><title>A Gentle Introduction to Neural Networks (with Python)</title><link>https://pyvideo.org/pycon-italia-2017/a-gentle-introduction-to-neural-networks-with-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A gentle introduction to neural networks, and making your own with
Python.&lt;/p&gt;
&lt;p&gt;This session is especially designed to be accessible to everyone,
including anyone with no expertise in mathematics, computer science or
Python.&lt;/p&gt;
&lt;p&gt;From this session you will have an intuitive understanding of what
neural networks are and how they work. If you are more technically
capable, you will see how you could make your own with Python and numpy.&lt;/p&gt;
&lt;p&gt;Part 1 - Ideas:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;the search for AI, hard problems for computers easy for humans&lt;/li&gt;
&lt;li&gt;learning from examples (simple classifier)&lt;/li&gt;
&lt;li&gt;biologically inspired neurons and networks&lt;/li&gt;
&lt;li&gt;training a neural network&lt;/li&gt;
&lt;li&gt;the back propagation breakthrough&lt;/li&gt;
&lt;li&gt;matrix ways of working (good for computers)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Part 2 - Python:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Python is easy, and everywhere&lt;/li&gt;
&lt;li&gt;Python notebooks&lt;/li&gt;
&lt;li&gt;the MNIST data set&lt;/li&gt;
&lt;li&gt;a very simple neural network class&lt;/li&gt;
&lt;li&gt;focus on concise and efficient matrix calculations with numpy&lt;/li&gt;
&lt;li&gt;97.5% accuracy recognising handwritten numbers - with just a few lines of code!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Part 3 - Live Demo! … and Q&amp;amp;A&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tariq Rashid</dc:creator><pubDate>Fri, 07 Apr 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-04-07:/pycon-italia-2017/a-gentle-introduction-to-neural-networks-with-python.html</guid><category>PyCon Italia 2017</category><category>image-processing</category><category>numpy</category><category>neural network</category><category>Artificial Intelligence</category><category>Machine Learning</category></item><item><title>GPU-accelerated data analysis in Python: a study case in Material Sciences</title><link>https://pyvideo.org/pycon-italia-2018/gpu-accelerated-data-analysis-in-python-a-study-case-in-material-sciences.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Max Planck Computing and Data Facility is engaged in the development
and optimization of algorithms and applications for high performance
computing as well as for data-intensive projects. As programming
language in data science, Python is now used at MPCDF in the scientific
area of “atom probe crystallography” (APT): a Fourier analysis in 3D
space can be simulated in order to reveal composition and
crystallographic structure at the atomic scale of billions APT
experimental data sets.&lt;/p&gt;
&lt;p&gt;The Python data ecosystem has proved to be well suited to this, as it
has grown beyond the confines of single machines to embrace scalability.
The talk aims to describe our approach to scaling across multiple GPUs,
and the role of visualization methods too.&lt;/p&gt;
&lt;p&gt;Our data workflow analysis relies on the GPU-accelerated Python software
package PyNX, an open source library which provides fast parallel
computation scattering. The code takes advantage of the high throughput
of GPUs, using the pyCUDA library.&lt;/p&gt;
&lt;p&gt;Exploratory data analysis, high productivity and rapid prototyping with
high performance are enabled through Jupyter Notebooks and Python
packages e.g., pandas, matplotlib/plotly. In production stage,
interactive visualization is realized by using standard scientific tool,
e.g. Paraview, an open-source 3D visualization program which requires
Python modules to generate visualization components within VTK files.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 14:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Giuseppe Di Bernardo</dc:creator><pubDate>Sat, 21 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-21:/pycon-italia-2018/gpu-accelerated-data-analysis-in-python-a-study-case-in-material-sciences.html</guid><category>PyCon Italia 2018</category><category>GPUComputing</category><category>visualization</category><category>mathematical-modelling</category><category>image-processing</category><category>bigdata</category><category>matplotlib</category><category>analytics</category><category>data-visualization</category><category>data-analysis</category><category>Data Mining</category><category>scientific-computing</category><category>physics</category><category>python3</category></item><item><title>Image Generation with Tensorflow (GANs)</title><link>https://pyvideo.org/pycon-italia-2018/image-generation-with-tensorflow-gans.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python is an opensource language that has a wide community, and nowadays
the biggest companies also create frameworks, libraries with Python and
open- sourced them. Tensorflow is the most used library in Deep Learning
by researchers and there are many examples of various fields like
Computer Vision, Natural Language Processing, Signal Processing.&lt;/p&gt;
&lt;p&gt;Nowadays, Generative Adversarial Networks a.k.a. GAN collect nearly all
interests on it by the Computer Vision experts. There are diverse
applications like image colorization, image generation from random
numbers, computer game character creation, face frontalization, face
alignment, 2D to 3D image transfer, style transfer and so on.&lt;/p&gt;
&lt;p&gt;In this talk, we are going to talk about GANs and the implementation
details on Tensorflow which is backed by Google and has the power of
either work on CPU and GPU.&lt;/p&gt;
&lt;p&gt;The implementation of GANs can be divided into 2 parts. One is called
generator and other is called discriminator. In this talk, the
differences between the discriminator and generator also are mentioned.&lt;/p&gt;
&lt;p&gt;Besides, some various architecture of GANs like PGGAN, DCGAN, STARGAN,
architectures showed in Tensorflow code, which of these are not already
implemented in Tensorflow by the date now.&lt;/p&gt;
&lt;p&gt;The session will be finished with showing some examples of outputs in
face generation, room generation, and also live demo of the style
transfer implementation.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 15:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Cenk Bircanoğlu</dc:creator><pubDate>Sat, 21 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-21:/pycon-italia-2018/image-generation-with-tensorflow-gans.html</guid><category>PyCon Italia 2018</category><category>Deep-Learning</category><category>image-processing</category><category>computer-science</category><category>tensorflow</category><category>ComputerVision</category></item><item><title>Applying serverless architecture pattern to distributed data processing</title><link>https://pyvideo.org/pycon-italia-2018/applying-serverless-architecture-pattern-to-distributed-data-processing.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Serverless architectures refer to applications that significantly depend
on “cloud” services (knows as Backend as a Service) or on custom code
that’s run in ephemeral runtime (Function as a Service or “FaaS&amp;quot;).&lt;/p&gt;
&lt;p&gt;To application developers, “serverless” mean app where some certain
logic of it is still written by the developer but unlike traditional
architectures or microservices is run in stateless compute runtime that
is event-triggered, may only last for one invocation, and fully managed
by a cloud. Serverless helps developers to transfer responsibility for
keeping their apps up and running as well as scaling out their workload
capacity without involving DevOps/ops as we got used to.&lt;/p&gt;
&lt;p&gt;In this talk we will go through whole “serverless” thing: from
decomposing app and its logic to microservices and further to smaller
bits, i.e. functions to defining data flow through functions and
building their fault-tolerant pipeline. Moreover, we will go through a
demo that highlights key takeaways:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;what are functions, what it could and could not be&lt;/li&gt;
&lt;li&gt;how to design scalable architecture without getting into troubles by
hitting concrete bottlenecks&lt;/li&gt;
&lt;li&gt;how serverless can help scaling in/out compute capacity for data
processing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The demo itself will include examples of applying serverless
architecture pattern to emotion recognition app based on TensorFlow and
OpenCV 3.3&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 20 April&lt;/strong&gt; at 15:15 &lt;a class="reference external" href="/en/sprints/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Denis Makogon</dc:creator><pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-20:/pycon-italia-2018/applying-serverless-architecture-pattern-to-distributed-data-processing.html</guid><category>PyCon Italia 2018</category><category>serverless</category><category>image-processing</category><category>data-exploration</category><category>emotion-recognition</category><category>Deep-Learning</category><category>opencv</category><category>tensorflow</category><category>python3</category></item></channel></rss>