<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_michal-jamroz.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-12-12T00:00:00+00:00</updated><entry><title>Posterior Collapse in Deep Generative models</title><link href="https://pyvideo.org/pydata-warsaw-2019/posterior-collapse-in-deep-generative-models.html" rel="alternate"></link><published>2019-12-12T00:00:00+00:00</published><updated>2019-12-12T00:00:00+00:00</updated><author><name>Michał Jamroż</name></author><id>tag:pyvideo.org,2019-12-12:pydata-warsaw-2019/posterior-collapse-in-deep-generative-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Generative models are powerful Machine Learning models useful at
extracting information from high-dimensional data, but they sometimes
suffer from the problem called &amp;quot;posterior collapse&amp;quot; which prevents them
from learning representation having practical value. I am going to show
why and when it happens, also how to deal with it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Deep generative models like Variational AutoEncoders (VAEs) and
Generative Adversarial Networks (GANs) turned out to be very successful
in real-world applications of machine learning, including: natural image
modelling, data compression, audio synthesis and many more.
Unfortunately, it appears that models belonging to VAEs family - under
some conditions may suffer from an undesired phenomenon called
&amp;quot;posterior collapse&amp;quot; which causes them to learn poor data
representation. The talk's purpose is to present this problem and its
practical implications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The presentation will comprise following elements:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Short introduction of basic Variational AutoEncoder model&lt;/li&gt;
&lt;li&gt;Introducing the &amp;quot;posterior collapse&amp;quot; problem&lt;/li&gt;
&lt;li&gt;How posterior collapse affects learning from data - natural images
examples&lt;/li&gt;
&lt;li&gt;Some research on dealing with posterior collapse&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Audience&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Being familiarised with the topic of generative modelling will be
helpful for anyone attending the talk, but it's not required. In fact,
everyone having basic understanding of neural networks, representation
learning and probability can gain useful information. Presentation won't
be overloaded with mathematical formulas, I will do my best to present
math-related aspects in an intuitive form.&lt;/p&gt;
</summary></entry><entry><title>Deep learning for image segmentation</title><link href="https://pyvideo.org/pydata-warsaw-group/deep-learning-for-image-segmentation.html" rel="alternate"></link><published>2016-09-28T00:00:00+00:00</published><updated>2016-09-28T00:00:00+00:00</updated><author><name>Mateusz Opala</name></author><id>tag:pyvideo.org,2016-09-28:pydata-warsaw-group/deep-learning-for-image-segmentation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;#6 PyData Warsaw&lt;/p&gt;
&lt;p&gt;Deep learning techniques ignited a great progress in many computer vision tasks like image classification, object detection, and segmentation. Almost every month a new method is published that achieves state-of-the-art result on some common benchmark dataset. In addition to that, DL is being applied to new problems in CV.&lt;/p&gt;
&lt;p&gt;In the talk we’re going to focus on DL application to image segmentation task. We want to show the practical importance of this task for the fashion industry by presenting our case study with results achieved with various attempts and methods.&lt;/p&gt;
</summary></entry><entry><title>Representation learning</title><link href="https://pyvideo.org/pydata-warsaw-group/representation-learning.html" rel="alternate"></link><published>2015-09-24T00:00:00+00:00</published><updated>2015-09-24T00:00:00+00:00</updated><author><name>Mateusz Opala</name></author><id>tag:pyvideo.org,2015-09-24:pydata-warsaw-group/representation-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;#1 PyData Warsaw&lt;/p&gt;
&lt;p&gt;In the last couple of years there’ve been a lot of buzz generated around performance of deep learning algorithms. DeepMind’s AI plays Atari games, Google’s AI recognizes cats on youtube, smartphones are great at speech recognition, and who knows what we’ll read about tomorrow.&lt;/p&gt;
&lt;p&gt;In the talk we’re going to show you what’s deep learning about using a couple of practical examples. You’ll see that the state-of-the-art of machine learning is not out of reach of a determined pythonista who doesn’t keep away from math.&lt;/p&gt;
</summary></entry></feed>