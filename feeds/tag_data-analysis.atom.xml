<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_data-analysis.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-05-05T00:00:00+00:00</updated><entry><title>Introduction to Exploratory Data Analysis with the Sci-Analysis Python Package</title><link href="https://pyvideo.org/pytexas-2019/introduction-to-exploratory-data-analysis-with-the-sci-analysis-python-package.html" rel="alternate"></link><published>2019-04-13T00:00:00+00:00</published><updated>2019-04-13T00:00:00+00:00</updated><author><name>Chris Morrow</name></author><id>tag:pyvideo.org,2019-04-13:pytexas-2019/introduction-to-exploratory-data-analysis-with-the-sci-analysis-python-package.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Exploratory Data Analysis is an important step in data science and analysis. The PyData stack has many useful tools for performing EDA but the learning curve to use these tools can be steep. Sci-Analysis simplifies EDA by combining meaningful visualizations with the appropriate statistical analysis.&lt;/p&gt;
</summary><category term="Sci-Analysis"></category><category term="data-analysis"></category></entry><entry><title>Deep Learning for brain MRI segmentation: Big Data, AI and HPC meet together</title><link href="https://pyvideo.org/pycon-italia-2019/deep-learning-for-brain-mri-segmentation-big-data-ai-and-hpc-meet-together.html" rel="alternate"></link><published>2019-05-05T00:00:00+00:00</published><updated>2019-05-05T00:00:00+00:00</updated><author><name>Giuseppe Di Bernardo</name></author><id>tag:pyvideo.org,2019-05-05:pycon-italia-2019/deep-learning-for-brain-mri-segmentation-big-data-ai-and-hpc-meet-together.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;With ever-increasing advancements in technology, neuroscientists are
able to collect data in greater volumes and with finer resolution. There
has been a growing interest in leveraging this vast volume of data
across levels of analysis, measurement techniques, and experimental
paradigms to gain more insight into brain function. At multiple stages
and levels of neuroscience investigation, ML holds great promise as an
addition to the arsenal of analysis tools for discovering how the brain
works. As quantitative analysis of brain MRI is routine for many
neurological diseases and conditions, deep learning-based segmentation
approaches for brain Magnetic Resonance Imaging (MRI) are gaining
interest due to their self-learning and generalisation ability over
large amounts of data. On the other hand, High Performance Computing
(HPC) and AI will increasingly intertwine as we transition to an
exascale future using new computing, storage, and communications
technologies. In this talk I will walk you through fundamentals of
generating high- performance deep-learning models in TensorFlow platform
using Python on large computing system (e.g NVIDIA® Tesla® GPUs powered
by Tensor Cores), in order to infer and segment thousands of cell
centroids out of the brain objects of interest. From a more
technological perspective, although astonishing results have been
achieved concerning the distribution of training large convolutional
neural networks on big data, to date the Python scientific ecosystem is
still missing tools for an optimised and, above all, distributed
inference of deep learning models. In this talk I will show you how a
tiling-based inferencing approach could be a good solution to remedy the
problem. The talk is intended for intermediate PyData researchers and
practitioners. Basic to intermediate level experience in image
recognition/object detection deep learning applications is assumed.
Overall, a good proficiency with the Python language and with scientific
python libraries (e.g. numpy, TensorFlow, Keras) are required for the
entire talk.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1794"&gt;https://python.it/feedback-1794&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Sunday 5 May&lt;/strong&gt; at 11:00 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="GPUComputing"></category><category term="parallelization"></category><category term="bio-informatics"></category><category term="Machine Learning"></category><category term="ComputerVision"></category><category term="optimization"></category><category term="data-analysis"></category><category term="Artificial Intelligence"></category></entry><entry><title>You don't need n dimensions when you have pandas</title><link href="https://pyvideo.org/pycon-italia-2019/you-dont-need-n-dimensions-when-you-have-pandas.html" rel="alternate"></link><published>2019-05-05T00:00:00+00:00</published><updated>2019-05-05T00:00:00+00:00</updated><author><name>Pietro Battiston</name></author><id>tag:pyvideo.org,2019-05-05:pycon-italia-2019/you-dont-need-n-dimensions-when-you-have-pandas.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;a class="reference external" href="https://pietrobattiston.it/wiki/python:pycon#talk_you_don_t_need_n_dimensions_when_you_have_pandas"&gt;Click here for slides and material
used&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;After a (very) quick general introduction to &lt;tt class="docutils literal"&gt;pandas&lt;/tt&gt;, and in
particular to pandas &lt;strong&gt;indexes&lt;/strong&gt; , this talk will focus on particular
types of indexes, &lt;tt class="docutils literal"&gt;MultiIndex&lt;/tt&gt;es, and on the many &lt;tt class="docutils literal"&gt;pandas&lt;/tt&gt;
features allowing us to use them to store and analyze multidimensional
data.&lt;/p&gt;
&lt;p&gt;We will discover together &lt;em&gt;why&lt;/em&gt; &lt;tt class="docutils literal"&gt;pandas&lt;/tt&gt; does not have (any more) data
structures with more than 2 dimensions, and why we should not regret
them. We will then look at further ways to “restructure” data, including
&lt;tt class="docutils literal"&gt;groupby&lt;/tt&gt; e &lt;tt class="docutils literal"&gt;window&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1771"&gt;https://python.it/feedback-1771&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Sunday 5 May&lt;/strong&gt; at 11:45 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="data-structures"></category><category term="numpy"></category><category term="pandas"></category><category term="data-analysis"></category><category term="pydata"></category></entry><entry><title>Please tell me why?! Explaining Machine Learning predictions in Python with Shap</title><link href="https://pyvideo.org/pycon-italia-2019/please-tell-me-why-explaining-machine-learning-predictions-in-python-with-shap.html" rel="alternate"></link><published>2019-05-04T00:00:00+00:00</published><updated>2019-05-04T00:00:00+00:00</updated><author><name>Alessio Guerrieri</name></author><id>tag:pyvideo.org,2019-05-04:pycon-italia-2019/please-tell-me-why-explaining-machine-learning-predictions-in-python-with-shap.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we will discuss the problem of making results coming from
machine learning models understandable to both the data scientists and
the final users. While most machine learning frameworks already include
metrics that measure the importance of different features during
training, fewer allow us to understand which features were most
important for a specific prediction at runtime. We will describe our use
case, discuss a few options and finally present Shap, an open-source
python library able to interpret many different models. Shap comes with
both general purpose tools and specialized tools for families of machine
learning models and with integrations for Jupyter and Matplotlib for
easy use during exploration and testing of a model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1601"&gt;https://python.it/feedback-1601&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Saturday 4 May&lt;/strong&gt; at 17:15 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="scikit-learn"></category><category term="machine-learning"></category><category term="data-analysis"></category></entry><entry><title>Pandas ecosystem 2019</title><link href="https://pyvideo.org/pycon-italia-2019/pandas-ecosystem-2019.html" rel="alternate"></link><published>2019-05-03T00:00:00+00:00</published><updated>2019-05-03T00:00:00+00:00</updated><author><name>Marc Garcia</name></author><id>tag:pyvideo.org,2019-05-03:pycon-italia-2019/pandas-ecosystem-2019.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;pandas is more than 10 years old now. In this time, it became almost a
standard for building data pipelines and perform data analysis in
Python. As the popularity of the project grows, it also grows the number
of projects that depend or interact with pandas.&lt;/p&gt;
&lt;p&gt;This talk will cover this ecosystem of projects around pandas, mainly in
the prespective of scalability and performance. Discussing for example
how projects like Arrow are key for the future of pandas, or how Dask is
overcoming pandas limitations.&lt;/p&gt;
&lt;p&gt;In a first part, the talk will focus on pandas itself, its components,
and its architecture. This will give the required context for a second
part, that will explain related projects, how they interact with pandas,
and what the whole ecosystem can offer to users.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1613"&gt;https://python.it/feedback-1613&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 12:00 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="pydata"></category><category term="analytics"></category><category term="data-analysis"></category><category term="Data Mining"></category><category term="data"></category><category term="pandas"></category></entry><entry><title>Beyond Search</title><link href="https://pyvideo.org/europython-2013/beyond-search.html" rel="alternate"></link><published>2013-07-05T00:00:00+00:00</published><updated>2013-07-05T00:00:00+00:00</updated><author><name>Honza Král</name></author><id>tag:pyvideo.org,2013-07-05:europython-2013/beyond-search.html</id><summary type="html"></summary><category term="search"></category><category term="elasticsearch"></category><category term="data-analysis"></category></entry><entry><title>Scegliere le armi per la battaglia del calcolo intensivo</title><link href="https://pyvideo.org/europython-2013/scegliere-le-armi-per-la-battaglia-del-calcolo-intensivo.html" rel="alternate"></link><published>2013-07-05T00:00:00+00:00</published><updated>2013-07-05T00:00:00+00:00</updated><author><name>Enrico Franchi</name></author><id>tag:pyvideo.org,2013-07-05:europython-2013/scegliere-le-armi-per-la-battaglia-del-calcolo-intensivo.html</id><summary type="html"></summary><category term="bigdata"></category><category term="optimization"></category><category term="data-analysis"></category><category term="hpc"></category><category term="performance"></category><category term="scientific-computing"></category></entry><entry><title>Never get in a battle of bits without ammunition.</title><link href="https://pyvideo.org/europython-2013/never-get-in-a-battle-of-bits-without-ammunition.html" rel="alternate"></link><published>2013-07-04T00:00:00+00:00</published><updated>2013-07-04T00:00:00+00:00</updated><author><name>Enrico Franchi</name></author><id>tag:pyvideo.org,2013-07-04:europython-2013/never-get-in-a-battle-of-bits-without-ammunition.html</id><summary type="html"></summary><category term="cython"></category><category term="C/C++"></category><category term="nosql"></category><category term="mongodb"></category><category term="numeric"></category><category term="iPython"></category><category term="optimization"></category><category term="Algorithms"></category><category term="data-analysis"></category><category term="hpc"></category><category term="performance"></category><category term="scientific-computing"></category><category term="numpy"></category></entry><entry><title>Introduction to machine learning using Python tools</title><link href="https://pyvideo.org/europython-2013/introduction-to-machine-learning-using-python-tools.html" rel="alternate"></link><published>2013-07-02T00:00:00+00:00</published><updated>2013-07-02T00:00:00+00:00</updated><author><name>Satish Shankar</name></author><id>tag:pyvideo.org,2013-07-02:europython-2013/introduction-to-machine-learning-using-python-tools.html</id><summary type="html"></summary><category term="statistics"></category><category term="machine-learning"></category><category term="datamining"></category><category term="Algorithms"></category><category term="data-analysis"></category><category term="scientific-computing"></category><category term="sklearn"></category></entry><entry><title>GPU-accelerated data analysis in Python: a study case in Material Sciences</title><link href="https://pyvideo.org/pycon-italia-2018/gpu-accelerated-data-analysis-in-python-a-study-case-in-material-sciences.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Giuseppe Di Bernardo</name></author><id>tag:pyvideo.org,2018-04-21:pycon-italia-2018/gpu-accelerated-data-analysis-in-python-a-study-case-in-material-sciences.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Max Planck Computing and Data Facility is engaged in the development
and optimization of algorithms and applications for high performance
computing as well as for data-intensive projects. As programming
language in data science, Python is now used at MPCDF in the scientific
area of “atom probe crystallography” (APT): a Fourier analysis in 3D
space can be simulated in order to reveal composition and
crystallographic structure at the atomic scale of billions APT
experimental data sets.&lt;/p&gt;
&lt;p&gt;The Python data ecosystem has proved to be well suited to this, as it
has grown beyond the confines of single machines to embrace scalability.
The talk aims to describe our approach to scaling across multiple GPUs,
and the role of visualization methods too.&lt;/p&gt;
&lt;p&gt;Our data workflow analysis relies on the GPU-accelerated Python software
package PyNX, an open source library which provides fast parallel
computation scattering. The code takes advantage of the high throughput
of GPUs, using the pyCUDA library.&lt;/p&gt;
&lt;p&gt;Exploratory data analysis, high productivity and rapid prototyping with
high performance are enabled through Jupyter Notebooks and Python
packages e.g., pandas, matplotlib/plotly. In production stage,
interactive visualization is realized by using standard scientific tool,
e.g. Paraview, an open-source 3D visualization program which requires
Python modules to generate visualization components within VTK files.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 14:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="GPUComputing"></category><category term="visualization"></category><category term="mathematical-modelling"></category><category term="image-processing"></category><category term="bigdata"></category><category term="matplotlib"></category><category term="analytics"></category><category term="data-visualization"></category><category term="data-analysis"></category><category term="Data Mining"></category><category term="scientific-computing"></category><category term="physics"></category><category term="python3"></category></entry><entry><title>Hacking Your Way Into Machine Learning</title><link href="https://pyvideo.org/pycon-italia-2018/hacking-your-way-into-machine-learning.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Laksh Arora</name></author><id>tag:pyvideo.org,2018-04-21:pycon-italia-2018/hacking-your-way-into-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;You might have heard of Machine Learning from your co-worker or in a local meetup and are enticed to get started but not sure how to take that first step. Confused between different sources, where to start from or how to proceed given a particular problem statement or dataset, then this talk is for you. It is aimed at complete beginners ( maybe you? ) who are just starting in machine learning and are ready to commit.
The talk will go something like this - each of the following items will be explained how it’s useful and why we should use it. Then alongside showcase, that same step applied to the real example(dataset) of that particular item so that the audience will be able to grasp the idea. It will add to around 35 minutes leaving us with 10 minutes for Q&amp;amp;A.
1) Context ( 5 mins ):
Discuss why we need Machine Learning and how we can use Machine Learning in different domains.
2) Resources ( 3 mins):
Talks about the dataset availability, online competitions, and Open Source libraries such as Scikit-learn, Matplotlib, Keras.
3) Jupyter Notebook (25 mins):
This Jupyter notebook will be a great starting point for most Supervised Machine Learning projects that involve common tasks: a) Imports and data loading (2 mins )
b) Data Exploration (5 mins)
c) Data Cleaning (3 mins)
d) Feature Engineering (4 mins)
e) Model Exploration (6 mins)
f) Final Model Building and Prediction ( 5 mins)
4) Wrap up ( 2 mins ):
Finalizing my talk, sharing some tips etc.
5) Q&amp;amp;A ( 10 mins ):
Question and Answering with the Audience.
Hope to inspire the audience to get started with machine learning, explore different domains, to learn, to create and engage with the Machine Learning Community.&lt;/p&gt;
</summary><category term="data-analysis"></category><category term="data-visualization"></category><category term="Python"></category><category term="scikit-learn"></category><category term="matplotlib"></category><category term="analytics"></category><category term="scipy"></category><category term="machine-learning"></category><category term="data"></category><category term="Statistical Learning"></category></entry><entry><title>Lies, damned lies, and statistics</title><link href="https://pyvideo.org/pycon-italia-2018/lies-damned-lies-and-statistics.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Marco Bonzanini</name></author><id>tag:pyvideo.org,2018-04-21:pycon-italia-2018/lies-damned-lies-and-statistics.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Statistics show that eating ice cream causes death by drowning.&lt;/p&gt;
&lt;p&gt;If this sounds baffling, this talk will help you to understand
correlation, bias, statistical significance and other statistical
techniques that are commonly (mis)used to support an argument that
leads, by accident or on purpose, to drawing the wrong conclusions.&lt;/p&gt;
&lt;p&gt;The casual observer is exposed to the use of statistics and probability
in everyday life, but it is extremely easy to fall victim of a
statistical fallacy, even for professional users.&lt;/p&gt;
&lt;p&gt;The purpose of this talk is to help the audience understand how to
recognise and avoid these fallacies, by combining an introduction to
statistics with examples of lies and damned lies, in a way that is
approachable for beginners.&lt;/p&gt;
&lt;p&gt;Agenda:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Correlation and causation&lt;/li&gt;
&lt;li&gt;Simpson’s Paradox&lt;/li&gt;
&lt;li&gt;Sampling bias and polluted surveys&lt;/li&gt;
&lt;li&gt;Data visualisation gone wild&lt;/li&gt;
&lt;li&gt;Statistical significance (and Data dredging a.k.a. p-hacking)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="reference external" href="https://speakerdeck.com/marcobonzanini/lies-damned-lies-and-statistics-at-pycon-italia-2018"&gt;Slides&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 12:00 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="data-visualization"></category><category term="statistics"></category><category term="data-analysis"></category><category term="pydata"></category></entry><entry><title>Predicting future states using High Order Markov Chains</title><link href="https://pyvideo.org/pycon-italia-2018/predicting-future-states-using-high-order-markov-chains.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Pietro Mascolo</name></author><id>tag:pyvideo.org,2018-04-21:pycon-italia-2018/predicting-future-states-using-high-order-markov-chains.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In modern automated systems (Interactive Voice Response, help chatbots,
routing systems, etc.) it is very often important to be able to predict
what is the most likely next step for the current user. One way of
addressing this issue is using sequence algorithms such as Markov
Chains.&lt;/p&gt;
&lt;p&gt;After a quick introduction to the concept of Markov chains and Markov
processes, we will explore the basics and the implementation of a simple
High Order Markov chain to predict what the most likely next state in a
sequence, based on previous states. We will be using anonymized
real-life data of an automated system and we will try to come up with a
model that can give us the most probable next state using Markov chains
of different orders.&lt;/p&gt;
&lt;p&gt;Things we will see in detail: - Mathematics and rationale behind Markov
Chains; - Basic implementation of First Order Markov Chains; -
Implementation of High Order Markov Chains; - Real life application of
the developed model.&lt;/p&gt;
&lt;p&gt;An undergraduate level of understanding of Linear Algebra and basic
Python skills will be useful to follow the talk.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 15:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="pydata"></category><category term="Pyston"></category><category term="algebra"></category><category term="Machine Learning"></category><category term="scipy"></category><category term="data-analysis"></category><category term="mathematics"></category><category term="data"></category><category term="python3"></category></entry><entry><title>Using Python to bring democracy to the A.I. age</title><link href="https://pyvideo.org/pycon-italia-2018/using-python-to-bring-democracy-to-the-ai-age.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Felipe Cabral</name></author><id>tag:pyvideo.org,2018-04-21:pycon-italia-2018/using-python-to-bring-democracy-to-the-ai-age.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;TL;DR&lt;/p&gt;
&lt;div class="section" id="when-you-go-full-big-data-at-public-data-and-become-a-citzen"&gt;
&lt;h4&gt;When you go full Big Data at public data and become a citzen.&lt;/h4&gt;
&lt;p&gt;Audience type: developers, data scientists of any level of expertise.&lt;/p&gt;
&lt;p&gt;After a political coup Brazil drowned in scandals and political
disbelief. That was the final straw for us.&lt;/p&gt;
&lt;p&gt;We created a bot persona who uses Machine Learning to analyze public
spending, launching our own data journalism investigations. As expected
we use the internet publicize our findings and icing on it was to use
Twitter to directly engage the public and politicians under the topic of
suspicious expenses.&lt;/p&gt;
&lt;p&gt;Come with me and I’ll show some figures from Brazilian corruption, share
some code and cherry-pick the best of our toolbox to deal with public
data and machine learning. I’ll introduce our public dashboard that
makes visualization and browsing government data easy peasy. And surely
we can take a look in some tweets from Rosie, the robot, and how some
politicians are now vociferating with a ROBOT on social media.&lt;/p&gt;
&lt;p&gt;And you guessed it right: everything is open-source and our mission is
to create a global community to bring democracy to the A.I. age.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 18:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</summary><category term="machine-learning"></category><category term="Python"></category><category term="agile"></category><category term="Data Mining"></category><category term="bigdata"></category><category term="data-visualization"></category><category term="OpenSource"></category><category term="data-analysis"></category><category term="e-gov"></category><category term="data"></category></entry><entry><title>Deep Learning from zero to hero</title><link href="https://pyvideo.org/pycon-italia-2018/deep-learning-from-zero-to-hero.html" rel="alternate"></link><published>2018-04-20T00:00:00+00:00</published><updated>2018-04-20T00:00:00+00:00</updated><author><name>Gianluca Carucci</name></author><id>tag:pyvideo.org,2018-04-20:pycon-italia-2018/deep-learning-from-zero-to-hero.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Avete sentito parlare di Deep Learning ma credete che la teoria alla
base sia troppo complessa? Non avete una laurea in matematica e
statistica e pensate che il machine learning non faccia per voi? Niente
paura: avrete solo bisogno di una conoscenze di base di Python.&lt;/p&gt;
&lt;p&gt;Conoscete la regola dell’80/20? Con il 20% delle conoscenze potete
raggiungere l’80% dei risultati: in questo talk vi mostrerò in modo
pratico tramite delle demo - alcuni trucchi per costruire dei buoni
modelli predittivi, evitando di perdere (tanto) tempo nella scelta dei
tools e delle librerie necessarie al vostro scopo.&lt;/p&gt;
&lt;p&gt;L’obbiettivo è fornirvi le basi pratiche con cui scegliere un modello di
rete neurale, farne training e ottimizzarlo nel modo più adatto alla
tipologia del problema che dovete affrontare.&lt;/p&gt;
&lt;p&gt;Agenda: - Introduzione al Deep Learning - Un esempio di training senza
scrivere codice - Sviluppare, testare e ottimizzare un modello reale -
Considerazioni finali&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;venerdì 20 aprile&lt;/strong&gt; at 12:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="machine-learning"></category><category term="Keras"></category><category term="Deep-Learning"></category><category term="data-analysis"></category><category term="tensorflow"></category><category term="computer-science"></category><category term="neural network"></category></entry><entry><title>Voting-based Ranking Combination using Python</title><link href="https://pyvideo.org/pycon-italia-2018/voting-based-ranking-combination-using-python.html" rel="alternate"></link><published>2018-04-20T00:00:00+00:00</published><updated>2018-04-20T00:00:00+00:00</updated><author><name>Ferran Muiños</name></author><id>tag:pyvideo.org,2018-04-20:pycon-italia-2018/voting-based-ranking-combination-using-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Slides:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://slides.com/ferranmuinos/deck#/"&gt;Using votes to combine
rankings&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;How to best combine the outcome of several ranked data into a single,
meaningful consensus ranking is a recurrent problem in scientific data
analysis. Particularly, in genome data analysis we are often bound to
merge ranked data arising from separate statistical analyses.&lt;/p&gt;
&lt;p&gt;Traditional blending strategies applied in the field rely on techniques
to combine statistical significance, but this approach on its own has
been associated with a number of caveats.&lt;/p&gt;
&lt;p&gt;We hereto present a voting-based heuristics implemented in Python which
leverages both Schulze’s voting algorithm and optimization techniques to
combine rankings upon credibility scores inferred from prior knowledge.
This rationale can be used alongside state-of-the-art methods to
systematically incorporate prior knowledge, thereby leading to more
interpretable outcomes. The scope of the method is quite general and may
be of use in other data analysis contexts.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Presenter: &lt;a class="reference external" href="https://goo.gl/QDCMf3"&gt;Ferran Muiños&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Authors of the work: &lt;a class="reference external" href="https://goo.gl/QDCMf3"&gt;Ferran Muiños&lt;/a&gt;,
&lt;a class="reference external" href="https://goo.gl/weg7Nh"&gt;Francisco Martínez-Jiménez&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Focus:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To showcase a scientific data analysis problem arising from the study of
cancer biology and how we approached it by implementing our own tool in
Python.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Target Audience:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The talk aims to a broad Python audience. Minimum Python fluency is
required. Acquaintance with basic notions of data analysis may be
helpful to best follow the talk.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;venerdì 20 aprile&lt;/strong&gt; at 16:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="Python"></category><category term="statistics"></category><category term="genetics"></category><category term="bio-informatics"></category><category term="data-analysis"></category></entry><entry><title>How to turn Wikipedia into a Quiz Game</title><link href="https://pyvideo.org/pycon-italia-2017/how-to-turn-wikipedia-into-a-quiz-game.html" rel="alternate"></link><published>2017-04-08T00:00:00+00:00</published><updated>2017-04-08T00:00:00+00:00</updated><author><name>Andrea Cappelli</name></author><id>tag:pyvideo.org,2017-04-08:pycon-italia-2017/how-to-turn-wikipedia-into-a-quiz-game.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Quiz games let people test their knowledge through multi-choice
questions. Unfortunately, generating such questions can be very
time-consuming and it is typically done manually. In this talk we
will present a pipeline to automatically generate quiz games starting
from generic knowledge (e.g. Wikipedia). The pipeline consists of the
following components: (i) a parser to retrieve text from Wikipedia
pages, (ii) a Natural Language Processing module (based on the Google
Natural Language API) to extract information about syntax, entities
and relations, (iii) a Natural Language Generation module to generate
test questions and correct answers, and finally (iv) a domain-aware
module that uses domain-specific knowledge to generate wrong answers
(i.e. distractors). Every module is written in Python and it is based
on either available libraries or Cloud services (e.g., Google Natural
Language).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;: basic knowledge of python, minimal understanding
of text syntactic analysis.&lt;/p&gt;
</summary><category term="nlp"></category><category term="AI"></category><category term="games"></category><category term="computational-linguistics"></category><category term="data-analysis"></category><category term="text-analysis"></category><category term="google-cloud"></category><category term="Artificial Intelligence"></category><category term="linked-data"></category></entry><entry><title>Introduction to Data-Analysis with Pandas / Time Series Analysis with Pandas</title><link href="https://pyvideo.org/pycon-italia-2017/introduction-to-data-analysis-with-pandas-time-series-analysis-with-pandas.html" rel="alternate"></link><published>2017-04-08T00:00:00+00:00</published><updated>2017-04-08T00:00:00+00:00</updated><author><name>Alexander Hendorf</name></author><id>tag:pyvideo.org,2017-04-08:pycon-italia-2017/introduction-to-data-analysis-with-pandas-time-series-analysis-with-pandas.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas is the &lt;em&gt;Swiss-Multipurpose Knife&lt;/em&gt; for Data Analysis in Python.
With Pandas dealing with data-analysis is easy and simple but there are
some things you need to get your head around first as Data-Frames and
Data-Series.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;first part&lt;/strong&gt; of talk with provide an &lt;strong&gt;introduction to Pandas&lt;/strong&gt;
for beginners, while the &lt;strong&gt;second part&lt;/strong&gt; will focus on &lt;strong&gt;Time Series
Analysis&lt;/strong&gt; with Pandas.&lt;/p&gt;
&lt;p&gt;part &lt;strong&gt;one&lt;/strong&gt; (~40&amp;quot;) &lt;em&gt;Introduction to Pandas&lt;/em&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;reading and writing data across multiple formats (CSV, Excel, JSON,
SQL, HTML,…)&lt;/li&gt;
&lt;li&gt;statistical data analysis and aggregation.&lt;/li&gt;
&lt;li&gt;work with built-in data visualisation&lt;/li&gt;
&lt;li&gt;inner-mechanics of Pandas: Data-Frames, Data-Series &amp;amp; Numpy.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;part &lt;strong&gt;two&lt;/strong&gt; (~20&amp;quot;) &lt;em&gt;Time Series Analysis&lt;/em&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;how to analyse periodical data with pandas&lt;/li&gt;
&lt;li&gt;how to mangle, reshape and pivot&lt;/li&gt;
&lt;li&gt;caveats when working with timed data&lt;/li&gt;
&lt;li&gt;visualize your data on the fly&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;bonus (if we have time left)&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;gain insights with statsmodels (e.g. seasonality)&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="data-visualization"></category><category term="computer-science"></category><category term="statistics"></category><category term="data-analysis"></category></entry><entry><title>Sparking Pandas: an experiment</title><link href="https://pyvideo.org/pycon-italia-2017/sparking-pandas-an-experiment.html" rel="alternate"></link><published>2017-04-07T00:00:00+00:00</published><updated>2017-04-07T00:00:00+00:00</updated><author><name>Francesco Bruni</name></author><id>tag:pyvideo.org,2017-04-07:pycon-italia-2017/sparking-pandas-an-experiment.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas is a good library to deal with tabular data. What if you need to
manage an amount of data that doesn’t fit into memory? What if you want
to “distribute” your computations among multiple machines?&lt;/p&gt;
&lt;p&gt;Starting from a real scenario, Apache Spark will be presented as the
main tool to read and process collected data. It will be shown how a
Pandas-like syntax will come in handy to run aggregations, filtering and
grouping using a Spark Dataframe.&lt;/p&gt;
&lt;p&gt;A previous knowledge of Docker and Docker Compose will be very useful
while knowing MongoDB (where data will be fetched from) is not
mandatory. Basics of functional programming will help to understand
Spark inner logic.&lt;/p&gt;
</summary><category term="microservices"></category><category term="Jupyter"></category><category term="mongodb"></category><category term="data-visualization"></category><category term="data-analysis"></category><category term="spark"></category><category term="docker"></category></entry><entry><title>Data Science &amp; Data Visualization in Python. How to harness power of Python for social good?</title><link href="https://pyvideo.org/pydata-berlin-2017/data-science-data-visualization-in-python-how-to-harness-power-of-python-for-social-good.html" rel="alternate"></link><published>2017-06-30T00:00:00+00:00</published><updated>2017-06-30T00:00:00+00:00</updated><author><name>Radovan Kavicky</name></author><id>tag:pyvideo.org,2017-06-30:pydata-berlin-2017/data-science-data-visualization-in-python-how-to-harness-power-of-python-for-social-good.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python as an Open Data Science tool offers many libraries for data visualization and I will show you how to use and combine the best. I strongly believe that power of data is not only in the information &amp;amp; insight that data can provide us, Data is and can be really beautiful and can not only transform our perception but also the world that we all live in.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In my talk I will primarily focus on answering/offer the answer to these questions:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Why we need data science and why more and more people should be really interested in analyzing data and data visualization? (motivation)&lt;/li&gt;
&lt;li&gt;What is data science and how to start doing it in Python? (introduction of procedures, tools, most popular IDE-s for Python, etc.)&lt;/li&gt;
&lt;li&gt;What tools for data analysis and data visualization Python offers? (in each stage of analysis the best libraries will be shown for the specific purpose; as for data visualization we will focus particularly on Bokeh, Seaborn, Plotly and use of Jupyter Notebook and Plotly)&lt;/li&gt;
&lt;li&gt;How to 'unlock' the insight hidden in data through Python and how to use it to transform not only public administration or business, but ultimately the transformation of the whole society and economy towards the insight &amp;amp; knowledge based? (potential of data science)&lt;/li&gt;
&lt;li&gt;Open Data, Open Government Partnership, Open Public Administration &amp;amp; all the advantages of Open Data Science &amp;amp; Python. Data-Driven Approach. Everywhere. Now. (the end of talk +vision)&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="python"></category><category term="data-science"></category><category term="data-visualization"></category><category term="analytics"></category><category term="PyData"></category><category term="PyDataBLN"></category><category term="PyDataBerlin"></category><category term="PyDataBA"></category><category term="PyDataBratislava"></category><category term="talk"></category><category term="Data"></category><category term="Bokeh"></category><category term="Social Good"></category><category term="datascience"></category><category term="jupyter"></category><category term="open science"></category><category term="open data science"></category><category term="DataVisualization"></category><category term="data-analysis"></category><category term="analysis"></category><category term="matplotlib"></category><category term="numpy"></category><category term="data wrangling"></category><category term="jupyter notebook"></category><category term="pandas"></category><category term="machine learning"></category><category term="deep learning"></category><category term="Open Data"></category><category term="Citizen Data Science"></category></entry><entry><title>Data Transformation: A Framework for Exploratory Data Analysis</title><link href="https://pyvideo.org/pydata-dc-2016/data-transformation-a-framework-for-exploratory-data-analysis.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Tony Ojeda</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/data-transformation-a-framework-for-exploratory-data-analysis.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Exploratory data analysis plays a critical role in the job of every data scientist, but very few have a structured process or framework for exploring data quickly and efficiently. This talk will introduce the exploratory framework I use in my day-to-day work and will walk attendees through a practical example of how to use the framework to unlock hidden insights with the help of Python libraries.&lt;/p&gt;
&lt;p&gt;At the heart of data analysis, there lies a need to understand the real world entities being represented in the data. Every data set we encounter is an attempt to capture a slice of our complex world and communicate some information about it in a way that has potential to be informative to humans, machines, or both. Moving from basic analyses to advanced analytics requires the ability to imagine multiple ways of conceptualizing the composition of entities and the relationships present in our data. It also requires the realization that different levels of aggregation, disaggregation, and transformation can open up new pathways to understanding our data and identifying the valuable insights it contains.&lt;/p&gt;
&lt;p&gt;In this talk, we’ll discuss several ways to think about the composition and representation of our data. We’ll also demonstrate a series of methods that leverage tools like networks, hierarchical aggregations, and unsupervised clustering to visually explore our data, transform it to discover new insights, help frame analytical problems and questions, and even improve machine learning model performance. In exploring these approaches, and with the help of Python libraries such as Pandas, Scikit-Learn, Seaborn, and NetworkX, we will provide a practical framework for thinking creatively and visually about your data and unlocking latent value and insights hidden deep beneath its surface.&lt;/p&gt;
</summary><category term="analysis"></category><category term="Data"></category><category term="Data Analysis"></category><category term="framework"></category></entry><entry><title>Using Exploratory Data Analysis to Discover Patterns in Image and Document Collections</title><link href="https://pyvideo.org/pydata-chicago-2016/using-exploratory-data-analysis-to-discover-patterns-in-image-and-document-collections.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Mehrdad Yazdani</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/using-exploratory-data-analysis-to-discover-patterns-in-image-and-document-collections.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://docs.google.com/presentation/d/1StRN0-_0x4BPkFFQ79GusgQAqXgwvJ1Fc8Tlu68YO4E/edit"&gt;https://docs.google.com/presentation/d/1StRN0-_0x4BPkFFQ79GusgQAqXgwvJ1Fc8Tlu68YO4E/edit&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Exploratory Data Analysis (EDA) is one of the key sets of procedures for summarizing a dataset. In this talk we will develop an EDA procedure for large collections of documents and images (such as photo albums, emails, articles, etc). We will show features used from NLP and Deep Neural Nets and also introduce novel visualization techniques for large image collections using PyImagePlot.&lt;/p&gt;
</summary><category term="analysis"></category><category term="Data"></category><category term="data analysis"></category><category term="patterns"></category></entry><entry><title>How do I apply a function to a pandas Series or DataFrame?</title><link href="https://pyvideo.org/data-school/pandas-30-apply-function.html" rel="alternate"></link><published>2016-08-23T00:00:00+00:00</published><updated>2016-08-23T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-08-23:data-school/pandas-30-apply-function.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever struggled to figure out the differences between apply, map, and applymap? In this video, I'll explain when you should use each of these methods and demonstrate a few common use cases. Watch the end of the video for three important announcements!&lt;/p&gt;
&lt;p&gt;This is video 30 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="NumPy"></category></entry><entry><title>How do I create a pandas DataFrame from another object?</title><link href="https://pyvideo.org/data-school/pandas-29-dummy-dataframe.html" rel="alternate"></link><published>2016-08-16T00:00:00+00:00</published><updated>2016-08-16T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-08-16:data-school/pandas-29-dummy-dataframe.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever needed to create a DataFrame of &amp;quot;dummy&amp;quot; data, but without reading from a file? In this video, I'll demonstrate how to create a DataFrame from a dictionary, a list, and a NumPy array. I'll also show you how to create a new Series and attach it to the DataFrame.&lt;/p&gt;
&lt;p&gt;This is video 29 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="NumPy"></category></entry><entry><title>How do I change display options in pandas?</title><link href="https://pyvideo.org/data-school/pandas-28-customize-display.html" rel="alternate"></link><published>2016-08-09T00:00:00+00:00</published><updated>2016-08-09T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-08-09:data-school/pandas-28-customize-display.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever wanted to change the way your DataFrame is displayed? Perhaps you needed to see more rows or columns, or modify the formatting of numbers? In this video, I'll demonstrate how to change the settings for five common display options in pandas.&lt;/p&gt;
&lt;p&gt;This is video 28 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>How do I avoid a SettingWithCopyWarning in pandas?</title><link href="https://pyvideo.org/data-school/pandas-27-setting-with-copy-warning.html" rel="alternate"></link><published>2016-08-02T00:00:00+00:00</published><updated>2016-08-02T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-08-02:data-school/pandas-27-setting-with-copy-warning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you've been using pandas for a while, you've likely encountered a SettingWithCopyWarning. The proper response is to modify your code appropriately, not to turn off the warning! In this video, I'll show you two common scenarios in which this warning arises, explain why it's occurring, and then demonstrate how to address it.&lt;/p&gt;
&lt;p&gt;This is video 27 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="missing data"></category></entry><entry><title>How do I find and remove duplicate rows in pandas?</title><link href="https://pyvideo.org/data-school/pandas-26-duplicate-data.html" rel="alternate"></link><published>2016-07-26T00:00:00+00:00</published><updated>2016-07-26T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-07-26:data-school/pandas-26-duplicate-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;During the data cleaning process, you will often need to figure out whether you have duplicate data, and if so, how to deal with it. In this video, I'll demonstrate the two key methods for finding and removing duplicate rows, as well as how to modify their behavior to suit your specific needs.&lt;/p&gt;
&lt;p&gt;This is video 26 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="duplicate data"></category></entry><entry><title>How do I work with dates and times in pandas?</title><link href="https://pyvideo.org/data-school/pandas-25-dates-and-times.html" rel="alternate"></link><published>2016-07-19T00:00:00+00:00</published><updated>2016-07-19T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-07-19:data-school/pandas-25-dates-and-times.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Let's say that you have dates and times in your DataFrame and you want to analyze your data by minute, month, or year. What should you do? In this video, I'll demonstrate how you can convert your data to &amp;quot;datetime&amp;quot; format, enabling you to access a ton of convenient attributes and perform datetime comparisons and mathematical operations.&lt;/p&gt;
&lt;p&gt;This is video 25 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="data visualization"></category></entry><entry><title>How do I create dummy variables in pandas?</title><link href="https://pyvideo.org/data-school/pandas-24-dummy-variables.html" rel="alternate"></link><published>2016-07-12T00:00:00+00:00</published><updated>2016-07-12T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-07-12:data-school/pandas-24-dummy-variables.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you want to include a categorical feature in your machine learning model, one common solution is to create dummy variables. In this video, I'll demonstrate three different ways you can create dummy variables from your existing DataFrame columns. I'll also show you a trick for simplifying your code that was introduced in pandas 0.18.&lt;/p&gt;
&lt;p&gt;This is video 24 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="machine learning"></category></entry><entry><title>More of your pandas questions answered!</title><link href="https://pyvideo.org/data-school/pandas-23-viewer-questions.html" rel="alternate"></link><published>2016-07-05T00:00:00+00:00</published><updated>2016-07-05T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-07-05:data-school/pandas-23-viewer-questions.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, I'm answering a few of the pandas questions I've received in the YouTube comments: Could you explain how to read the pandas documentation? What is the difference between ufo.isnull() and pd.isnull(ufo)? Why are DataFrame slices inclusive when using .loc, but exclusive when using .iloc? How do I randomly sample rows from a DataFrame?&lt;/p&gt;
&lt;p&gt;This is video 23 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="reproducibility"></category></entry><entry><title>How do I use pandas with scikit-learn to create Kaggle submissions?</title><link href="https://pyvideo.org/data-school/pandas-22-prepare-for-machine-learning.html" rel="alternate"></link><published>2016-06-28T00:00:00+00:00</published><updated>2016-06-28T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-06-28:data-school/pandas-22-prepare-for-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you been using scikit-learn for machine learning, and wondering whether pandas could help you to prepare your data and export your predictions? In this video, I'll demonstrate the simplest way to integrate pandas into your machine learning workflow, and will create a submission for Kaggle's Titanic competition in just a few lines of code!&lt;/p&gt;
&lt;p&gt;This is video 22 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="scikit-learn"></category><category term="machine learning"></category></entry><entry><title>How do I make my pandas DataFrame smaller and faster?</title><link href="https://pyvideo.org/data-school/pandas-21-reduce-dataframe-size.html" rel="alternate"></link><published>2016-06-21T00:00:00+00:00</published><updated>2016-06-21T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-06-21:data-school/pandas-21-reduce-dataframe-size.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Are you working with a large dataset in pandas, and wondering if you can reduce its memory footprint or improve its efficiency? In this video, I'll show you how to do exactly that in one line of code using the &amp;quot;category&amp;quot; data type, introduced in pandas 0.15. I'll explain how it works, and how to know when you shouldn't use it.&lt;/p&gt;
&lt;p&gt;This is video 21 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>When should I use the "inplace" parameter in pandas?</title><link href="https://pyvideo.org/data-school/pandas-20-inplace-parameter.html" rel="alternate"></link><published>2016-06-14T00:00:00+00:00</published><updated>2016-06-14T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-06-14:data-school/pandas-20-inplace-parameter.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We've used the &amp;quot;inplace&amp;quot; parameter many times during this video series, but what exactly does it do, and when should you use it? In this video, I'll explain how &amp;quot;inplace&amp;quot; affects methods such as &amp;quot;drop&amp;quot; and &amp;quot;dropna&amp;quot;, and why it is always False by default.&lt;/p&gt;
&lt;p&gt;This is video 20 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="missing data"></category></entry><entry><title>How do I select multiple rows and columns from a pandas DataFrame?</title><link href="https://pyvideo.org/data-school/pandas-19-select-dataframe-rows-and-columns.html" rel="alternate"></link><published>2016-06-07T00:00:00+00:00</published><updated>2016-06-07T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-06-07:data-school/pandas-19-select-dataframe-rows-and-columns.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever been confused about the &amp;quot;right&amp;quot; way to select rows and columns from a DataFrame? pandas gives you an incredible number of options for doing so, but in this video, I'll outline the current best practices for row and column selection using the loc, iloc, and ix methods.&lt;/p&gt;
&lt;p&gt;This is video 19 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>What do I need to know about the pandas index? (Part 2)</title><link href="https://pyvideo.org/data-school/pandas-18-index-part-2.html" rel="alternate"></link><published>2016-06-02T00:00:00+00:00</published><updated>2016-06-02T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-06-02:data-school/pandas-18-index-part-2.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In part two of our discussion of the index, we'll switch our focus from the DataFrame index to the Series index. After discussing index-based selection and sorting, I'll demonstrate how automatic index alignment during mathematical operations and concatenation enables us to easily work with incomplete data in pandas.&lt;/p&gt;
&lt;p&gt;This is video 18 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="missing data"></category></entry><entry><title>What do I need to know about the pandas index? (Part 1)</title><link href="https://pyvideo.org/data-school/pandas-17-index-part-1.html" rel="alternate"></link><published>2016-05-31T00:00:00+00:00</published><updated>2016-05-31T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-05-31:data-school/pandas-17-index-part-1.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The DataFrame index is core to the functionality of pandas, yet it's confusing to many users. In this video, I'll explain what the index is used for and why you might want to store your data in the index. I'll also demonstrate how to set and reset the index, and show how that affects the DataFrame's shape and contents.&lt;/p&gt;
&lt;p&gt;This is video 17 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>How do I handle missing values in pandas?</title><link href="https://pyvideo.org/data-school/pandas-16-missing-values.html" rel="alternate"></link><published>2016-05-26T00:00:00+00:00</published><updated>2016-05-26T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-05-26:data-school/pandas-16-missing-values.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Most datasets contain &amp;quot;missing values&amp;quot;, meaning that the data is incomplete. Deciding how to handle missing values can be challenging! In this video, I'll cover all of the basics: how missing values are represented in pandas, how to locate them, and options for how to drop them or fill them in.&lt;/p&gt;
&lt;p&gt;This is video 16 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="missing data"></category></entry><entry><title>How do I explore a pandas Series?</title><link href="https://pyvideo.org/data-school/pandas-15-explore-series.html" rel="alternate"></link><published>2016-05-24T00:00:00+00:00</published><updated>2016-05-24T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-05-24:data-school/pandas-15-explore-series.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When you start working with a new dataset, how should you go about exploring it? In this video, I'll demonstrate some of the basic tools in pandas for exploring both numeric and non-numeric data. I'll also show you how to create simple visualizations in a single line of code!&lt;/p&gt;
&lt;p&gt;This is video 15 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="data visualization"></category></entry><entry><title>When should I use a "groupby" in pandas?</title><link href="https://pyvideo.org/data-school/pandas-14-analyze-data-by-category.html" rel="alternate"></link><published>2016-05-19T00:00:00+00:00</published><updated>2016-05-19T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-05-19:data-school/pandas-14-analyze-data-by-category.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The pandas &amp;quot;groupby&amp;quot; method allows you to split a DataFrame into groups, apply a function to each group independently, and then combine the results back together. This is called the &amp;quot;split-apply-combine&amp;quot; pattern, and is a powerful tool for analyzing data across different categories. In this video, I'll explain when you should use a groupby and then demonstrate its flexibility using four different examples.&lt;/p&gt;
&lt;p&gt;This is video 14 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="data visualization"></category></entry><entry><title>How do I change the data type of a pandas Series?</title><link href="https://pyvideo.org/data-school/pandas-13-change-data-type-of-series.html" rel="alternate"></link><published>2016-05-17T00:00:00+00:00</published><updated>2016-05-17T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-05-17:data-school/pandas-13-change-data-type-of-series.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever tried to do math with a pandas Series that you thought was numeric, but it turned out that your numbers were stored as strings? In this video, I'll demonstrate two different ways to change the data type of a Series so that you can fix incorrect data types. I'll also show you the easiest way to convert a boolean Series to integers, which is useful for creating dummy/indicator variables for machine learning.&lt;/p&gt;
&lt;p&gt;This is video 13 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>How do I use string methods in pandas?</title><link href="https://pyvideo.org/data-school/pandas-12-string-methods.html" rel="alternate"></link><published>2016-05-12T00:00:00+00:00</published><updated>2016-05-12T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-05-12:data-school/pandas-12-string-methods.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;pandas includes powerful string manipulation capabilities that you can easily apply to any Series of strings. In this video, I'll show you how to access string methods in pandas (along with a few examples), and then end with two bonus tips to help you maximize your efficiency.&lt;/p&gt;
&lt;p&gt;This is video 12 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="regular expressions"></category><category term="string processing"></category></entry><entry><title>How do I use the "axis" parameter in pandas?</title><link href="https://pyvideo.org/data-school/pandas-11-dataframe-axis.html" rel="alternate"></link><published>2016-05-10T00:00:00+00:00</published><updated>2016-05-10T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-05-10:data-school/pandas-11-dataframe-axis.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When performing operations on a pandas DataFrame, such as dropping columns or calculating row means, it is often necessary to specify the &amp;quot;axis&amp;quot;. But what exactly is an axis? In this video, I'll help you to build a mental model for understanding the axis parameter so that you will know when and how to use it.&lt;/p&gt;
&lt;p&gt;This is video 11 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>Your pandas questions answered!</title><link href="https://pyvideo.org/data-school/pandas-10-viewer-questions.html" rel="alternate"></link><published>2016-05-05T00:00:00+00:00</published><updated>2016-05-05T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-05-05:data-school/pandas-10-viewer-questions.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, I'm answering a few of the pandas questions I've received in the YouTube comments: When reading from a file, how do I read in only a subset of the columns or rows? How do I iterate through a Series or a DataFrame? How do I drop all non-numeric columns from a DataFrame? How do I know whether I should pass an argument as a string or a list?&lt;/p&gt;
&lt;p&gt;This is video 10 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>How do I apply multiple filter criteria to a pandas DataFrame?</title><link href="https://pyvideo.org/data-school/pandas-09-multiple-filter-criteria.html" rel="alternate"></link><published>2016-05-03T00:00:00+00:00</published><updated>2016-05-03T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-05-03:data-school/pandas-09-multiple-filter-criteria.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Let's say that you want to filter the rows of a DataFrame by multiple conditions. In this video, I'll demonstrate how to do this using two different logical operators. I'll also explain the special rules in pandas for combining filter criteria, and end with a trick for simplifying chained conditions!&lt;/p&gt;
&lt;p&gt;This is video 9 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>How do I filter rows of a pandas DataFrame by column value?</title><link href="https://pyvideo.org/data-school/pandas-08-filter-dataframe-rows.html" rel="alternate"></link><published>2016-04-28T00:00:00+00:00</published><updated>2016-04-28T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-04-28:data-school/pandas-08-filter-dataframe-rows.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Let's say that you only want to display the rows of a DataFrame which have a certain column value. How would you do it? pandas makes it easy, but the notation can be confusing and thus difficult to remember. In this video, I'll work up to the solution step-by-step using regular Python code so that you can truly understand the logic behind pandas filtering notation.&lt;/p&gt;
&lt;p&gt;This is video 8 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>How do I sort a pandas DataFrame or a Series?</title><link href="https://pyvideo.org/data-school/pandas-07-sort-dataframe-or-series.html" rel="alternate"></link><published>2016-04-26T00:00:00+00:00</published><updated>2016-04-26T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-04-26:data-school/pandas-07-sort-dataframe-or-series.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;pandas allows you to sort a DataFrame by one of its columns (known as a &amp;quot;Series&amp;quot;), and also allows you to sort a Series alone. The sorting API changed in pandas version 0.17, so in this video, I'll demonstrate both the &amp;quot;old way&amp;quot; and the &amp;quot;new way&amp;quot; to sort. I'll also show you how to sort a DataFrame by multiple columns at once!&lt;/p&gt;
&lt;p&gt;This is video 7 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>How do I remove columns from a pandas DataFrame?</title><link href="https://pyvideo.org/data-school/pandas-06-remove-dataframe-column.html" rel="alternate"></link><published>2016-04-21T00:00:00+00:00</published><updated>2016-04-21T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-04-21:data-school/pandas-06-remove-dataframe-column.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you have DataFrame columns that you're never going to use, you may want to remove them entirely in order to focus on the columns that you do use. In this video, I'll show you how to remove columns (and rows), and will briefly explain the meaning of the &amp;quot;axis&amp;quot; and &amp;quot;inplace&amp;quot; parameters.&lt;/p&gt;
&lt;p&gt;This is video 6 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>How do I rename columns in a pandas DataFrame?</title><link href="https://pyvideo.org/data-school/pandas-05-rename-dataframe-column.html" rel="alternate"></link><published>2016-04-19T00:00:00+00:00</published><updated>2016-04-19T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-04-19:data-school/pandas-05-rename-dataframe-column.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;You will often want to rename the columns of a DataFrame so that their names are descriptive, easy to type, and don't contain any spaces. In this video, I'll demonstrate three different strategies for renaming columns so that you can choose the best strategy to fit your particular situation.&lt;/p&gt;
&lt;p&gt;This is video 5 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>Why do some pandas commands end with parentheses (and others don't)?</title><link href="https://pyvideo.org/data-school/pandas-04-methods-and-attributes.html" rel="alternate"></link><published>2016-04-14T00:00:00+00:00</published><updated>2016-04-14T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-04-14:data-school/pandas-04-methods-and-attributes.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;To access most of the functionality in pandas, you have to call the methods and attributes of DataFrame and Series objects. In this video, I'll discuss some common methods and attributes, and show you how to tell the difference between them. (Hint: It's all about the parentheses!)&lt;/p&gt;
&lt;p&gt;This is video 4 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>How do I select a pandas Series from a DataFrame?</title><link href="https://pyvideo.org/data-school/pandas-03-select-series-from-dataframe.html" rel="alternate"></link><published>2016-04-12T00:00:00+00:00</published><updated>2016-04-12T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-04-12:data-school/pandas-03-select-series-from-dataframe.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;DataFrames and Series are the two main object types in pandas for data storage: a DataFrame is like a table, and each column of the table is called a Series. You will often select a Series in order to analyze or manipulate it. In this video, I'll show you how to select a Series using &amp;quot;bracket notation&amp;quot; and &amp;quot;dot notation&amp;quot;, and will discuss the limitations of dot notation. I'll also demonstrate how to create a new Series in a DataFrame.&lt;/p&gt;
&lt;p&gt;This is video 3 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>What is pandas? (Introduction to the Q&amp;A series)</title><link href="https://pyvideo.org/data-school/pandas-01-introduction.html" rel="alternate"></link><published>2016-04-07T00:00:00+00:00</published><updated>2016-04-07T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-04-07:data-school/pandas-01-introduction.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;pandas is a full-featured Python library for data analysis, manipulation, and visualization. This video series is for anyone who wants to work with data in Python, regardless of whether you are brand new to pandas or have some experience.&lt;/p&gt;
&lt;p&gt;This is video 1 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category></entry><entry><title>How do I read a tabular data file into pandas?</title><link href="https://pyvideo.org/data-school/pandas-02-read-tabular-data-file.html" rel="alternate"></link><published>2016-04-07T00:00:00+00:00</published><updated>2016-04-07T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2016-04-07:data-school/pandas-02-read-tabular-data-file.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Tabular data&amp;quot; is just data that has been formatted as a table, with rows and columns (like a spreadsheet). You can easily read a tabular data file into pandas, even directly from a URL! In this video, I'll walk you through how to do that, including how to modify some of the default arguments of the read_table function to solve common problems.&lt;/p&gt;
&lt;p&gt;This is video 2 of 30 in the series, &lt;a class="reference external" href="http://www.dataschool.io/easier-data-analysis-with-pandas/"&gt;Easier data analysis in Python with pandas&lt;/a&gt;. The notebook and datasets shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/pandas-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="data science"></category><category term="data analysis"></category><category term="data wrangling"></category><category term="data processing"></category><category term="pandas"></category><category term="tutorial"></category><category term="Data School"></category><category term="csv"></category></entry><entry><title>Dplython: Intuitive Data Analysis, Funky Python</title><link href="https://pyvideo.org/pygotham-2016/dplython-intuitive-data-analysis-funky-python.html" rel="alternate"></link><published>2016-07-16T00:00:00+00:00</published><updated>2016-07-16T00:00:00+00:00</updated><author><name>Chris Riederer</name></author><id>tag:pyvideo.org,2016-07-16:pygotham-2016/dplython-intuitive-data-analysis-funky-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The goal of data analysis is to write code that manipulates data to give us answers. Ideally, we could translate our questions into code as quickly as we could think! Dplython is an open source Python library (inspired by R's &amp;quot;dplyr&amp;quot;) that improves productivity by constraining analysis to a core set of the most common data manipulation operations. By mapping the way we think about typical tasks to functions, dplython moves data analysis closer to &amp;quot;speed-of-thought.&amp;quot; In this talk, I'll describe the core ideas behind dplython, present a tutorial on using it for data analysis, and give a technical peek at Pythonic lazy evaluations created with operator overloading.&lt;/p&gt;
</summary><category term="Data Analysis"></category></entry><entry><title>Data mining and integration with Python</title><link href="https://pyvideo.org/pytexas-2015/data-mining-and-integration-with-python.html" rel="alternate"></link><published>2015-10-09T00:00:00+00:00</published><updated>2015-10-09T00:00:00+00:00</updated><author><name>Isaac Vidas</name></author><id>tag:pyvideo.org,2015-10-09:pytexas-2015/data-mining-and-integration-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There is an abundance of data in social media sites (Wikipedia,
Facebook, Instagram, etc.) which can be accessed through web APIs. But
how do we know that the data from the Wikipedia article on &amp;quot;Golden Gate
Bridge&amp;quot; goes along with the data from &amp;quot;Golden Gate Bridge&amp;quot; Facebook
page? This represents an important question about integrating data from
various sources.&lt;/p&gt;
&lt;p&gt;In this talk, I'll outline important aspects of structured data mining,
integration and entity resolution methods in a scalable system.&lt;/p&gt;
</summary><category term="Data"></category><category term="Data Analysis"></category><category term="data mining"></category></entry><entry><title>SociaLite: Python intergrated query Language for Data Analysis</title><link href="https://pyvideo.org/scipy-2014/socialite-python-intergrated-query-language-for.html" rel="alternate"></link><published>2014-07-09T00:00:00+00:00</published><updated>2014-07-09T00:00:00+00:00</updated><author><name>Jiwon Seo</name></author><id>tag:pyvideo.org,2014-07-09:scipy-2014/socialite-python-intergrated-query-language-for.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;SociaLite is a Python-integrated query language for data analysis. It
makes scientific data analysis simple, yet achieves fast performance
with its compiler optimizations. We support relational tables and
operations in SociaLite as well as Python integration, which makes it
easy to implement various analysis algorithms, including Blast algorithm
and genome assembly algorithm in bioinformatics.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;SociaLite is a Python-integrated query language for distributed data
analysis.
It makes scientific data analysis simple, yet achieves fast
performance with its compiler optimizations. The performance of
SociaLite is often more than three orders of magnitude faster than
Hadoop programs, and close to optimized C programs. For example,
PageRank algorithm can be implemented in just 2 lines of SociaLite
query, which runs nearly as fast as an optimal parallelized C code.&lt;/p&gt;
&lt;p&gt;SociaLite supports well-known high-level concepts to make data analysis
easy for non-expert programmers. We support relational tables for
storing data, and relational operations, such as join, selection, and
projection, for processing the data. Moreover, SociaLite queries are
fully integrated with Python, so both SociaLite and Python code can be
used to implement data analysis logic. For the integration with Python,
we support embedding and extending SociaLite, where embedding supports
using SociaLite queries directly in Python code, and extending supports
using Python functions in SociaLite queries.&lt;/p&gt;
&lt;p&gt;The Python integration makes it easy to implement various analysis
algorithms in SociaLite and Python. For example, the BLAST algorithm in
bioinformatics can be implemented in just a few lines of SociaLite
queries and Python code. Also genome assembly algorithm -- generating a
De Bruijn graph and applying Eulerian cycle algorithm -- can be simply
implemented. In the talk, I will demonstrate these algorithms in
SociaLite as well as more general algorithms such as K-means clustering
and logistic regression.&lt;/p&gt;
&lt;p&gt;The SociaLite queries are compiled to highly optimized
parallel/distributed code; we apply optimizations such as pipelined
evaluation and prioritization. The runtime system also speeds up the
performance; for example, the customized memory allocator reduces memory
allocation time and footprint. In short, SociaLite makes
high-performance data analysis easy with its high-level abstractions and
compiler/runtime optimizations.&lt;/p&gt;
</summary><category term="bioinformatics"></category><category term="blast"></category><category term="data analysis"></category></entry></feed>