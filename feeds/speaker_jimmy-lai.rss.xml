<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Jimmy Lai</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 17 May 2025 00:00:00 +0000</lastBuildDate><item><title>Automated Refactoring Large Python Codebases</title><link>https://pyvideo.org/europython-2022/automated-refactoring-large-python-codebases.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;EuroPython 2022 - Automated Refactoring Large Python Codebases - presented by Jimmy Lai&lt;/p&gt;
&lt;p&gt;[Liffey A on 2022-07-15]&lt;/p&gt;
&lt;p&gt;Like many companies with multi-million-line Python codebases, Carta has struggled to adopt best practices like Black formatting and type annotation. The extra work needed to do the right thing competes with the almost overwhelming need for new development, and unclear code ownership and lack of insight into the size and scope of type problems add to the burden. We’ve greatly mitigated these problems by building an automated refactoring pipeline that applies Black formatting and backfills missing types via incremental Github pull requests. Our refactor applications use LibCST and MonkeyType to modify the Python syntax tree and use GitPython/PyGithub to create and manage pull requests. It divides changes into small, easily reviewed pull requests and assigns appropriate code owners to review them. After creating and merging more than 3,000 pull requests, we have fully converted our large codebase to Black format and have added type annotations to more than 50,000 functions. In this talk, you’ll learn to use LibCST to build automated refactoring tools that fix general Python code quality issues at scale and how to use GitPython/PyGithub to automate the code review process.
Slides: &lt;a class="reference external" href="https://www.slideshare.net/jimmy_lai/europython-2022-automated-refactoring-large-python-codebases"&gt;https://www.slideshare.net/jimmy_lai/europython-2022-automated-refactoring-large-python-codebases&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License &lt;a class="reference external" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;http://creativecommons.org/licenses/by-nc-sa/4.0/&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jimmy Lai</dc:creator><pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2022-07-11:/europython-2022/automated-refactoring-large-python-codebases.html</guid><category>EuroPython 2022</category></item><item><title>Python Linters at Scale</title><link>https://pyvideo.org/europython-2023/python-linters-at-scale.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[EuroPython 2023 — Terrace 2B on 2023-07-19]&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://ep2023.europython.eu/session/python-linters-at-scale"&gt;https://ep2023.europython.eu/session/python-linters-at-scale&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Black, Flake8, isort, and Mypy are useful Python linters but it’s challenging to use them effectively at scale in the case of multiple codebases, in a large codebase, or with many developers. Linter analysis on large codebases is slow. Linters may slow down developers by asking them to fix trivial issues. Running linters in distributed CI jobs makes it hard to understand the overall developer experience.&lt;/p&gt;
&lt;p&gt;In this talk, we'll walk you through solving those scaling problems using a reusable linter framework that releases new linter updates automatically, reuses consistent configurations, runs linters on only updated code to speedup runtime, collects logs and metrics to provide observability, and builds auto fixes for common linter issues. Our linter runs are fast and scalable. Every week, they run 10k times on multiple millions of lines of code in over 25 codebases, generating 25k suggestions for more than 200 developers. Its autofixes also save 20 hours of developer time every week.&lt;/p&gt;
&lt;p&gt;This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License &lt;a class="reference external" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;http://creativecommons.org/licenses/by-nc-sa/4.0/&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jimmy Lai</dc:creator><pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-17:/europython-2023/python-linters-at-scale.html</guid><category>EuroPython 2023</category></item><item><title>Streamlining Testing in a Large Python Codebase</title><link>https://pyvideo.org/europython-2024/streamlining-testing-in-a-large-python-codebase.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[EuroPython 2024 — Terrace 2B on 2024-07-12]&lt;/p&gt;
&lt;p&gt;Streamlining Testing in a Large Python Codebase by Jimmy Lai&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://ep2024.europython.eu/session/streamlining-testing-in-a-large-python-codebase"&gt;https://ep2024.europython.eu/session/streamlining-testing-in-a-large-python-codebase&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Maintaining code quality through effective testing becomes increasingly challenging as codebases expand and developer teams grow. In our rapidly expanding codebase, we encountered common obstacles such as increasing test suite execution time, slow test coverage reporting and delayed test startup. By leveraging innovative strategies using open-source tools, we achieved remarkable enhancements in testing efficiency and code quality.&lt;/p&gt;
&lt;p&gt;Challenges Faced:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Test Suite Execution Time: The duration of test suite execution escalated significantly as we added more tests over time, hampering development speed.&lt;/li&gt;
&lt;li&gt;Slow Test Startup: Complex test setup led to prolonged test startup times, impeding developer productivity.&lt;/li&gt;
&lt;li&gt;Test Coverage Reporting Overhead: Coverage tools introduced substantial overhead and impacted test performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Solutions Implemented:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Parallel Test Execution: We applied pytest-xdist to distribute tests across multiple runners, significantly reducing test suite execution time and enabling faster development iterations.&lt;/li&gt;
&lt;li&gt;Optimized Test Startup: Pre-installing dependencies in a Docker image and utilizing Kubernetes for auto-scaling continuous integration runners helped expedite test startup times, improving developer efficiency. For local development, we used pytest-hot-reloading to reload tests fast after code editing.&lt;/li&gt;
&lt;li&gt;Efficient Test Coverage Reporting: Customizing the coverage tool to collect data only on updated files of pull requests minimized overhead on test coverage reporting.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As a result, in the past year, our test case volume increased by 8000, test coverage was elevated to 85%, and Continuous Integration (CI) test duration was maintained under 15 minute&lt;/p&gt;
&lt;p&gt;---&lt;/p&gt;
&lt;p&gt;This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License: &lt;a class="reference external" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;https://creativecommons.org/licenses/by-nc-sa/4.0/&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jimmy Lai</dc:creator><pubDate>Mon, 08 Jul 2024 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2024-07-08:/europython-2024/streamlining-testing-in-a-large-python-codebase.html</guid><category>EuroPython 2024</category></item><item><title>Building a Knowledge Graph - the new search engine technology</title><link>https://pyvideo.org/pycon-apac-2014/building-a-knowledge-graph-the-new-search-engin.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Knowledge graph is the new search engine technology. All the leading
search engine exploit knowledge graph to provide more accurate result to
user, e.g. Bing, Google, Yahoo.&lt;/p&gt;
&lt;p&gt;In this talk, the speaker will demonstrate how to build a searchable
knowledge graph from scratch. Lots of python tools will be applied
during the process. The process includes data wrangling, graph entity
indexing, full text search and web visualization. The data sources are
from dbpedia.org. Enormous amount of entities are collected and stored
to graph database for relationship querying and full text search engine
for searching. In the web visualization, a searchable interface and
visualized result demonstrate the knowledgable information to customer.&lt;/p&gt;
&lt;p&gt;About the speaker&lt;/p&gt;
&lt;p&gt;Jimmy Lai is a Python fan, and his interested topics are natural
language processing and machine learning. He specializes in combining
machine learning algorithm and cloud computing technology to do big data
analysis, building application services.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jimmy Lai</dc:creator><pubDate>Fri, 27 Jun 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2014-06-27:/pycon-apac-2014/building-a-knowledge-graph-the-new-search-engin.html</guid><category>PyCon APAC 2014</category></item><item><title>Python Profilers We Built for Efficiency</title><link>https://pyvideo.org/pycon-taiwan-2019/python-profilers-we-built-for-efficiency.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Day 1, R2 11:30–12:00&lt;/p&gt;
&lt;p&gt;To solve efficiency issue of our Python application. We started with cProfile to profile function call CPU cost and found it couldn't differentiate call-stacks sharing the same function calls. Asyncio makes the issue worse, since gathered functions all have the event loop as caller. We ended up build our own function call profilers:
* CPU cost profiler: CPU instructions per function call with complete call stack.
* Latency profiler with asyncio support: collect timestamp/latency per function call and yield from await.
* Profiler identifies lru_cache opportunities: functions have high cost and high hit rate of parameters/returns.&lt;/p&gt;
&lt;p&gt;We share how we implemented those profilers. After this talk, you'll have learned how to:
* Build profilers by registering a callback function for function calls.
* Handle call stacks in asyncio world.
* Use different timers and traversing through call-stack.
* Implement a CPU profiler, latency profiler lru_cache opportunities profiler.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://github.com/jimmylai/talks"&gt;https://github.com/jimmylai/talks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speaker: Jimmy Lai&lt;/p&gt;
&lt;p&gt;Jimmy Lai is a Software Engineer in Instagram Infrastructure. His recent interest is Python efficiency, including profiling, optimization and asyncio. He has been sharing his experiences in PyCon Taiwan since 2012. This year, he plan to share his latency efficiency experiences on large scale Python web application.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jimmy Lai</dc:creator><pubDate>Fri, 20 Sep 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-09-20:/pycon-taiwan-2019/python-profilers-we-built-for-efficiency.html</guid><category>PyCon Taiwan 2019</category></item><item><title>Fixit - a lint framework writes better Python code for you – PyCon Taiwan 2020</title><link>https://pyvideo.org/pycon-taiwan-2020/fixit-a-lint-framework-writes-better-python-code-for-you-pycon-taiwan-2020.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Day 1, R1 13:45–14:15&lt;/p&gt;
&lt;p&gt;Python is flexible and allows us to implement the same function in different ways. Some ways are simpler, more efficient, or more secure than others and are preferred as coding conventions. We have a big codebase with hundreds of developers and thus coding convention is especially important to prevent bad patterns being copy-pasted and spread around. We started with building lint rules as Flake8 plugins and found limitations. We also wanted to be able to provide auto-fixes for lint violations. So we built Fixit.
Fixit is a lint framework that complements Flake8. It’s based on LibCST which makes it possible to provide auto-fixes. Lint rules are made easy to build through matcher pattern, test toolkit, utility helpers (e.g. scope analysis) for non-trivial boilerplate. It is optimized for efficiency, easy to customize and comes with many builtin lint rules. In this talk, you’ll learn our story of building Fixit and learn to use it in your project to help you write better Python code!&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://github.com/jimmylai/talks/blob/master/pycon_taiwan_2020_fixit.pdf"&gt;https://github.com/jimmylai/talks/blob/master/pycon_taiwan_2020_fixit.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speaker: Jimmy Lai&lt;/p&gt;
&lt;p&gt;Jimmy Lai is a Software Engineer in Instagram Infrastructure. His recent interest is Python efficiency, including profiling, optimization and asyncio. He has been sharing his experiences in PyCon Taiwan since 2012. This year, he plan to share his automated refactoring experience on large scale Python codebase.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jimmy Lai</dc:creator><pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-09-05:/pycon-taiwan-2020/fixit-a-lint-framework-writes-better-python-code-for-you-pycon-taiwan-2020.html</guid><category>PyCon Taiwan 2020</category></item><item><title>Python Linters at Scale</title><link>https://pyvideo.org/pycon-us-2023/python-linters-at-scale.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Black, Flake8, isort, and Mypy are useful Python linters but it’s
challenging to use them effectively at scale in the case of multiple
codebases, in a large codebase, or with many developers. Manually
managing consistent linter versions and configurations across codebases
requires endless effort. Linter analysis on large codebases is slow.
Linters may slow down developers by asking them to fix trivial issues.
Running linters in distributed CI jobs makes it hard to understand the
overall developer experience.&lt;/p&gt;
&lt;p&gt;To handle these scale challenges, we developed a reusable linter
framework that releases new linter updates automatically, reuses
consistent configurations, runs linters on only updated code to speedup
runtime, collects logs and metrics to provide observability, and builds
auto fixes for common linter issues. Our linter runs are fast and
scalable. Every week, they run 10k times on multiple millions of lines
of code in over 25 codebases, generating 25k suggestions for more than
200 developers. Its autofixes also save 20 hours of developer time every
week.&lt;/p&gt;
&lt;p&gt;In this talk, we’ll walk you through popular Python linters and
configuration recommendations, and we will discuss common issues and
solutions when scaling them out. Using linters more effectively will
make it much easier for you to apply best practices and more quickly
write better code.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jimmy Lai</dc:creator><pubDate>Sat, 22 Apr 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-04-22:/pycon-us-2023/python-linters-at-scale.html</guid><category>PyCon US 2023</category></item><item><title>Scaling the Mountain: A Framework for Tackling Large-Scale Tech Debt</title><link>https://pyvideo.org/pycon-us-2025/scaling-the-mountain-a-framework-for-tackling-large-scale-tech-debt.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Managing tech debt in large legacy codebases isn’t just a challenge—it’s an ongoing battle that can drain developer productivity and morale. In this talk, I’ll introduce a Python-powered Tech Debt Framework bar-raiser designed to help teams tackle even the most daunting tech debt problems with 100,000+ violations. This open-source framework empowers developers and engineering leaders by: - Tracking Progress: Measure and visualize the state of tech debt and trends over time. - Recognizing Contributions: Celebrate developer efforts and foster accountability with contribution leaderboards and automated shoutouts. - Automating Fixes: Save countless hours with codemods that address repetitive debt patterns, allowing developers to focus on higher-priority work.&lt;/p&gt;
&lt;p&gt;Through real-world case studies, I’ll showcase how we: - Reduced 70,000+ pyright-ignore annotations to boost type-checking coverage from 60% to 99.5%. - Converted a monolithic sync codebase to async, addressing blocking IO issues and adopting asyncio effectively.&lt;/p&gt;
&lt;p&gt;Attendees will gain actionable strategies for scaling Python automation, fostering team buy-in, and systematically reducing tech debt across massive codebases. Whether you’re dealing with type errors, legacy dependencies, or async transitions, this talk provides a roadmap for creating cleaner, more maintainable code at scale.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jimmy Lai</dc:creator><pubDate>Sat, 17 May 2025 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2025-05-17:/pycon-us-2025/scaling-the-mountain-a-framework-for-tackling-large-scale-tech-debt.html</guid><category>PyCon US 2025</category></item><item><title>Jimmy Lai - Automated Python Refactoring Powered by LibCST - Pyninsula #25</title><link>https://pyvideo.org/pyninsula-2020/jimmy-lai-automated-python-refactoring-powered-by-libcst-pyninsula-25.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jimmy Lai</dc:creator><pubDate>Tue, 17 Mar 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-03-17:/pyninsula-2020/jimmy-lai-automated-python-refactoring-powered-by-libcst-pyninsula-25.html</guid><category>Pyninsula 2020</category></item></channel></rss>