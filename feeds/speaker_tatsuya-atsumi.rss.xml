<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Wed, 21 Sep 2016 00:00:00 +0000</lastBuildDate><item><title>Pythonで入門するApache Spark</title><link>https://pyvideo.org/pycon-japan-2016/pythonderu-men-suruapache-spark.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;現在、世界的に普及が進んでいる大規模分散処理フレームワークのApache Sparkについて、その基礎及び、Python APIを通じた各種ライブラリの使い方について、Sparkについて触れた事がない方でもわかるように基本から解説します。 Sparkは集計処理のような従来の操作のほか、機械学習のような複雑なワークロードにも対応しているため、様々な大規模分散処理を簡単に実装することが可能になります。
Abstract&lt;/p&gt;
&lt;p&gt;Apache Sparkは2013年にApache Software Foundationに寄贈されて以来、Hadoop MapReduceに変わる新たな大規模分散処理フレームワークとして急速な進化と普及を続けています。&lt;/p&gt;
&lt;p&gt;Sparkは早くからPythonを重要な言語と位置付けており、Scala, Javaに加えPythonのAPIが公式から提供されています。そのため、JavaやScalaといった言語の経験がない方でも手軽に大規模分散処理を実装することができる点も非常に魅力的です。&lt;/p&gt;
&lt;p&gt;また、Sparkには近年のAIブームにより注目を集めている機械学習を扱うためのライブラリであるMLlibや、SQLで処理を記述するためのSpark SQL、ストリーミング処理を記述するSpark Streamingなど、近年のトレンドに応じたライブラリが公式に提供されているため、単純な集計処理以外にも様々なワークロードに対応することが可能です。&lt;/p&gt;
&lt;p&gt;本講演では、Python APIを通じてApache Sparkの使い方及び各種ライブラリの使い方について基本からご説明いたします。&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tatsuya Atsumi</dc:creator><pubDate>Wed, 21 Sep 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-09-21:pycon-japan-2016/pythonderu-men-suruapache-spark.html</guid></item></channel></rss>