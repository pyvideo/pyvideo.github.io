<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Ilia Sucholutsky</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_ilia-sucholutsky.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2023-07-31T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Human-in-the-Loop Mixup</title><link href="https://pyvideo.org/uai-2023/human-in-the-loop-mixup.html" rel="alternate"></link><published>2023-07-31T00:00:00+00:00</published><updated>2023-07-31T00:00:00+00:00</updated><author><name>Katherine M. Collins</name></author><id>tag:pyvideo.org,2023-07-31:/uai-2023/human-in-the-loop-mixup.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Human-in-the-Loop Mixup&amp;quot;
Katherine M. Collins, Umang Bhatt, Weiyang Liu, Vihari Piratla, Ilia Sucholutsky, Bradley C. Love, Adrian Weller
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/collins23a.html"&gt;https://proceedings.mlr.press/v216/collins23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Aligning model representations to humans has been found to improve robustness and generalization. However, such methods often focus on standard observational data. Synthetic …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Human-in-the-Loop Mixup&amp;quot;
Katherine M. Collins, Umang Bhatt, Weiyang Liu, Vihari Piratla, Ilia Sucholutsky, Bradley C. Love, Adrian Weller
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/collins23a.html"&gt;https://proceedings.mlr.press/v216/collins23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Aligning model representations to humans has been found to improve robustness and generalization. However, such methods often focus on standard observational data. Synthetic data is proliferating and powering many advances in machine learning; yet, it is not always clear whether synthetic labels are perceptually aligned to humans – rendering it likely model representations are not human aligned. We focus on the synthetic data used in mixup: a powerful regularizer shown to improve model robustness, generalization, and calibration. We design a comprehensive series of elicitation interfaces, which we release as HILL MixE Suite, and recruit 159 participants to provide perceptual judgments along with their uncertainties, over mixup examples. We find that human perceptions do not consistently align with the labels traditionally used for synthetic points, and begin to demonstrate the applicability of these findings to potentially increase the reliability of downstream models, particularly when incorporating human uncertainty. We release all elicited judgments in a new data hub we call H-Mix.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/256-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/256-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</content><category term="UAI 2023"></category></entry><entry><title>Poster Spotlights 1</title><link href="https://pyvideo.org/uai-2023/poster-spotlights-1.html" rel="alternate"></link><published>2023-07-31T00:00:00+00:00</published><updated>2023-07-31T00:00:00+00:00</updated><author><name>Nicolas Gisolfi</name></author><id>tag:pyvideo.org,2023-07-31:/uai-2023/poster-spotlights-1.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Poster Spotlights 1 (session chair: Nicolas Gisolfi, all spotlights virtual)&lt;/p&gt;
&lt;p&gt;91   |   Quasi-Bayesian Nonparametric Density Estimation via Autoregressive Predictive Updates   Sahra Ghalebikesabi, Christopher C. Holmes, Edwin Fong, Brieuc Lehmann
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/ghalebikesabi23a.html"&gt;https://proceedings.mlr.press/v216/ghalebikesabi23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;190   |   Conditional Counterfactual Causal Effect for Individual Attribution
Ruiqi Zhao, lei zhang, Shengyu Zhu …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Poster Spotlights 1 (session chair: Nicolas Gisolfi, all spotlights virtual)&lt;/p&gt;
&lt;p&gt;91   |   Quasi-Bayesian Nonparametric Density Estimation via Autoregressive Predictive Updates   Sahra Ghalebikesabi, Christopher C. Holmes, Edwin Fong, Brieuc Lehmann
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/ghalebikesabi23a.html"&gt;https://proceedings.mlr.press/v216/ghalebikesabi23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;190   |   Conditional Counterfactual Causal Effect for Individual Attribution
Ruiqi Zhao, lei zhang, Shengyu Zhu, Zitong Lu, Zhenhua Dong, Chaoliang Zhang, Jun Xu, Zhi Geng, Yangbo He,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/zhao23a.html"&gt;https://proceedings.mlr.press/v216/zhao23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;196   |   Random Reshuffling with Variance Reduction: New Analysis and Better Rates
Grigory Malinovsky, Alibek Sailanbayev, Peter Richtárik,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/malinovsky23a.html"&gt;https://proceedings.mlr.press/v216/malinovsky23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;227   |   Multi-View Graph Contrastive Learning for Solving Vehicle Routing Problems
Yuan Jiang, Zhiguang Cao, Yaoxin Wu, Jie Zhang,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/jiang23a.html"&gt;https://proceedings.mlr.press/v216/jiang23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;303   |   MFA: Multi-scale Feature-aware Attack for Object Detection
Wen Chen, Yushan Zhang, Zhiheng Li, Yuehuan Wang,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/chen23d.html"&gt;https://proceedings.mlr.press/v216/chen23d.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;325   |   Incentivising Diffusion while Preserving Differential Privacy
Fengjuan Jia, Mengxiao Zhang, Jiamou Liu, Bakh Khoussainov,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/jia23a.html"&gt;https://proceedings.mlr.press/v216/jia23a.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;472   |   Residual-Based Error Bound for Physics-Informed Neural Networks
Shuheng Liu, Xiyue Huang, Pavlos Protopapas,
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/liu23b.html"&gt;https://proceedings.mlr.press/v216/liu23b.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;617   |   On the Informativeness of Supervision Signals
Ilia Sucholutsky, Ruairidh McLennan Battleday, Katherine M. Collins, Raja Marjieh, Joshua Peterson, Pulkit Singh, Umang Bhatt, Nori Jacoby, Adrian Weller, Thomas L. Griffiths
&lt;a class="reference external" href="https://proceedings.mlr.press/v216/sucholutsky23a.html"&gt;https://proceedings.mlr.press/v216/sucholutsky23a.html&lt;/a&gt;&lt;/p&gt;
</content><category term="UAI 2023"></category></entry></feed>