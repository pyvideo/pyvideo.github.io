<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 21 Feb 2014 00:00:00 +0000</lastBuildDate><item><title>An introduction to video action recognition</title><link>https://pyvideo.org/pydata-london-2014/an-introduction-to-video-action-recognition.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At WIDE IO, we are specialists in image processing and video analytics;
we have individual experience using Python, Numpy and Scipy for Computer
Vision applications since 2007. Now, the environment has become much
mature. Our goal with this talk is to share our enthusiasm and to
present the basic steps required to perform image and video pattern
analysis with Python. In our tutorial, we’ll investigate how to build an
action recognition framework and how to do video-tracking with
traditional vision models based on a bag-of- keypoints. By going through
examples, we’ll discuss how in practice computer vision for
real-applications involve a trade-off between esthetical theories and
utilitarianism. We will explore the various tricks that allow engineers
to boost global performances, methods for running experiments and a
mechanism for how to prepare the data... All these points are just a
nice pretext to discuss our favorite tools: Numpy and Scipy of course,
but also more exotic ones such as MediaLovinToolkit, PyCUDA, Bob and
PyCVF... At the end of the talk, we’ll conclude by briefly discussing
future imperatives, especially with respect to mobility and cloud
computing.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bertrand Nouvel</dc:creator><pubDate>Fri, 21 Feb 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2014-02-21:pydata-london-2014/an-introduction-to-video-action-recognition.html</guid></item></channel></rss>