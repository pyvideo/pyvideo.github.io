<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Bernd Bischl</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_bernd-bischl.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2023-07-31T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Quantifying Aleatoric and Epistemic Uncertainty in Machine Learning</title><link href="https://pyvideo.org/uai-2023/quantifying-aleatoric-and-epistemic-uncertainty-in-machine-learning.html" rel="alternate"></link><published>2023-07-31T00:00:00+00:00</published><updated>2023-07-31T00:00:00+00:00</updated><author><name>Lisa Wimmer</name></author><id>tag:pyvideo.org,2023-07-31:/uai-2023/quantifying-aleatoric-and-epistemic-uncertainty-in-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Quantifying Aleatoric and Epistemic Uncertainty in Machine Learning: Are Conditional Entropy and Mutual Information Appropriate Measures?&amp;quot;
Lisa Wimmer, Yusuf Sale, Paul Hofman, Bernd Bischl, Eyke Hüllermeier
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/wimmer23a.html"&gt;https://proceedings.mlr.press/v216/wimmer23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
The quantification of aleatoric and epistemic uncertainty in terms of conditional entropy and mutual information …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Quantifying Aleatoric and Epistemic Uncertainty in Machine Learning: Are Conditional Entropy and Mutual Information Appropriate Measures?&amp;quot;
Lisa Wimmer, Yusuf Sale, Paul Hofman, Bernd Bischl, Eyke Hüllermeier
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/wimmer23a.html"&gt;https://proceedings.mlr.press/v216/wimmer23a.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
The quantification of aleatoric and epistemic uncertainty in terms of conditional entropy and mutual information, respectively, has recently become quite common in machine learning. While the properties of these measures, which are rooted in information theory, seem appealing at first glance, we identify various incoherencies that call their appropriateness into question. In addition to the measures themselves, we critically discuss the idea of an additive decomposition of total uncertainty into its aleatoric and epistemic constituents. Experiments across different computer vision tasks support our theoretical findings and raise concerns about current practice in uncertainty quantification.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/374-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/374-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</content><category term="UAI 2023"></category></entry></feed>