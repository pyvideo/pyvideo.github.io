<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Dean Wampler</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_dean-wampler.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-07-23T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Ray: A System for High-performance, Distributed Python Applications</title><link href="https://pyvideo.org/europython-2020/ray-a-system-for-high-performance-distributed-python-applications.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Dean Wampler</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/ray-a-system-for-high-performance-distributed-python-applications.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Scale your applications from a laptop to a cluster with ease&lt;/p&gt;
&lt;p&gt;Ray (&lt;a class="reference external" href="http://ray.io"&gt;http://ray.io&lt;/a&gt;) is an open-source, distributed framework from U.C. Berkeley’s RISELab that easily scales Python applications from a laptop to a cluster. While broadly applicable, it was developed to solve the unique performance challenges …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Scale your applications from a laptop to a cluster with ease&lt;/p&gt;
&lt;p&gt;Ray (&lt;a class="reference external" href="http://ray.io"&gt;http://ray.io&lt;/a&gt;) is an open-source, distributed framework from U.C. Berkeley’s RISELab that easily scales Python applications from a laptop to a cluster. While broadly applicable, it was developed to solve the unique performance challenges of ML/AI systems, such as the heterogeneous task scheduling and state management required for hyperparameter tuning and model training, running simulations when training reinforcement learning (RL) models, and model serving. Ray is now used in many production deployments.&lt;/p&gt;
&lt;p&gt;I'll explain the problems that Ray solves for cluster-wide scaling of general Python applications and for specific examples, like RL workloads. Ray’s features include rapid scheduling and execution of “tasks” and management of distributed state, such as model parameters during training. I'll compare Ray to other libraries for distributed Python.&lt;/p&gt;
&lt;p&gt;This talk is for you if you need to scale your Python applications to a cluster and you want a robust, yet easy-to-use API to do it. You don't need to be a distributed systems expert to use Ray. You'll learn when to use Ray versus alternatives, how it’s used in several open source systems, and how to use it in your projects.&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Architecture"></category><category term="Data"></category><category term="Deep Learning"></category><category term="Distributed Systems"></category><category term="Microservices"></category></entry><entry><title>Ray: A System for High-performance, Distributed Python Applications</title><link href="https://pyvideo.org/pycon-us-2020/ray-a-system-for-high-performance-distributed-python-applications.html" rel="alternate"></link><published>2020-04-15T00:00:00+00:00</published><updated>2020-04-15T00:00:00+00:00</updated><author><name>Dean Wampler</name></author><id>tag:pyvideo.org,2020-04-15:/pycon-us-2020/ray-a-system-for-high-performance-distributed-python-applications.html</id><content type="html"></content><category term="PyCon US 2020"></category></entry></feed>