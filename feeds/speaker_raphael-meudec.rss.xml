<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Tue, 05 Nov 2019 00:00:00 +0000</lastBuildDate><item><title>tf-explain: Interpretability for Tensorflow 2.0</title><link>https://pyvideo.org/pydata-new-york-city-2019/tf-explain-interpretability-for-tensorflow-20.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deep learning models now emerge in multiple domains. The question data scientists and users always ask is 'Why does it work?'. Explaining decisions from neural networks is vital for model improvements and analysis, and users' adoption. In this talk, I will explain interpretability methods implementations with TF2.0 and introduce tf-explain, a TF2.0 library for interpretability.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">RaphaÃ«l Meudec</dc:creator><pubDate>Tue, 05 Nov 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-11-05:pydata-new-york-city-2019/tf-explain-interpretability-for-tensorflow-20.html</guid></item></channel></rss>