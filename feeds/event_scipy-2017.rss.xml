<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 05 Aug 2017 00:00:00 +0000</lastBuildDate><item><title>Network Science and Statistics - Fundamentals and Applications</title><link>https://pyvideo.org/scipy-2017/network-science-and-statistics-fundamentals-and-applications.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There are audio issues with this video that cannot be fixed. We recommend listening to the tutorial without headphones to minimize the buzzing sound.
Tutorial information may be found at &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this tutorial, we will cover the fundamentals and practical aspects of network science and how it can be used to solve problems in science and society! Outline:&lt;/p&gt;
&lt;p&gt;Part 1: Introduction (30 min)&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Networks of all kinds: biological, transportation.&lt;/li&gt;
&lt;li&gt;Representation of networks, NetworkX data structures&lt;/li&gt;
&lt;li&gt;Basic quick-and-dirty visualizations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Part 2: Hubs and Paths (40 min)&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Finding important nodes; applications&lt;/li&gt;
&lt;li&gt;Pathfinding algorithms and their applications&lt;/li&gt;
&lt;li&gt;Hands-on: implementing path-finding algorithms&lt;/li&gt;
&lt;li&gt;Visualize degree and betweenness centrality distributions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Part 3: Cliques, Triangles &amp;amp; Structures (40 min)&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Definition of cliques&lt;/li&gt;
&lt;li&gt;Triangles as the simplest complex clique, applications&lt;/li&gt;
&lt;li&gt;Using path-finding algorithms to find structures in a graph.&lt;/li&gt;
&lt;li&gt;Open triangles as recommender systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Part 4: Bipartite Graphs (30 min)&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Definition of bipartite graphs, applications&lt;/li&gt;
&lt;li&gt;Constructing bipartite graphs in NetworkX.&lt;/li&gt;
&lt;li&gt;Summary statistics of bipartite graphs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Part 5: Advanced Network Visualizations &amp;amp; Concepts (40 min)&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Basic concepts in rational layouts: node positioning, node colouring.&lt;/li&gt;
&lt;li&gt;Plots: Circos, Arc, Hive, Matrix, Flow plots&lt;/li&gt;
&lt;li&gt;Handling large graphs using matrices.&lt;/li&gt;
&lt;li&gt;Graph diffs and their application to analysis of time-variant, evolving graphs.&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Eric Ma</dc:creator><pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-08-05:scipy-2017/network-science-and-statistics-fundamentals-and-applications.html</guid><category>tutorial</category></item><item><title>Pandas for Data Analysis</title><link>https://pyvideo.org/scipy-2017/pandas-for-data-analysis.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There are audio issues with this video that cannot be fixed. We recommend listening to the tutorial without headphones to minimize the buzzing sound.&lt;/p&gt;
&lt;p&gt;Tutorial information may be found at &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Data Science and Machine learning have been synonymous with languages like Python. Libraries like numpy and Pandas have become the de facto standard when working with data.
The DataFrame object provided by Pandas gives us the ability to work with heterogeneous unstructured data that is commonly used in &amp;quot;real world&amp;quot; data.&lt;/p&gt;
&lt;p&gt;New learners are often drawn to Python and Pandas because of all the different and exciting types of models and insights the language can do and provide, but are awestruck when faced with the initial learning curve.&lt;/p&gt;
&lt;p&gt;This tutorial aims to guide the learner from using spreadsheets to using the Pandas DataFrame.
Not only does moving to a programming language allow the user to have a more reproducible workflow, but as datasets get larger, some cannot even be opened in a spreadsheet program. The goal is to have an absolute beginner proficient enough with Pandas that they can start working with data in Python.&lt;/p&gt;
&lt;p&gt;We will cover how to load and view our data. Then, some basic methods to do quick visualizations of our data for exploratory data analysis. We will then work on combining and working multiple datasets (concatenating and merging), and introduce what Dr. Hadley Wickham has coined &amp;quot;tidy data&amp;quot;. Tidy data is an important concept because the process of tidying data will fix a host of data problems that are needed to perform analysis. We then cover functions and applying methods to our data with a focus on data cleaning, and how we can use the concept of split-apply-combine (groupby) to summarize or reduce our data.&lt;/p&gt;
&lt;p&gt;Finally, we cover the basics of string manipulation and how to use it to clean data before briefly covering the role of Pandas in analysis packages such as scikit learn. The tutorial will with a fitted model.&lt;/p&gt;
&lt;p&gt;The goal is to get people familiar with Python and Pandas so they can learn and explore many other parts of the Python ecosystem.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Daniel Chen</dc:creator><pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-08-05:scipy-2017/pandas-for-data-analysis.html</guid><category>pandas</category></item><item><title>Interactive Data Visualization with HoloViews &amp; Bokeh</title><link>https://pyvideo.org/scipy-2017/interactive-data-visualization-with-holoviews-bokeh.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There are audio issues with this video that cannot be fixed. We recommend listening to the tutorial without headphones to minimize the buzzing sound.
Tutorial information may be found at &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Visualization represents a major bottleneck in scientific research, engineering, data science, and data analytics. The tools in the Python scientific ecosystem make it very simple to do many of the tasks required, but building visualizations to help understand complex patterns and relationships in your data still typically involves a large amount of custom coding for every new type of plot. Writing long and detailed scripts for plotting slows down the process of exploration and reporting, while the difficulty involved means that many important observations and discoveries are missed due to inadequate visualizations. The complexity of the resulting plotting code makes it difficult to rapidly build sophisticated, interactive visualizations that can quickly reveal the underlying structure of the data, and once such complex plotting scripts have been created they can be a major impediment to future understanding, reproduction, and modification of the research process.&lt;/p&gt;
&lt;p&gt;In this tutorial, you will learn how to approach the problem of interactive visualization declaratively. Using the HoloViews library, you can annotate your data and store it in general-purpose containers that will be instantly visualizable. The declarative objects in HoloViews wrap your data to make it incredibly easy to visualize how different sets of data relate to each other, using subfigures, animations, interactive widgets and custom interactions. This flexibility has made HoloViews the chosen future replacement for the high-level Bokeh Charts API and works particularly well with IPython/Jupyter notebooks, where you can immediately see the output from selecting, combining, slicing, or sampling these objects. Each of these operations generates a different type of visualization, that can be flexibly extended even to complex dashboards deployed using the Bokeh server or Jupyter dashboards.&lt;/p&gt;
&lt;p&gt;The core design principle of HoloViews is to make it simple to create complex plot layouts and interactivity by applying compositional operations to a small number of elements and containers. Since HoloViews separates the declaration of the data from the precise visual details of the plotting code, the same HoloViews objects can be rendered using matplotlib for publication-quality plots, or bokeh for interactive use. Overall, this means the user can focus on &lt;strong&gt;what&lt;/strong&gt; to plot before worrying about &lt;strong&gt;how&lt;/strong&gt; exactly it should be displayed, providing a huge boost in productivity.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jean-Luc Stevens</dc:creator><pubDate>Fri, 04 Aug 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-08-04:scipy-2017/interactive-data-visualization-with-holoviews-bokeh.html</guid><category>tutorial</category><category>HoloViews</category><category>Bokeh</category></item><item><title>Modern Optimization Methods in Python</title><link>https://pyvideo.org/scipy-2017/modern-optimization-methods-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Highly-constrained, large-dimensional, and non-linear optimizations are found at the root of most of today's forefront problems in statistics, quantitative finance, risk, operations research, materials design, and other predictive sciences. Tools for optimization, however, have not changed much in the past 40 years -- until very recently. The abundance of parallel computing resources has stimulated a shift away from using reduced models to solve statistical and predictive problems, and toward more direct methods for solving high-dimensional nonlinear optimization problems.&lt;/p&gt;
&lt;p&gt;This tutorial will introduce modern tools for solving optimization problems -- beginning with traditional methods, and extending to solving high-dimensional non-convex optimization problems with highly nonlinear constraints. We will start by introducing the cost function, and it's use in local and global optimization. We will then address how to monitor and diagnose your optimization convergence and results, tune your optimizer, and utilize compound termination conditions. This tutorial will discuss building and applying box constraints, penalty functions, and symbolic constraints. We will then demonstrate methods to efficiently reduce search space through the use of robust optimization constraints. Real-world inverse problems can be expensive, thus we will show how to enable your optimization to seamlessly leverage parallel computing. Large-scale optimizations also can greatly benefit from efficient solver restarts and the saving of state. This tutorial will cover using asynchronous computing for results caching and archiving, dynamic real-time optimization, and dimensional reduction. Next we will discuss new optimization methods that leverage parallel computing to perform blazingly-fast global optimizations and n-dimensional global searches. Finally, we will close with applications of global optimization in statistics and quantitative finance.&lt;/p&gt;
&lt;p&gt;The audience need not be an expert in optimization, but should have interest in solving hard real-world optimization problems. We will begin with a walk through some introductory optimizations, learning how to build confidence in understanding your results. By the end of the tutorial, participants will have working knowledge of how to use modern constrained optimization tools, how to enable their solvers to leverage high-performance parallel computing, and how to utilize legacy data and surrogate models in statistical and predictive risk modeling.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Michael McKerns</dc:creator><pubDate>Fri, 04 Aug 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-08-04:scipy-2017/modern-optimization-methods-in-python.html</guid></item><item><title>Designing a Python-based Monte Carlo Tool for Generating Non-Equilibrium Semi-Crystalline Polymer Configurations</title><link>https://pyvideo.org/scipy-2017/designing-a-python-based-monte-carlo-tool-for-generating-non-equilibrium-semi-crystalline-polymer-configurations.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Semi-crystalline polymers are a class of polymers which are used in applications ranging from piping to photovoltaics to food packaging. Despite their near-ubiquitous use, our understanding of semi-crystalline polymer microstructure and its connection to mechanical properties is far from complete. While measuring the mechanical properties of material systems using Molecular Dynamics simulations is routine, generating the initial conditions for semi-crystalline polymers is difficult due to their non-equilibrium, kinetically trapped nature. In this contribution, I discuss the development of a python-based simulation tool which uses an adapted Configurational Bias Monte Carlo technique to “grow” coarse-grained representations of semi-crystalline polymer systems. Specifically, I will discuss the process of developing a performant and flexible simulation tool for materials simulation using various tools in the python ecosystem including NumPy, Cython, VTK, and various profiling tools.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tyler Martin</dc:creator><pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-18:scipy-2017/designing-a-python-based-monte-carlo-tool-for-generating-non-equilibrium-semi-crystalline-polymer-configurations.html</guid><category>monte carlo</category></item><item><title>Distributed Convex Optimization for GLMs</title><link>https://pyvideo.org/scipy-2017/distributed-convex-optimization-for-glms.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Oftentimes data scientists have specific modeling problems that call for highly customized solutions, which can lead to writing new optimization routines. In this talk we will discuss writing large-scale optimization algorithms in Python. Starting from a quick review of the math behind convex optimization, we will implement some common algorithms with custom tweaks, first in NumPy and then at scale with Dask arrays. Leveraging the distributed dask scheduler, we will also look at asynchronous variants of these algorithms. While looking at these implementations, we will discuss the challenges of properly testing optimization routines. The focus will be on applications to large scale generalized linear models and will include a demo of the currently in-development dask-glm project. We will end with some benchmarks comparing dask-glm with the SciPy stack (statsmodels, scikit-learn) as well as other popular big data tools such as H20. This talk is written from the perspective of a data scientist, not a nuts-and-bolts computer scientist, and so is focused on customizing and extending the SciPy stack for large scale data science problems. This talk will be co-presented by Chris White (Capital One) and Hussain Sultan (SQN Strategies).&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Chris White</dc:creator><pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-18:scipy-2017/distributed-convex-optimization-for-glms.html</guid></item><item><title>Keynote - Academic Open Source</title><link>https://pyvideo.org/scipy-2017/keynote-academic-open-source.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Academia, in particular academic science, has a great deal to learn and gain from its harmony with open source. Similarly, open source communities increasingly find themselves responsible for education. This talk will touch on the past, present, and possible future of the rich, delicate symbiosis between academia and open source.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kathryn Huff</dc:creator><pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-18:scipy-2017/keynote-academic-open-source.html</guid><category>keynote</category></item><item><title>MatchPy A Pattern Matching Library</title><link>https://pyvideo.org/scipy-2017/matchpy-a-pattern-matching-library.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pattern matching is a powerful tool for symbolic computations, based on the well-defined theory of term rewriting systems.
Application domains include algebraic expressions, abstract syntax trees or XML and JSON data.
Unfortunately, no implementations of pattern matching as general and flexible as in Mathematica exists for Python.
In this talk, we introduce the open source module MatchPy (&lt;a class="reference external" href="https://github.com/HPAC/matchpy"&gt;https://github.com/HPAC/matchpy&lt;/a&gt;), which offers this functionality in Python.
In addition, we implemented a novel algorithm which finds matches for large pattern sets more efficiently by exploiting similarities between patterns.
We will demonstrate how MatchPy can be used with example from the linear algebra domain.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Manuel Krebber</dc:creator><pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-18:scipy-2017/matchpy-a-pattern-matching-library.html</guid><category>matchpy</category></item><item><title>MNE Python to See the Brain at a Millisecond Time Scale</title><link>https://pyvideo.org/scipy-2017/mne-python-to-see-the-brain-at-a-millisecond-time-scale.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;MNE-Python to See the Brain at a Millisecond Time-Scale&lt;/p&gt;
&lt;p&gt;MNE (&lt;a class="reference external" href="http://martinos.org/mne/"&gt;http://martinos.org/mne/&lt;/a&gt;) is a Python software package for processing electrophysiology signals: magnetoencephalography (MEG), electroencephalography (EEG) and intracranial EEG data which measure the weak electromagnetic signals originating from neural currents in the brain. It provides a full workflow for data preprocessing, forward modeling using boundary element models (BEM), source imaging using distributed source models, time-frequency analysis, non-parametric statistics, and connectivity measures, in both sensor and source space. MNE is developed by an international team of contributors, with particular care on computational efficiency, code correctness and readability, enabling reproducibility of scientific results. MNE-Python is provided under the BSD license and is available on all platform that support the scientific Python stack.&lt;/p&gt;
&lt;p&gt;In this talk I will explain what types of data problem MNE users face and illustrate with code snippets and images how MNE leverages numpy (for data containers and array oriented numerics), scipy (mostly for signal processing, linear algebra and optimization), matplotlib (for plotting also interactively) and mayavi to produce 3D images of the brain with a millisecond resolution.&lt;/p&gt;
&lt;p&gt;Talk material will be extracted from the documentation &lt;a class="reference external" href="http://martinos.org/mne/dev/documentation.html"&gt;http://martinos.org/mne/dev/documentation.html&lt;/a&gt; and our example gallery (&lt;a class="reference external" href="http://martinos.org/mne/dev/auto_examples/index.html"&gt;http://martinos.org/mne/dev/auto_examples/index.html&lt;/a&gt;) powered by sphinx-gallery (&lt;a class="reference external" href="https://sphinx-gallery.readthedocs.io/en/latest/"&gt;https://sphinx-gallery.readthedocs.io/en/latest/&lt;/a&gt;).&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexandre Gramfort</dc:creator><pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-18:scipy-2017/mne-python-to-see-the-brain-at-a-millisecond-time-scale.html</guid><category>mne</category></item><item><title>Berryconda Scientific Python on the Raspberry Pi</title><link>https://pyvideo.org/scipy-2017/berryconda-scientific-python-on-the-raspberry-pi.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Raspberry Pi is a series of low cost single-board computers widely used for teaching computer science and popular with the robotics community. Although Python has been a target programming language on the Pi, the selection of scientific Python packages available in the default Raspbian operating system is often limited. Many of the popular newer libraries are missing, and only older versions of many of the core packages are available. Users wanting a wider and more up-to-date selection of packages are left to compile the software themselves or to use an alternative operating system.     The berryconda project aims to address these limitations. Berryconda is a conda based Python distribution for the Raspberry Pi. With it, you can install and manage a scientific python stack on your Raspberry Pi using conda, an open-source package and environment management system.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jonathan Helmus</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/berryconda-scientific-python-on-the-raspberry-pi.html</guid></item><item><title>Big Data Processing with Apache Beam Python</title><link>https://pyvideo.org/scipy-2017/big-data-processing-with-apache-beam-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Two trends for data analysis are the ever increasing size of data sets and the drive for lower-latency results. In this talk, we present Apache Beam--a parallel programming model that allows one to implement batch and streaming data processing jobs that can run on a variety of scalable execution engines like Spark and Dataflow--and its new Python SDK. We discuss some of the interesting challenges in providing a Pythonic API and execution environment for distributed processing, and show how Beam allows the user to write a Python pipeline once that can run in both batch and streaming mode. We walk through a few examples of data processing pipelines in Beam for use cases such as real time data analytics and feature engineering with Tensorflow for machine learning pipelines.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Robert Bradshaw</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/big-data-processing-with-apache-beam-python.html</guid></item><item><title>bqplot Seamless Interactive Visualizations in the Jupyter Notebook</title><link>https://pyvideo.org/scipy-2017/bqplot-seamless-interactive-visualizations-in-the-jupyter-notebook.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;bqplot is a Python plotting library based on d3.js that offers its functionality directly in the Jupyter Notebook, including selections, interactions, and arbitrary css customizations. In bqplot, every element of a chart is an interactive ipython widget that can be bound to a python function, which serves as the callback when an interaction takes place. The bidirectional communication between Python and JavaScript is a feature of bqplot that makes the python code aware of any interactions the user has with the visualization. This allows the rapid generation of full fledged web applications directly in the Notebook with just a few lines of Python code. We will also review some of bqplot's many new and innovative visualizations and interactions - including the MarketMap and the FastIntervalSelector and demonstrate concrete applications that leverage them to enhance a Data Science or Machine Learning workflow.     The talk will also cover bqplot's seamless integration with the native Jupyter widgets - including layout and styling of web applications, as well as the integration with other widget libraries such as ipyleaflet or ipyvolume. We will also demonstrate the simple way to export bqplot charts as stand alone web applications through the embedding mechanism of the ipywidgets library.&lt;/p&gt;
&lt;p&gt;Finally, we will highlight bqplot as the first plotting library to have complete integration with the new JupyterLab IDE by demonstrating dashboarding, resizing and custom integrations.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dhruv Madeka</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/bqplot-seamless-interactive-visualizations-in-the-jupyter-notebook.html</guid><category>bqplot</category><category>jupyter notebook</category></item><item><title>Dataflow Notebooks Encoding and Using Cell Dependencies</title><link>https://pyvideo.org/scipy-2017/dataflow-notebooks-encoding-and-using-cell-dependencies.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dataflow notebooks extend the Jupyter Notebook environment and IPython kernel to allow users to construct clear dependencies between cells, making it possible to construct a graph that details all defined dependencies between cells. In this environment, unique, persistent cell identifiers make references between cells more robust than existing solutions. Using the dependency graph, we can dynamically update upstream dependencies for a cell or select downstream cells that depend on the current one. This helps users better organize their work, allows for non-linear orderings of cells, and enables greater reproducibility and more opportunities for reuse.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">David Koop</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/dataflow-notebooks-encoding-and-using-cell-dependencies.html</guid></item><item><title>Deploying Interactive Jupyter Dashboards for Visualizing Hundreds of Millions of Datapoints, in 30 Lines of Python</title><link>https://pyvideo.org/scipy-2017/deploying-interactive-jupyter-dashboards-for-visualizing-hundreds-of-millions-of-datapoints-in-30-lines-of-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;It can be difficult to assemble the right set of packages from the Python scientific software ecosystem to solve complex problems. This presentation will show step by step how to make and deploy a concise, fast, and fully reproducible recipe for interactive visualization of millions or billions of datapoints using very few lines of Python in a Jupyter notebook using a combination of the HoloViews, Datashader, Dask, Bokeh and paramNB libraries and deployed as a Jupyter Dashboard.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Philipp Rudiger</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/deploying-interactive-jupyter-dashboards-for-visualizing-hundreds-of-millions-of-datapoints-in-30-lines-of-python.html</guid><category>jupyter notebook</category></item><item><title>HDF Data Services</title><link>https://pyvideo.org/scipy-2017/hdf-data-services.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the SciPy community, HDF5 has rapidly emerged as the de facto technology for storing and sharing large volumes of numerical data. There has also been increased interest in the SciPy community with using cloud based computing to tackle challenging computational requirements. With the Highly Scalable Data Service (HSDS), a Python-based web-service, HDF5 data can now be read and written to object-based storage (e.g. AWS S3) and accessed over http using a RESTful api. As a web service this opens up many avenues to utilize HDF in ways that would have been difficult to achieve previously. In addition to the service itself, h5pyd is a package written specifically for Python clients that enables access to the HDF REST API in a way that is compatible with the popular h5py package.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">John Readey</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/hdf-data-services.html</guid></item><item><title>Hunting for Emerging Trends in Music Using Bayesian Inference</title><link>https://pyvideo.org/scipy-2017/hunting-for-emerging-trends-in-music-using-bayesian-inference.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;iHeartRadio is the largest owner of terrestrial radio stations in country, broadcasting continuously to over 850 stations across every major media market. Yet today, radio is just one of many different channels for music discovery. Streaming services and social media are revealing new underground artists and genres to music fans, as well as delivering more information into the hands of industry experts. During this talk, I will discuss how iHeartRadio uses Bayesian techniques to analyze various data sources to deliver the hottest new tracks to over 100 million registered users, while avoiding the most overplayed music. Researchers and analysts who are comfortable with the PyData toolset and interested in applications of Bayesian inference will enjoy this talk.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alex Companioni</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/hunting-for-emerging-trends-in-music-using-bayesian-inference.html</guid></item><item><title>Interactive Geophysics</title><link>https://pyvideo.org/scipy-2017/interactive-geophysics.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the deployment of a short-course on electromagnetic geophysics, we have been developing strategies for developing an “educational stack.” Web-based textbooks and interactive simulations built using Jupyter notebooks provide an entry-point for course participants to reproduce content they are shown and to dive into the code used to build them. Our overarching aim is to make the geophysical concepts accessible and interactive: from first introduction, to research and applied work. We will share the tools we are using and discuss some of our learnings.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lindsey Heagy</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/interactive-geophysics.html</guid></item><item><title>Make it Work, Make it Right, Make it Fast Debugging and Profiling in Dask</title><link>https://pyvideo.org/scipy-2017/make-it-work-make-it-right-make-it-fast-debugging-and-profiling-in-dask.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dask is a pure Python library for parallel and distributed computing. It's designed with simplicity and flexibility in mind, making it easy to parallelize the kind of messy custom workflows that often show up in science. However, once you get something working, how do you debug or profile it? Debugging and profiling parallel code is notoriously hard! In this talk we'll cover the various tools Dask provides for diagnosing bugs and performance bottlenecks, as well as tips and techniques for resolving these issues.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">James Crist</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/make-it-work-make-it-right-make-it-fast-debugging-and-profiling-in-dask.html</guid><category>dask</category></item><item><title>Materials Project A Prime Case of Software Engineering in Materials Sciences</title><link>https://pyvideo.org/scipy-2017/materials-project-a-prime-case-of-software-engineering-in-materials-sciences.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The (MP, &lt;a class="reference external" href="https://materialsproject.org"&gt;https://materialsproject.org&lt;/a&gt;) is harnessing the power of supercomputing together with state-of-the-art quantum mechanical theory and a scientific workflow stack driven by open-source Python software to compute the properties of all known inorganic materials and beyond, design novel materials and offer the data for free to the community together with online analysis and design algorithms. MP now also allows users to contribute and share new theoretical and experimental materials data with its community of more than 30,000 users which is an important step in MP’s effort to deliver a next-generation collaborative platform for Materials (Data) Science.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Patric</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/materials-project-a-prime-case-of-software-engineering-in-materials-sciences.html</guid></item><item><title>nbgrader - A Tool for Creating and Grading Assignments in the Jupyter Notebook</title><link>https://pyvideo.org/scipy-2017/nbgrader-a-tool-for-creating-and-grading-assignments-in-the-jupyter-notebook.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As usage of the Jupyter notebook in scientific computing becomes increasingly ubiquitous, so too does its presence in classrooms. In this talk, I will describe &lt;em&gt;nbgrader&lt;/em&gt;, a tool developed by and for instructors to create and grade rich, interactive assignments in the notebook. On its own, nbgrader provides functionality for creating assignments and then for both automatic and manual grading of submissions. When combined with JupyterHub, it supports the full grading pipeline: creating assignments, releasing them to students, collecting submissions, grading, and generating personalized feedback. To demonstrate the use of nbgrader, I will walk the audience through the basics of the tool, and then outline two example workflows: one using standalone nbgrader, and one using nbgrader with JupyterHub. In doing so, I will illustrate to instructors how they can create their own assignments in the notebook using nbgrader.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jessica Hamrick</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/nbgrader-a-tool-for-creating-and-grading-assignments-in-the-jupyter-notebook.html</guid><category>jupyter notebook</category><category>nbgrader</category></item><item><title>pomegranate Fast and Flexible Probabilistic Modeling in Python</title><link>https://pyvideo.org/scipy-2017/pomegranate-fast-and-flexible-probabilistic-modeling-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;pomegranate is a python package that extends the ideas behind scikit-learn to probabilistic models such as mixtures, Bayesian networks, and hidden Markov models. pomegranate is built to be modular by separating out the probability distributions from the models themselves, allowing both arbitrary distributions to be used for any model, and making the modeling of different features with different distributions a breeze. pomegranate was built with large quantities of data in mind, supporting both an out-of-core API for when your data doesn't fit in memory, built-in multi-threaded parallelism made possibly by releasing the GIL, and most recently GPU support for large Gaussian models. This talk will be an overview of the most important features behind pomegranate and motivate the concept of probabilistic modeling.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jacob Schreiber</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/pomegranate-fast-and-flexible-probabilistic-modeling-in-python.html</guid><category>pomegranate</category></item><item><title>PyHRF A Python Library for the Analysis of fMRI Data Based on the Study of Hemodynamics</title><link>https://pyvideo.org/scipy-2017/pyhrf-a-python-library-for-the-analysis-of-fmri-data-based-on-the-study-of-hemodynamics.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Neuroimaging techniques, as functional Magnetic Resonance Imaging (fMRI), allow the in vivo study of brain function by measuring the changes induced by cerebral activity.     BOLD is non-invasive, non-ionizing, and it gives access in vivo to brain activity with a relatively high spatial resolution. However, it does not give access to true physiological parameters. Unlike BOLD, ASL provides a direct and more localized quantitative measurement of the cerebral blood flow, allowing a direct comparison between subjects, pathological/non-pathological population groups, and experiments.     Most used open source libraries for the analysis of fMRI data (i.e.,SPM, FSL, AFNI) consider the hemodynamic response function (HRF) of the neuronal activity as a constant in all the brain and the same for all subjects. However, several works show that the HRF changes across different regions of the brain and other aspects, increasing thus the probability of obtaining false negative results and decreasing the reliability of the results.     In this talk, we will present PyHRF (www.pyhrf.org), a software to analyze BOLD and ASL fMRI data using a joint detection-estimation (JDE) approach of the cerebral activity: it jointly detects cortical activation and estimates the hemodynamic response function (HRF). Contrary to existing tools, PyHRF estimates the HRF instead of considering it constant in all the brain and for all subjects, improving thus the reliability of the results. Here, we lay out the architecture, concept and implementation of the package and present some examples of how it works to show why PyHRF is a tool suitable for use by non experts and clinicians.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aina Frau-Pascual</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/pyhrf-a-python-library-for-the-analysis-of-fmri-data-based-on-the-study-of-hemodynamics.html</guid><category>PyHRF</category></item><item><title>Python and Tableau Building an Interactive and Beautiful Data Visualization with TabPy</title><link>https://pyvideo.org/scipy-2017/python-and-tableau-building-an-interactive-and-beautiful-data-visualization-with-tabpy.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Want to build an engaging and compelling dashboard? With the new release of Tableau, we can compose beautiful data visualization while leveraging a large number of machine-learning libraries through TabPy, a local HTTP Python server. In this session, we will explore Python functions in Tableau and go through two examples of data visualization. You will learn how to develop interactive dashboards by using TabPy.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Chloe Tseng</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/python-and-tableau-building-an-interactive-and-beautiful-data-visualization-with-tabpy.html</guid><category>tabpy</category><category>tableau</category></item><item><title>Quantifying Plastic Deformation using Machine Learning</title><link>https://pyvideo.org/scipy-2017/quantifying-plastic-deformation-using-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We propose and demonstrate the basic computational standards for quantifying the accumulated plastic deformation of crystalline materials through the use of non-intrusive, cheap and high-throughput mechanical tests such as Digital Image Correlation (DIC). We demonstrate the utility of machine learning approaches for classifying and distinguishing DIC-data samples from materials with varying degrees of mechanical deformation.While such plastic deformation should be apparent in an electron microscope study of the tested material, we develop a standard for optical digital-image correlation and machine learning that should serve as a substitute for electron microscopy, with the idea that the DIC strategy is both cheaper and higher-throughput. In order to provide a clear, quantitative example of our techniques and standards, we use samples of dislocation patterns on material surfaces that have been mechanically deformed at varying degrees. These samples have been generated by the use of two dimensional discrete dislocation dynamics. Such data is directly comparable to the mechanical deformation of thin films.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Michail Tzimas</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/quantifying-plastic-deformation-using-machine-learning.html</guid></item><item><title>Reskit — A Library for Creating and Curating Reproducible Pipelines for Scientific Machine Learning</title><link>https://pyvideo.org/scipy-2017/reskit-a-library-for-creating-and-curating-reproducible-pipelines-for-scientific-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this work we introduce Reskit (researcher’s kit), a library for creating and curating reproducible pipelines for scientific machine learning. A natural extension of the Scikit Pipelines to general classes of pipelines, Reskit allows for the efficient and transparent optimization of each pipeline step. Its main features include data caching, compatibility with most of the scikit-learn objects, optimization constraints such as forbidden combinations, and table generation for quality metrics. Reskit’s design will be especially useful for researchers requiring pipeline versioning and reproducibility, while running large volumes of experiments.&lt;/p&gt;
&lt;p&gt;Link: &lt;a class="reference external" href="https://github.com/neuro-ml/reskit"&gt;https://github.com/neuro-ml/reskit&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dmitry Petrov</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/reskit-a-library-for-creating-and-curating-reproducible-pipelines-for-scientific-machine-learning.html</guid><category>reskit</category><category>machine learning</category></item><item><title>Robust Color Matching of Geospatial Data: An Alternative to Histogram Matching</title><link>https://pyvideo.org/scipy-2017/robust-color-matching-of-geospatial-data-an-alternative-to-histogram-matching.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Color balancing algorithms such as histogram matching are often applied to remote sensing data to make images of the same area taken at different times appear visually consistent with a reference image. However, if the input data differs from the reference image due to clouds, snow, or other issues, existing color balancing methods can produce severe artifacts. We introduce a new method, implemented using the Scipy stack, that fits a smooth color transfer function based on coregistered points and a-priori knowledge of the approximate white balance for the image. This approach provides color consistency with the reference image without introducing visually unrealistic artifacts when clouds and snow are present.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joe Kington</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/robust-color-matching-of-geospatial-data-an-alternative-to-histogram-matching.html</guid></item><item><title>SciSheets: Providing the Power of Programming with the Simplicity of Spreadsheets</title><link>https://pyvideo.org/scipy-2017/scisheets-providing-the-power-of-programming-with-the-simplicity-of-spreadsheets.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Many biologists perform calculations on complex data using spreadsheet formulas because they are uncomfortable with existing programming tools. Unfortunately, calculations in spreadsheets are ill-equipped for code reuse, handling complex data, scaling calculations, and sharing with program literate collaborators. We explore the extent to which non-programmer scientists benefit from a spreadsheet system under development, SciSheets, in which: python is the formula language; spreadsheets can be exported as a standalone python program to enhance scalability and code reuse; and nested tables are provided to organize complex data. The talk will discuss case studies from plant genetics and coevolution of microbes.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joseph Hellerstein</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/scisheets-providing-the-power-of-programming-with-the-simplicity-of-spreadsheets.html</guid><category>scisheets</category></item><item><title>Systematic Application of PySPH to Bubble Dynamics</title><link>https://pyvideo.org/scipy-2017/systematic-application-of-pysph-to-bubble-dynamics.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Understanding bubble dynamics is an important component in understanding a variety of physical systems. Numerical simulations of these systems is appealing given the limited number of analytic cases and the expense and constraints of experiments. Bubble dynamics present unique numerical challenges. Interfacial forces, large deformations, and large density ratios all require that numerical stability, flexibility and efficiency be considered. Smooth particle hydrodynamics (SPH) offers a unique tool that inherently accommodates large geometric deformations and multiphase interfaces. In this work we use and extend PySPH, an open source SPH code that has been designed for easy extension in Python, to model isolated bubble oscillations and shape deformations. Our research is focused on identifying a system of compatible operators and adjustments that can accommodate the necessary parameter gradients while also maintaining stability and convergence within the SPH framework.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Erin Arai</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/systematic-application-of-pysph-to-bubble-dynamics.html</guid></item><item><title>The OOF Finite Element Tool for Materials Science</title><link>https://pyvideo.org/scipy-2017/the-oof-finite-element-tool-for-materials-science.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The NIST-developed Object-Oriented Finite Element code (OOF) is a is a long-standing project to develop a toolset for the segmentation, meshing, and finite-element analysis of microstructural images of materials, intended for the materials science audience, offering a materials-friendly GUI, a Python-based command-line, and Python and C++ APIs for extensibility.
The OOF development team has recently made substantial progress in expanding the scope of this tool to include history-dependent properties, motivated by crystal plasticity. In addition, we have an emerging interest in incorporating the OOF tool into new multi-scale materials analysis frameworks being built in the MGI. Among the challenges are the need to retain a high level of generality and ease of use while making these changes.
The team's development approaches to these recent modifications and emerging goals will be described.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Reid</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/the-oof-finite-element-tool-for-materials-science.html</guid></item><item><title>Tomviz: A Platform for Reproducible Materials Tomography</title><link>https://pyvideo.org/scipy-2017/tomviz-a-platform-for-reproducible-materials-tomography.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The use of transmission electron microscopy to collect and reconstruct tomographic data in 3D at near atomic resolutions presents a number of challenges. The open source Tomviz project was developed to address these challenges, managing a complex series of steps going from raw data to reconstructed visualizations using a reproducible data pipeline. Tomviz recently made its 1.0 release, collaboratively developed by Kitware and Cornell. It offers a cross-platform desktop application, leveraging Python, SciPy, and NumPy coupled with the powerful ParaView, VTK and ITK projects to offer a specialized interface for materials scientists. The pipeline offers Python data operators that can be edited in the interface, saved, rerun, and edited further to process, visualize and export data with a view of the 3D tomographic data.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marcus Hanwell</dc:creator><pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-17:scipy-2017/tomviz-a-platform-for-reproducible-materials-tomography.html</guid><category>tomviz</category><category>tomography</category></item><item><title>A Fast Template Periodogram for Finding Periodic (Non-Sinusoidal) Waveforms in Noisy, Irregularly-Sampled Time Series Data</title><link>https://pyvideo.org/scipy-2017/a-fast-template-periodogram-for-finding-periodic-non-sinusoidal-waveforms-in-noisy-irregularly-sampled-time-series-data.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Astronomers are often interested in detecting periodic signals in noisy time-series data. The Lomb-Scargle periodogram was designed for this purpose, and can efficiently handle complications like irregular sampling and heteroskedastic measurement errors. However, many signals in astronomy are non-sinusoidal, and while extensions to the Lomb-Scargle periodogram are able to handle a variety of waveform shapes, this comes at the cost of decreased sensitivity. Template fitting algorithms provide better sensitivity by explicitly fitting a fixed-shape waveform to the data, but this is too computationally demanding to be practical for large surveys. We present a new algorithm, the Fast Template Periodogram, that combines the speed advantage of Lomb-Scargle with the sensitivity of template fitting. The Fast Template Periodogram provides up to 4 orders of magnitude of speedup over more naive template fitting methods for large surveys with greater than 1,000 datapoints per object.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">John Hoffman</dc:creator><pubDate>Sun, 16 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-16:scipy-2017/a-fast-template-periodogram-for-finding-periodic-non-sinusoidal-waveforms-in-noisy-irregularly-sampled-time-series-data.html</guid></item><item><title>Vizic - A Jupyter Based Interactive Visualization Tool for Astronomical Catalogs</title><link>https://pyvideo.org/scipy-2017/vizic-a-jupyter-based-interactive-visualization-tool-for-astronomical-catalogs.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In the face of ever-growing datasets in astronomical sky surveys, we present Vizic, a Python/JavaScript library designed for Jupyter Notebook, which visualizes astronomical catalogs and presents them in vectorized form inside widgets in Jupyter notebooks. Visualized catalogs are fully interactive under a tiled web map approach. Vizic provides a unique and efficient way to visualize and explore multiple catalogs through interactive object filtering, color mapping, zooming and data selection using a lasso-like tool. In addition, custom overlays such as Voronoi layer can assist astronomers to visualize and interact with cosmic structures. At the end of this talk, we will give a brief demo to illustrate the potentials of Vizic in scientific research.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Weixiang Yu</dc:creator><pubDate>Sun, 16 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-16:scipy-2017/vizic-a-jupyter-based-interactive-visualization-tool-for-astronomical-catalogs.html</guid><category>vizic</category><category>jupyter</category></item><item><title>Creating Reproducible Experiments with ReproZip</title><link>https://pyvideo.org/scipy-2017/creating-reproducible-experiments-with-reprozip.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Reproducibility is a core component of the scientific process: it helps researchers all around the world to verify research results and also to build on them, allowing science to move forward. Unfortunately, computational reproducibility can be very painful. We’ll present an open source tool for computational reproducibility, ReproZip. ReproZip is written in Python, and was designed to simplify the process of making an experiment reproducible across platforms. ReproZip creates self-contained, reproducible packages by automatically tracking, identifying, and capturing all its required dependencies: programs, libraries, data, and configuration files. The original user can share the package with others, who can then use ReproZip to unpack and rerun the experiment on their favorite operating system.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Vicky Steeves</dc:creator><pubDate>Sat, 15 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-15:scipy-2017/creating-reproducible-experiments-with-reprozip.html</guid><category>reprozip</category></item><item><title>Introducing JOSS The Journal of Open Source Software</title><link>https://pyvideo.org/scipy-2017/introducing-joss-the-journal-of-open-source-software.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk describes the motivation and progress of the Journal of Open Source Software (JOSS), a free, open-access journal designed to publish brief papers about research software. The primary purpose of JOSS is to enable developers of research software to receive citation credit equivalent to typical archival publications. Rather than a review of a lengthy software paper (including, e.g., methodology, validation, sample results), JOSS submissions undergo rigorous peer review of both the abstract and software itself, including documentation, tests, continuous integration, and licensing. The JOSS review process is modeled on the established approach of the rOpenSci collaboration. The entire submission and review process occurs openly on GitHub; papers not yet accepted remain visible and under review until the authors make appropriate changes for acceptance---unlike other journals, papers requiring major revision are not rejected. Since its public release in May 2016, JOSS has published 87 papers as of March 2017, with an additional 38 currently under review.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kyle Niemeyer</dc:creator><pubDate>Sat, 15 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-15:scipy-2017/introducing-joss-the-journal-of-open-source-software.html</guid></item><item><title>Predicting Phenotype from Genotype with Machine Learning</title><link>https://pyvideo.org/scipy-2017/predicting-phenotype-from-genotype-with-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As increasing numbers of people choose to have their genomes sequenced and made available for research, more genomic data is available for analysis by machine learning approaches. Single Nucleotide Polymorphisms (SNPs) are known to be a major factor influencing many physical traits, diseases and other phenotypes. Using publicly available data and tools we predict phenotype from genotype using SNP data (approximately 1 million SNPs). We utilize data analysis and machine learning approaches only, no domain knowledge, so that our automated approach may be generally used to predict different phenotypes from genotype. In the first application of our method we predicted eye color with 87% accuracy.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Patricia Francis-Lyon</dc:creator><pubDate>Sat, 15 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-15:scipy-2017/predicting-phenotype-from-genotype-with-machine-learning.html</guid></item><item><title>Sacred: How I Learned to Stop Worrying and Love the Research</title><link>https://pyvideo.org/scipy-2017/sacred-how-i-learned-to-stop-worrying-and-love-the-research.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we’ll present a toolchain for conducting and organizing computational experiments consisting of Sacred -- the core framework --  and two supporting tools: Labwatch and Sacredboard.  These tools are agnostic of the methods and libraries used, and instead focus on solving the universal everyday problems of running computational experiments like reproducing results, bookkeeping, tuning hyperparameters, and organizing and analyising the runs and results. Attendees will be introduced to the core features of these libraries, and learn how they can form the basis for an effective and efficient workflow for machine learning research.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Klaus Greff</dc:creator><pubDate>Sat, 15 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-15:scipy-2017/sacred-how-i-learned-to-stop-worrying-and-love-the-research.html</guid><category>Sacred</category><category>Labwatch</category><category>Sacredboard</category></item><item><title>A Python API for Earth</title><link>https://pyvideo.org/scipy-2017/a-python-api-for-earth.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At Descartes Labs, we use the commercial cloud to run global-scale machine learning applications over satellite imagery. Our core software stack builds upon many of the OSGeo projects including GDAL and Mapserver, as well as the rich ecosystem of Python libraries. Internally we have processed over 5 Petabytes of public and private satellite imagery, including the full data corpus from the Landsat and Copernicus missions. By combining the above open-source tools with a FUSE-based filesystem for cloud storage, we have enabled a scalable compute platform that has demonstrated reading over 200 GB/s of satellite imagery into cloud compute nodes. In particular, we have generated global 15m Landsat-8, 20m Sentinel-1, and 10m Sentinel-2 composites, using over 10,000 CPUs.     We recently created a public open-source python client library that can be used to query and access imagery from within our platform, and made this platform available to researchers for non-commercial projects. In this talk we will describe how researchers can get started on the Descartes Labs Platform, and demonstrate examples in crop yield analysis and land use/land cover classification.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sam Skillman</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/a-python-api-for-earth.html</guid></item><item><title>Bringing the Generic Mapping Tools to Python</title><link>https://pyvideo.org/scipy-2017/bringing-the-generic-mapping-tools-to-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Generic Mapping Tools (GMT) is an open-source software package widely used in the geosciences to process and visualize time series and gridded data. Maps generated by GMT are ubiquitous in scientific publications in areas such as seismology and oceanography. We present a new GMT Python wrapper library built by the GMT team. We will show the design plans, internal implementations, and demonstrate an initial prototype of the library. Our wrapper connects to the GMT C API using ctypes and allows input and output using data from numpy ndarrays and xarray Datasets. The library is still in early stages of design and implementation and we are eager for contributions and feedback from the Scipy community.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Leonardo Uieda</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/bringing-the-generic-mapping-tools-to-python.html</guid></item><item><title>Calculating Radiation Doses for Tumor Treatment with Learning Algorithms</title><link>https://pyvideo.org/scipy-2017/calculating-radiation-doses-for-tumor-treatment-with-learning-algorithms.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Central to the planning of radiation therapy for cancer treatment is the calculation of radiation dose delivered to a patient. The optimization and subsequent delivery of a radiation therapy plan is only as good as the accuracy of the underlying radiation dose estimate. This work recasts the radiation dose estimation problem as a supervised regression task, with the goal of approximating slow, but accurate Monte Carlo-based dose calculations to within clinically acceptable error levels by using a fast to run machine learning algorithm.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Roy Keyes</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/calculating-radiation-doses-for-tumor-treatment-with-learning-algorithms.html</guid></item><item><title>ChiantiPy a Python Package for Astrophysical Spectroscopy</title><link>https://pyvideo.org/scipy-2017/chiantipy-a-python-package-for-astrophysical-spectroscopy.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;ChiantiPy is an interface to the CHIANTI atomic database for astrophysical spectroscopy. The highly-cited CHIANTI project, now in its 20th year, is an invaluable resource to the solar physics community. The ChiantiPy project brings the power of the scientific Python stack to the CHIANTI database, allowing solar physicists and astronomers to easily make use of this atomic data and calculate commonly used quantities from it such as radiative loss rates and emissivities for particular atomic transitions. In this talk, we will briefly discuss the history of the CHIANTI database and the ChiantiPy project as well as the current state of the project and its place in the solar physics community. We will demonstrate some of the capabilities of the ChiantiPy code and show examples of how ChiantiPy can be used in both modeling and observational studies. Finally, we'll discuss how ChiantiPy helps to bring the power of the CHIANTIC atomic database to the growing set of astronomy-related tools in Python.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Will Barnes</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/chiantipy-a-python-package-for-astrophysical-spectroscopy.html</guid><category>ChiantiPy</category></item><item><title>Composable Multiprocessing and Multithreading for Numeric Libraries</title><link>https://pyvideo.org/scipy-2017/composable-multiprocessing-and-multithreading-for-numeric-libraries.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Among numeric communities Python is popular because of its easy to use number crunching modules like Numpy, Scipy, Tensor Flow, Theano, Dask, and Numba – to name but a few. These modules often use parallel processing in order to exploit all of the resources of multi-core processors efficiently. However, when used together in the same application, or in an application which exposes parallelism itself, these Python modules can interfere with each other by requesting too many worker threads. That leads to inefficiency or even causes failure of the code due to resource exhaustion. Last year, the Intel® Threading Building Blocks (Intel® TBB) module for Python introduced a new approach to tackle these issues. However, It is limited to a single process and packages which can switch to using the Intel® TBB library for multi-threading (e.g. Numpy, Dask, Joblib, and Numba). In this work, we address both limitations in the existing approach by introducing a way to compose parallelism implemented with OpenMP* runtime and to support multiprocessing coordination for both Intel® TBB and OpenMP threading runtimes.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Anton Malakhov</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/composable-multiprocessing-and-multithreading-for-numeric-libraries.html</guid></item><item><title>Dash - A New Framework for Building User Interfaces for Technical Computing</title><link>https://pyvideo.org/scipy-2017/dash-a-new-framework-for-building-user-interfaces-for-technical-computing.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you are a data scientist today, it's actually pretty tough to build a data visualization web-application. If you're not a full-stack developer, you're practically out of luck.&lt;/p&gt;
&lt;p&gt;But GUIs like sliders, dropdowns, and text inputs are extremely helpful to the data scientist or engineer. If you're an R programmer, you're in luck with Shiny. If you're a MATLAB programmer, you can use GUIDE (but good luck sharing it!).     The dash project introduces a framework for building web-based technical computing apps (GUIs). It's like a Shiny for Python. dash is built off of plotly.js and react.js to provide rich interactive graphing and user interfaces and Python's flask to provide a simple but scalable web server.&lt;/p&gt;
&lt;p&gt;This talk will introduce the scientific community to Dash. We'll go over motivations behind the project, the basic architecture of the framework, several interactive examples, and leave with a vision for the future of interactive and sharable technical computing.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Chris Parmer</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/dash-a-new-framework-for-building-user-interfaces-for-technical-computing.html</guid></item><item><title>Dask - Advanced Techniques</title><link>https://pyvideo.org/scipy-2017/dask-advanced-techniques.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dask enables parallel computing in Python. While commonly used for its parallel and NumPy, Pandas implementations, Dask is also capable of a variety of more advanced parallel computing workflows. This talk dives into these advanced features features and applications beyond the typical distributed dataframe to talk about asynchronicity, dynamic and self-building computations,
multi-user workflows, and more.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Matthew Rocklin</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/dask-advanced-techniques.html</guid></item><item><title>Deep Learning with Geospatial Data</title><link>https://pyvideo.org/scipy-2017/deep-learning-with-geospatial-data.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deep learning is all the rage these days, but what do you do when your data isn’t handwritten digits, or pictures of cats? Geospatial data comes with it’s own unique challenges—huge high dimensional datasets in weird file formats, irregular and often mismatched grids, and a pervasive lack of labeled training data… to name just a few! In this talk, we’ll explore cutting up and resampling giant remote sensing rasters using modern python tools like rasterio, georasters, and GDAL; detrending, extracting, and storing information with pandas; sensible dataset and dimensionality reduction through scipy transforms; and a few places to go in Keras and other deep learning libraries. Come learn how to jump from satellite or airborne data to your own “geoMINST” database that’s ingestible to your favorite deep learning technique!&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Shane Grigsby</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/deep-learning-with-geospatial-data.html</guid></item><item><title>Diversity &amp; Inclusion at the SciPy Conference</title><link>https://pyvideo.org/scipy-2017/diversity-inclusion-at-the-scipy-conference.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Studies have shown that diversity in the workplace increases productivity and leads to better outcomes. These benefits can be directly applied to the SciPy stack, community, and conference. In this talk we present an analysis of the gender diversity of SciPy Conference speakers over the years. We compare these statistics to external diversity surveys of academia and industry, and use the results to develop metrics that evaluate the success of the diversity efforts of the conference. Additionally, we will showcase the work of the diversity committee for this year’s conference and our efforts going forward, including using the methodology developed from the gender diversity speaker statistics on self-reported demographic data of conference attendees that we are collecting for the first time this year.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Julie Hollek</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/diversity-inclusion-at-the-scipy-conference.html</guid></item><item><title>Drilling the Chicxulub Impact Structure: Study of Large Impact Formation and Effects on Life during IODP/ICDP Expedition 364</title><link>https://pyvideo.org/scipy-2017/drilling-the-chicxulub-impact-structure-study-of-large-impact-formation-and-effects-on-life-during-iodpicdp-expedition-364.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In 2016, the International Ocean Discovery Program Expedition 364 drilled and analysed 830 m of core from the 66 million year old Chicxulub impact crater’s peak ring. Chicxulub is unique as the only preserved large impact on Earth and the only impact event linked to mass extinction. Key results are that the Chicxulub peak ring is formed from fractured basement rocks that may host a subsurface biosphere. The impactite layer overlying the peak ring in turn provides insight into resurge and tsunami processes, while the Paleogene sediments contain the record of the recovery of life after the mass extinction event. Analyses greatly aided by a public-private partnership on X-ray CT imaging and analysis with Enthought.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sean Gulick</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/drilling-the-chicxulub-impact-structure-study-of-large-impact-formation-and-effects-on-life-during-iodpicdp-expedition-364.html</guid><category>keynote</category></item><item><title>Efficient Array Computing in C++ with xtensor and Apache Arrow</title><link>https://pyvideo.org/scipy-2017/efficient-array-computing-in-c-with-xtensor-and-apache-arrow.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will discuss joint work between the xtensor and Apache Arrow open source projects, which can help enable the development of machine learning and other numerical computing applications. xtensor provides efficient multidimensional array computing for C++14 using expression templates, with Python bindings and NumPy interoperability. Apache Arrow provides cross-language array metadata and shared memory IO for moving tabular and tensor-like array data efficiently between compute environments.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sylvain Corlay</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/efficient-array-computing-in-c-with-xtensor-and-apache-arrow.html</guid></item><item><title>Efficient Image Search and Identification - The Making of Wine O.AI</title><link>https://pyvideo.org/scipy-2017/efficient-image-search-and-identification-the-making-of-wine-oai.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This presentation will discuss the implementation of an image-based identification system for wine labels using Python scientific and machine learning libraries. An overview of the methodology for this technique, called content-based image retrieval, will be presented. Techniques for improving search accuracy and retrieval time will also be discussed. The intended audience is individuals who have intermediate Python experience and a limited or basic familiarity with machine learning and computer vision techniques.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Michelle Gill</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/efficient-image-search-and-identification-the-making-of-wine-oai.html</guid></item><item><title>Fully Convolutional Networks for Image Segmentation</title><link>https://pyvideo.org/scipy-2017/fully-convolutional-networks-for-image-segmentation.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Recently, a considerable advancemet in the area of Image Segmentation was achieved after state-of-the-art methods based on Fully Convolutional Networks (FCNs) were developed. The objective of Image Segmentation problem is to label every pixel in the image with the class of its enclosing object or region. This problem is extremely challenging because the method should have strong classification and localization properties at the same time. While being very complicated, image segmentation is an important problem as it has many applications in medicine, autonomous driving and other fields. In our talk, we go through theory of the recent state-of-the-art methods for image segmentation based on FCNs and present our library which aims to provide a simplified way for users to apply these methods for their own problems.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Daniil Pakhomov</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/fully-convolutional-networks-for-image-segmentation.html</guid></item><item><title>Hybrid-Vocal-Classifier (HVC): a Python Package to Automate Labeling of Birdsong for Behavioral Experiments</title><link>https://pyvideo.org/scipy-2017/hybrid-vocal-classifier-hvc-a-python-package-to-automate-labeling-of-birdsong-for-behavioral-experiments.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Neuroscientists study songbirds to understand how the brain learns and produces motor skills. Like babies learning to talk, songbirds acquire their song socially during a critical period in development. To understand the neural basis of birdsong, neuroscientists carry out behavioral experiments. Often analysis requires labeling the elements of song (known as &amp;quot;syllables&amp;quot;) by hand, which consumes many person-hours. Several methods have been proposed to automate labeling syllables, but little work has been done to compare them. Hybrid-vocal-classifier (HVC) is a Python package for comparing methods and automating labeling. It is tested on a large collection of hand-labeled song, now made publicly available. Users can configure HVC with human-readable YAML files. HVC loads data collected with different programs by making use of the SciPy/Numpy stack. It includes previously proposed algorithms, implemented in scikit-learn, as well as artificial neural network models built in Keras. Initial results obtained with HVC suggest convolutional neural networks yield higher accuracy predictions with less training data than the best models previously proposed.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">David Nicholson</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/hybrid-vocal-classifier-hvc-a-python-package-to-automate-labeling-of-birdsong-for-behavioral-experiments.html</guid></item><item><title>Keynote - Coding for Science and Innovation</title><link>https://pyvideo.org/scipy-2017/keynote-coding-for-science-and-innovation.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Computing has been driving forward a revolution in how science and technology can solve new problems. Python has grown to be a central player in this game, from computational physics to data science. I would  like to explore some lessons learned doing science with Python as well as doing Python libraries for science. What are the ingredients that the scientists need? What technical and project-management choices drove the success of projects I've been involved with? How do these demands and offers shape our ecosystem?&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Gaël Varoquaux</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/keynote-coding-for-science-and-innovation.html</guid><category>keynote</category></item><item><title>LabbookDB</title><link>https://pyvideo.org/scipy-2017/labbookdb.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;LabbookDB currently ships a relational database structure for life science research along with a number of functions to conveniently add/retrieve information and generate summaries. The core concept of LabbookDB is that most of the information classically tracked in a lab book can be more efficiently and more reliably stored in a relational database. We overcome the portability limitations of designed-for-analysis spreadsheets and databases by building the database schema around atomized physical interactions of objects in the laboratory (and providing ready-for-analysis dataframes as a compatibility layer). LabbookDB provides a wet work metadata storage model excellently suited for explorative ex-post reporting and analysis, as well as a great infrastructure for automated wet work tracking.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Horea-Ioan Ioanas</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/labbookdb.html</guid><category>LabbookDB</category></item><item><title>Learning in Cycles Implementing Sustainable Machine Learning Models in Production</title><link>https://pyvideo.org/scipy-2017/learning-in-cycles-implementing-sustainable-machine-learning-models-in-production.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Machine learning textbooks tend to focus too narrowly on specific algorithms or code without looking at the bigger picture. One key real-world application that's rarely covered: predictive models which are regularly updated with new data stemming from earlier predictions. Done poorly, repeated models can amplify the errors and biases of their initial versions. But when done right, they can learn from those mistakes over time, and employ the results of previous versions as new training data to keep the model fresh and productive over the course of months or years of applied use. With examples from my own work in the political, nonprofit, and civic data science fields, this talk will introduce a framework for designing machine learning models that get better over time.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Therriault</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/learning-in-cycles-implementing-sustainable-machine-learning-models-in-production.html</guid></item><item><title>Lightning Talks 2017-07-14</title><link>https://pyvideo.org/scipy-2017/lightning-talks-2017-07-14.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Lightning Talks 2017-07-14&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="12%" /&gt;
&lt;col width="23%" /&gt;
&lt;col width="65%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head" rowspan="2"&gt;Start&lt;/th&gt;
&lt;th class="head" rowspan="2"&gt;Speakers&lt;/th&gt;
&lt;th class="head" rowspan="2"&gt;Subject&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td rowspan="5"&gt;2:45&lt;/td&gt;
&lt;td rowspan="5"&gt;Chaya Stern&lt;/td&gt;
&lt;td rowspan="5"&gt;&lt;strong&gt;cpDetect&lt;/strong&gt;
- A Bayesian Change Point Detection Package, wrote for
a package.  Finds chunks and splits them in your time
series.  On github.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;5:20&lt;/td&gt;
&lt;td rowspan="4"&gt;James&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Script All the Things!&lt;/strong&gt;
- Programming is a perishable skill.  So script all
the things and get better at it.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;10:10&lt;/td&gt;
&lt;td rowspan="4"&gt;Dana Miller&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Buildings + Python&lt;/strong&gt;
- Buildings use 40% of energy, make lots of data on
BACnet, sMAP 2, and use Python&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;15:00&lt;/td&gt;
&lt;td rowspan="4"&gt;Adam Hood&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Datalore&lt;/strong&gt;
- JetBrains new Python IDE for Data Science with
intentions (suggestions), continuous execution, more.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;18:45&lt;/td&gt;
&lt;td rowspan="4"&gt;Christie Koehler&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;How to Measure Open Source Sustainability&lt;/strong&gt;
- Foundational projects are just getting by.  Want to
develop a metric for sustainability.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="3"&gt;24:50&lt;/td&gt;
&lt;td rowspan="3"&gt;Imanshu Mishra&lt;/td&gt;
&lt;td rowspan="3"&gt;&lt;strong&gt;PEP8Speaks&lt;/strong&gt;
- Automated mailing for PEP8 issues.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;28:20&lt;/td&gt;
&lt;td rowspan="4"&gt;Randy Ludwig&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Data Science for Babies&lt;/strong&gt;
- Analyzing for Eat/Sleep/Poop metrics using broken
linear fit.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="3"&gt;34:00&lt;/td&gt;
&lt;td rowspan="3"&gt;Kyle Penner&lt;/td&gt;
&lt;td rowspan="3"&gt;&lt;strong&gt;Thank you Images&lt;/strong&gt;
- AstroPy and ApplePy let me make pretty pictures.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;38:10&lt;/td&gt;
&lt;td rowspan="4"&gt;Jane Williams &amp;amp;
Alyssa Whitwell&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Clover's Health ASE program&lt;/strong&gt;
- Clover grew fast and made an Associate Software
Engineer program. 100% retention.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;43:50&lt;/td&gt;
&lt;td rowspan="4"&gt;Santosh&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;MiGA&lt;/strong&gt;
- RDP's Microbial Genome Atlas.  Upload your genome to
identify.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="5"&gt;48:00&lt;/td&gt;
&lt;td rowspan="5"&gt;M  Pacer&lt;/td&gt;
&lt;td rowspan="5"&gt;&lt;strong&gt;IPython News&lt;/strong&gt;
- IPython 6.0 is out, and requires Python 3.x;
IPython.display.display now built in; Fernando Perez
is teaching reproducible research.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="5"&gt;51:40&lt;/td&gt;
&lt;td rowspan="5"&gt;James Powell&lt;/td&gt;
&lt;td rowspan="5"&gt;&lt;strong&gt;gormless&lt;/strong&gt;
- People don't care about domain models, but there is
no limit of complexity in real world so we regularize
it.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;58:10&lt;/td&gt;
&lt;td rowspan="4"&gt;David Shu&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Python Widgets for Astronomy Visualization&lt;/strong&gt;
- Firefly Archive Access System; Firefly_widgets. Use
cookiecutter template.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;1:03:00&lt;/td&gt;
&lt;td rowspan="4"&gt;Peter Wang&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Yeah!&lt;/strong&gt;
- Python and open source won!  Future ways of looking
at systems and openess.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Chaya Stern</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/lightning-talks-2017-07-14.html</guid><category>lightning talks</category></item><item><title>Make Your Observational Study an Experiment</title><link>https://pyvideo.org/scipy-2017/make-your-observational-study-an-experiment.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The gold standard of scientific inquiry is a Randomized Controlled Trial (RCT). Random assignment cures a variety of ills in experimental design.&lt;/p&gt;
&lt;p&gt;Unfortunately in the social sciences, an RCT can often be cost-prohibitive, impossible to construct, or unethical. In disciplines like Epidemiology and Economics, the solution has been observational studies. These studies provide some understanding of the issues explored, but lack the causal assertions of an RCT.     Luckily, we don’t have to give up there. This talk focuses on techniques that we can use to draw rigorous conclusions from data we already have. We will explore propensity matching and related tools to estimate the probability of treatment for a given subject. We’ll look at matching, and explore implementation details for making this algorithm (much) more efficient. And we’ll finish with a discussion of the limitations/sensitivity of the results. Attendees will walk away with a tool set for drawing more robust conclusions from data in the messy world of observational studies.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Peter Skipper</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/make-your-observational-study-an-experiment.html</guid></item><item><title>MetPy’s Choice of Unit Support - A Descent into Madness</title><link>https://pyvideo.org/scipy-2017/metpys-choice-of-unit-support-a-descent-into-madness.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Proper handling of physical quantities (aka. “units”) is important for scientific programming, and is something computers should be able to facilitate for programmers. This talk explores a few of the currently maintained libraries for unit support in Python and discusses the challenges and pitfalls of using them within the rest of the scientific Python stack.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ryan May</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/metpys-choice-of-unit-support-a-descent-into-madness.html</guid></item><item><title>NEXT - Machine Learning, Crowdsourcing, and Cartoons</title><link>https://pyvideo.org/scipy-2017/next-machine-learning-crowdsourcing-and-cartoons.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Obtaining useful crowdsourcing results often requires more responses than can be easily collected. Reducing the number of responses required can be done by adapting to previous responses with &amp;quot;adaptive&amp;quot; sampling algorithms, but these algorithms present a fundamental challenge when paired with crowdsourcing. At UW–Madison, we have built a powerful crowdsourcing data collection tool called NEXT (&lt;a class="reference external" href="http://nextml.org"&gt;http://nextml.org&lt;/a&gt;) that can be used with arbitrary adaptive algorithms. Each week, our system is used by The New Yorker to run their Cartoon Caption contest (&lt;a class="reference external" href="http://www.newyorker.com/cartoons/vote"&gt;http://www.newyorker.com/cartoons/vote&lt;/a&gt;). In this paper, we will explain what NEXT is and it's applications, architecture and experimentalist use.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Scott Sievert</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/next-machine-learning-crowdsourcing-and-cartoons.html</guid></item><item><title>PyGBe - Python, GPUs and Boundary Elements for Biomolecular Electrostatics</title><link>https://pyvideo.org/scipy-2017/pygbe-python-gpus-and-boundary-elements-for-biomolecular-electrostatics.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyGBe is a Python library that applies the boundary element method for molecular-electrostatics and simple nanoparticle plasmonics. We treat molecular-electrostatics with a continuum model and handle localized surface plasmon calculations in the quasistatic approximation.&lt;/p&gt;
&lt;p&gt;PyGBe provides faster time-to-solution and also new problem-solving options to scientists in molecular biology, biochemistry and applied physics. It can handle solvent-filled cavities and stern layers; solve for protein-surface electrostatic interactions; probe protein orientation near charged nanosurfaces; and localized surface plasmon resonance with an eye towards nano-scale biosensor calculations.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Natalia Clementi</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/pygbe-python-gpus-and-boundary-elements-for-biomolecular-electrostatics.html</guid><category>PyGBe</category></item><item><title>Pygridtools - A Collaboration Academia, Open Source, and the Private Sector</title><link>https://pyvideo.org/scipy-2017/pygridtools-a-collaboration-academia-open-source-and-the-private-sector.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In fields like hydrodynamic (finite difference) modeling, creating the numerical model grid is a crucial first step. However, generating a curvilinear-orthogonal grid can be a challenging task in and of itself. Perhaps equally challenging can be locating and compiling from source code the C-libraries to do so. By collaborating with academic and open source communities, Geosyntec Consultants was able to help bridge the availability and usability gaps for the tools needs to generate, manipulate, and visualize results on model grids. In this talk, I discuss how we collaborated with these communities to successfully build these tools, share them back with the communities, and provide a brief demo of their use.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Paul Hobs</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/pygridtools-a-collaboration-academia-open-source-and-the-private-sector.html</guid></item><item><title>Rambutan - A Python Package for Predicting 3D Genome Architecture</title><link>https://pyvideo.org/scipy-2017/rambutan-a-python-package-for-predicting-3d-genome-architecture.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Recently, Hi-C has been used to probe the 3D chromatin architecture of multiple organisms and cell types. A computational method for predicting pairwise contacts without the need to run a Hi-C experiment would be invaluable in understanding the role that 3D chromatin architecture plays in genome biology. In this talk I will describe Rambutan, a Python package that uses a deep convolutional neural network to predict Hi-C contacts at 1 kb resolution using nucleotide sequence and DNaseI assay signal as inputs. I will explain the area of chromatin architecture briefly, how Rambutan fits in with other methods in the field, validate this model using both traditional accuracy metrics and at biological tasks, and show how one can use Rambutan simply in their own work.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jacob Schreiber</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/rambutan-a-python-package-for-predicting-3d-genome-architecture.html</guid></item><item><title>Scientific Analysis at Scale - a Comparison of Five Systems</title><link>https://pyvideo.org/scipy-2017/scientific-analysis-at-scale-a-comparison-of-five-systems.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Scientific discoveries are increasingly driven by the analysis of large volumes of image data, and many tools and systems have emerged to support distributed data storage and scalable computation. It is not always immediately clear, however, how well these systems support real-world scientific use cases. Our team set out to evaluate the performance and ease-of-use of five such systems (SciDB, Myria, Spark, Dask, and TensorFlow), as applied to real-world image analysis pipelines drawn from astronomy and neuroscience. We find that each tool has distinct advantages and shortcomings, which point the way to new research opportunities in making large-scale scientific image analysis both efficient and easy to use.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jake VanderPlas</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/scientific-analysis-at-scale-a-comparison-of-five-systems.html</guid></item><item><title>Scientific MicroPython on Microcontrollers and IoT</title><link>https://pyvideo.org/scipy-2017/scientific-micropython-on-microcontrollers-and-iot.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;MicroPython is a implementation of Python 3 optimised to run on a microcontroller with MHz and greater than= 10 Kbytes of RAM. But even with these hardware constraints, scientific MicroPython is already available and practical. I will present MicroPython from the perspective of users and developers, demonstrating scientific usage of MicroPython on some boards connected to sensors and Internet.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Roberto Colistete Jr</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/scientific-micropython-on-microcontrollers-and-iot.html</guid></item><item><title>Stingray - A Library of Time Series Methods for Astronomical X Ray Data</title><link>https://pyvideo.org/scipy-2017/stingray-a-library-of-time-series-methods-for-astronomical-x-ray-data.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Stingray(&lt;a class="reference external" href="https://github.com/StingraySoftware/Stingray"&gt;https://github.com/StingraySoftware/Stingray&lt;/a&gt;) is a spectral-timing software package for astrophysical X-ray (and more) data. The package merges existing efforts for a (spectral-)timing package in Python and is composed of a library of time series methods (including power spectra, cross spectra, covariance spectra, and lags); scripts to load FITS data files from different missions; a simulator of light curves and event lists that includes different kinds of variability and more complicated phenomena based on the impulse response of given physical events (e.g. reverberation); and a GUI to ease the learning curve for new users.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Himanshu Mishra</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/stingray-a-library-of-time-series-methods-for-astronomical-x-ray-data.html</guid><category>stingray</category><category>x ray</category></item><item><title>Terabytes at Your Fingertips - Interactive Big Data Coding with PySpark</title><link>https://pyvideo.org/scipy-2017/terabytes-at-your-fingertips-interactive-big-data-coding-with-pyspark.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Effective programmers work in tight loops: make a small change to the code, run it, observe the effect, repeat. Sadly, we can't observe big distributed systems with print() or &amp;quot;step.&amp;quot; We'll learn how to find the root problem when our distributed code breaks and how to scale fixes back up to handle terabytes of data. Attendees will leave with a toolbox for increasing their productivity with large distributed systems.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sam Penrose</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/terabytes-at-your-fingertips-interactive-big-data-coding-with-pyspark.html</guid></item><item><title>The Demeshening The Next Generation of Particle Support in yt</title><link>https://pyvideo.org/scipy-2017/the-demeshening-the-next-generation-of-particle-support-in-yt.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Large N-body particle datasets present a unique challenge for analysis and visualization. With multi-terabyte datasets becoming increasingly common, the goal of performing large-scale analysis and visualization of such large quantities of data becomes increasingly challenging.&lt;/p&gt;
&lt;p&gt;In this talk we describe a new particle indexing scheme we have designed for yt, a python toolkit for the analysis and visualization of 3D simulation data. By making use of compressed Morton bitmaps to index the locations of particles, we substantially decrease the overhead to perform spatial chunking. By rethinking the high-level yt API for N-body data to be more particle-centric, we are able to scale analysis and visualization to datasets containing very large numbers of particles while reaping performance improvements and decreased memory overhead when working with smaller datasets.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Nathan Goldbaum</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/the-demeshening-the-next-generation-of-particle-support-in-yt.html</guid><category>yt</category></item><item><title>The Spyder Ecosystem of Plugins</title><link>https://pyvideo.org/scipy-2017/the-spyder-ecosystem-of-plugins.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we want to introduce to the community a new set of third-party Spyder plugins (developed during the last six months) that extend the program functionality in interesting and novel ways. These plugins are: a &lt;em&gt;Notebook&lt;/em&gt; plugin, that integrates the classic Jupyter notebook in Spyder; a &lt;em&gt;Reports&lt;/em&gt; plugin, that allows users to write documents in markdown, with embedded code snippets and graphics, and export them to HTML and PDF; a &lt;em&gt;Terminal&lt;/em&gt; plugin, that integrates system terminals in Spyder; and a &lt;em&gt;Vim&lt;/em&gt; plugin, that allows using the most common Vim keybindings in Spyder's editor.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Carlos Cordoba</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/the-spyder-ecosystem-of-plugins.html</guid><category>spyder</category></item><item><title>WARNO - Multi platform Monitoring Framework for Remote Sensing Instrumentation</title><link>https://pyvideo.org/scipy-2017/warno-multi-platform-monitoring-framework-for-remote-sensing-instrumentation.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Department of Energy’s Atmospheric Radiation Measurement program (ARM) has more than thirty radars spread around the world at three permanent and three mobile sites. These radars come from different manufacturers and operate at different frequencies. This presents some challenges when it comes to monitoring the performance of the entire radar network by the relatively small team. To help with this situation, the radar engineering team has designed a platform for monitoring of multiple instruments at geographically remote sites. This platform, the Watchdog for ARM Radar Network Operations (WARNO), is a multi-level distributed open source set of software that monitors hundreds of different streams of data on each radar. Each installation of WARNO has an extensible and configurable plugin architecture that allows for easy modification of data collection without the need to modify the core code. Each distributed installation communicates with a central monitoring server that accumulates all of the data from each radar installation for ease of comparison. There is an additional plugin architecture for data analytics that allows for higher-level feature detection, as well as warn-on-alarm type features. Data is presented through a robust web interface capable of plotting and statistics on the data, as well as user-based customization. WARNO is written in Python, although plugins can be written in multiple languages.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joseph</dc:creator><pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-14:scipy-2017/warno-multi-platform-monitoring-framework-for-remote-sensing-instrumentation.html</guid></item><item><title>Anatomy of Matplotlib</title><link>https://pyvideo.org/scipy-2017/anatomy-of-matplotlib.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This tutorial will be the introduction to Matplotlib. Users will learn the types of plots and experiment with them. Then the fundamental concepts and terminologies of Matplotlib are introduced. Next, we will learn how to change the &amp;quot;look and feel&amp;quot; of plots. Finally, users will be introduced to other toolkits that extends Matplotlib.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ben Root</dc:creator><pubDate>Thu, 13 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-13:scipy-2017/anatomy-of-matplotlib.html</guid></item><item><title>Introduction to Numerical Computing with NumPy</title><link>https://pyvideo.org/scipy-2017/introduction-to-numerical-computing-with-numpy.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;NumPy provides Python with a powerful array processing library and an elegant syntax that is well suited to expressing computational algorithms clearly and efficiently. We'll introduce basic array syntax and array indexing, review some of the available mathematical functions in numpy, and discuss how to write your own routines. Along the way, we'll learn just enough of matplotlib to display results from our examples.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dillon Niederhut</dc:creator><pubDate>Thu, 13 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-13:scipy-2017/introduction-to-numerical-computing-with-numpy.html</guid><category>tutorial</category></item><item><title>Lightning Talks 2017-07-13</title><link>https://pyvideo.org/scipy-2017/lightning-talks-2017-07-13.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Lightning Talks 2017-07-13&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="12%" /&gt;
&lt;col width="23%" /&gt;
&lt;col width="65%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head" rowspan="2"&gt;Start&lt;/th&gt;
&lt;th class="head" rowspan="2"&gt;Speakers&lt;/th&gt;
&lt;th class="head" rowspan="2"&gt;Subject&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;1:45&lt;/td&gt;
&lt;td rowspan="4"&gt;Stephan van der
Walt&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Elegant SciPy book&lt;/strong&gt;
- Its free online with executable notebooks, explore
the table of contents.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;7:20&lt;/td&gt;
&lt;td rowspan="4"&gt;Loranna&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;JOSS&lt;/strong&gt;
- Journal of Open Source Science seeks to rewards
contributors of software.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;17:45&lt;/td&gt;
&lt;td rowspan="4"&gt;Daniel&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;MolSSI&lt;/strong&gt;
- Molecular Software Sciences Institute is a new, well
funded, open source (OSI) institute.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;20:15&lt;/td&gt;
&lt;td rowspan="4"&gt;Meagan Lang&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;cykdtree &amp;amp; cgal4py&lt;/strong&gt;
- Build KD-trees (e.g., load balancing) and Delanay
Transformations (e.g., continuous distributions).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;24:15&lt;/td&gt;
&lt;td rowspan="4"&gt;Tobi Shenk&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;DNA dashboard&lt;/strong&gt;
- Made a DNA dashboard.  Genetists should visualize
more with Bokeh.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="3"&gt;29:30&lt;/td&gt;
&lt;td rowspan="3"&gt;Prabhu
Ramachandran&lt;/td&gt;
&lt;td rowspan="3"&gt;&lt;strong&gt;Teaching Old Dogs New Tricks&lt;/strong&gt;
- Jupyter presentation tools: tex2ipy, ipyaml&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;35:00&lt;/td&gt;
&lt;td rowspan="4"&gt;Christian&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Reproducible Self-publishing&lt;/strong&gt;
- Making pretty papers and presentations reexecutable,
Latex + Python + data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;40:00&lt;/td&gt;
&lt;td rowspan="4"&gt;Matt Craig&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Vpython-Jupyter&lt;/strong&gt;
- Teaching Physics and Astronomy; simple visual models
with physics;  GlowScript instead of install.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;44:45&lt;/td&gt;
&lt;td rowspan="4"&gt;Jason Grout&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Jupyter Lab&lt;/strong&gt;
- New computation environment: collapsible cells, lots
of media viewers, more&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;50:30&lt;/td&gt;
&lt;td rowspan="4"&gt;Henry Senyondo&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Data Package Manager&lt;/strong&gt;
- Data Retriever to download, clean, and stick into
your databases.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;54:00&lt;/td&gt;
&lt;td rowspan="4"&gt;Justin&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;&amp;quot;The Bachelor&amp;quot; Fantasy League&lt;/strong&gt;
- scrape Wikipedia; use Plot.ly;  web visualization
with Dash;  deploy on Heroku&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Stéfan van der Walt</dc:creator><pubDate>Thu, 13 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-13:scipy-2017/lightning-talks-2017-07-13.html</guid><category>lightning talks</category></item><item><title>Optimised Finite Difference Computation from Symbolic Equations</title><link>https://pyvideo.org/scipy-2017/optimised-finite-difference-computation-from-symbolic-equations.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Domain-specific high-productivity environments are playing an increasingly important role in scientific computing due to the increased levels of abstraction and automation they provide. In this talk we introduce Devito, an open-source domain-specific framework for solving partial differential equations from symbolic problem definitions by the finite difference method. We highlight the generation and automated execution of highly optimized stencil code from only a few lines of high-level symbolic Python for a set of operators used in seismic inversion problems, before exploring the use of Devito for a range of scientific equations.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Michael Lange</dc:creator><pubDate>Thu, 13 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-13:scipy-2017/optimised-finite-difference-computation-from-symbolic-equations.html</guid></item><item><title>Parallel Data Analysis in Python</title><link>https://pyvideo.org/scipy-2017/parallel-data-analysis-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This tutorial teaches the fundamentals of parallel programming in Python. It focuses on covering a few programming techniques rather than diving into one framework or tool in particular.&lt;/p&gt;
&lt;p&gt;Student Goals:&lt;/p&gt;
&lt;p&gt;Students will walk away with a high-level understanding of both parallel problems and how to reason about parallel computing frameworks. They will also walk away with hands-on experience using a variety of frameworks easily accessible from Python.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Matthew Rocklin</dc:creator><pubDate>Thu, 13 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-13:scipy-2017/parallel-data-analysis-in-python.html</guid><category>tutorial</category></item><item><title>Parallelizing Scientific Python with Dask</title><link>https://pyvideo.org/scipy-2017/parallelizing-scientific-python-with-dask.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Dask is a flexible tool for parallelizing Python code on a single machine or across a cluster. We can think of dask at a high and a low level:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;High level collections: Dask provides high-level Array, Bag, and DataFrame collections that mimic NumPy, lists, and Pandas but can operate in parallel on datasets that don't fit into main memory. Dask's high-level collections are alternatives to NumPy and Pandas for large datasets.&lt;/li&gt;
&lt;li&gt;Low Level schedulers: Dask provides dynamic task schedulers that execute task graphs in parallel. These execution engines power the high-level collections mentioned above but can also power custom, user-defined workloads. These schedulers are low-latency (around 200 us) and work hard to run computations in a small memory footprint. Dask's schedulers are an alternative to direct use of threading or multiprocessing libraries in complex cases or other task scheduling systems like Luigi or IPython parallel.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Different users operate at different levels but it is useful to understand both. This tutorial will cover both the high-level use of dask.array and dask.dataframe and low-level use of dask graphs and schedulers.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">James Crist</dc:creator><pubDate>Thu, 13 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-13:scipy-2017/parallelizing-scientific-python-with-dask.html</guid><category>tutorial</category><category>dask</category></item><item><title>Sarkas - A Fast Pure Python Molecular Dynamics Code</title><link>https://pyvideo.org/scipy-2017/sarkas-a-fast-pure-python-molecular-dynamics-code.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Molecular dynamics (MD) simulations are a powerful technique to understand many-body systems at the atomistic level, helping us understand the influence of micro-scale structural and temporal properties on the observed macroscopic properties of interest. Though there exists MD codes for such simulations, to our knowledge there isn't a pure-Python production-scale MD code. This motivated us to develop Sarkas - a production-scale pure-Python open-source MD code for particles interacting through Coulomb and screened Coulomb potentials. Though pure-Python, Sarkas is high-performant with execution speeds comparable to compiled languages (eg. C). This is due to the extensive use of Numpy arrays and a just-in-time compilation using Numba. Sarkas simulates 3D systems with potential energy and forces computed using a highly efficient Particle-Particle Particle-Mesh (PPPM) algorithm. The systems of our interest are strongly coupled plasmas such as dusty plasmas, ultracold neutral plasmas and warm dense matter. The user-friendliness of Python combined with high performance enables Sarkas to serve as a useful design tool for experimentalists to efficiently sample a wide parameter space of interest.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Gautham Dharuman</dc:creator><pubDate>Thu, 13 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-13:scipy-2017/sarkas-a-fast-pure-python-molecular-dynamics-code.html</guid></item><item><title>scikit image - Image Processing for Python</title><link>https://pyvideo.org/scipy-2017/scikit-image-image-processing-for-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;scikit-image is a collection of image processing algorithms for the
SciPy ecosystem. It has a Pythonic API, is well documented, and aims
to provide researchers and practitioners with well-tested, fundamental
building blocks for rapidly constructing sophisticated image
processing pipelines.&lt;/p&gt;
&lt;p&gt;In this tutorial, we provide an interactive overview of the library,
where participants have the opportunity to try their hand at various
image processing challenges.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Stéfan van der Walt</dc:creator><pubDate>Thu, 13 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-13:scipy-2017/scikit-image-image-processing-for-python.html</guid><category>scikit image</category><category>tutorial</category></item><item><title>Signal Processing and Communications Hands On Using scikit dsp comm</title><link>https://pyvideo.org/scipy-2017/signal-processing-and-communications-hands-on-using-scikit-dsp-comm.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this tutorial I intend to start with a basic review of discrete-time signals and systems using a module I developed for my book Signals and Systems for Dummies. Once a basic foundation is provided, all using hands-on Python code examples in a Jupyter notebook, I will move to more advanced topics relative to statistical signal processing, digital communications and software defined radio. Digital communication transmitter and receiver simulations will be explored using Python code modules found in the newly posted scikit-dsp-comm as well as data acquisition code used in conjunction with a popular $20 software-defined radio USB dongle (RTL-SDR).
The capstone portion of the tutorial will have the students write code to recover FM stereo radio broadcasts from a raw complex signal file obtained from the output of a popular $20 software defined radio module (the RTLSDR).  Hardware will be provided for small groups to work together.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mark Wic</dc:creator><pubDate>Thu, 13 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-13:scipy-2017/signal-processing-and-communications-hands-on-using-scikit-dsp-comm.html</guid><category>signal processing</category><category>software defined radio</category><category>tutorial</category></item><item><title>Automatic Code Generation with SymPy</title><link>https://pyvideo.org/scipy-2017/automatic-code-generation-with-sympy.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This tutorial will introduce code generation concepts using the SymPy library. SymPy is a pure Python library for symbolic mathematics. Code generation refers to the act of converting a SymPy symbolic expression into equivalent code in some language. This allows one to use SymPy to symbolically model a problem, and generate fast numerical code for specific platforms that executes that model. This is a powerful tool that is useful to scientists in many domains. Code generation allows users to speed up existing code, to deal only with the high level mathematics of a problem, avoids mathematical errors and typos, makes it possible to deal with expressions that would otherwise be too large to write by hand, and opens possibilities to perform automatic mathematical optimizations of expressions.&lt;/p&gt;
&lt;p&gt;SymPy supports generating code for C, C++, Fortran, Matlab/Octave, Python, Cython, Julia, Javascript, LLVM, Rust, Haskell, Mathematica, Tensorflow, and Theano, and can easily be extended to other languages. SymPy’s code generation is used by libraries such as PyDy, pyodesys, sympybotics, pycalphad, and many other programs.&lt;/p&gt;
&lt;p&gt;Learning objectives&lt;/p&gt;
&lt;p&gt;Attendees will be able to:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;write SymPy expressions describing mathematical functions and identify the function arguments and outputs.&lt;/li&gt;
&lt;li&gt;use the SymPy code printers to transform SymPy expressions representing common domain specific functions into multiple output languages.&lt;/li&gt;
&lt;li&gt;use the SymPy code generation routines to output compilable C code and use Cython to access these functions in Python.&lt;/li&gt;
&lt;li&gt;generate custom vectorized functions with the three SymPy functions: lambdify, ufuncify, and autowrap.&lt;/li&gt;
&lt;li&gt;create both custom code printers that make use of specialized C libraries and common subexpression elimination (CSE).&lt;/li&gt;
&lt;li&gt;subclass the core SymPy printers and create a printer for a custom language.&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jason Moore</dc:creator><pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-12:scipy-2017/automatic-code-generation-with-sympy.html</guid><category>tutorial</category><category>sympy</category></item><item><title>Cython for Data, Scientists, and Data Scientists</title><link>https://pyvideo.org/scipy-2017/cython-for-data-scientists-and-data-scientists.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Cython is a foundational technology behind many packages you use everyday, including NumPy, SciPy, Pandas, Scikit-Learn, Scikit-Image, PyTables, and h5py. Developers, data scientists, and researchers use Cython to accelerate Python, access NumPy efficiently at the C level, and interface Python with C or C++. Cython's expressivity, its stability and maturity, and its gradual typing approach make it a uniquely flexible tool that has become a critical component for many projects.&lt;/p&gt;
&lt;p&gt;This tutorial will be fast paced, and is geared towards data scientists and Python users looking to take their Python performance to the next level. Basic familiarity with C or C++ is assumed.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dillon Niederhut</dc:creator><pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-12:scipy-2017/cython-for-data-scientists-and-data-scientists.html</guid><category>tutorial</category><category>cython</category></item><item><title>From the Field to Geostationary Orbit - Mapping Lightning with Python</title><link>https://pyvideo.org/scipy-2017/from-the-field-to-geostationary-orbit-mapping-lightning-with-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Lightning measurements generate hierarchically clustered, time-tagged, georeferenced datasets, which is rare in the Earth sciences. Therefore, practical knowledge concerning lightning data formats, services, and visualization approaches is underdeveloped. Using data from new instruments and recent field campaigns we will show the utility of xarray and other Python tools for traversing and visualizing lighting data alongside other meteorological datasets, with a view toward reference implementations that speed use of lightning data by the wider scientific and operational forecasting community.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Eric Bruning</dc:creator><pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-12:scipy-2017/from-the-field-to-geostationary-orbit-mapping-lightning-with-python.html</guid></item><item><title>Global 5 Meter Resolution Time Series Mosaics</title><link>https://pyvideo.org/scipy-2017/global-5-meter-resolution-time-series-mosaics.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Planet is nearing full operations to image the entire world every day. This volume of data is most easily viewed through global time series mosaics. This talk will explain the process of selecting the best scenes, and how they are assembled to build weekly, monthly, and seasonal representations of the Earth.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Amit Kapadia</dc:creator><pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-12:scipy-2017/global-5-meter-resolution-time-series-mosaics.html</guid></item><item><title>HDF5 take 2 - h5py &amp; PyTables</title><link>https://pyvideo.org/scipy-2017/hdf5-take-2-h5py-pytables.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;HDF5 is a hierarchical, binary database format that has become the de facto standard for scientific computing. While the specification may be used in a relatively simple way (persistence of static arrays) it also supports several high-level features that prove invaluable. These include chunking, ragged data, extensible data, parallel I/O, compression, complex selection, and in-core calculations. Moreover, HDF5 bindings exist for almost every language - including two Python libraries (PyTables and h5py). This tutorial will cover HDF5 itself through the lens of both h5py and PyTables and will show how to use them in order to persist NumPy and pandas containers.&lt;/p&gt;
&lt;p&gt;This tutorial will discuss tools, strategies, and hacks for really squeezing every ounce of performance out of HDF5 in new or existing projects. It will also go over fundamental limitations in the specification and provide creative and subtle strategies for getting around them. We will also see how pandas can use HDF5 via its HDFStore module. Overall, this tutorial will show how HDF5 plays nicely with all parts of an application making the code and data both faster and smaller.     Knowledge of Python, NumPy, pandas, C or C++, and basic HDF5 is recommended but not required.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tom Kooij</dc:creator><pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-12:scipy-2017/hdf5-take-2-h5py-pytables.html</guid><category>tutorial</category></item><item><title>Lightning Talks 2017-07-12</title><link>https://pyvideo.org/scipy-2017/lightning-talks-2017-07-12.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Lightning Talks 2017-07-12&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="12%" /&gt;
&lt;col width="23%" /&gt;
&lt;col width="65%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head" rowspan="2"&gt;Start&lt;/th&gt;
&lt;th class="head" rowspan="2"&gt;Speakers&lt;/th&gt;
&lt;th class="head" rowspan="2"&gt;Subject&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;1:30&lt;/td&gt;
&lt;td rowspan="4"&gt;Aaron Meurer&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Doctr&lt;/strong&gt;
- We built a better tool to push from TravisCI to
GitHub Pages&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;6:30&lt;/td&gt;
&lt;td rowspan="4"&gt;Daniel Chen&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;SciPy 2017 Notes&lt;/strong&gt;
- A github repo (scipy_2017_notes) of links and
tutorial information from this conference.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;7:15&lt;/td&gt;
&lt;td rowspan="4"&gt;Allen Downey&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Physical Modeling in Python&lt;/strong&gt;
- tinyurl,.com/modsimpy; writing a book and am looking
for simple models to teach students.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;8:45&lt;/td&gt;
&lt;td rowspan="4"&gt;Oliver Zeigermann&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;How do Convolutional Neural Networks &amp;quot;See&amp;quot;&lt;/strong&gt;
- Techniques to visualize feature detection in the
Insight neural network.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="5"&gt;14:30&lt;/td&gt;
&lt;td rowspan="5"&gt;Sebastian Raschka&lt;/td&gt;
&lt;td rowspan="5"&gt;&lt;strong&gt;Screenlamp&lt;/strong&gt;
- We made Hypothosis pipeline builder for experimental
biologists, with database filtering steps.  Based on
BioPandas&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;20:00&lt;/td&gt;
&lt;td rowspan="4"&gt;Theodore Lindsay
and Floris van
Breugel&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;FigureFirst&lt;/strong&gt;
- Make it easy to use MatPlotLib and Inkscape to build
beautiful scientific figures.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="3"&gt;26:00&lt;/td&gt;
&lt;td rowspan="3"&gt;Pamela Wu&lt;/td&gt;
&lt;td rowspan="3"&gt;&lt;strong&gt;SynthPy:  Real Answers for Fake Data&lt;/strong&gt;
-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;31:45&lt;/td&gt;
&lt;td rowspan="4"&gt;Nick Murphy&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;PlasmaPy&lt;/strong&gt;
- Beginning a community developed Python package for
plasma physics.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="5"&gt;34:00&lt;/td&gt;
&lt;td rowspan="5"&gt;Scott Collis&lt;/td&gt;
&lt;td rowspan="5"&gt;&lt;strong&gt;Py-ART&lt;/strong&gt;
- Python ARM Radar Toolkit, exposing world of radar
meteorology to SciPy stack.  Taking comments on our
roadmap.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;36:45&lt;/td&gt;
&lt;td rowspan="4"&gt;Bill Spotz&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Using Jupyter to make Citations&lt;/strong&gt;
- The journey of using Jupyter notebooks to add real
citations.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="5"&gt;42:15&lt;/td&gt;
&lt;td rowspan="5"&gt;Jose Felipe&lt;/td&gt;
&lt;td rowspan="5"&gt;&lt;strong&gt;Test support in Jupyter/Ipython through cell&lt;/strong&gt;
&lt;strong&gt;magics&lt;/strong&gt;
- Starting with iPython/Unittests, make unittesting in
cells&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td rowspan="4"&gt;47:45&lt;/td&gt;
&lt;td rowspan="4"&gt;Scott Cole&lt;/td&gt;
&lt;td rowspan="4"&gt;&lt;strong&gt;Burrito Data Analytics&lt;/strong&gt;
- Specialized Visualization and data collection
profiles in the quest for better burittos&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aaron Meurer</dc:creator><pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-12:scipy-2017/lightning-talks-2017-07-12.html</guid><category>lightning talks</category></item><item><title>Machine Learning with scikit learn Part One</title><link>https://pyvideo.org/scipy-2017/machine-learning-with-scikit-learn-part-one.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Machine learning is the task of extracting knowledge from data, often with the goal of generalizing to new and unseen data. Applications of machine learning  now touch nearly every aspect of everyday life, from the face detection in our phones and the streams of social media we consume to picking restaurants,
partners, and movies. Machine learning has also become indispensable to many empirical sciences, from physics, astronomy and biology to social sciences.&lt;/p&gt;
&lt;p&gt;Scikit-learn has emerged as one of the most popular toolkits for machine learning, and is now widely used in industry and academia. The goal of this tutorial is to enable participants to use the wide variety of machine learning algorithms available in scikit-learn on their own data sets, for their own domains.&lt;/p&gt;
&lt;p&gt;This tutorial will comprise an introductory morning session and an advanced afternoon session. The morning part of the tutorial will cover basic concepts of machine learning, data representation, and preprocessing. We will explain different problem settings and concepts such as supervised learning,  unsupervised learning, dimensionality reduction, anomaly detection or clustering, and illustrate them with applications showing with algorithms can be used in each situation. We will cover the different families of methods (nearest-neighbors, kernel machines, tree-based techniques, linear models, neural network) with demos of SVMs, Random Forests, K-Means, PCA, t-SNE,
multi-layer perceptions and others.&lt;/p&gt;
&lt;p&gt;In the afternoon session, we will discuss setting hyper-parameters and how to prevent overfitting. We will go in-depth into the trade-off of model complexity and dataset size, as well as discussing complexity of learning algorithms and how to cope with very large datasets using online methods that support out-of-core computations. The session will conclude by stepping
through the process of building machine learning pipelines consisting of feature extraction, preprocessing and supervised learning.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andreas Mueller</dc:creator><pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-12:scipy-2017/machine-learning-with-scikit-learn-part-one.html</guid></item><item><title>Machine Learning with scikit learn Part Two</title><link>https://pyvideo.org/scipy-2017/machine-learning-with-scikit-learn-part-two.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Machine learning is the task of extracting knowledge from data, often with the
goal of generalizing to new and unseen data. Applications of machine learning now touch nearly every aspect of everyday life, from the face detection in our phones and the streams of social media we consume to picking restaurants, partners, and movies. Machine learning has also become indispensable to many empirical sciences, from physics, astronomy and biology to social sciences.&lt;/p&gt;
&lt;p&gt;Scikit-learn has emerged as one of the most popular toolkits for machine learning, and is now widely used in industry and academia. The goal of this tutorial is to enable participants to use the wide variety of machine learning algorithms available in scikit-learn on their own data sets, for their own domains.&lt;/p&gt;
&lt;p&gt;This tutorial will comprise an introductory morning session and an advanced afternoon session. The morning part of the tutorial will cover basic concepts of machine learning, data representation, and preprocessing. We will explain different problem settings and concepts such as supervised learning, unsupervised learning, dimensionality reduction, anomaly detection or clustering, and illustrate them with applications showing with algorithms can be used in each situation. We will cover the different families of methods (nearest-neighbors, kernel machines, tree-based techniques, linear models, neural network) with demos of SVMs, Random Forests, K-Means, PCA, t-SNE, multi-layer perceptrons and others.&lt;/p&gt;
&lt;p&gt;In the afternoon session, we will discuss setting hyper-parameters and how to prevent overfitting. We will go in-depth into the trade-off of model complexity and dataset size, as well as discussing complexity of learning algorithms and how to cope with very large datasets using online methods that support
out-of-core computations. The session will conclude by stepping
through the process of building machine learning pipelines consisting of feature extraction, preprocessing and supervised learning.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andreas Mueller</dc:creator><pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-12:scipy-2017/machine-learning-with-scikit-learn-part-two.html</guid></item><item><title>pulse2percept - A Python based Simulation Framework for Bionic Vision</title><link>https://pyvideo.org/scipy-2017/pulse2percept-a-python-based-simulation-framework-for-bionic-vision.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;By 2020 roughly 200 million people worldwide will suffer from photoreceptor diseases such as retinitis pigmentosa and age-related macular degeneration, and a variety of retinal sight restoration technologies are being developed to target these diseases. Two brands of retinal prostheses are already being implanted in patients. Analogous to cochlear implants, these devices use a grid of electrodes to stimulate remaining retinal cells. However, clinical experience with these implants has made it apparent that the vision restored by these devices differs substantially from normal sight. To better understand the current state-of-the-art in prosthetic vision, we developed a computational model based on human behavioral data that can predict the perceptual experience of retinal prosthesis patients. The model is implemented as an open-source Python package (&lt;a class="reference external" href="https://github.com/uwescience/pulse2percept"&gt;https://github.com/uwescience/pulse2percept&lt;/a&gt;), which provides a modular and extensible user interface, making it straightforward for users to simulate novel implants, stimuli, and retinal models. We will give an overview of the software, review our solutions to various technical challenges, and discuss the broader impact of this work for the computational neuroscience community.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Michael Beyeler</dc:creator><pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-12:scipy-2017/pulse2percept-a-python-based-simulation-framework-for-bionic-vision.html</guid></item><item><title>Time Atmospheric Data During VORTEX SE</title><link>https://pyvideo.org/scipy-2017/time-atmospheric-data-during-vortex-se.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Verification of the Origins of Rotation in Tornadoes Experiment Southeast (VORTEX-SE) is a field collaboration between several different institutions to gain a comprehensive look at atmospheric conditions conducive for tornadic activity in the Southeastern United States. In 2016 and 2017, Texas Tech University Atmospheric Science researchers deployed semi-permanent StickNet weather stations to record fine-scale atmospheric data. Python tools were utilized and developed to visualize the weather conditions occurring at each individual station as well as provide a comprehensive look over the entire StickNet domain. Examples of how Python is used to create real-time meteograms and display NWS radar data from the NEXRAD Amazon Web Services archive will be presented.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Abby Kenyon</dc:creator><pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-12:scipy-2017/time-atmospheric-data-during-vortex-se.html</guid></item><item><title>Computational Statistics</title><link>https://pyvideo.org/scipy-2017/computational-statistics.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Description:&lt;/p&gt;
&lt;p&gt;Do you know the difference between standard deviation and standard error?  Do you know what statistical test to use for any occasion?  Do you really know what a p-value is?  How about a confidence interval?&lt;/p&gt;
&lt;p&gt;Most people don’t really understand these concepts, even after taking several statistics classes.  The problem is that these classes focus on mathematical methods that bury the concepts under a mountain of details.&lt;/p&gt;
&lt;p&gt;This tutorial uses Python to implement simple statistical experiments that develop deep understanding.  I will present examples using real-world data to answer relevant questions, and attendees will practice with hands-on exercises.&lt;/p&gt;
&lt;p&gt;The tutorial material is based on my book, &lt;em&gt;Think Stats&lt;/em&gt;, a class I teach at Olin College, and my blog, “Probably Overthinking It.”     Audience&lt;/p&gt;
&lt;p&gt;Attendees should have at least basic level Python.  No statistical background is required.  We will work with Jupyter notebooks that use Pandas, NumPy and SciPy, but no prior experience with these libraries is required.&lt;/p&gt;
&lt;p&gt;Attendees will learn about resampling and related tools that use random simulation to perform statistical inference, including estimation and hypothesis testing.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Allen Downey</dc:creator><pubDate>Tue, 11 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-11:scipy-2017/computational-statistics.html</guid></item><item><title>Numba - Tell Those C++ Bullies to Get Lost</title><link>https://pyvideo.org/scipy-2017/numba-tell-those-c-bullies-to-get-lost.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you spent hours fighting with SWIG? Are you mystified by complicated NumPy array operations that you wrote only 2 months ago? Come and learn how to accelerate your existing Python code by an order (or orders!) of magnitude using Numba. You'll learn about using just-in-time compilation, writing custom NumPy ufuncs (the easy way!), and more!&lt;/p&gt;
&lt;p&gt;The entire tutorial is presented as a series of Jupyter Notebooks.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Gil Forsyth</dc:creator><pubDate>Tue, 11 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-11:scipy-2017/numba-tell-those-c-bullies-to-get-lost.html</guid></item><item><title>Software Carpentry Scientific Python Course Part 1</title><link>https://pyvideo.org/scipy-2017/software-carpentry-scientific-python-course-part-1.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Software Carpentry (SWC) is a volunteer non-profit organization dedicated to teaching basic computing skills to researchers. SWC lessons cover such topics as Linux shell, Python, Git, SQL, and R. In this hands-on workshop you will be introduced to the main concepts of programming in Python.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Maxim Belkin</dc:creator><pubDate>Tue, 11 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-11:scipy-2017/software-carpentry-scientific-python-course-part-1.html</guid></item><item><title>Software Carpentry Scientific Python Course Part 2</title><link>https://pyvideo.org/scipy-2017/software-carpentry-scientific-python-course-part-2.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutorial materials found here: &lt;a class="reference external" href="https://scipy2017.scipy.org/ehome/220975/493423/"&gt;https://scipy2017.scipy.org/ehome/220975/493423/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Software Carpentry (SWC) is a volunteer non-profit organization dedicated to teaching basic computing skills to researchers. SWC lessons cover such topics as Linux shell, Python, Git, SQL, and R. In this hands-on workshop you will be introduced to the main concepts of programming in Python.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Maxim Belkin</dc:creator><pubDate>Tue, 11 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-11:scipy-2017/software-carpentry-scientific-python-course-part-2.html</guid></item><item><title>The Jupyter Interactive Widget Ecosystem</title><link>https://pyvideo.org/scipy-2017/the-jupyter-interactive-widget-ecosystem.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter widgets are powerful tools for building user interfaces with graphical controls such as sliders and text boxes inside a Jupyter notebook. Interactive widgets can also be rendered in Sphinx documentation, nbviewer, and static web pages. Jupyter widgets are more than a collection of controls, they also are a framework that makes it easy to build custom GUI controls. Examples of custom widget packages include libraries for interactive 2-D charting (bqplot), 3-D graphics (pythreejs, ipyvolume), mapping (ipyleaflet), and more.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Matt Craig</dc:creator><pubDate>Tue, 11 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-11:scipy-2017/the-jupyter-interactive-widget-ecosystem.html</guid><category>jupyter notebook</category><category>jupyter widgets</category></item></channel></rss>