<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Joseph Halpern</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_joseph-halpern.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-08-03T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Bounded Rationality in Las Vegas: Probabilistic Finite Automata Play Multi-Armed Bandits</title><link href="https://pyvideo.org/uai-2020/bounded-rationality-in-las-vegas-probabilistic-finite-automata-play-multi-armed-bandits.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Xinming Liu</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/bounded-rationality-in-las-vegas-probabilistic-finite-automata-play-multi-armed-bandits.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Bounded Rationality in Las Vegas: Probabilistic Finite Automata Play Multi-Armed Bandits&lt;/p&gt;
&lt;p&gt;Xinming Liu (Cornell University)*; Joseph Halpern (Cornell University)&lt;/p&gt;
&lt;p&gt;While traditional economics assumes that humans are fully rational agents who always maximize their expected utility, in practice, we constantly observe apparently irrational behavior. One explanation is that people have â€¦&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Bounded Rationality in Las Vegas: Probabilistic Finite Automata Play Multi-Armed Bandits&lt;/p&gt;
&lt;p&gt;Xinming Liu (Cornell University)*; Joseph Halpern (Cornell University)&lt;/p&gt;
&lt;p&gt;While traditional economics assumes that humans are fully rational agents who always maximize their expected utility, in practice, we constantly observe apparently irrational behavior. One explanation is that people have limited computational power, so that they are, quite rationally, making the best decisions they can, given their computational limitations.  To test this hypothesis, we consider the multi-armed bandit (MAB) problem. We examine a simple strategy for playing an MAB that can be implemented easily by a probabilistic finite automaton (PFA). Roughly speaking, the PFA sets certain expectations, and plays an arm as long as it meets them. If the PFA has sufficiently many states, it performs near-optimally. Its performance degrades gracefully as the number of states decreases. Moreover, the PFA acts in a &amp;quot;&amp;quot;human-like&amp;quot;&amp;quot; way, exhibiting a number of standard human biases, like an optimism bias and a negativity bias.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry></feed>