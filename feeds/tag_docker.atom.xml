<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_docker.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-10-08T00:00:00+00:00</updated><entry><title>Introduction To Docker / Python Microservices</title><link href="https://pyvideo.org/hsvpy-huntsvilles-python-meetup/introduction-to-docker-python-microservices.html" rel="alternate"></link><published>2019-10-08T00:00:00+00:00</published><updated>2019-10-08T00:00:00+00:00</updated><author><name>Kyle Galloway</name></author><id>tag:pyvideo.org,2019-10-08:hsvpy-huntsvilles-python-meetup/introduction-to-docker-python-microservices.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Two talks: 1) How Docker helped save a company time and money by automated environment setup / A look at Python Microservices using celery&lt;/p&gt;
</summary><category term="Docker"></category><category term="microservices"></category></entry><entry><title>Automate Your Integration Tests Using pytest-docker-compose</title><link href="https://pyvideo.org/kiwi-pycon-2019/automate-your-integration-tests-using-pytest-docker-compose.html" rel="alternate"></link><published>2019-08-24T00:00:00+00:00</published><updated>2019-08-24T00:00:00+00:00</updated><author><name>Phoenix Zerin</name></author><id>tag:pyvideo.org,2019-08-24:kiwi-pycon-2019/automate-your-integration-tests-using-pytest-docker-compose.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Sometimes unit tests aren't enough, and you need to actually deploy your solution to see how it behaves as a whole. Utilities like docker-compose make it easy to stand up an entire environment, but the actual testing part still has to be done manually... or does it? Learn how to automate your integration tests using pytest-docker-compose today!&lt;/p&gt;
</summary><category term="docker"></category><category term="docker-compose"></category><category term="pytest"></category><category term="testing"></category></entry><entry><title>Docker meets Python - A look on the Docker SDK for Python</title><link href="https://pyvideo.org/europython-2019/docker-meets-python-a-look-on-the-docker-sdk-for-python.html" rel="alternate"></link><published>2019-07-12T00:00:00+00:00</published><updated>2019-07-12T00:00:00+00:00</updated><author><name>Jan Wagner</name></author><id>tag:pyvideo.org,2019-07-12:europython-2019/docker-meets-python-a-look-on-the-docker-sdk-for-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;My talk aims to introduce and have a closer look on the Docker SDK for
Python.&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;I will cover:&lt;/div&gt;
&lt;div class="line"&gt;- How and where to get the SDK&lt;/div&gt;
&lt;div class="line"&gt;- How it works and how to use it in general&lt;/div&gt;
&lt;div class="line"&gt;- Possible use-cases like: Processing Container-Logs, Testing with
pytest on different Python Versions, Deploy via Python Script, etc..&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;For my talk, you should know what Docker is and how to use it.&lt;/div&gt;
&lt;div class="line"&gt;A basic idea of pytest and server administration is nice to have, but
not necessarily needed to follow my talk.&lt;/div&gt;
&lt;/div&gt;
</summary><category term="Deployment/Continuous Integration and Delivery"></category><category term="DevOps general"></category><category term="Docker"></category><category term="Testing"></category><category term="Virtualization"></category></entry><entry><title>How we run GraphQL APIs in production on our Kubernetes cluster</title><link href="https://pyvideo.org/europython-2019/how-we-run-graphql-apis-in-production-on-our-kubernetes-cluster.html" rel="alternate"></link><published>2019-07-12T00:00:00+00:00</published><updated>2019-07-12T00:00:00+00:00</updated><author><name>Alexys Jacob</name></author><id>tag:pyvideo.org,2019-07-12:europython-2019/how-we-run-graphql-apis-in-production-on-our-kubernetes-cluster.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk I would like to share the workflow and tools we use to
build, deploy and operate GraphQL APIs on our on-premise Kubernetes
cluster.&lt;/p&gt;
&lt;p&gt;I will share code and command examples explaining how we are operating
our applications since our recent transition from REST APIs on Web
servers to GraphQL APIs containers on Kubernetes.&lt;/p&gt;
&lt;p&gt;This talk will not be about the difference between REST and GraphQL but
focus on the workflow, tools and experience we gained in switching our
run time environments and API models.&lt;/p&gt;
&lt;p&gt;At Numberly, we have built and are operating our own on-premise
Kubernetes cluster so we will also be talking about its capabilities and
share some of the experience we gained in doing so.&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Proposed agenda:&lt;/div&gt;
&lt;div class="line"&gt;- Our previous workflow and its limitations&lt;/div&gt;
&lt;div class="line"&gt;- How we designed our Kubernetes cluster, its capabilities and the
choices we made&lt;/div&gt;
&lt;div class="line"&gt;- Developer workflow, environments management and deployment&lt;/div&gt;
&lt;div class="line"&gt;- Our GraphQL stack, featuring a sample application&lt;/div&gt;
&lt;div class="line"&gt;- What we're still working on to improve&lt;/div&gt;
&lt;/div&gt;
</summary><category term="APIs"></category><category term="Best Practice"></category><category term="Case Study"></category><category term="Docker"></category><category term="Infrastructure"></category></entry><entry><title>Optimizing Docker builds for Python applications</title><link href="https://pyvideo.org/europython-2019/optimizing-docker-builds-for-python-applications.html" rel="alternate"></link><published>2019-07-12T00:00:00+00:00</published><updated>2019-07-12T00:00:00+00:00</updated><author><name>Dmitry Figol</name></author><id>tag:pyvideo.org,2019-07-12:europython-2019/optimizing-docker-builds-for-python-applications.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Do you deploy Python applications in Docker? Then this session is for
you!&lt;/div&gt;
&lt;div class="line"&gt;We will start by reviewing a simple Dockerfile to package a Python
application and move to more complex examples which speed up the build
process and reduce the size of the resulting Docker image for both
development and production builds.&lt;/div&gt;
&lt;/div&gt;
</summary><category term="Deployment/Continuous Integration and Delivery"></category><category term="Docker"></category></entry><entry><title>Basta problemi con tensorflow usando Docker &amp; Nvidia Docker</title><link href="https://pyvideo.org/pycon-italia-2019/basta-problemi-con-tensorflow-usando-docker-nvidia-docker.html" rel="alternate"></link><published>2019-05-04T00:00:00+00:00</published><updated>2019-05-04T00:00:00+00:00</updated><author><name>Nicola Landro</name></author><id>tag:pyvideo.org,2019-05-04:pycon-italia-2019/basta-problemi-con-tensorflow-usando-docker-nvidia-docker.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Di sicuro vi sarà capitato che condividendo o effettuando un progetto
tensorflow questo non funzioni correttamente. Soprattutto non riesco a
far scalare la mia app perchè non ho abbastanza macchine con GPU e
eseguire lo scale su macchine con solo CPU è costoso per poi ottenere
scarsi benefici. La soluzione è utilizzare Docker e Nvidia Docker.
Vedremo perchè Docker è migliore di una macchina virtuale e come
cambiano le prestazioni rispetto ad andare direttamente sulla macchina.
Vedremo trucchi su come strutturare dei docker-compose file senza
duplicazione per poter sviluppare agilmente sia con GPU che senza, poter
effettuare un deploy con tranquillità e poter scalare facilmente anche
senza GPU. Slide Link: &amp;lt;&lt;a class="reference external" href="https://www.slideshare.net/NicolaLandro/basta"&gt;https://www.slideshare.net/NicolaLandro/basta&lt;/a&gt;-
problemicontensorflowusandodockernvidiadocker&amp;gt;&lt;/p&gt;
&lt;p&gt;Feedback form: &lt;a class="reference external" href="https://python.it/feedback-1528"&gt;https://python.it/feedback-1528&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Saturday 4 May&lt;/strong&gt; at 10:45 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="OSX"></category><category term="windows"></category><category term="devops"></category><category term="Machine Learning"></category><category term="GNU/Linux"></category><category term="cuda"></category><category term="tensorflow"></category><category term="docker"></category></entry><entry><title>Geospatial analysis with Python</title><link href="https://pyvideo.org/pycon-italia-2019/geospatial-analysis-with-python.html" rel="alternate"></link><published>2019-05-03T00:00:00+00:00</published><updated>2019-05-03T00:00:00+00:00</updated><author><name>Francesco Bruni</name></author><id>tag:pyvideo.org,2019-05-03:pycon-italia-2019/geospatial-analysis-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Due to its effectiveness and simplicity, Python is spreading as a choice
for handling geospatial data. From running algorithms capable of
extracting geo- referred insights or processing geo archives, Python
could represent a powerful tool to handle geo-related problems thanks to
an extensive set of libraries. The training will give an overview about
processing geospatial data with Python. An approximate agenda will
include:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Introduction&lt;ul&gt;
&lt;li&gt;setting up the the environment&lt;/li&gt;
&lt;li&gt;an introduction to geospatial world&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Working with geospatial data&lt;ul&gt;
&lt;li&gt;playing with geo archives (vector/rasters)&lt;/li&gt;
&lt;li&gt;extracting geo analytics&lt;/li&gt;
&lt;li&gt;Vector tiles big vector data&lt;/li&gt;
&lt;li&gt;Apache Spark for geospatial raster analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Python for Earth observation&lt;ul&gt;
&lt;li&gt;Classifying earth observation images&lt;/li&gt;
&lt;li&gt;Extracting insights from Copernicus products&lt;/li&gt;
&lt;li&gt;Use SNAP from Python&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;No tools are required for attending this training. Bring your PC with
Docker installed. Further instructions will be provided.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1674"&gt;https://python.it/feedback-1674&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 10:30 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt; in __on &lt;strong&gt;Saturday 4
May&lt;/strong&gt; at 18:00 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="Jupyter"></category><category term="pyspark"></category><category term="geospatial"></category><category term="geopynotebook"></category><category term="spark"></category><category term="docker"></category></entry><entry><title>PostgreSQL on the kube</title><link href="https://pyvideo.org/pycon-italia-2019/postgresql-on-the-kube.html" rel="alternate"></link><published>2019-05-03T00:00:00+00:00</published><updated>2019-05-03T00:00:00+00:00</updated><author><name>Marco Nenciarini</name></author><id>tag:pyvideo.org,2019-05-03:pycon-italia-2019/postgresql-on-the-kube.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Kubernetes è un sistema di orchestrazione di container che permette di
gestire il deploy, lo scaling e l’aggiornamento di una applicazione e di
tutti i suoi componenti.&lt;/p&gt;
&lt;p&gt;In questo talk parleremo di quali strumenti sono a disposizione per
effettuare un deploy di un database PostgreSQL in un cluster Kubernetes.
Inoltre vedremo come sia implementabile l’alta disponibilità e la
disaster recovery, in maniera da avere i propri dati al sicuro e sempre
accessibili.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1784"&gt;https://python.it/feedback-1784&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 10:30 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="postgresql"></category><category term="postgres"></category><category term="kubernetes"></category><category term="storage"></category><category term="containers"></category><category term="docker"></category><category term="k8s"></category><category term="cloud"></category></entry><entry><title>DevOps di applicazioni Python (e non solo) su OpenShift</title><link href="https://pyvideo.org/pycon-italia-2018/devops-di-applicazioni-python-e-non-solo-su-openshift.html" rel="alternate"></link><published>2018-04-20T00:00:00+00:00</published><updated>2018-04-20T00:00:00+00:00</updated><author><name>Francesco Fiore</name></author><id>tag:pyvideo.org,2018-04-20:pycon-italia-2018/devops-di-applicazioni-python-e-non-solo-su-openshift.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="section" id="abstract"&gt;
&lt;h4&gt;Abstract&lt;/h4&gt;
&lt;p&gt;OpenShift Origin è la Platform-as-a-Service opensource di riferimento.
Basata su Kubernetes e Docker, contiene features aggiuntive e
integrazioni con altri componenti che semplificano le pratiche di
DevOps.&lt;/p&gt;
&lt;p&gt;Dopo una breve introduzione ad Openshift ed alla sua architettura,
vedremo come:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;fare il setup di infrastrutture applicative microservice-based (es.
microservizi Python Flask/Django, single page application Angular,
ecc…)&lt;/li&gt;
&lt;li&gt;creare una piattaforma di Continuous Integration e Continuous
Delivery&lt;/li&gt;
&lt;li&gt;implementare e gestire la CI/CD di microservice-based application
sfruttando l’integrazione con Git e Jenkins&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="agenda"&gt;
&lt;h4&gt;Agenda&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;architettura di base di OpenShift&lt;/li&gt;
&lt;li&gt;come costruire un &lt;em&gt;project&lt;/em&gt; OpenShift: &lt;em&gt;builds&lt;/em&gt; e &lt;em&gt;deployments&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;automatizzare il setup mediante &lt;em&gt;template&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;utilizzare Git, Jenkins e Openshift per creare una semplice pipeline
di CI/CD&lt;/li&gt;
&lt;li&gt;strategie di deployment avanzate: &lt;em&gt;blue-green deployment&lt;/em&gt; , &lt;em&gt;A/B
deployment&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="prerequisiti"&gt;
&lt;h4&gt;Prerequisiti&lt;/h4&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;conoscenza base di Git e Jenkins&lt;/li&gt;
&lt;li&gt;conoscenza base dei concetti CI/CD e DevOps&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;in __on &lt;strong&gt;venerdì 20 aprile&lt;/strong&gt; at 11:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</summary><category term="microservices"></category><category term="continuous-integration"></category><category term="git"></category><category term="continuous-delivery"></category><category term="kubernetes"></category><category term="devops"></category><category term="jenkins"></category><category term="docker"></category><category term="OpenShift"></category></entry><entry><title>PaaS per tutti i gusti: CI/CD sotto controllo con Kubernetes e Dokku</title><link href="https://pyvideo.org/pycon-italia-2018/paas-per-tutti-i-gusti-cicd-sotto-controllo-con-kubernetes-e-dokku.html" rel="alternate"></link><published>2018-04-20T00:00:00+00:00</published><updated>2018-04-20T00:00:00+00:00</updated><author><name>Claudio Mignanti</name></author><id>tag:pyvideo.org,2018-04-20:pycon-italia-2018/paas-per-tutti-i-gusti-cicd-sotto-controllo-con-kubernetes-e-dokku.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In questo talk saranno illustrati processi e workflow tipici dei
paradigmi del DevOp e delle metodologie Agile. Vedremo quali
&lt;strong&gt;accorgimenti&lt;/strong&gt; devono essere presi con le applicazioni pacchettizzate
con &lt;strong&gt;Docker&lt;/strong&gt; , in particolare le applicazioni Django e come &lt;strong&gt;evitare
le problematiche principali che portano frustrazione e impediscono
un’adozione reale della CI/CD&lt;/strong&gt;. Saranno presentati degli esempi pratici
&lt;strong&gt;workflow&lt;/strong&gt; implementati con successo, in modo snello, versionato e
ripetibile, in ambienti che vanno dal test fino alla produzione. In
ultimo faremo una carrellata dei sistemi di &lt;strong&gt;PaaS&lt;/strong&gt; più in voga del
momento concentrandoci quindi su &lt;strong&gt;Dokku&lt;/strong&gt; e &lt;strong&gt;Kubernetes&lt;/strong&gt; , che
coprono tutto il ventaglio delle necessità di deploy, dal piccolo sito
fino al sistema ultra scalabile e ridondato.&lt;/p&gt;
&lt;p&gt;Prerequisito per il talk è conoscere i concetti base di Docker e
dell’uso di git. Durante il talk con 3 distinti esempi e demo di
complessità crescente esploreremo il mondo della CI/CD.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;venerdì 20 aprile&lt;/strong&gt; at 12:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="paas"></category><category term="continuous-integration"></category><category term="gitlab"></category><category term="kubernetes"></category><category term="testing"></category><category term="git"></category><category term="docker"></category></entry><entry><title>Scaling your Data infrastructure</title><link href="https://pyvideo.org/pycon-italia-2018/scaling-your-data-infrastructure.html" rel="alternate"></link><published>2018-04-20T00:00:00+00:00</published><updated>2018-04-20T00:00:00+00:00</updated><author><name>Christian Barra</name></author><id>tag:pyvideo.org,2018-04-20:pycon-italia-2018/scaling-your-data-infrastructure.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;This talk aims to answer a few questions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;What do you do when you need to move your model from your laptop to
production?&lt;/li&gt;
&lt;li&gt;Is &lt;tt class="docutils literal"&gt;big data == I need to use JVM&lt;/tt&gt; the right assumption?&lt;/li&gt;
&lt;li&gt;How can I put my jupyter notebook in production?&lt;/li&gt;
&lt;li&gt;How do you apply the best software engineering practices (testing and
ci for example) inside your data science process?&lt;/li&gt;
&lt;li&gt;How do you “decouple” your data scientists, developers and devops
teams?&lt;/li&gt;
&lt;li&gt;How do you guarantee the reproducibility of your models?&lt;/li&gt;
&lt;li&gt;How do you scale your training process when does not fit in memory
anymore?&lt;/li&gt;
&lt;li&gt;How do you serve your models and provide an easy rollback system?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Agenda:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The Data Science workflow&lt;/li&gt;
&lt;li&gt;Scaling is not just a matter of the size of your Data&lt;/li&gt;
&lt;li&gt;Scaling when the size of your Data matters&lt;/li&gt;
&lt;li&gt;DDS, Dockerized Data Science&lt;/li&gt;
&lt;li&gt;Cassiny&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ll share my experience highlighting some of the challenges I faced and
the solutions I came up to answer these questions.&lt;/p&gt;
&lt;p&gt;During this presentation I will mention libraries like jupyter, atom,
scikit- learn, dask, ray, parquet, arrow and many others.&lt;/p&gt;
&lt;p&gt;The principles and best practices I will share are something that you
can apply, more or less easily, if you are running or in the process to
run a production system based on the Python stack.&lt;/p&gt;
&lt;p&gt;This talk will focus on (my) best practices to run the Python Data stack
together and I will also talk about Cassiny, an open source project I
started, that aims to simplify your life if you want to use a completely
Python based solution in your data science workflow.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 20 April&lt;/strong&gt; at 11:00 &lt;a class="reference external" href="/en/sprints/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="Jupyter"></category><category term="CloudComputing"></category><category term="pydata"></category><category term="#lessonslearned"></category><category term="Big-Data"></category><category term="S3"></category><category term="Data-Scientist"></category><category term="#amicodialessia"></category><category term="java"></category><category term="docker"></category><category term="cloud"></category></entry><entry><title>Aplicações web com Flask e Docker</title><link href="https://pyvideo.org/flask-conf-2018/aplicacoes-web-com-flask-e-docker.html" rel="alternate"></link><published>2018-08-25T00:00:00+00:00</published><updated>2018-08-25T00:00:00+00:00</updated><author><name>Felipe Alcantara</name></author><id>tag:pyvideo.org,2018-08-25:flask-conf-2018/aplicacoes-web-com-flask-e-docker.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Aplicações web com Flask e Docker - Palestra de Felipe Alcantara na Flask Conf 2018.&lt;/p&gt;
</summary><category term="flask"></category><category term="docker"></category></entry><entry><title>Launch Jupyter to the Cloud with Docker and Terraform</title><link href="https://pyvideo.org/pycon-israel-2018/launch-jupyter-to-the-cloud-with-docker-and-terraform.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Cheuk Ting Ho</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/launch-jupyter-to-the-cloud-with-docker-and-terraform.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Launch Jupyter to the Cloud: an example of using Docker and Terraform&lt;/p&gt;
&lt;p&gt;In this talk, we will use a task: hiring a GPU on Google Cloud Platform to train neural network, as an example to show how an application can be deployed on a cloud platform with Docker and Terraform. The goal is to have Jupyter Notebook running in an environment with Tensorflow (GPU version) and other libraries installed on a Google Compute Engine.&lt;/p&gt;
&lt;p&gt;This talk is for people with no experience in application deployment on cloud service but would benefit form computational reproducibility and cloud service, potentially data scientists/ analysts or tech practitioners who didn't have a software developing background. We will use an example that is simple but useful in data science to demonstrate basic usage of Docker and Terraform which would be beneficial to beginners who would like to simplify their work flow with those tools.&lt;/p&gt;
</summary><category term="jupyter"></category><category term="docker"></category><category term="terraform"></category></entry><entry><title>Docker for Data Science</title><link href="https://pyvideo.org/pycon-us-2018/docker-for-data-science.html" rel="alternate"></link><published>2018-05-10T00:00:00+00:00</published><updated>2018-05-10T00:00:00+00:00</updated><author><name>Aly Sivji</name></author><id>tag:pyvideo.org,2018-05-10:pycon-us-2018/docker-for-data-science.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter notebooks simplify the process of developing and sharing Data Science projects across groups and organizations. However, when we want to deploy our work into production, we need to extract the model from the notebook and package it up with the required artifacts (data, dependencies, configurations, etc) to ensure it works in other environments. Containerization technologies such as Docker can be used to streamline this workflow.&lt;/p&gt;
&lt;p&gt;This hands-on tutorial presents Docker in the context of Reproducible Data Science - from idea to application deployment. You will get a thorough introduction to the world of containers; learn how to incorporate Docker into various Data Science projects; and walk through the process of building a Machine Learning model in Jupyter and deploying it as a containerized Flask REST API.&lt;/p&gt;
</summary><category term="jupyter"></category><category term="docker"></category><category term="data science"></category></entry><entry><title>Containerize all the things</title><link href="https://pyvideo.org/caipyra-2016/containerize-all-the-things.html" rel="alternate"></link><published>2016-06-25T00:00:00+00:00</published><updated>2016-06-25T00:00:00+00:00</updated><author><name>Andrews Medina</name></author><id>tag:pyvideo.org,2016-06-25:caipyra-2016/containerize-all-the-things.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Palestra do Andrews Medina no Caipyra 2016:&lt;/p&gt;
&lt;p&gt;Containerize all the things&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="http://talks.godoc.org/github.com/andrewsmedina/containerize-all-the-things/sample.slide#1"&gt;http://talks.godoc.org/github.com/andrewsmedina/containerize-all-the-things/sample.slide#1&lt;/a&gt;&lt;/p&gt;
</summary><category term="docker"></category><category term="devops"></category></entry><entry><title>Sparking Pandas: an experiment</title><link href="https://pyvideo.org/pycon-italia-2017/sparking-pandas-an-experiment.html" rel="alternate"></link><published>2017-04-07T00:00:00+00:00</published><updated>2017-04-07T00:00:00+00:00</updated><author><name>Francesco Bruni</name></author><id>tag:pyvideo.org,2017-04-07:pycon-italia-2017/sparking-pandas-an-experiment.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pandas is a good library to deal with tabular data. What if you need to
manage an amount of data that doesn’t fit into memory? What if you want
to “distribute” your computations among multiple machines?&lt;/p&gt;
&lt;p&gt;Starting from a real scenario, Apache Spark will be presented as the
main tool to read and process collected data. It will be shown how a
Pandas-like syntax will come in handy to run aggregations, filtering and
grouping using a Spark Dataframe.&lt;/p&gt;
&lt;p&gt;A previous knowledge of Docker and Docker Compose will be very useful
while knowing MongoDB (where data will be fetched from) is not
mandatory. Basics of functional programming will help to understand
Spark inner logic.&lt;/p&gt;
</summary><category term="microservices"></category><category term="Jupyter"></category><category term="mongodb"></category><category term="data-visualization"></category><category term="data-analysis"></category><category term="spark"></category><category term="docker"></category></entry><entry><title>Dockerizing the Python</title><link href="https://pyvideo.org/pycon-se-2017/dockerizing-the-python.html" rel="alternate"></link><published>2017-09-06T00:00:00+00:00</published><updated>2017-09-06T00:00:00+00:00</updated><author><name>Ambreen Sheikh</name></author><id>tag:pyvideo.org,2017-09-06:pycon-se-2017/dockerizing-the-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The focus of this talk will be on building and running python programs in a docker container. A major chunk of the talk will also concentrate on the docker setup &amp;amp; it’s complete echo system. The purpose behind the talk is the demonstrate the usage of docker in everyday python development &amp;amp; deployment environment.&lt;/p&gt;
</summary><category term="docker"></category></entry><entry><title>Extend Docker using Python</title><link href="https://pyvideo.org/pycon-israel-2017/extend-docker-using-python.html" rel="alternate"></link><published>2017-06-13T00:00:00+00:00</published><updated>2017-06-13T00:00:00+00:00</updated><author><name>Boaz Shuster</name></author><id>tag:pyvideo.org,2017-06-13:pycon-israel-2017/extend-docker-using-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Docker is the most popular platform to run Python applications within containers. Many companies are using this platform to either deploy micro-services or test the code changes before merging it to production. Docker has 3 extension points: Drivers, Plugins and user-facing API. I am going to focus on the latter (user-facing API) and by the end of the talk, you will learn Docker's REST API and know how to extend Docker capabilities using Python.&lt;/p&gt;
</summary><category term="docker"></category></entry><entry><title>Running jupyter notebook remotely in a docker swarm cluster</title><link href="https://pyvideo.org/pydata-barcelona-2017/running-jupyter-notebook-remotely-in-a-docker-swarm-cluster.html" rel="alternate"></link><published>2017-05-20T15:00:00+02:00</published><updated>2017-05-20T15:00:00+02:00</updated><author><name>Jordi Deu-Pons</name></author><id>tag:pyvideo.org,2017-05-20:pydata-barcelona-2017/running-jupyter-notebook-remotely-in-a-docker-swarm-cluster.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The current version of Jupyter Notebook computes the document state at the browser side, this is a problem if you run long jobs in a remote notebook from a laptop. If you close the browser you lose all the output of the current running cell. I will explain how we solved this problem in our lab. This solution it also allows a &amp;quot;walkie-talkie&amp;quot; like real-time collaboration.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The solution is based on running a docker container with a browser and a VNC server. All the remote access to the notebooks is done using Apache Guacamole a clientless remote desktop gateway. Everything is running on a dynamic docker swarm cluster of 20 nodes. As a lateral effect, this solution it also allows a real-time collaboration between users in a way that multiple users can access at the same time the same desktop (but they have to fight for the mouse and the keyboard).&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/jordeu/pytalks/tree/master/20170520_pydata_jupyter_in_a_docker_cluster"&gt;https://github.com/jordeu/pytalks/tree/master/20170520_pydata_jupyter_in_a_docker_cluster&lt;/a&gt;&lt;/p&gt;
</summary><category term="jupyter notebook"></category><category term="docker"></category><category term="swarm"></category></entry><entry><title>DIY Serverless Platform with Python3 and Docker</title><link href="https://pyvideo.org/pycon-jamaica-2016/diy-serverless-platform-with-python3-and-docker.html" rel="alternate"></link><published>2016-11-18T00:00:00+00:00</published><updated>2016-11-18T00:00:00+00:00</updated><author><name>Joir-dan Gumbs</name></author><id>tag:pyvideo.org,2016-11-18:pycon-jamaica-2016/diy-serverless-platform-with-python3-and-docker.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A walkthrough on how I built my own serverless platform to run both ephemeral and long-lasting functions in Python on top of Docker, capable of handling REST and websocket connections. Will go over architecture, show code, and discuss pain points as well as next steps.  #pyconjamaica2016&lt;/p&gt;
</summary><category term="Serverless"></category><category term="Docker"></category></entry><entry><title>Dev Ops meets Data Science Taking models from prototype to production with Docker</title><link href="https://pyvideo.org/pydata-dc-2016/dev-ops-meets-data-science-taking-models-from-prototype-to-production-with-docker.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Andy Terrel</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/dev-ops-meets-data-science-taking-models-from-prototype-to-production-with-docker.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;We present the evolution of a model to a production API that can scale to large e-commerce needs. On the journey we discuss metrics of success and how to use the Kubernetes cluster manager and associated tools for deploy. In addition to the use of these tools we highlight how to make use of the cluster management system for further testing and experimentation with your models.&lt;/p&gt;
&lt;p&gt;The chasm between data science and dev ops is often wide and impenetrable, but the two fields have more in common than meets the eye. Every data scientist will be able to lean in and help their career by investing in a basic understanding the basic principles of dev ops. In this talk I present the notions of service level indicators, objectives, and agreements. I cover the rigorous monitoring and testing of services. Finally we demonstrate how to build a basic data science workflow and push to production level APIs with Docker and Kubernetes.&lt;/p&gt;
&lt;p&gt;Kubernetes is an opinionated container cluster manager with an easy to use, robust interface. It can be use on very small and very large clusters. Docker is a container system that allows one to build code in an isolated environment. Paired with a container manager such as Kubernetes we are able to manage millions of instances as needed for a production deployment. These tools are two of many different options but are considered among the best open source solutions available.&lt;/p&gt;
</summary><category term="Data"></category><category term="data science"></category><category term="docker"></category><category term="models"></category><category term="science"></category></entry><entry><title>Setting up predictive analytics services with Palladium</title><link href="https://pyvideo.org/pydata-berlin-2016/setting-up-predictive-analytics-services-with-palladium.html" rel="alternate"></link><published>2016-06-07T00:00:00+00:00</published><updated>2016-06-07T00:00:00+00:00</updated><author><name>Andreas Lattner</name></author><id>tag:pyvideo.org,2016-06-07:pydata-berlin-2016/setting-up-predictive-analytics-services-with-palladium.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Description&lt;/p&gt;
&lt;p&gt;We will introduce Palladium, an open source framework for setting up predictive analytics services. It supports tasks like fitting, evaluating, storing, and distributing (predictive) models. Core ML processes are compatible with scikit-learn and a large number of scikit-learn’s features can be used. Besides the use of Palladium we will also show how to use it with Docker and Mesos / Marathon.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;In this talk, we will introduce Palladium, an open source framework for easily setting up predictive analytics services (&lt;a class="reference external" href="https://github.com/ottogroup/palladium"&gt;https://github.com/ottogroup/palladium&lt;/a&gt;). It supports tasks like fitting, evaluating, storing, distributing, and updating (predictive) models. Core machine learning processes are compatible with the open source machine learning library scikit-learn and thus, a large number of scikit-learn’s features can be used with Palladium. Although being implemented in Python, Palladium provides support for other languages and is shipped with examples how to integrate and expose R and Julia models. For an efficient deployment of services based on Palladium, a script to create Docker images automatically is provided. This talk will cover the use of Palladium including an example where a simple classification service is set up. We will also show how Docker and Mesos / Marathon can be used to deploy and scale Palladium-based services. Having basic knowledge about Machine Learning and/or scikit-learn would be an advantage when attending this talk.&lt;/p&gt;
</summary><category term="palladium"></category><category term="scikit-learn"></category><category term="docker"></category><category term="mesos"></category><category term="marathon"></category><category term="machine learning"></category></entry><entry><title>Building Python apps with Docker</title><link href="https://pyvideo.org/pytexas-2015/building-python-apps-with-docker.html" rel="alternate"></link><published>2015-10-09T00:00:00+00:00</published><updated>2015-10-09T00:00:00+00:00</updated><author><name>Mark Adams</name></author><id>tag:pyvideo.org,2015-10-09:pytexas-2015/building-python-apps-with-docker.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you haven't heard of Docker yet, its a great tool that allows you
wrap up your app and everything it needs to run: code, runtime, and even
system libraries and guarantee that it will always run the same,
regardless of the environment (local machine, server, or even the
cloud). Whether you're deploying a web app, performing data analysis, or
creating local environments for your dev team or CI builds, Docker can
help.&lt;/p&gt;
&lt;p&gt;I'll give an introduction to Docker, an overview of some of the current
tools in the Docker ecosystem (Docker Machine and Docker Compose) and
demonstrate how to create, build, and deploy Python applications using
Docker.&lt;/p&gt;
&lt;p&gt;This talk is targeted towards web developers, data scientists, or really
anyone who develops using Python that would like to learn more about
Docker and how it can help their projects.&lt;/p&gt;
</summary><category term="Docker"></category></entry></feed>