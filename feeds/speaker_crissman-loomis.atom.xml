<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Crissman Loomis</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_crissman-loomis.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-10-30T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Chainer</title><link href="https://pyvideo.org/scipy-japan-2019/chainer.html" rel="alternate"></link><published>2019-04-23T00:00:00+00:00</published><updated>2019-04-23T00:00:00+00:00</updated><author><name>Crissman Loomis</name></author><id>tag:pyvideo.org,2019-04-23:/scipy-japan-2019/chainer.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Chainer is a deep learning framework for flexible and intuitive coding of high performance experiments and applications. It is designed to maximize the trial-and-error speed with its Define-by-Run paradigm, which provides Pythonic programming of auto-differentiated neural networks. The framework can accelerate performance with multiple GPUs in distributed environments and …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Chainer is a deep learning framework for flexible and intuitive coding of high performance experiments and applications. It is designed to maximize the trial-and-error speed with its Define-by-Run paradigm, which provides Pythonic programming of auto-differentiated neural networks. The framework can accelerate performance with multiple GPUs in distributed environments and add-on packages enable quickly jumping into specific domains. In this talk, we introduce the abstract of Chainer’s API, its capabilities for accelerating the deep learning research and applications, and the future direction of the framework development.&lt;/p&gt;
&lt;div class="section" id="connect-with-us"&gt;
&lt;h4&gt;Connect with us!&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="https://twitter.com/enthought"&gt;https://twitter.com/enthought&lt;/a&gt;
&lt;a class="reference external" href="https://www.facebook.com/Enthought/"&gt;https://www.facebook.com/Enthought/&lt;/a&gt;
&lt;a class="reference external" href="https://www.linkedin.com/company/enthought"&gt;https://www.linkedin.com/company/enthought&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</content><category term="Scipy Japan 2019"></category></entry><entry><title>Hyperparameters - Autotuning to Make Performance Sing with Optuna</title><link href="https://pyvideo.org/scipy-japan-2020/hyperparameters-autotuning-to-make-performance-sing-with-optuna.html" rel="alternate"></link><published>2020-10-30T00:00:00+00:00</published><updated>2020-10-30T00:00:00+00:00</updated><author><name>Crissman Loomis</name></author><id>tag:pyvideo.org,2020-10-30:/scipy-japan-2020/hyperparameters-autotuning-to-make-performance-sing-with-optuna.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Hyperparameters are manual, often hard-coded, settings in programming. Some examples are selection of optimizers or learning rates in data science, database performance tuning, or video compression settings. These values and choices may seem incidental to the programming task, but can be extremely important for performance. Tuning them to find …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Hyperparameters are manual, often hard-coded, settings in programming. Some examples are selection of optimizers or learning rates in data science, database performance tuning, or video compression settings. These values and choices may seem incidental to the programming task, but can be extremely important for performance. Tuning them to find the right values can be difficult and time-consuming. This talk introduces Optuna, an open-source, eager interface, Python framework that automates the process of tuning hyperparameters using blackbox optimization, and highlights the new features and integration modules for other open-source projects available in v1.0.&lt;/p&gt;
&lt;p&gt;ハイパーパラメータとは、プログラミングにおける手動の設定のことで、多くの場合はハードコーディングされています。例としては、データサイエンスにおけるオプティマイザや学習率の選択、データベースのパフォーマンスチューニング、動画圧縮の設定などがあります。これらの値や選択は、プログラミングのタスクには付随的に見えるかもしれませんが、パフォーマンスにとっては非常に重要です。これらの値をチューニングして正しい値を見つけるのは難しく、時間のかかる作業です。この講演では、ブラックボックス最適化を使用してハイパーパラメータのチューニングプロセスを自動化する、オープンソースのイーガーインターフェース、PythonフレームワークであるOptunaを紹介し、v1.0で利用可能になった他のオープンソースプロジェクトの新機能と統合モジュールをハイライトします。&lt;/p&gt;
</content><category term="Scipy Japan 2020"></category></entry></feed>