<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_ali-king.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2016-11-05T00:00:00+00:00</updated><entry><title>Data Pipeline Evolution</title><link href="https://pyvideo.org/pycon-ireland-2016/data-pipeline-evolution.html" rel="alternate"></link><published>2016-11-05T00:00:00+00:00</published><updated>2016-11-05T00:00:00+00:00</updated><author><name>Ali King</name></author><id>tag:pyvideo.org,2016-11-05:pycon-ireland-2016/data-pipeline-evolution.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;How do you build a big data pipeline when the size of your data starts
to get out of hand? How do you improve on the initial model when
people are demanding more data, and faster?&lt;/p&gt;
&lt;p&gt;This talk covers the evolution of a data pipeline in Python, from
daily full load to up-to-the-minute event stream, based on our
experience at FanDuel. Technologies covered include Amazon EMR,
Redshift, Hadoop, Luigi, Spark and Kinesis. We also look at the
challenges and trade-offs, and building a big data engineering team.&lt;/p&gt;
</summary></entry></feed>