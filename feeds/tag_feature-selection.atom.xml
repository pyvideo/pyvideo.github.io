<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_feature-selection.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2015-06-28T00:00:00+00:00</updated><entry><title>Selecting the best model in scikit-learn using cross-validation</title><link href="https://pyvideo.org/data-school/scikit-learn-07-model-evaluation-with-cross-validation.html" rel="alternate"></link><published>2015-06-28T00:00:00+00:00</published><updated>2015-06-28T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2015-06-28:data-school/scikit-learn-07-model-evaluation-with-cross-validation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, we'll learn about K-fold cross-validation and how it can be used for selecting optimal tuning parameters, choosing between models, and selecting features. We'll compare cross-validation with the train/test split procedure, and we'll also discuss some variations of cross-validation that can result in more accurate estimates of model performance.&lt;/p&gt;
&lt;p&gt;This is the seventh video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="machine learning"></category><category term="data science"></category><category term="scikit-learn"></category><category term="tutorial"></category><category term="Data School"></category><category term="cross-validation"></category><category term="model evaluation"></category><category term="feature selection"></category><category term="parameter tuning"></category></entry><entry><title>Data science in Python: pandas, seaborn, scikit-learn</title><link href="https://pyvideo.org/data-school/scikit-learn-06-data-science-pipeline.html" rel="alternate"></link><published>2015-05-28T00:00:00+00:00</published><updated>2015-05-28T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2015-05-28:data-school/scikit-learn-06-data-science-pipeline.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this video, we'll cover the data science pipeline from data ingestion (with pandas) to data visualization (with seaborn) to machine learning (with scikit-learn). We'll learn how to train and interpret a linear regression model, and then compare three possible evaluation metrics for regression problems. Finally, we'll apply the train/test split procedure to decide which features to include in our model.&lt;/p&gt;
&lt;p&gt;This is the sixth video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="machine learning"></category><category term="data science"></category><category term="scikit-learn"></category><category term="tutorial"></category><category term="Data School"></category><category term="pandas"></category><category term="seaborn"></category><category term="linear regression"></category><category term="model evaluation"></category><category term="feature selection"></category><category term="visualization"></category></entry></feed>