<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_julian-eisenschlos.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-09-27T00:00:00+00:00</updated><entry><title>Know what you don't know, Tools to understand uncertainty in DL and use it in your favor</title><link href="https://pyvideo.org/pydata-cordoba-2019/know-what-you-dont-know-tools-to-understand-uncertainty-in-dl-and-use-it-in-your-favor.html" rel="alternate"></link><published>2019-09-27T00:00:00+00:00</published><updated>2019-09-27T00:00:00+00:00</updated><author><name>Julian Eisenschlos</name></author><id>tag:pyvideo.org,2019-09-27:pydata-cordoba-2019/know-what-you-dont-know-tools-to-understand-uncertainty-in-dl-and-use-it-in-your-favor.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As ML finds its way into critical applications like healthcare and autonomous vehicles, important concerns arise. When should it defer to a human to evaluate? How much risk is reasonable? Through the lens of Bayesian Neural Networks, we will show how to measure model uncertainty in Deep Learning models in practical settings, with immediate applications to active sampling and reinforcement learning&lt;/p&gt;
</summary><category term="machine learning"></category><category term="deep learning"></category><category term="neural networks"></category><category term="bayesian neural networks"></category></entry></feed>