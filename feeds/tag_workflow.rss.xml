<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Wed, 25 Oct 2017 00:00:00 +0000</lastBuildDate><item><title>Flow is in the Air: Best Practices of Building Analytical Data Pipelines with Apache Airflow</title><link>https://pyvideo.org/pycon-de-2017/flow-is-in-the-air-best-practices-of-building-analytical-data-pipelines-with-apache-airflow.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Dominik Benz&lt;/strong&gt; (&amp;#64;john_maverick)&lt;/p&gt;
&lt;p&gt;Dominik Benz holds a PhD from the University of Kassel in the field of Data Mining on the Social Web. Since 2012 he is working as a Big Data Engineer at Inovex GmbH. In this time, he was involved in several projects concerned with establishing analytical data platforms in various companies. He is most experienced in tools around the Hadoop Ecosystem like Apache Hive and Spark, and has hands-on experience with productionizing analytical applications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Apache Airflow is an Open-Source python project which facilitates an intuitive programmatic definition of analytical data pipelines. Based on 2+ years of productive experience, we summarize its core concepts, detail on lessons learned and set it in context with the Big Data Analytics Ecosystem.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Motivation &amp;amp; Outline&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Creating, orchestrating and running multiple data processing or analysis steps may cover a substantial portion of a Data Engineer and Data Scientist business. A widely adopted notion for this process is a &amp;quot;data pipeline&amp;quot; - which consists mainly of a set of &amp;quot;operators&amp;quot; which perform a particular action on data, with the possibility to specify dependencies among those. Real-Life examples may include:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Importing several files with different formats into a Hadoop platform, perform data cleansing, and training a machine learning model on the result&lt;/li&gt;
&lt;li&gt;perform feature extraction on a given dataset, apply an existing deep learning model to it, and write the results in the backend of a microservice&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Apache Airflow is an open-source Python project developed by AirBnB which facilitates the programmatic definition of such pipelines. Features which differentiate Airflow from similar projects like Apache Oozie, Luigi or Azkaban include (i) its pluggable architecture with several extension points (ii) the programmatic approach of &amp;quot;workflow is code&amp;quot; and (iii) its tight relationship with the the Python as well as the Big Data Analytics Ecosystem. Based on several years of productive usage, we briefly summarize the core concepts of Airflow, and detail in-depth on lessons learned and best practices from our experience. These include hints for getting efficient quickly with Airflow, approaches to structure workflows, integrating it in an enterprise landscape, writing plugins and extentions, and maintaining it in productive environment. We conclude with a comparison with other analytical workflow engines and summarize why we have chosen Airflow.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Questions answered by this talk&lt;/em&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;What are the core concepts of Apache Airflow?&lt;/li&gt;
&lt;li&gt;How can Airflow help me with moving data pipelines from analytics to production?&lt;/li&gt;
&lt;li&gt;Which concepts of Airflow make it more slim and more efficient compared to Apache Oozie?&lt;/li&gt;
&lt;li&gt;How can I specify dynamic dependencies at runtime between my analytical data processing steps?&lt;/li&gt;
&lt;li&gt;Which facilities does Airflow offer to enable automation and orchestration of analytical tasks?&lt;/li&gt;
&lt;li&gt;How can I extend the built-in facilities of Airflow by writing Python plugins?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;People who benefit most from this talk&lt;/em&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Data Scientists who are looking for a slim library to automate and control their data processing steps&lt;/li&gt;
&lt;li&gt;Data Engineers who want to save time debugging static workflow definitions (e.g. in XML)&lt;/li&gt;
&lt;li&gt;Project leaders interested in tools which lower the burden of moving from analytics to production&lt;/li&gt;
&lt;li&gt;Hadoop Cluster administrators eager to save cluster resources&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dominik Benz</dc:creator><pubDate>Wed, 25 Oct 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-10-25:pycon-de-2017/flow-is-in-the-air-best-practices-of-building-analytical-data-pipelines-with-apache-airflow.html</guid><category>workflow</category><category>data pipeline</category><category>data-science</category><category>analytics</category></item><item><title>Reproducible, One Button Workflows with the Jupyter Notebook &amp; Scons</title><link>https://pyvideo.org/scipy-2016/reproducible-one-button-workflows-with-the-jupyter-notebook-scons-scipy-2016-jessica-hamrick.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;What is the best way to develop analysis code in the Jupyter notebook, while managing complex dependencies between analyses? In this talk, I will introduce nbflow, which is a project that integrates a Python-based build system (SCons) with the Jupyter notebook, enabling researchers to easily build sophisticated,
complex analysis pipelines entirely within notebooks while still maintaining a &amp;quot;one-button workflow&amp;quot; in which all analyses can be executed, in the correct order, from a single command. I will show how nbflow can be applied to existing analyses and how it can be used to construct an analysis pipeline stretching the entire way from data cleaning, to computing statistics, to generating figures,
and even to automatically generating LaTeX commands that can be used in publications to format results without the risk of copy-and-paste error.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jessica Hamrick</dc:creator><pubDate>Thu, 14 Jul 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-07-14:scipy-2016/reproducible-one-button-workflows-with-the-jupyter-notebook-scons-scipy-2016-jessica-hamrick.html</guid><category>SciPy 2016</category><category>jupyter</category><category>jupyter notebook</category><category>workflow</category><category>nbflow</category></item><item><title>The development process of Python</title><link>https://pyvideo.org/europython-2011/the-development-process-of-python.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Ezio Melotti - 24 June 2011 in &amp;quot;Track Ravioli &amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python is an open source language, where everyone can contribute, and
thanks to Mercurial now it's even easier. With this talk I want to
unveil what happens &amp;quot;behind the scenes&amp;quot; of CPython and how you can get
involved and be part of the open source community that allows Python to
be one of the most popular programming languages.&lt;/p&gt;
&lt;p&gt;I will explain:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;what is the workflow of the CPython development;&lt;/li&gt;
&lt;li&gt;how to get a clone of Python;&lt;/li&gt;
&lt;li&gt;how to use Mercurial to do all the most common operations;&lt;/li&gt;
&lt;li&gt;what is the structure of the main CPython repository;&lt;/li&gt;
&lt;li&gt;what other are repositories are used;&lt;/li&gt;
&lt;li&gt;how to use the bug tracker to report and find bugs;&lt;/li&gt;
&lt;li&gt;how to use remote Mercurial repos to contribute code;&lt;/li&gt;
&lt;li&gt;what tools are used;&lt;/li&gt;
&lt;li&gt;how to get in touch with the core developers;&lt;/li&gt;
&lt;li&gt;what are the plans for the future.&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ezio Melotti</dc:creator><pubDate>Wed, 13 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-13:europython-2011/the-development-process-of-python.html</guid><category>community</category><category>contribute</category><category>cpython</category><category>mercurial</category><category>workflow</category></item><item><title>Continuous deployment</title><link>https://pyvideo.org/pycon-us-2011/pycon-2011--continuous-deployment.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Continuous deployment&lt;/p&gt;
&lt;p&gt;Presented by Laurens Van Houtven&lt;/p&gt;
&lt;p&gt;This talk is about continuous deployment practices and tools, lessons
learned from implementing it, and putting them into perspective. The
goal is to give other people tips and pointers for applying these ideas
themselves.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;Continuous deployment is the practice of putting the latest revision of
software into production use all the time, as opposed to working towards
larger releases. The important difference is iteration time: whereas
large software packages produce new software in timeframes of years or
months, continuous deployment teams typically put new code into
production in timeframes of hours or less.&lt;/p&gt;
&lt;p&gt;The practice is slowly attracting a small but growing group of loyal
followers, just like continuous integration over the past few years and
test- driven development did before that. They can be explained in terms
of being natural extensions of each other. Like TDD and CI, CD gets eyed
somewhat suspiciously (and rightfully so: skeptical analysis is great),
but the undersigned believes there's a legitimate advantage for many
applications.&lt;/p&gt;
&lt;p&gt;Many years ago, TTD and testing tools in general were mostly ad-hockery.
Now, with many different production-quality testing tools, this has
become unthinkable. Similarly, continuous integration was something
other people did for a long time, but now we have tools such as Buildbot
and Hudson. Continuous deployment is still somewhat in the early stage
in terms of ready-to-use tools, but it's likely that we'll see a similar
evolution.&lt;/p&gt;
&lt;p&gt;Here's a rough outline of what I plan to cover:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;a short history of people developed software&lt;/li&gt;
&lt;li&gt;from the recent models to CD (sort of a working definition of CD
here)&lt;/li&gt;
&lt;li&gt;when is it a good idea? pros/cons&lt;/li&gt;
&lt;li&gt;requirements &amp;amp; battle plan for applying CD in an existing development
environment (and possibly code base)&lt;/li&gt;
&lt;li&gt;an overview of existing tools and how they work together&lt;/li&gt;
&lt;li&gt;caveat emptors, known pitfalls (deployment and recovery strategies go
here, since most implementations figure out they need them after
stuff blows up)&lt;/li&gt;
&lt;li&gt;questions! (hopefully lots of people who've tried or are thinking
about implementing something similar -- like I said, there are a lot
of people implementing it but not too many ideas being bounced
around)&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Laurens Van Houtven</dc:creator><pubDate>Fri, 11 Mar 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-03-11:pycon-us-2011/pycon-2011--continuous-deployment.html</guid><category>cd</category><category>ci</category><category>continuousdeployment</category><category>deployment</category><category>pycon</category><category>pycon2011</category><category>softwaredevelopment</category><category>tdd</category><category>workflow</category></item></channel></rss>