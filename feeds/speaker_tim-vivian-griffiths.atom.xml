<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_tim-vivian-griffiths.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2016-09-18T00:00:00+00:00</updated><entry><title>Assessing performance of Support Vector Machine kernels</title><link href="https://pyvideo.org/pycon-uk-2016/assessing-performance-of-support-vector-machine-kernels.html" rel="alternate"></link><published>2016-09-18T00:00:00+00:00</published><updated>2016-09-18T00:00:00+00:00</updated><author><name>Tim Vivian-Griffiths</name></author><id>tag:pyvideo.org,2016-09-18:pycon-uk-2016/assessing-performance-of-support-vector-machine-kernels.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tim Vivian-Griffiths&lt;/p&gt;
&lt;p&gt;Machine learning methods can present new possibilities for research topics looking at identifying genetic aetiologies of disease. However in complex disorders, such as those seen in psychiatric conditions, this can be especially hard given the loosely defined phenotype classifications of the diseases.&lt;/p&gt;
&lt;p&gt;In this study, I examine how well the different kernel methods for Support Vector Machines do when trying to perform a binary classification on phenotypes that have been simulated from genotyped genetic data in schizophrenia cases and controls. These simulated phenotypes were made from different aspects of the data, either the main-effects or pairwise interactions between different mutations. The advantage of using simulated phenotypes over real case/control status is that now, the aetiology of the binary outcomes is known. The results show that when interactions between 20% of the inputs features are included, any small contribution of these are detectable when using a Radial Basis Function (RBF) kernel in a Support Vector Machine when compared with the performance of a linear kernel.&lt;/p&gt;
&lt;p&gt;These results show that the different performances of the RBF and linear kernels can be used to detect the presence of pairwise interactions between features, even when the effect sizes of these are only marginally larger in size than the main-effects.&lt;/p&gt;
</summary></entry><entry><title>Using Support Vector Machines in Scikit Learn to discover genetic aetiologies</title><link href="https://pyvideo.org/pydata-london-2016/tim-vivian-griffiths-using-support-vector-machines-in-scikit-learn-to-discover-genetic-aetiologies.html" rel="alternate"></link><published>2016-05-11T00:00:00+00:00</published><updated>2016-05-11T00:00:00+00:00</updated><author><name>Tim Vivian Griffiths</name></author><id>tag:pyvideo.org,2016-05-11:pydata-london-2016/tim-vivian-griffiths-using-support-vector-machines-in-scikit-learn-to-discover-genetic-aetiologies.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData London 2016&lt;/p&gt;
&lt;p&gt;This study uses machine learning methods in scikit-learn to find insights into the genetic aetiology of schizophrenia. It expands on the method of using a single genetic risk score per sample, by creating features from sub-sets of the genome - from single DNA mutations to functional gene-networks. The results have identified potential risk networks and evidence for interactions between mutations.&lt;/p&gt;
&lt;p&gt;Using Support Vector Machines to gain insights into the genetic aetiology of Schizophrenia&lt;/p&gt;
&lt;p&gt;Background&lt;/p&gt;
&lt;p&gt;Schizophrenia is a debilitating psychiatric disorder which affects approximately 1% of the general population. Results from twin studies suggest that genetic factors account for 80% of the variation of the disorder. However, to date, these have not been fully identified. Traditional methods involve performing a Genome Wide Association Study (GWAS), to find estimates of association that different mutations in DNA have with the disease.&lt;/p&gt;
&lt;p&gt;Schizophrenia is a highly polygenic disorder, meaning that it arises from a combination of genetic mutations, all contributing a small level of effect. These studies require very large sample sizes to have the statistical power to identify mutations of interest.&lt;/p&gt;
&lt;p&gt;The common approach is to combine this information into a single polygenic risk score for an individual, which can then be assessed for its predictive power to identify cases of the disease using a single feature Logistic Regression model.&lt;/p&gt;
&lt;p&gt;The machine learning approach&lt;/p&gt;
&lt;p&gt;Instead of creating this single score, different features from the individual association scores were created for use as inputs to machine learning algorithms. These features were either the information from the individual mutations themselves, or collections of mutations in genes which are known to be involved in various functional networks.&lt;/p&gt;
&lt;p&gt;The algorithm chosen was the Support Vector Machine (SVM). This was for a number of reasons:&lt;/p&gt;
&lt;p&gt;They can cope with a large number of input features, and can apply penalty procedures such as L1 regression to identify important features.
Kernel methods can be used to find evidence for interactions between the features - something that is lacking in the traditional methods.
Python libraries used&lt;/p&gt;
&lt;p&gt;This work was made possible by the use of two seminal libraries for Python: Pandas and scikit-learn. In addition the Joblib modules were used to carry out some simple parallel processing tasks on an HPC cluster if the desired information was not already provided by the modules in scikit-learn which already have these built in.&lt;/p&gt;
&lt;p&gt;Pandas made collecting information from sub-sets of the data very quick and efficient to carry out. Examples of this functionality will be given in the talk.&lt;/p&gt;
&lt;p&gt;Results so far&lt;/p&gt;
&lt;p&gt;While not improving on predictive power, the models did provide a rich insight into the association that different gene-networks have with the disorder, and identified genes which are targets of the Fragile X Mental Retardation Protein (FMRP) supporting findings from recent research in molecular biology. The information showing this were the coefficients assigned to the features seen in the boxplot provided. This was created by building multiple models, each with different train/test splits of the data to get the distributions of the coefficients. As can be seen, those assigned to the FMRP feature are consistently higher.&lt;/p&gt;
&lt;p&gt;The findings also show evidence for pair wise interactions between single point mutations. A series of procedures were carried out to simulate positive cases based on differing levels of contributions from main effects and interactions. This showed that without the contribution of the interactions, the results seen in the real world dataset by the kernel based models would not have been possible. Full details of how this was carried out will be discussed.&lt;/p&gt;
&lt;p&gt;Slides available here: &lt;a class="reference external" href="https://github.com/timvg80/PyDataLondon2016/blob/master/pydata.md"&gt;https://github.com/timvg80/PyDataLondon2016/blob/master/pydata.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GitHub Repo: &lt;a class="reference external" href="https://github.com/timvg80/PyDataLondon2016"&gt;https://github.com/timvg80/PyDataLondon2016&lt;/a&gt;&lt;/p&gt;
</summary></entry></feed>