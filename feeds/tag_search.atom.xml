<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_search.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-04-20T00:00:00+00:00</updated><entry><title>Beyond Search</title><link href="https://pyvideo.org/europython-2013/beyond-search.html" rel="alternate"></link><published>2013-07-05T00:00:00+00:00</published><updated>2013-07-05T00:00:00+00:00</updated><author><name>Honza Král</name></author><id>tag:pyvideo.org,2013-07-05:europython-2013/beyond-search.html</id><summary type="html"></summary><category term="search"></category><category term="elasticsearch"></category><category term="data-analysis"></category></entry><entry><title>ElasticSearch: Introduction and lessons learned</title><link href="https://pyvideo.org/europython-2013/elasticsearch-introduction-and-lessons-learned.html" rel="alternate"></link><published>2013-07-02T00:00:00+00:00</published><updated>2013-07-02T00:00:00+00:00</updated><author><name>Dougal Matthews</name></author><id>tag:pyvideo.org,2013-07-02:europython-2013/elasticsearch-introduction-and-lessons-learned.html</id><summary type="html"></summary><category term="Full Text Search"></category><category term="search"></category><category term="elasticsearch"></category><category term="database"></category></entry><entry><title>DjangoProject.com - Ricerca Full-Text con PostgreSQL</title><link href="https://pyvideo.org/pycon-italia-2018/djangoprojectcom-ricerca-full-text-con-postgresql.html" rel="alternate"></link><published>2018-04-20T00:00:00+00:00</published><updated>2018-04-20T00:00:00+00:00</updated><author><name>Paolo Melchiorre</name></author><id>tag:pyvideo.org,2018-04-20:pycon-italia-2018/djangoprojectcom-ricerca-full-text-con-postgresql.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Il sito web ufficiale del progetto &lt;strong&gt;Django&lt;/strong&gt; (
&lt;a class="reference external" href="http://www.djangoproject.com"&gt;www.djangoproject.com&lt;/a&gt; ) è basato
sull’ultima versione stabile di Django, la &lt;strong&gt;documentazione&lt;/strong&gt; del
progetto è generata con &lt;strong&gt;Sphinx&lt;/strong&gt; ed i documenti generati sono poi
memorizzati su &lt;strong&gt;PostgreSQL&lt;/strong&gt; per essere visualizzati sul sito.&lt;/p&gt;
&lt;p&gt;Il modulo per la &lt;strong&gt;ricerca&lt;/strong&gt; della documentazione nel sito del progetto
Django è molto utilizzato e fino a poco tempo fa era &lt;strong&gt;basato&lt;/strong&gt; su
&lt;strong&gt;Elasticsearch&lt;/strong&gt;. L’utilizzo di Elasticsearch ha causato &lt;strong&gt;problemi&lt;/strong&gt;
nella sincronizzazione dei dati e nell’aggiornamento dei driver di
connessione.&lt;/p&gt;
&lt;blockquote&gt;
In questo talk vedremo &lt;strong&gt;come&lt;/strong&gt; ho &lt;strong&gt;aggiornato&lt;/strong&gt; la funzione di
&lt;a class="reference external" href="https://docs.djangoproject.com/en/dev/search/?q=full+text+search"&gt;ricerca&lt;/a&gt;
del &lt;strong&gt;sito del progetto Django&lt;/strong&gt; utilizzando il modulo di &lt;strong&gt;Ricerca
Full- Text&lt;/strong&gt; di Django basato direttamente su &lt;strong&gt;PostgreSQL&lt;/strong&gt;. Questo
ha &lt;strong&gt;semplificato&lt;/strong&gt; molto l’infrastruttura e &lt;strong&gt;velocizzato&lt;/strong&gt; l’
&lt;strong&gt;aggiornamento&lt;/strong&gt; della documentazione, senza perdere nessuna delle
precedenti &lt;strong&gt;funzioni&lt;/strong&gt; di ricerca ma anzi migliorandole ed
aggiungendone altre da tempo richieste dagli &lt;strong&gt;utenti&lt;/strong&gt;.&lt;/blockquote&gt;
&lt;p&gt;Tramite questo talk potrai &lt;strong&gt;imparare&lt;/strong&gt; come &lt;strong&gt;aggiungere&lt;/strong&gt; una nuova
funzione di &lt;strong&gt;Ricerca Full-Text&lt;/strong&gt; nel &lt;strong&gt;tuo progetto&lt;/strong&gt; basato su Django
e PostgreSQL. In alternativa potreai imparare come &lt;strong&gt;aggiornare&lt;/strong&gt; la
ricerca esistente nel tuo sito se usi Elasticsearch o &lt;strong&gt;motori di
ricerca&lt;/strong&gt; simili .&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;&lt;em&gt;Per una **introduzione*&lt;/em&gt; ai temi del talk puoi leggere il mio articolo
sulla &lt;a class="reference external" href="http://www.paulox.net/2017/12/22/full-text-search-in-django-with-%20postgresql/"&gt;&amp;quot;Ricerca Full-Text in Django con
PostgreSQL&amp;quot;&lt;/a&gt;
basato sul mio talk presentato al &lt;a class="reference external" href="https://www.pycon.it/conference/talks/ricerca-full-text-in-django-con-%20postgresql"&gt;PyCon
Otto&lt;/a&gt;
nel 2017.*&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 20 April&lt;/strong&gt; at 16:45 &lt;a class="reference external" href="/en/sprints/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="web"></category><category term="search"></category><category term="postgresql"></category><category term="postgres"></category><category term="database"></category><category term="Python"></category><category term="documentation"></category><category term="django"></category><category term="elasticsearch"></category><category term="sphinx"></category><category term="Full Text Search"></category><category term="python3"></category></entry><entry><title>From Java to Python: Migrating Search Functionality at billiger.de</title><link href="https://pyvideo.org/pycon-de-2017/from-java-to-python-migrating-search-functionality-at-billigerde.html" rel="alternate"></link><published>2017-10-25T00:00:00+00:00</published><updated>2017-10-25T00:00:00+00:00</updated><author><name>Patrick Schemitz</name></author><id>tag:pyvideo.org,2017-10-25:pycon-de-2017/from-java-to-python-migrating-search-functionality-at-billigerde.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Patrick Schemitz&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Patrick is a Senior Scientist at solute GmbH. An avid Pythonista since 2003, his main responsibility is the billiger.de search functionality, which he (co-) wrote using first Lucene, later Solr and now SolrCloud. Besides that, he wrote the SVM-based offer categorization at billiger.de and has a keen interest in machine learning. Patrick holds a Ph.D. in particle physics from Karlsruhe university.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;billiger.de is a German price comparison site. Search is handled by a heavily customized Solr setup. When switching to SolrCloud earlier this year, instead of porting our custom SolrComponents to SolrCloud, we ended up re-implementing them in a Python service layer. Here we show how, and why.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The search on our price comparison site billiger.de is implemented using Solr and half a dozen custom SolrComponents. When switching from Solr to SolrCloud earlier this year, we had to go over all our custom components in order to make them cluster-ready. What we ended up doing instead was re-implementing the custom functionality in a Python service layer that in turn uses stock SolrCloud. This talk describes our journey, shows some code and advocates hiding implementation details like Solr v. SolrCloud behind a service layer. Ported functionality includes boosting more successful documents, identifying brands and categories in queries, &amp;quot;minimum match&amp;quot; search and facet ranking and alternatives.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</summary><category term="solrcloud"></category><category term="solr"></category><category term="search"></category><category term="python"></category></entry><entry><title>Ricerca full text in Django con PostgreSQL</title><link href="https://pyvideo.org/pycon-italia-2017/ricerca-full-text-in-django-con-postgresql.html" rel="alternate"></link><published>2017-04-08T00:00:00+00:00</published><updated>2017-04-08T00:00:00+00:00</updated><author><name>Paolo Melchiorre</name></author><id>tag:pyvideo.org,2017-04-08:pycon-italia-2017/ricerca-full-text-in-django-con-postgresql.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dalla versione 1.10 di &lt;strong&gt;Django&lt;/strong&gt; è presente il modulo che facilita
l’utilizzo del motore di &lt;strong&gt;ricerca full text&lt;/strong&gt; di PostgreSQL. Dal
momento che &lt;strong&gt;PostgreSQL&lt;/strong&gt; è utilizzato in molti progetti Django,
sfruttare il suo motore di ricerca full text permette di avere questa
funzionalità molto facilmente, senza dover configurare prodotti esterni
e senza doversi preoccupare di mantenere sincronizzati i dati tra
differenti sistemi. Vedremo come abbiamo sfruttato questa funzionalità
di ricerca full text in un &lt;strong&gt;progetto reale&lt;/strong&gt;.&lt;/p&gt;
</summary><category term="Full Text Search"></category><category term="search"></category><category term="postgresql"></category><category term="python3"></category><category term="django"></category></entry><entry><title>Fuzzy Search Algorithms How and When to Use Them</title><link href="https://pyvideo.org/pydata-dc-2016/fuzzy-search-algorithms-how-and-when-to-use-them.html" rel="alternate"></link><published>2016-10-08T00:00:00+00:00</published><updated>2016-10-08T00:00:00+00:00</updated><author><name>Jiaqi Liu</name></author><id>tag:pyvideo.org,2016-10-08:pydata-dc-2016/fuzzy-search-algorithms-how-and-when-to-use-them.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;So much of data science is about understanding the context around your data. In this talk, we hope to address how to work with messy text data by leveraging fuzzy search algorithms in python or against a database such as PostgreSQL. We will talk specifically about fuzzy algorithms such as Soundex, Trigram/n-gram search, and Levenshtein distances and demonstrate use cases in an ipython notebook.&lt;/p&gt;
</summary><category term="search"></category></entry><entry><title>Implementing distributed grid search for deep learning using scikit learn and joblib</title><link href="https://pyvideo.org/pydata-chicago-2016/implementing-distributed-grid-search-for-deep-learning-using-scikit-learn-and-joblib.html" rel="alternate"></link><published>2016-08-28T00:00:00+00:00</published><updated>2016-08-28T00:00:00+00:00</updated><author><name>Mike Heilman</name></author><id>tag:pyvideo.org,2016-08-28:pydata-chicago-2016/implementing-distributed-grid-search-for-deep-learning-using-scikit-learn-and-joblib.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://mheilman.github.io/pydata_chicago_2016/#/"&gt;https://mheilman.github.io/pydata_chicago_2016/#/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Grid search over hyperparameters is an important but computationally expensive process in machine learning, particularly for deep learning and tree ensembles. In this talk, I will describe how one can use joblib's recently added custom backend functionality to do distributed grid search on Amazon EC2 for a TensorFlow deep text classifier that follows the scikit-learn estimator API.&lt;/p&gt;
</summary><category term="deep learning"></category><category term="distributed"></category><category term="learning"></category><category term="scikit"></category><category term="search"></category></entry><entry><title>Add a search engine to your application using Xapian</title><link href="https://pyvideo.org/pytexas-2015/add-a-search-engine-to-your-application-using-xap.html" rel="alternate"></link><published>2015-10-09T00:00:00+00:00</published><updated>2015-10-09T00:00:00+00:00</updated><author><name>Ying Rou Zhao</name></author><id>tag:pyvideo.org,2015-10-09:pytexas-2015/add-a-search-engine-to-your-application-using-xap.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Search is a key component of most modern web and mobile applications. If
you want to add a full text search engine to your Python application and
effectively search large volumes of unstructured text, you could use
Xapian which is an open-source, light-weight and very fast C++ library.
Targeted to Python developers, this talk aims at introducing Xapian and
its Python bindings along with basic search concepts. We will show how
to build your search engine using Xapian step by step. Topics such as
indexing, stemming, querying and faceting techniques will be discussed
with code samples. A working prototype of a search engine built with
Xapian will be demonstrated in the end.&lt;/p&gt;
&lt;p&gt;demo repo: &lt;a class="reference external" href="https://github.com/jingle3276/imdb250"&gt;https://github.com/jingle3276/imdb250&lt;/a&gt; slides:
&lt;a class="reference external" href="https://docs.google.com/presentation/d/1wQVQig5Vdj5unQAkQQI8mELmX2zqjQ6S9OqeQIDqgoc/edit#slide=id.p"&gt;https://docs.google.com/presentation/d/1wQVQig5Vdj5unQAkQQI8mELmX2zqjQ6S9OqeQIDqgoc/edit#slide=id.p&lt;/a&gt;&lt;/p&gt;
</summary><category term="search"></category></entry><entry><title>Large Problems in Django, Mostly Solved</title><link href="https://pyvideo.org/djangocon-us-2010/djangocon-2010--large-problems-in-django--mostly-.html" rel="alternate"></link><published>2010-09-08T00:00:00+00:00</published><updated>2010-09-08T00:00:00+00:00</updated><author><name>Eric Holscher</name></author><id>tag:pyvideo.org,2010-09-08:djangocon-us-2010/djangocon-2010--large-problems-in-django--mostly-.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk is based on my popular series of blog posts highlighting
applications from the community. I will highlight some of the best
applications that the Django/Python community has put together, talk
about places that are lacking, and talk about what these popular
applications have in common.&lt;/p&gt;
&lt;p&gt;Part 1&lt;/p&gt;
&lt;p&gt;I have written a series of blog posts about &amp;quot;Large problems&amp;quot; in the
community, and how they have been solved by members of our community
with reusable apps. Previously I have covered:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Delayed Execution&lt;/li&gt;
&lt;li&gt;Search&lt;/li&gt;
&lt;li&gt;APIs&lt;/li&gt;
&lt;li&gt;Documentation&lt;/li&gt;
&lt;li&gt;Database Migrations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I will update my thoughts on these issues, as well as talking about a
couple of other new issues that I think that have been solved in a
decent way. These include:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Remote Command Execution&lt;/li&gt;
&lt;li&gt;Debugging in Development&lt;/li&gt;
&lt;li&gt;Continuous Integration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Part 2&lt;/p&gt;
&lt;p&gt;In this part I will highlight issues that are still headaches for the
Community. These are places where there is a good chance for growth for
third party apps, and places where I have personally found some friction
in my development. A couple examples of this are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Deployment&lt;/li&gt;
&lt;li&gt;Class Based Views / Thread Safety&lt;/li&gt;
&lt;li&gt;Debugging Production Environments&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Part 3&lt;/p&gt;
&lt;p&gt;From the above applications that are well done, what makes a popular
reusable app? This won't be my thoughts, but more looking at apps that
have been successful and trying to see what they have in common. A good
app and a good reusable app are necessarily different, and I think it
will be interesting to look at what traits make reusable apps popular.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://ericholscher.com/tag/largeproblems/"&gt;Large problems posts&lt;/a&gt;&lt;/p&gt;
</summary><category term="api"></category><category term="ci"></category><category term="continuousintegration"></category><category term="databasemigrations"></category><category term="debugging"></category><category term="delayedexecutions"></category><category term="deployment"></category><category term="djangocon"></category><category term="djangocon2010"></category><category term="documentation"></category><category term="migrations"></category><category term="safety"></category><category term="search"></category></entry><entry><title>Beyond Python Enhanced Generators</title><link href="https://pyvideo.org/europython-2011/beyond-python-enhanced-generators.html" rel="alternate"></link><published>2011-07-24T00:00:00+00:00</published><updated>2011-07-24T00:00:00+00:00</updated><author><name>Erik Groeneveld</name></author><id>tag:pyvideo.org,2011-07-24:europython-2011/beyond-python-enhanced-generators.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Erik Groeneveld - 23 June 2011 in &amp;quot;Track Spaghetti&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Right after the introduction of PEP342 (Enhanced Generators) we started
to decompose programs into generators. It was soon discovered that for
real-life problems one would need something like &amp;quot;yield from&amp;quot;, as is
described in PEP380. At that time, we already had a similar solution
called '&lt;a class="reference external" href="http://weightless.io/compose"&gt;compose&lt;/a&gt;', which we adapted
to PEP380.&lt;/p&gt;
&lt;p&gt;After 5 years working with 'compose', we found a small set of other
features that are essential if you want to use Enhanced Generators not
only as a way of lightweight command scheduling, but also a a pipe-line,
or parser. Indeed, the latter concepts are what real co-routines are
about.&lt;/p&gt;
&lt;p&gt;This talk introduces what is needed on top of PEPs 342 and 380 based on
experience with decomposing big enterprise search engines into
co-routines. Parts of it have been presented on SPA (2008) and
EuroPython (2010). Understanding of Enhanced Generators is a
prerequisite.&lt;/p&gt;
&lt;p&gt;Experience has shown that the topic is subtle enough to require quite
some time for full understanding, hence the suggestion for a 90 min
slot.&lt;/p&gt;
</summary><category term="generators"></category><category term="search"></category></entry><entry><title>Scraping Techniques to Extract Advertisements from Web Pages</title><link href="https://pyvideo.org/europython-2011/scraping-techniques-to-extract-advertisements-fro.html" rel="alternate"></link><published>2011-07-24T00:00:00+00:00</published><updated>2011-07-24T00:00:00+00:00</updated><author><name>Mirko Urru</name></author><id>tag:pyvideo.org,2011-07-24:europython-2011/scraping-techniques-to-extract-advertisements-fro.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Mirko Urru,Stefano Cotta Ramusino - 24 June 2011 in
&amp;quot;Track Tagliatelle &amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Online Advertising is an emerging research field, at the intersection of
Information Retrieval, Machine Learning, Optimization, and
Microeconomics. Its main goal is to choose the right ads to present to a
user engaged in a given task, such as Sponsored Search Advertising or
Contextual Advertising. The former puts ads on the page returned from a
Web search engine following a query. The latter puts ads within the
content of a generic, third party, Web page. The ads themselves are
selected and served by automated systems based on the content displayed
to the user.&lt;/p&gt;
&lt;p&gt;Web scraping is the set of techniques used to automatically get some
information from a website instead of manually copying it. In
particular, we're interested in studying and adopting scraping
techniques for: i. accessing tags as object members ii. finding out tags
whose name, contents or attributes match selection criteria iii.
accessing tag attributes by using a dictionary-like syntax.&lt;/p&gt;
&lt;p&gt;In this talk, we focus on the adoption of scraping techniques in the
contextual advertising field. In particular, we present a system aimed
at finding the most relevant ads for a generic web page p. Starting from
p, the system selects a set of its inlinks (i.e., the pages that link p)
and extracts the ads contained into them. Selection is performed
querying the Google search engine, whereas extraction is made by using
suitable scraping techniques.&lt;/p&gt;
</summary><category term="google"></category><category term="scraping"></category><category term="search"></category><category term="web"></category></entry><entry><title>django-rdflib and postgresql - the best of both worlds</title><link href="https://pyvideo.org/europython-2011/django-rdflib-and-postgresql-the-best-of-both-w.html" rel="alternate"></link><published>2011-07-13T00:00:00+00:00</published><updated>2011-07-13T00:00:00+00:00</updated><author><name>Stefan Talpalaru</name></author><id>tag:pyvideo.org,2011-07-13:europython-2011/django-rdflib-and-postgresql-the-best-of-both-w.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Stefan Talpalaru - 21 June 2011 in &amp;quot;Track Ravioli&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;rdflib is a python library implementing a database with various triples
back- end, parser, data serializers, SPARQL is a Python interface to
extract/insert triples. We integrated it in Django reusing the database
connection and exposing an ORM interface, along with full-text search on
literals. This presentation shows a django-rdflib case study with a
PostgreSQL backend in &lt;a class="reference external" href="http://brancusi1.usc.edu"&gt;Brain Architecture Management
System&lt;/a&gt; - a neuroscientific project for the
University of Southern California. Benefits of the flexible RDF
structure will be shown, allowing researchers to insert free format
data, making data public with a customizable serialization and use the
powerful full-text search integrated in PostgreSQL.&lt;/p&gt;
&lt;p&gt;Objective: show attendees an effective combination of RDF, PostgreSQL
full- text search and Django ORM via django-rdflib.&lt;/p&gt;
&lt;p&gt;Requirements: Django familiarity.&lt;/p&gt;
</summary><category term="architecture"></category><category term="database"></category><category term="django"></category><category term="orm"></category><category term="postgresql"></category><category term="reusing"></category><category term="search"></category><category term="serialization"></category><category term="university"></category></entry><entry><title>Komponenten einer komplexen Web-Applikation</title><link href="https://pyvideo.org/pycon-de-2013/komponenten-einer-komplexen-web-applikation.html" rel="alternate"></link><published>2013-10-16T00:00:00+00:00</published><updated>2013-10-16T00:00:00+00:00</updated><author><name>Daniel Hepper</name></author><id>tag:pyvideo.org,2013-10-16:pycon-de-2013/komponenten-einer-komplexen-web-applikation.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Komplexe Web-Applikationen bestehen aus mehr als einem Webserver, einer
Datenbank und etwas Code. Dieser Vortrag gibt einen Überblick über die
typischen Bausteine wie Celery als Task Queue, Haystack für
Volltextsuche, Sentry als Log-Diensten und automatischem Deployment mit
Fabric und Salt. Die vorgestellte Komponenten werden anhand einer
Django-Applikation erläutert, sind jedoch zum Großteil auch mit anderen
Frameworks nutzbar.&lt;/p&gt;
</summary><category term="celery"></category><category term="deployment"></category><category term="django"></category><category term="elasticsearch"></category><category term="fabric"></category><category term="haystack"></category><category term="salt"></category><category term="search"></category><category term="sentry"></category><category term="solr"></category></entry></feed>