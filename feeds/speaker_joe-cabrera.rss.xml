<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Joe Cabrera</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sun, 21 Apr 2024 00:00:00 +0000</lastBuildDate><item><title>High Performance Python Microservice Communication</title><link>https://pyvideo.org/pybay-2018/high-performance-python-microservice-communication.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joe Cabrera</dc:creator><pubDate>Sat, 18 Aug 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-08-18:/pybay-2018/high-performance-python-microservice-communication.html</guid><category>PyBay 2018</category></item><item><title>Building a data processing pipeline in Python</title><link>https://pyvideo.org/pygotham-2015/building-a-data-processing-pipeline-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Recently, the growth of publicly available data has been enormous.
Python has a number of libraries and tool to aid you in building your
data processing pipeline. These tools include Celery, Requests,
BeautifulSoup and SQL-Alchemy. When combined together you can build an
efficient and scalable data processing pipeline.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joe Cabrera</dc:creator><pubDate>Sat, 15 Aug 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-08-15:/pygotham-2015/building-a-data-processing-pipeline-in-python.html</guid><category>PyGotham 2015</category></item><item><title>Indexing all the things: Building your search engine in Python</title><link>https://pyvideo.org/pygotham-2017/indexing-all-the-things-building-your-search-engine-in-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Since the emergence of Elasticsearch, common Information Retrieval tasks such as indexing, scoring and retrieval of documents into a search engine have never been easier. However unique challenges still exist for indexing large sets of data from databases. At Jopwell, we need to insure that data in our database is kept in constant sync with data in our search index.&lt;/p&gt;
&lt;p&gt;Initially you need to take data from a traditional SQL database and flatten it for indexing in Elasticsearch. Since indexing this data can be a memory intensive task, Celery is useful for ensuring you can index large sets of data in both a distributed and memory-conservative manner. Once all your documents are in your Elasticsearch index, you need to retrieve data from your database related to a user’s search results.&lt;/p&gt;
&lt;p&gt;In this talk, I’ll show the basics of creating a search engine in Python, keeping these it synced with another data store and how you can keep your index running smoothly.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Talk Outline&lt;/strong&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Introduction to the problem (2 min)&lt;/li&gt;
&lt;li&gt;Building your document indexer (7 min)&lt;ul&gt;
&lt;li&gt;Flattening database data into a search document&lt;/li&gt;
&lt;li&gt;Using Celery to index documents efficiently&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scoring and search results retrieval (7 min)&lt;ul&gt;
&lt;li&gt;Scoring algorithms&lt;/li&gt;
&lt;li&gt;Retrieving matching results from the database&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Strategies for syncing data from (7 min)&lt;ul&gt;
&lt;li&gt;Traditional SQL database&lt;/li&gt;
&lt;li&gt;Elasticsearch index&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Future work (2 min)&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joe Cabrera</dc:creator><pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-10-06:/pygotham-2017/indexing-all-the-things-building-your-search-engine-in-python.html</guid><category>PyGotham 2017</category></item><item><title>Sanely Working with Legacy Code</title><link>https://pyvideo.org/pytexas-2024/sanely-working-with-legacy-code.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Sanely Working with Legacy Code&lt;/p&gt;
&lt;p&gt;For many developers, they will inevitably have to work with legacy code at some point in their careers. It requires a different set of skills to navigate these codebases as opposed to greenfield code where you start with a clean slate. Join me in exploring techniques to approach legacy code including how to improve documentation, increase testing coverage, refactoring code into smaller more testable units and techniques when you lack time to add tests.&lt;/p&gt;
&lt;p&gt;Speaker: Joe Cabrera&lt;/p&gt;
&lt;p&gt;I am a software engineer with +10 years of professional experience building scalable and distributed systems for companies. I am also a subject matter expert in Information Retrieval and Personalized Search. I have spoken at several Python conferences, helped to organize a conference and am involved in the Python open source community.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joe Cabrera</dc:creator><pubDate>Sun, 21 Apr 2024 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2024-04-21:/pytexas-2024/sanely-working-with-legacy-code.html</guid><category>PyTexas 2024</category></item></channel></rss>