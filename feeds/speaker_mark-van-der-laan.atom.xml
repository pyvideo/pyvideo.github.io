<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Mark van der Laan</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_mark-van-der-laan.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-08-03T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Generalized Policy Elimination: an efficient algorithm for Nonparametric Contextual Bandits</title><link href="https://pyvideo.org/uai-2020/generalized-policy-elimination-an-efficient-algorithm-for-nonparametric-contextual-bandits.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Aurelien Bibaut</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/generalized-policy-elimination-an-efficient-algorithm-for-nonparametric-contextual-bandits.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;dl class="docutils"&gt;
&lt;dt&gt;&amp;quot;We  propose   the  Generalized   Policy  Elimination  (GPE)   algorithm,  an&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;oracle-efficient  contextual bandit  (CB) algorithm  inspired by  the Policy
Elimination   algorithm   of   cite{dudik2011}.    We   prove   the   first
regret-optimality  guarantee theorem  for an  oracle-efficient CB  algorithm
competing  against   a  nonparametric  class  with   infinite  VC-dimension.
Specifically, we show that GPE is â€¦&lt;/p&gt;&lt;/dd&gt;&lt;/dl&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;dl class="docutils"&gt;
&lt;dt&gt;&amp;quot;We  propose   the  Generalized   Policy  Elimination  (GPE)   algorithm,  an&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;oracle-efficient  contextual bandit  (CB) algorithm  inspired by  the Policy
Elimination   algorithm   of   cite{dudik2011}.    We   prove   the   first
regret-optimality  guarantee theorem  for an  oracle-efficient CB  algorithm
competing  against   a  nonparametric  class  with   infinite  VC-dimension.
Specifically, we show that GPE is regret-optimal (up to logarithmic factors)
for policy classes with integrable entropy.&lt;/p&gt;
&lt;p class="last"&gt;For classes  with larger entropy, we  show that the core  techniques used to
analyze GPE  can be  used to design  an $varepsilon$-greedy  algorithm with
regret bound  matching that of the  best algorithms to date.   We illustrate
the  applicability of  our algorithms  and theorems  with examples  of large
nonparametric policy  classes, for  which the relevant  optimization oracles
can be efficiently implemented.&amp;quot;&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
</content><category term="UAI 2020"></category></entry></feed>