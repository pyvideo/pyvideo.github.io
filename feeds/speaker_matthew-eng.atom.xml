<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Matthew Eng</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_matthew-eng.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2021-10-01T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Building quality data pipelines</title><link href="https://pyvideo.org/pygotham-2021/building-quality-data-pipelines.html" rel="alternate"></link><published>2021-10-01T00:00:00+00:00</published><updated>2021-10-01T00:00:00+00:00</updated><author><name>Matthew Eng</name></author><id>tag:pyvideo.org,2021-10-01:/pygotham-2021/building-quality-data-pipelines.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Working with data can be daunting when making code changes. As we make
transformational changes to our data, how do we know that the quality of our
data is preserved? Performing these transformations on large datasets can be
even more daunting, as the number of areas that could have â€¦&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Working with data can be daunting when making code changes. As we make
transformational changes to our data, how do we know that the quality of our
data is preserved? Performing these transformations on large datasets can be
even more daunting, as the number of areas that could have been affected.
The number of areas to troubleshoot can be numerous, making it time-
consuming to identify the root cause to be fixed.&lt;/p&gt;
&lt;p&gt;Instead of going through a manual checklist of data points and features to
check, this talk will walk through a framework for how you can readily apply
testing to ensure that any data transformations we make are accurate, and&lt;/p&gt;
&lt;p&gt;This talk is for anyone working with datasets where maintaining the quality
of our data i&lt;/p&gt;
</content><category term="PyGotham 2021"></category></entry></feed>