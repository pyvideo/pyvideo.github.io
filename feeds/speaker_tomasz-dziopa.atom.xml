<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_tomasz-dziopa.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-12-12T00:00:00+00:00</updated><entry><title>Generative Text Modelling: Scratching the surface</title><link href="https://pyvideo.org/pydata-warsaw-2019/generative-text-modelling-scratching-the-surface.html" rel="alternate"></link><published>2019-12-12T00:00:00+00:00</published><updated>2019-12-12T00:00:00+00:00</updated><author><name>Tomasz Dziopa</name></author><id>tag:pyvideo.org,2019-12-12:pydata-warsaw-2019/generative-text-modelling-scratching-the-surface.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Recent progress in generating natural language text catches media
attention. Are we about to get flooded by autogenerated fake news? Let's
learn about approaches to machine-generated text. Get a high level idea
of how can you apply basic approaches like N-grams, HMMs as well as
advanced ones such as RNNs and VAEs. We'll apply those methods to
real-world datasets of Polish articles from Wikipedia.&lt;/p&gt;
&lt;p&gt;Recent progress in generating natural language text sparks controversy
and catches global media attention. Are we about to get flooded by
machine- generated fake news? Are we on the edge of a completely new
level of troll farms about to emerge? In this talk I will go over
approaches to machine- generated text. You will get a high level idea of
how can you apply basic approaches like N-grams, Hidden Markov Model as
well as advanced ones such as RNNs and Variational Autoencoders. We will
cover the main challenges like methods of evaluation, and potential use
cases. We will also have fun applying aforementioned methods into real
world datasets of Polish articles from Wikipedia.&lt;/p&gt;
</summary></entry></feed>