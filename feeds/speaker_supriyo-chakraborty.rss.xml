<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Supriyo Chakraborty</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 16 Oct 2023 00:00:00 +0000</lastBuildDate><item><title>Lessons Learned in WatsonX Training: Scaling Cloud-Native PyTorch FSDP to 20B Parameters</title><link>https://pyvideo.org/pytorch-conference-2023/lessons-learned-in-watsonx-training-scaling-cloud-native-pytorch-fsdp-to-20b-parameters.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we will cover lessons learned along our almost year-and-a-half journey scaling up the WatsonX.AI stack for foundation model pretraining. Starting from 100M parameters on bare metal, we scaled PyTorch training to 20B parameters on cloud-based multi-node systems. We'll discuss the challenges encountered along the way, as well as the solutions we employed. This includes working with the PyTorch team to field test Fully-Sharded and Hybrid-Shard Data Parallel update protocols (FSDP/HSDP), as well as handling the associated communication vs computation bottlenecks, which are not always straightforward. We'll also review our collaboration on cloud-native distributed checkpointing, and development of a stateful and scalable distributed dataloader, allowing us to restart unstable jobs mid-epoch without revisiting stale data. And finally, we'll cover ongoing and upcoming challenges, like maintaining job stability and tensor parallelism integration.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Davis Wertheimer</dc:creator><pubDate>Mon, 16 Oct 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-10-16:/pytorch-conference-2023/lessons-learned-in-watsonx-training-scaling-cloud-native-pytorch-fsdp-to-20b-parameters.html</guid><category>PyTorch Conference 2023</category></item></channel></rss>