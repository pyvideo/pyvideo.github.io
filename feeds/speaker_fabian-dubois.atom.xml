<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_fabian-dubois.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2016-09-22T00:00:00+00:00</updated><entry><title>Building a data preparation pipeline with Pandas and AWS Lambda</title><link href="https://pyvideo.org/pycon-japan-2016/building-a-data-preparation-pipeline-with-pandas-and-aws-lambda.html" rel="alternate"></link><published>2016-09-22T00:00:00+00:00</published><updated>2016-09-22T00:00:00+00:00</updated><author><name>Fabian Dubois</name></author><id>tag:pyvideo.org,2016-09-22:pycon-japan-2016/building-a-data-preparation-pipeline-with-pandas-and-aws-lambda.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When working on a data project, you will be often be facing messy input files with lots of missing or ill formatted values. Data providers may update manually, making the data source even more error prone. Once you geed the data to a data visualization or a dashboard, this will create many issues. I will show how to create a data preparation pipeline using with Pandas running on AWS Lambda.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;In the talk, I will first review typical cases where a data scientist or data application developper may be faced with dirty data in unpractical formats (think excel files). I will in particular discuss my experience building data visualization in a data journalism environment here data is gathered and updated manually.&lt;/p&gt;
&lt;p&gt;I will present alternative tools that are available on the market (Talend Dataprep, Trifacta wrangler for example), and explain why you may want to roll out your own solution. Then we will see how we can use python and pandas to clean the data, first by interacting with it in a jupyter notebook, then making it into a script.&lt;/p&gt;
&lt;p&gt;Finally, we will see how to streamline the preparation using AWS Lambda, in an example where will will automatically run our process whenever data is updated in a google spreadsheet, and uploading the clean dataset on AWS S3.&lt;/p&gt;
</summary></entry></feed>