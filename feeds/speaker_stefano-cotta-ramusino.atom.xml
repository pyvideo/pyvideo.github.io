<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_stefano-cotta-ramusino.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2014-07-22T00:00:00+00:00</updated><entry><title>JSON data + RML template = PDF report</title><link href="https://pyvideo.org/europython-2011/json-data-rml-template-pdf-report.html" rel="alternate"></link><published>2011-07-24T00:00:00+00:00</published><updated>2011-07-24T00:00:00+00:00</updated><author><name>Stefano Cotta Ramusino</name></author><id>tag:pyvideo.org,2011-07-24:europython-2011/json-data-rml-template-pdf-report.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Stefano Cotta Ramusino - 23 June 2011 in &amp;quot;Track
Ravioli&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The main problem with reports generated in Python is how to separate the
content from the style using ReportLab library, because all informations
should be saved in a single source file that, by example, is impossible
to understand for your graphic designer.&lt;/p&gt;
&lt;p&gt;So the solution: just modularizes all components you need and identify
simple container formats for your data input (JSON) and document
template (ReportLab RML).&lt;/p&gt;
&lt;p&gt;Now with the power of Genshi and XInclude we will create dynamic
templates that include specific snippets (e.g., to generate on the fly a
decent graph with matplotlib or cairoplot to fill some lacks of
ReportLab) and we will detach the stylesheet from the template
structure.&lt;/p&gt;
&lt;p&gt;And at the end you can also have the internationalization service in the
PDF report generation!&lt;/p&gt;
</summary><category term="internationalization"></category><category term="json"></category><category term="matplotlib"></category></entry><entry><title>Scraping Techniques to Extract Advertisements from Web Pages</title><link href="https://pyvideo.org/europython-2011/scraping-techniques-to-extract-advertisements-fro.html" rel="alternate"></link><published>2011-07-24T00:00:00+00:00</published><updated>2011-07-24T00:00:00+00:00</updated><author><name>Mirko Urru</name></author><id>tag:pyvideo.org,2011-07-24:europython-2011/scraping-techniques-to-extract-advertisements-fro.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Mirko Urru,Stefano Cotta Ramusino - 24 June 2011 in
&amp;quot;Track Tagliatelle &amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Online Advertising is an emerging research field, at the intersection of
Information Retrieval, Machine Learning, Optimization, and
Microeconomics. Its main goal is to choose the right ads to present to a
user engaged in a given task, such as Sponsored Search Advertising or
Contextual Advertising. The former puts ads on the page returned from a
Web search engine following a query. The latter puts ads within the
content of a generic, third party, Web page. The ads themselves are
selected and served by automated systems based on the content displayed
to the user.&lt;/p&gt;
&lt;p&gt;Web scraping is the set of techniques used to automatically get some
information from a website instead of manually copying it. In
particular, we're interested in studying and adopting scraping
techniques for: i. accessing tags as object members ii. finding out tags
whose name, contents or attributes match selection criteria iii.
accessing tag attributes by using a dictionary-like syntax.&lt;/p&gt;
&lt;p&gt;In this talk, we focus on the adoption of scraping techniques in the
contextual advertising field. In particular, we present a system aimed
at finding the most relevant ads for a generic web page p. Starting from
p, the system selects a set of its inlinks (i.e., the pages that link p)
and extracts the ads contained into them. Selection is performed
querying the Google search engine, whereas extraction is made by using
suitable scraping techniques.&lt;/p&gt;
</summary><category term="google"></category><category term="scraping"></category><category term="search"></category><category term="web"></category></entry><entry><title>GNU/Linux Hardware Emulation with Python</title><link href="https://pyvideo.org/europython-2014/gnulinux-hardware-emulation-with-python.html" rel="alternate"></link><published>2014-07-22T00:00:00+00:00</published><updated>2014-07-22T00:00:00+00:00</updated><author><name>Stefano Cotta Ramusino</name></author><id>tag:pyvideo.org,2014-07-22:europython-2014/gnulinux-hardware-emulation-with-python.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Do want to test the connection code to a wifi/gsm network, but you
haven't any dongle? Do you want to check your software notification when
the battery is low, but you're testing your application on your desktop?
Do you want to manipulate the data coming from a device, but you've lend
it to someone else? &lt;em&gt;No problem, you can emulate all these with Python!&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;With the kernel &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Inotify"&gt;inotify&lt;/a&gt;
feature, the &lt;a class="reference external" href="https://launchpad.net/python-dbusmock"&gt;D-Bus mocker
library&lt;/a&gt; and the &lt;a class="reference external" href="http://pyudev.readthedocs.org/en/latest/api/pyudev.html#pyudev.Monitor"&gt;udev
monitoring&lt;/a&gt;
we try to detect the different events that occours when you're using a
specific set of connected devices.&lt;/p&gt;
&lt;p&gt;Then we try to mimic these devices investigating also the kernel drivers
if necessary.&lt;/p&gt;
&lt;p&gt;At the end we're ready to connect the simulation routines to our testing
procedure.&lt;/p&gt;
</summary></entry></feed>