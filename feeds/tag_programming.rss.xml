<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 12 Jul 2019 00:00:00 +0000</lastBuildDate><item><title>And now for something completely different.</title><link>https://pyvideo.org/europython-2019/and-now-for-something-completely-different.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The goal of this talk is to show the audience a different way of
thinking about and developing regex statements.&lt;/p&gt;
&lt;p&gt;I have been working with UNIX for decades now and, although i always
managed to avoid Perl, i have been intrigued with Regex constructs ever
since my first encounter. These weird unreadable things that can
transform text like nothing else or can find what i’m looking for in
massive files, in no time at all. I’ve created regexes that only appeal
to the most nerdiest of nerds and i’ve stunned colleagues by fixing
their futile regex attempts in just a few keystrokes. But when Damian
Conway showed me how regexes really work i was awestruck. And now i want
to share this knowledge.&lt;/p&gt;
&lt;p&gt;This talk is aimed at pythonistas that have some experience with the re
module. I will take some easy examples and explain in plain english how
a regex engine searches for a match. This will show that a regex is not
some mysterious incomprehensible pattern description or declarative
blueprint. Instead it is a small program that is very good at comparing
single characters. Like any programming language it turns out that once
you understand the rules and structure it suddenly becomes so much
easier to use.&lt;/p&gt;
&lt;p&gt;With this new found knowledge we will up the ante and try some more
difficult stuff, adding other semantics and some tips and tricks. We’ll
look at some pitfalls, maybe compare regex to python solutions and have
a look at some regexes found in the wild (either on my drive or on
github).&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Danny Engelbarts</dc:creator><pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-12:europython-2019/and-now-for-something-completely-different.html</guid><category>Compiler and Interpreters</category><category>Mind Bending</category><category>Programming</category><category>Python Skills</category><category>Tooling</category></item><item><title>Code review for Beginners and Experts: Tips &amp; Tricks</title><link>https://pyvideo.org/europython-2019/code-review-for-beginners-and-experts-tips-tricks.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Code review is not just boring duty. It's mutual responsibility for
the software we're releasing. It's one of the most critical aspects of
code quality, and therefore it's the first step of quality assurance.
This is also the key to easier programming and better maintainability.
Clean code is much easier to debug, and it's much harder to introduce
a bug in such code.&lt;/div&gt;
&lt;div class="line"&gt;When you think about code review, you probably think about verifying
and examining the code. Reviewing the expert's code may look like a
waste of time because he knows what he's doing. Reviewing the code by
a beginner may look like a waste of time because he's not able to find
as many defects as an experienced developer. Code review is a code
quality tool in the first place, but it's also much beyond that. You
can teach or help someone, learn from somebody and much more both from
the position of reviewer and reviewee.&lt;/div&gt;
&lt;div class="line"&gt;There is much more about the real power of code review which I want to
share with you.&lt;/div&gt;
&lt;div class="line"&gt;This talk is also about how to do it the right way and how to not do
it based on lessons learned and my experience within the diverse teams
of people with a variety of knowledge and experience. I was reviewing
the code but, on the other hand, I was also being reviewed. I'd like
to pass my observations to people who are reviewing the code both in
commercial and open source projects for a while. This talk is also for
those who want to start to review the code, but they do not know how
to do it.&lt;/div&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Łukasz Kąkol</dc:creator><pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-12:europython-2019/code-review-for-beginners-and-experts-tips-tricks.html</guid><category>Best Practice</category><category>Clean Code</category><category>Code Analysis</category><category>Development</category><category>Programming</category></item><item><title>Get up to speed with Cython 3.0</title><link>https://pyvideo.org/europython-2019/get-up-to-speed-with-cython-30.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Processing lots of data, in need of more speed, or struggling to make
use of native code? The Cython compiler for Python solves all of these
problems in a pythonic way, by compiling Python code to optimised C
code.&lt;/p&gt;
&lt;p&gt;Cython [1] has a very long history of faithfully helping users to solve
their Python performance problems and integrating native code into
Python in production critical settings, while stimulating somewhat less
confidence with its 0.x versioning scheme. For the next Cython version,
a stable 3.0 release, we are planning to clean up several historically
grown issues in the language to make the Cython compiler more friendly
for modern Python users to work with.&lt;/p&gt;
&lt;p&gt;In this talk, I will show how Cython can be used for compiling and
speeding up Python code, using fast native data structures and
libraries. I will then give an overview of the changes that are on their
way for the 3.0 release and how they will affect the user experience.&lt;/p&gt;
&lt;p&gt;[1] &lt;a class="reference external" href="https://cython.org"&gt;https://cython.org&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Stefan Behnel</dc:creator><pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-11:europython-2019/get-up-to-speed-with-cython-30.html</guid><category>C-Languages</category><category>Compiler and Interpreters</category><category>Cython</category><category>Performance</category><category>Programming</category></item><item><title>Practical decorators</title><link>https://pyvideo.org/europython-2019/practical-decorators.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Decorators are one of Python's most powerful features. But even if you
understand what they do, it's not always obvious what you can do with
them. Sure, from a practical perspective, they let you remove repeated
code from your callables. And semantically, they let you think at a
higher level of abstraction, applying the same treatment to functions
and classes.&lt;/p&gt;
&lt;p&gt;But what can you actually do with them? For many Python developers I've
encountered, decorators sometimes appear to be a solution looking for a
problem.&lt;/p&gt;
&lt;p&gt;In this talk, I'll show you some practical uses for decorators, and how
you can use them to make your code more readable and maintainable, while
also providing more semantic power. Moreover, you'll see examples of
things would be hard to do without decorators. I hope that after this
talk, you'll have a good sense of how to use decorators in your own
Python projects.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Reuven Lerner</dc:creator><pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-11:europython-2019/practical-decorators.html</guid><category>Compiler and Interpreters</category><category>Data Structures</category><category>Programming</category><category>Python Skills</category><category>Python general</category></item><item><title>Teaching Programming to the Next Generation</title><link>https://pyvideo.org/europython-2019/teaching-programming-to-the-next-generation.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Our generation of young people in school (aged 5-18) have noticed the
connection between Computer pRogramming, Technology &amp;amp; Success and
Billionaires.On mass they are clamoring to master the skill of Computer
pRogramming. We describe a successful working model for the teaching of
Computer pRogamming.&lt;/p&gt;
&lt;p&gt;Computer Science is now regarded as one of the leading disciplines in
the 21st century. Computers are ubiquitous and prevalent in most, if not
all, sectors of our modern society – applications include using them in
weather forecasting, robotic surgery, space exploration, e-commerce,
smart cities, driverless cars, etc.&lt;/p&gt;
&lt;p&gt;Therefore, coding or computer programming is now regarded by many as an
essential skill for the young person, and it has been dubbed the ‘4th’
R’ (computer pRogramming) along with Reading, wRiting and aRithmetic.&lt;/p&gt;
&lt;p&gt;In recognition of the new status of computer programming, governments
worldwide have launched initiatives to have it taught in schools from
Kindergarten through to junior school and all the way through secondary
school.&lt;/p&gt;
&lt;p&gt;So, the question emerges is how do we best teach and motivate the next
generation in acquiring this skill? Given the fact that this field is
very much in its infancy, there are insufficient number of skilled
Computer Science teachers and very little pedagogy to guide the
educator. Therefore, the whole world is learning how best to teach this
subject by trial and error.&lt;/p&gt;
&lt;p&gt;The talk will describe a case study whereby coding/computer programming,
in the form of Python programming, was introduced to a group of 110
young people from the ages of 11 to 18 (Years 7-13 in a U.K secondary
school). The talk will include descriptions of the various teaching
methodologies introduced to the young people for this purpose and the
outcomes; the talk will also address various challenges and questions
about how to teach coding to young people. The talk will conclude with
helpful suggestions, based on the findings of the case study, on how to
proceed with the teaching of computer programming to these people.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lilian Nandi anonymous</dc:creator><pubDate>Wed, 10 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-10:europython-2019/teaching-programming-to-the-next-generation.html</guid><category>All Other Programming Languages</category><category>Education</category><category>Programming</category><category>Python 3</category><category>Teaching</category></item><item><title>Using Python to create political acts</title><link>https://pyvideo.org/pycon-italia-2019/using-python-to-create-political-acts.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Last Pycon Italia I showed how my team has using Python and Data Science
to fight corruption - &lt;a class="reference external" href="https://www.youtube.com/watch?v=JiJ5a4CXRF8&amp;amp;t=8s"&gt;https://www.youtube.com/watch?v=JiJ5a4CXRF8&amp;amp;t=8s&lt;/a&gt;
This time I want to show something that can be replicated in Italy right
after we finish the presentation.&lt;/p&gt;
&lt;p&gt;As &amp;#64;participatory (World Bank Internet impact researcher) says, every
country has a good response for public pressure across the internet, and
this response is even better within autocratic governments because they
want to keep healthy international relations. But how we can keep a
record of all the drafts of legislation that are happening right now?
How we can use this information and create an action for the public to
show their agreement or not for every change that happens.&lt;/p&gt;
&lt;p&gt;With Scrapy, Python, Django, and Open source! Let me show you how has
been done in Brazil and the Pipeline that makes possible to replicated
here in Italy!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1702"&gt;https://python.it/feedback-1702&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 10:30 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Felipe Cabral</dc:creator><pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-03:pycon-italia-2019/using-python-to-create-political-acts.html</guid><category>web-scraping</category><category>Python</category><category>programming</category><category>scrapy</category><category>api</category><category>open-data</category><category>opendata</category><category>hacking</category></item><item><title>Bug hunting for dummies</title><link>https://pyvideo.org/europython-2013/bug-hunting-for-dummies.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Antonio Cuni</dc:creator><pubDate>Tue, 02 Jul 2013 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2013-07-02:europython-2013/bug-hunting-for-dummies.html</guid><category>debugging</category><category>testing</category><category>programming</category><category>tdd</category><category>gdb</category><category>code generation</category><category>pdb</category></item><item><title>Concurrency in Python - concepts, frameworks and best practices</title><link>https://pyvideo.org/pycon-de-2018/concurrency-in-python-concepts-frameworks-and-best-practices.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you run in situations where concurrent execution could speed up
your Python code? Are you using a GUI toolkit?&lt;/p&gt;
&lt;p&gt;This talk gives you the background to use concurrency in your code
without shooting yourself in the foot - which is quite easy if you don't
understand how concurrent execution differs from linear execution!&lt;/p&gt;
&lt;p&gt;The presentation starts with explaining some concepts like concurrency,
parallelism, resources, atomic operations, race conditions and
deadlocks.&lt;/p&gt;
&lt;p&gt;Then we discuss the commonly-used approaches to concurrency:
multithreading with the &lt;tt class="docutils literal"&gt;threading&lt;/tt&gt; module, multiprocessing with the
&lt;tt class="docutils literal"&gt;multiprocessing&lt;/tt&gt; module, and event loops (which include the
&lt;tt class="docutils literal"&gt;asyncio&lt;/tt&gt; framework). Each of these approaches has its typical use
cases, which are explained.&lt;/p&gt;
&lt;p&gt;You can implement concurrency on a number of abstraction levels. The
lowest level consists of primitives like locks, events, semaphores and
so on. A higher abstraction level is using queues, typically with worker
threads or processes. Even higher abstraction levels are active objects
(hiding primitives or queues behind an API; this includes &amp;quot;actors&amp;quot; if
you heard of them), the thread and process pools in
&lt;tt class="docutils literal"&gt;concurrent.futures&lt;/tt&gt; and the &lt;tt class="docutils literal"&gt;asyncio&lt;/tt&gt; framework. Finally, you can
&amp;quot;outsource&amp;quot; concurrency by leaving it to a message broker, which is a
distinct process that receives and distributes messages.&lt;/p&gt;
&lt;p&gt;The talk closes with some tips and best practices, mainly:&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Stefan Schwarzer</dc:creator><pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-26:pycon-de-2018/concurrency-in-python-concepts-frameworks-and-best-practices.html</guid><category>Parallel Programming</category><category>Programming</category><category>Python</category></item><item><title>Beyond Jupyter Notebooks - Building your own Data Science platform with Python &amp; Docker</title><link>https://pyvideo.org/pycon-de-2018/beyond-jupyter-notebooks-building-your-own-data-science-platform-with-python-docker.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Interactive notebooks like Jupyter have become more and more popular in
the recent past and build the core of many data scientist's workplace.
Being accessed via web browser they allow scientists to easily structure
their work by combining code and documentation.&lt;/p&gt;
&lt;p&gt;Yet notebooks often lead to isolated and disposable analysis artefacts.
Keeping the computation inside those notebooks does not allow for
convenient concurrent model training, model exposure or scheduled model
retraining.&lt;/p&gt;
&lt;p&gt;Those issues can be addressed by taking advantage of recent developments
in the discipline of software engineering. Over the past years
containerization became the technology of choice for crafting and
deploying applications. Building a data science platform that allows for
easy access (via notebooks), flexibility and reproducibility (via
containerization) combines the best of both worlds and addresses Data
Scientist's hidden needs.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joshua Görner</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/beyond-jupyter-notebooks-building-your-own-data-science-platform-with-python-docker.html</guid><category>Artificial Intelligence</category><category>Algorithms</category><category>Data Science</category><category>DevOps</category><category>Infrastructure</category><category>Jupyter</category><category>Machine Learning</category><category>Programming</category><category>Python</category></item><item><title>Big Data Systems Performance: The Little Shop of Horrors</title><link>https://pyvideo.org/pycon-de-2018/big-data-systems-performance-the-little-shop-of-horrors.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The confusion around terms such as like NoSQL, Big Data, Data Science,
Spark, SQL, and Data Lakes often creates more fog than clarity. However,
clarity about the underlying technologies is crucial to designing the
best technical solution in any field relying on huge amounts of data
including data science, machine learning, but also more traditional
analytical systems such as data integration, data warehousing,
reporting, and OLAP.&lt;/p&gt;
&lt;p&gt;In my presentation, I will show that often at least three dimensions are
cluttered and confused in discussions when it comes to data management:
First, buzzwords (labels &amp;amp; terms like &amp;quot;big data&amp;quot;, &amp;quot;AI&amp;quot;, &amp;quot;data lake&amp;quot;);
second, data design patterns (principles &amp;amp; best practices like:
selection push-down, materialization, indexing); and Third, software
platforms (concrete implementations &amp;amp; frameworks like: Python, DBMS,
Spark, and NoSQL-systems).&lt;/p&gt;
&lt;p&gt;Only by keeping these three dimensions apart, it is possible to create
technically-sound architectures in the field of big data analytics.&lt;/p&gt;
&lt;p&gt;I will show concrete examples, which through a simple redesign and wise
choice of the right tools and technologies, run thereby up to 1000 times
faster. This in turn triggers tremendous savings in terms of development
time, hardware costs, and maintenance effort.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jens Dittrich</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/big-data-systems-performance-the-little-shop-of-horrors.html</guid><category>Algorithms</category><category>Big Data</category><category>Data Science</category><category>Infrastructure</category><category>Parallel Programming</category><category>Programming</category><category>Python</category><category>Science</category></item><item><title>Driving simulation and data analysis of magnetic nanostructures through Jupyter Notebook</title><link>https://pyvideo.org/pycon-de-2018/driving-simulation-and-data-analysis-of-magnetic-nanostructures-through-jupyter-notebook.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We present ongoing work from a project that makes a particular computer
simulation (implemented in C++ and Tk/Tcl) accessible through a Python
interface, and through the Jupyter Notebook. The talk describes the
motivation and current status of the project.&lt;/p&gt;
&lt;p&gt;In more detail, the computer simulation in question is the Object
Oriented Micromagnetic Modelling Framework
(&lt;a class="reference external" href="http://math.nist.gov/oommf/"&gt;OOMMF&lt;/a&gt;) which is likely the most
widely used micromagnetic simulation package. It can be driven through a
graphical (Tk) user interface or through a configuration file that
defines a simulation run.&lt;/p&gt;
&lt;p&gt;In this talk, we first show a Python interface to OOMMF that allows the
driving of OOMMF simulations from a Python program or interpreter
prompt. This way we embed a widely used scientific code from 1990s in a
general purpose programming language
[&lt;a class="reference external" href="https://doi.org/10.1063/1.4977225"&gt;1&lt;/a&gt;] and enable the full use of
the ecosystem of scientific libraries available for Python. For example,
design optimisation, specialised post-processing, and the creation of
figures can all be carried out using a single script; making the work
more easily reproducible.&lt;/p&gt;
&lt;p&gt;Second, we integrate the Python interface to OOMMF into a Jupyter
notebook, so that all existing benefits of using Jupyter are inherited
for the use in computational micromagnetics, which is the reason we
named our code Jupyter- OOMMF (&lt;a class="reference external" href="http://joommf.github.io/"&gt;JOOMMF&lt;/a&gt;). A
&lt;a class="reference external" href="https://tryjoommf.soton.ac.uk/"&gt;JupyterHub installation&lt;/a&gt; of the tool
reduces barriers in uptake, and all the code is &lt;a class="reference external" href="https://github.com/joommf"&gt;on
github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We discuss the benefits of driving computer simulation and data analysis
through Jupyter Notebooks.&lt;/p&gt;
&lt;p&gt;This project is a part of the Jupyter-OOMMF (JOOMMF) activity in the
&lt;a class="reference external" href="http://opendreamkit.org/"&gt;OpenDreamKit&lt;/a&gt; project and we acknowledge
financial support from Horizon 2020 European Research Infrastructures
project (676541). The work is also supported by the EPSRC CDT in Next
Generation Computational Modelling EP/L015382/1, and the EPSRC grants
EP/M022668/1 and EP/N032128/1.&lt;/p&gt;
&lt;p&gt;For additional context: micromagnetic modelling is a key research method
in academia and industry to support development of high-capacity
magnetic storage devices that are cheap, fast, and reliable, and to
enable research into future alternative storage and processing
technologies such as spintronics. The OOMMF modelling package has been
used in &lt;a class="reference external" href="https://math.nist.gov/oommf/oommf_cites.html"&gt;over 2500
publications&lt;/a&gt; since
1999.&lt;/p&gt;
&lt;p&gt;[1] Beg, M., Pepper, R. A., and Fangohr, H. User interfaces for
computational science: A domain specific language for OOMMF embedded in
Python. AIP Advances 7, 056025 (2017), &lt;a class="reference external" href="https://doi.org/10.1063/1.4977225"&gt;https://doi.org/10.1063/1.4977225&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Hans Fangohr</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/driving-simulation-and-data-analysis-of-magnetic-nanostructures-through-jupyter-notebook.html</guid><category>Data Science</category><category>Jupyter</category><category>Programming</category><category>Python</category><category>Science</category></item><item><title>Observe all your applications</title><link>https://pyvideo.org/pycon-de-2018/observe-all-your-applications.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;You just deployed your new version of an application or micro-service;
how do you know everything works as expected? You run your comprehensive
test suite to verify functional correctness for known scenarios and
performance tests before deploying, but does your application really
work at the moment or is it just responding with error messages to all
incoming requests?&lt;/p&gt;
&lt;p&gt;I’m part of the team that runs a huge infrastructure for the SAP HANA
development. This infrastructure is vital for nearly all development &amp;amp;
testing activities of SAP HANA. As this infrastructure is powered by
multiple in-house developed applications, we immediately want to know if
an application starts to fail and we need to be able to quickly diagnose
what caused the failure.&lt;/p&gt;
&lt;p&gt;This talk will give you an overview how we monitor our full stack from
the 2000 physical machines up to the 10,000 parallel running Python
application processes, micro-service instances and batch processing
jobs. It includes a review about the used tools, bad and good examples
of instrumentation in Python code, the resulting visualisation and an
outlook on upcoming improvements.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Christoph Heer</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/observe-all-your-applications.html</guid><category>DevOps</category><category>Infrastructure</category><category>Networks</category><category>Programming</category><category>Python</category></item><item><title>Achieving Resilient Code with Integration Tests</title><link>https://pyvideo.org/pycon-de-2018/achieving-resilient-code-with-integration-tests.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;You are maybe like me: I never learned at school how to write tests. My
teachers gave me at first a broad overview of computer history. Then,
they explained me some basic design patterns. And to finish, I often had
to write more or less basic programs, to validate and demonstrate my
skills. Not the kind of code I would be really proud of today: the
procrastinator monkey living in my head at this time was more thinking
about planning my summer holidays, rather than writing Ninja code!&lt;/p&gt;
&lt;p&gt;And to make things worse, my studies focused on network and system
engineering. Not software architecture. Funny story, because I decided
to become programmer a couple of years later…&lt;/p&gt;
&lt;p&gt;What I realize now is that I don’t have as much time as before to learn.
And in a world driven by business, where time is money, and where
tradeoffs are the rule, there is rarely enough money to write both shiny
new features and a complete test suite.&lt;/p&gt;
&lt;p&gt;People who practice Test-Driven Development know how complicated it can
be to write proper tests. TDD is often discouraging at first: the
learning curve is steep. But this problem also exists in the testing
world in general. Because writing good tests is hard, many beginners get
headaches trying to reach this goal. How to convince project managers to
have more time for writing tests in these conditions…&lt;/p&gt;
&lt;p&gt;But “le jeu en vaut la chandelle” as we say in French (&amp;quot;the juice is
worth the squeeze&amp;quot;). Well tested applications are not only easier to
maintain and extend. They also have in general a better API. That’s what
we will see in this talk, by focusing on how to write integration tests.
Our journey will begin with a presentation of different testing
strategies. We will then jump to the practical part, using Pytest,
interface testing , dependency injections and stubs, amongst many
others. And because we want to add nice buzzwords on our resume after
PyConDE, we will finish this talk by automating the whole with Docker
Compose.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexandre Figura</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/achieving-resilient-code-with-integration-tests.html</guid><category>Programming</category><category>Python</category></item><item><title>Introduction and practical experience about Quantum Computing using the Python libraries from IBM and Google</title><link>https://pyvideo.org/pycon-de-2018/introduction-and-practical-experience-about-quantum-computing-using-the-python-libraries-from-ibm-and-google.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As publicly announced in early 2018, Daimler AG has started cooperations
with IBM and Google on Quantum Computing. When doing concrete
experiments with the Quantum Computing cloud based offerings, two
different Python libraries provided by IBM and Google are used. They are
named QISKIT in the case of IBM and CIRQ in the case of Google. The
experiments with both libraries are handled using appropriate Jupyter
Notebooks. This talk gives a brief introduction on Quantum Computing,
specifically on Quantum Computers based on transmon-based QBits. This is
followed by an introduction of the both Python libraries that are used.
Then some details about the Jupyter notebooks that are used are given.
The talk will finish with some demos and an overview about the most
important practical experiences with both Quantum Computing offerings.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dr. Andreas Riegg</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/introduction-and-practical-experience-about-quantum-computing-using-the-python-libraries-from-ibm-and-google.html</guid><category>Jupyter</category><category>Programming</category><category>Python</category><category>Science</category></item><item><title>IoT using Python on Linux: Lessons Learned</title><link>https://pyvideo.org/pycon-de-2018/iot-using-python-on-linux-lessons-learned.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In a distributed sensor network system with a Java based Cloud
application, mobile apps and a proprietary radio protocol accompanying
it we developed an IoT appliance that connects the existing radio
infrastructure to the Cloud service developed in-house.&lt;/p&gt;
&lt;p&gt;Using CPython 3.5 + Debian GNU/Linux 9 on an ARMv7 platform, we
developed the following features:&lt;/p&gt;
&lt;p&gt;Over the course of this project, we learned a lot about Test Driven
Development of Python apps in teams and DevOps in the IoT space. We
would now like to share our experience developing a Python application
for a headless IoT device and the things we would liked to have known
upfront.&lt;/p&gt;
&lt;p&gt;The talk is held both by Matthias Schmidt (Senior Architect at diva-e)
and Thomas Keppler (Software Developer at diva-e).&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Keppler</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/iot-using-python-on-linux-lessons-learned.html</guid><category>DevOps</category><category>Infrastructure</category><category>Networks</category><category>Programming</category><category>Python</category></item><item><title>Pyccel, a Fortran static compiler for scientific High-Performance Computing</title><link>https://pyvideo.org/pycon-de-2018/pyccel-a-fortran-static-compiler-for-scientific-high-performance-computing.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Pyccel&lt;/em&gt; is a new &lt;strong&gt;static compiler&lt;/strong&gt; for Python that uses &lt;strong&gt;Fortran&lt;/strong&gt;
as backend language while enabling High-Performance Computing &lt;strong&gt;HPC&lt;/strong&gt;
capabilities.&lt;/p&gt;
&lt;p&gt;Fortran is a computer language for scientific programming that is
tailored for efficient run-time execution on a wide variety of
processors. Even if the &lt;em&gt;2003&lt;/em&gt; and &lt;em&gt;2008&lt;/em&gt; standards added major
improvements like &lt;em&gt;OOP, Coarrays, Submodules, do concurrent&lt;/em&gt; , etc ...
they are not covered by all available compilers. Moreover, the Fortran
developer still suffers from the lack of &lt;strong&gt;meta-programming&lt;/strong&gt; compared
to &lt;strong&gt;C++&lt;/strong&gt; ones. Therefore, it is more and more difficult for applied
mathematicians and computational physicists to write applications at the
&lt;em&gt;state of art&lt;/em&gt; (targeting CPUs, GPUs, MICs) while implementing
complicated algorithms or numerical schemes.&lt;/p&gt;
&lt;p&gt;Pyccel can be used in two cases:&lt;/p&gt;
&lt;p&gt;In order to achieve the second point, we developed an internal DSL for
&lt;em&gt;types&lt;/em&gt; and &lt;em&gt;macros&lt;/em&gt;. The later is used to map sentences based on
&lt;em&gt;mpi4py&lt;/em&gt; , &lt;em&gt;scipy.linalg.blas or lapack&lt;/em&gt; onto the appropriate calls in
Fortran. Moreover, two parsers, for &lt;em&gt;OpenMP&lt;/em&gt; and &lt;em&gt;OpenACC&lt;/em&gt; , were added
too, allowing for explicit parallelism through the use of pragmas.&lt;/p&gt;
&lt;p&gt;Last but not least, Pyccel is an extension of &lt;strong&gt;Sympy&lt;/strong&gt;. Actually, it
converts a Python code to symbolic expressions/trees, from a Full Syntax
Tree ( &lt;em&gt;RedBaron&lt;/em&gt; ), then annotates the new AST using types or different
settings provided by the user.&lt;/p&gt;
&lt;p&gt;In this talk, after a brief description of Pyccel, I will show different
applications including Finite Elements (1d, 2d, 3d), Semi-Lagrangian
schemes (4d), Kronecker linear solvers, diagnostics for 5D kinetic
simulations and Machine Learning for Partial Differential Equations.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dr. Ing. Ratnani Ahmed</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/pyccel-a-fortran-static-compiler-for-scientific-high-performance-computing.html</guid><category>Artificial Intelligence</category><category>Algorithms</category><category>Astronomy</category><category>Parallel Programming</category><category>Programming</category><category>Python</category><category>Science</category></item><item><title>Script, Library, or Executable: You can have it all!</title><link>https://pyvideo.org/pycon-de-2018/script-library-or-executable-you-can-have-it-all.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;I will describe one possible way to achieve this using the following
features:&lt;/p&gt;
&lt;p&gt;We want to create a package layout that can support a CLI interface, an
importable library, and a GUI all while sharing as much code as
possible.&lt;/p&gt;
&lt;p&gt;Although text and graphical interfaces are very different we can provide
a consistent API with careful consideration. This way users can easily
use our library or either interface without starting all over again.&lt;/p&gt;
&lt;p&gt;First we will layout a single-file CLI script using argparse similar to
the Unix &lt;tt class="docutils literal"&gt;wc&lt;/tt&gt; tool that takes a text file and outputs the following
information:&lt;/p&gt;
&lt;p&gt;We'll discuss the &lt;tt class="docutils literal"&gt;__name__ == __main__&lt;/tt&gt; Python idiom, separating the
argument parsing from the main function, and why keeping as little as
possible in &lt;tt class="docutils literal"&gt;__main__&lt;/tt&gt; is better for reusability.&lt;/p&gt;
&lt;p&gt;There are several pros and cons to providing others with a single-file
script. It's easy to develop and simple to read, but it requires any
user to have the correct version of Python installed. It's also
difficult for other developers to reuse the code in their own projects
or deploy to PyPI.&lt;/p&gt;
&lt;p&gt;Next we'll take our single-file script and expand it into a basic Python
package using a main folder, &lt;strong&gt;init&lt;/strong&gt;.py, and a cli.py script to expose
the same CLI as before.&lt;/p&gt;
&lt;p&gt;We'll discuss how to restructure the main and parsing functions from
step 1 into an public API defined by the &lt;strong&gt;init&lt;/strong&gt;.py that exposes the
same CLI functionality as a library.&lt;/p&gt;
&lt;p&gt;We won't dive into setup.py at all, but there will be links and a brief
description on the various tools to layout a package such as
cookiecutter and setup.py.&lt;/p&gt;
&lt;p&gt;The &lt;a class="reference external" href="https://github.com/chriskiehl/Gooey"&gt;Gooey&lt;/a&gt; project can easily
expose a CLI as GUI with a few decorators. We'll discuss briefly how to
use Gooey and some of the extra functionality it provides to create more
advanced GUIs.&lt;/p&gt;
&lt;p&gt;We'll also give a simple mental model for how it maps argparse argument
types to GUI widgets.&lt;/p&gt;
&lt;p&gt;Until step 3 all we required of users was a working Python 3
installation. However, adding Gooey requires users to have a working
Python installer, the Gooey library, and wxPython. Typically GUIs are
meant for higher-level users so asking them to install all of this to
benefit from our little app is too much.&lt;/p&gt;
&lt;p&gt;Instead we'll see how we run PyInstaller on our entry script to package
up all our dependencies &lt;strong&gt;including&lt;/strong&gt; Python itself into a simple
executable. We'll briefly discuss the build and dist output folders from
PyInstaller along with the ability to use it to package all sorts of
complicated Python applications using Qt, Numpy, etc.&lt;/p&gt;
&lt;p&gt;End-users in management don't even have to know we used Python!&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Luke Lee</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/script-library-or-executable-you-can-have-it-all.html</guid><category>Programming</category><category>Python</category></item><item><title>Selinon - dynamic distributed task flows</title><link>https://pyvideo.org/pycon-de-2018/selinon-dynamic-distributed-task-flows.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever tried to define and process complex workflows for data
processing? If the answer is yes, you might have struggled to find the
right framework for that. You've probably came across Celery - popular
task flow management for Python. Celery is great, but it does not
provide enough flexibility and dynamic features needed badly in complex
flows. As we discovered all the limitations, we decided to implement
Selinon.&lt;/p&gt;
&lt;p&gt;Have you ever tried to define and process complex workflows for data
processing? If the answer is yes, you might have struggled to find the
right framework for that. You've probably came across Celery - popular
task flow management for Python. Celery is great, but it does not
provide enough flexibility and dynamic features needed badly in complex
flows. As we discovered all the limitations, we decided to implement
Selinon.&lt;/p&gt;
&lt;p&gt;Selinon enhances Celery task flow management and allows you to create
and model task flows in your distributed environment that can
dynamically change behavior based on computed results in your cluster,
automatically resolve tasks that need to be executed in case of
selective task runs, automatic tracing mechanism and many others.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Fridolín Pokorný</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/selinon-dynamic-distributed-task-flows.html</guid><category>Big Data</category><category>Infrastructure</category><category>Parallel Programming</category><category>Programming</category><category>Python</category></item><item><title>Testing in Python - The Big Picture</title><link>https://pyvideo.org/pycon-de-2018/testing-in-python-the-big-picture.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Any team developing and maintaining software - be it free and open
source or commercial - employs one form of software testing or another.
But what are the different kinds of tests in our tool boxes? And how are
they best used? In this talk we'll take a look around and try to answer
these questions.&lt;/p&gt;
&lt;p&gt;First, we'll examine the basic concepts of testing: Everyone has
probably at least heard about &lt;em&gt;unit tests&lt;/em&gt; , but are they all you need?
&lt;em&gt;Performance tests&lt;/em&gt; can help you find out how well your product performs
under load and detect bottle necks early on. &lt;em&gt;Manual testing&lt;/em&gt; is often
looked down upon, since it's not automated, but is it always a bad idea?
And what even &lt;em&gt;is&lt;/em&gt; &lt;em&gt;mutation testing&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;We'll also get to know a lot of the amazing testing tools from the
Python ecosystem. Find out what the best test runner is (Spoiler alert:
it's pytest). Learn how to make writing test more fun and less work
using tools like mock, Faker and factory_boy. Measure the quality of
your test suite using coverage.py.&lt;/p&gt;
&lt;p&gt;But no tool is the right one for any situation. We'll also talk about
when and how to use each of the tools, while debunking common
misconceptions and demonstrating best practices.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Niklas Meinzer</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/testing-in-python-the-big-picture.html</guid><category>Programming</category><category>Python</category></item><item><title>PyOhio 2011: Procedures, Objects, Reusability: "httplib", "urllib2", and Their Discontents</title><link>https://pyvideo.org/pyohio-2011/pyohio-2011-procedures-objects-reusability-q.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Procedures, Objects, Reusability: httplib, urllib2 and their discontents&lt;/p&gt;
&lt;p&gt;Presented by Brandon Craig Rhodes&lt;/p&gt;
&lt;p&gt;Python supports two major programming paradigms: procedures, and object
orientation. This talk will claim that, when it comes to code re-use,
these two paradigms are NOT created equal: because object-oriented
programming encourages the programmer to write methods that consider
everything else inside of &amp;quot;self&amp;quot; to be fair game, it encourages highly
coupled code that proves brittle when extended.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brandon Rhodes</dc:creator><pubDate>Sat, 30 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-30:pyohio-2011/pyohio-2011-procedures-objects-reusability-q.html</guid><category>codereuse</category><category>httplib</category><category>oop</category><category>programming</category><category>pyohio</category><category>pyohio2011</category><category>reuse</category><category>self</category><category>urllib2</category></item><item><title>Learning a new codebase</title><link>https://pyvideo.org/djangocon-us-2010/djangocon-2010--learning-a-new-codebase.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will be on methods of reading code for comprehension. While
the project will be walking through various third-party Django apps, the
experiences and conclusions are drawn from joining a large, existing
Django project which lacked documentation.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;In the broadest sense, this talk is on how to read code. More than this,
it is a series of methods and practices which one can follow to get up
to speed on a new codebase. The subject of this talk will be
open-sourced Django projects, but many of the experiences which fuel
this talk will be based on joining a new team. It will cover tracing
execution paths, finding the more interesting portions of a codebase, as
well as how to address any issues you may have found in it.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Justin Lilly</dc:creator><pubDate>Thu, 09 Sep 2010 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2010-09-09:djangocon-us-2010/djangocon-2010--learning-a-new-codebase.html</guid><category>djangocon</category><category>djangocon2010</category><category>programming</category></item><item><title>SCons - Software bauen in Python</title><link>https://pyvideo.org/pycon-de-2013/scons-software-bauen-in-python.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Dieser Vortrag stellt SCons (www.scons.org) und seine Benutzung vor. Er
richtet sich in erster Linie an Softwareentwickler oder Betreuer von
großen Buildumgebungen, die nach Alternativen zu herkömmlichen Tools,
wie CMake oder autotools, suchen.&lt;/p&gt;
&lt;p&gt;SCons ist ein Buildsystem das vollständig in Python programmiert wird.
Die Eingabedateien zur Definition der einzelnen Buildschritte werden
ebenfalls als Pythonskripte ausgeführt. Durch diese Kombination einer
DSL (Domain Specific Language) mit der Allzwecksprache Python, lassen
sich auch komplizierte Softwareprojekte einfach spezifizieren und bauen.&lt;/p&gt;
&lt;p&gt;Das Framework das sich hinter dem Startskript verbirgt, ist auf einfache
Erweiterbarkeit und hohe Flexibilität ausgelegt.&lt;/p&gt;
&lt;p&gt;Während des Vortrags soll gezeigt werden wie man ein Projekt richtig
anfängt und make-typische Denkweisen vermeidet. Die Vorteile von SCons
und Standardfragen, z.B. zur Erweiterung des Systems für neue
Buildschritte, werden diskutiert.&lt;/p&gt;
&lt;p&gt;Am Ende soll der Zuhörer einen Eindruck von der Arbeitsweise des
Programms erhalten haben, und entscheiden können ob sich der Einsatz von
SCons für sein Softwareprojekt lohnen würde.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dirk Bächle</dc:creator><pubDate>Wed, 16 Oct 2013 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2013-10-16:pycon-de-2013/scons-software-bauen-in-python.html</guid><category>building</category><category>build system</category><category>framework</category><category>programming</category><category>software</category></item></channel></rss>