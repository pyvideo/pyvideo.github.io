<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - SciPy 2024</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/event_scipy-2024.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2024-07-08T00:00:00+00:00</updated><subtitle></subtitle><entry><title>A modern build-backend for CPython C/C++/Fortran/Cython extensions</title><link href="https://pyvideo.org/scipy-2024/a-modern-build-backend-for-cpython-ccfortrancython-extensions.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Jean-Christophe Fillion-Robin</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/a-modern-build-backend-for-cpython-ccfortrancython-extensions.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Discover how scikit-build-core revolutionizes Python extension building with its seamless integration of CMake and Python packaging standards. Learn about its enhanced features for cross-compilation, multi-platform support, and simplified configuration, which enable writing binary extensions with pybind11, Nanobind, Fortran, Cython, C++, and more. Dive into the transition from the classic …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Discover how scikit-build-core revolutionizes Python extension building with its seamless integration of CMake and Python packaging standards. Learn about its enhanced features for cross-compilation, multi-platform support, and simplified configuration, which enable writing binary extensions with pybind11, Nanobind, Fortran, Cython, C++, and more. Dive into the transition from the classic scikit-build to the robust scikit-build-core and explore its potential to streamline package distribution across various environments.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>An Integrated Toolkit for Collaborative Machine Learning Model Development</title><link href="https://pyvideo.org/scipy-2024/an-integrated-toolkit-for-collaborative-machine-learning-model-development.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Heinrich Peters</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/an-integrated-toolkit-for-collaborative-machine-learning-model-development.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Model Share AI (AIMS) is an easy-to-use Python library designed to streamline collaborative ML model development, model provenance tracking, and model deployment, as well as a host of other functions aiming to maximize the real-world impact of ML research. AIMS features collaborative project spaces, allowing users to analyze and …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Model Share AI (AIMS) is an easy-to-use Python library designed to streamline collaborative ML model development, model provenance tracking, and model deployment, as well as a host of other functions aiming to maximize the real-world impact of ML research. AIMS features collaborative project spaces, allowing users to analyze and compare their models in a standardized fashion. Model performance and various model metadata are automatically captured to facilitate provenance tracking and allow users to learn from and build on previous submissions. Additionally, AIMS allows users to deploy ML models built in Scikit-Learn, TensorFlow Keras, PyTorch, and ONNX into live REST APIs and automatically generated web apps with minimal code. The ability to deploy models with minimal effort and to make them accessible to non-technical end-users through web apps has the potential to make ML research more applicable to real-world challenges.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>An Introduction to Impact Charts</title><link href="https://pyvideo.org/scipy-2024/an-introduction-to-impact-charts.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Darren Vengroff</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/an-introduction-to-impact-charts.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Impact charts, as implemented in the impactchart (&lt;a class="reference external" href="https://github.com/vengroff/impactchart"&gt;https://github.com/vengroff/impactchart&lt;/a&gt;) package, make it easy to take a data set and visualize the impact of one variable on another in ways that techniques like scatter plots and linear regression can't, especially when there are other variables involved.&lt;/p&gt;
&lt;p&gt;In …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Impact charts, as implemented in the impactchart (&lt;a class="reference external" href="https://github.com/vengroff/impactchart"&gt;https://github.com/vengroff/impactchart&lt;/a&gt;) package, make it easy to take a data set and visualize the impact of one variable on another in ways that techniques like scatter plots and linear regression can't, especially when there are other variables involved.&lt;/p&gt;
&lt;p&gt;In this talk, we will introduce impact charts, demonstrate how they find easter-egg impacts we embed in synthetic data, show how they can find hidden impacts in a real-world use case, show how you can create your first impact chart with just a few lines of code, and finally talk a bit about the interpretable machine learning techniques they are built upon.&lt;/p&gt;
&lt;p&gt;Impact charts are primarily visual, so this talk will be too.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>anywidget: custom Jupyter Widgets made easy</title><link href="https://pyvideo.org/scipy-2024/anywidget-custom-jupyter-widgets-made-easy.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Trevor Manz</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/anywidget-custom-jupyter-widgets-made-easy.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Visualization plays a critical role in the analysis and decision making with data, yet the manner in which state-of-the-art visualization approaches are disseminated limit their adoption into modern analytical workflows. Jupyter Widgets bridge this gap between Python and interactive web interfaces, allowing for both programmatic and interactive manipulation of …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Visualization plays a critical role in the analysis and decision making with data, yet the manner in which state-of-the-art visualization approaches are disseminated limit their adoption into modern analytical workflows. Jupyter Widgets bridge this gap between Python and interactive web interfaces, allowing for both programmatic and interactive manipulation of data and code. However, their development has historically been tedious and error-prone.&lt;/p&gt;
&lt;p&gt;In this talk, you will learn about anywidget, a Python library that simplifies widgets, making their development more accessible, reliable, and enjoyable. I will showcase new visualization libraries built with anywidget and explain how its design enables environments beyond Jupyter to add support.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>AstroPhot: Fitting Everything Everywhere all at Once in Astronomical Images</title><link href="https://pyvideo.org/scipy-2024/astrophot-fitting-everything-everywhere-all-at-once-in-astronomical-images.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Connor Stone</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/astrophot-fitting-everything-everywhere-all-at-once-in-astronomical-images.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We present AstroPhot, a tool to accelerate the analysis of astronomical images. AstroPhot allows for simultaneously modelling images with galaxies and point sources in multi-band and time domain data. In this talk I will the benefits and challenges of how we used PyTorch (a differentiable and GPU accelerated scientific …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We present AstroPhot, a tool to accelerate the analysis of astronomical images. AstroPhot allows for simultaneously modelling images with galaxies and point sources in multi-band and time domain data. In this talk I will the benefits and challenges of how we used PyTorch (a differentiable and GPU accelerated scientific python library) to allow for fast development without sacrificing numerical performance. I will detail our development process as well as how we encourage users of all skill levels to engage with our documentation/tools.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Atomistic uncertainty driven data generation in ANI neural network potentials</title><link href="https://pyvideo.org/scipy-2024/atomistic-uncertainty-driven-data-generation-in-ani-neural-network-potentials.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Nick Terrel</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/atomistic-uncertainty-driven-data-generation-in-ani-neural-network-potentials.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Using machine learning to predict chemical properties and behavior is an important complement to traditional approaches to computation and simulation in chemistry. The ANAKIN-ME (ANI) methodology has been shown to produce generalized and transferable neural network potentials, trained on density functional theory (DFT) molecular energies, at a greatly reduced …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Using machine learning to predict chemical properties and behavior is an important complement to traditional approaches to computation and simulation in chemistry. The ANAKIN-ME (ANI) methodology has been shown to produce generalized and transferable neural network potentials, trained on density functional theory (DFT) molecular energies, at a greatly reduced computational cost. The work presented here details an approach to generating new data in an active learning scheme in order to improve predictions in the regions of chemical space with high predictive uncertainty at the atom level.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Bridging the gap between Earth Engine and the Scientific Python Ecosystem</title><link href="https://pyvideo.org/scipy-2024/bridging-the-gap-between-earth-engine-and-the-scientific-python-ecosystem.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Qiusheng Wu</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/bridging-the-gap-between-earth-engine-and-the-scientific-python-ecosystem.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Google Earth Engine's new data extraction interfaces seamlessly transfer geospatial data into familiar Python formats provided by NumPy, Pandas, GeoPandas, and Xarray. This integration empowers you to harness Earth Engine's vast data catalog and compute power directly within your preferred Python workflows. For example, the Xee library leverages Xarray's …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Google Earth Engine's new data extraction interfaces seamlessly transfer geospatial data into familiar Python formats provided by NumPy, Pandas, GeoPandas, and Xarray. This integration empowers you to harness Earth Engine's vast data catalog and compute power directly within your preferred Python workflows. For example, the Xee library leverages Xarray's lazy evaluation and Dask to streamline the extraction and analysis of Earth Engine data, offering a more Pythonic alternative to traditional image exports. Earth Engine's new data extraction interfaces unlock fresh geospatial analysis potential by leveraging the unique strengths of both the scientific Python ecosystem and Earth Engine.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Building Daft: Python + Rust = a better distributed query engine</title><link href="https://pyvideo.org/scipy-2024/building-daft-python-rust-a-better-distributed-query-engine.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Jay Chia</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/building-daft-python-rust-a-better-distributed-query-engine.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python is a popular language for data engineering workloads. In data engineering, developers must use a &amp;quot;Query Engine&amp;quot; to efficiently retrieve data, run data processing and then send data back out to a destination storage system or application.&lt;/p&gt;
&lt;p&gt;The Python API for Apache Spark (PySpark) is currently the most …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python is a popular language for data engineering workloads. In data engineering, developers must use a &amp;quot;Query Engine&amp;quot; to efficiently retrieve data, run data processing and then send data back out to a destination storage system or application.&lt;/p&gt;
&lt;p&gt;The Python API for Apache Spark (PySpark) is currently the most popular framework that most data engineers use for data engineering at large scale. However, PySpark has a heavy dependency on the JVM which causes high friction during the development process.&lt;/p&gt;
&lt;p&gt;In this talk, we discuss our work with the Daft Python Dataframe (www.getdaft.io) which is a distributed Python query engine built with Rust. We will perform a deep-dive into Daft architecture, and talk about how the strong synergy between Python and Rust enables key advantages for Daft to succeed as a query engine.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Coming Online: Enabling Real-Time and AI-Ready Scientific Discovery</title><link href="https://pyvideo.org/scipy-2024/coming-online-enabling-real-time-and-ai-ready-scientific-discovery.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Luigi Cruz</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/coming-online-enabling-real-time-and-ai-ready-scientific-discovery.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;From radio telescopes to proton accelerators, scientific instruments produce tremendous amounts of data at equally high rates. To handle this data deluge and to ensure the fidelity of the instruments’ observations, architects have historically written measurements to disk, enabling downstream scientists and researchers to build applications with pre-recorded files …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;From radio telescopes to proton accelerators, scientific instruments produce tremendous amounts of data at equally high rates. To handle this data deluge and to ensure the fidelity of the instruments’ observations, architects have historically written measurements to disk, enabling downstream scientists and researchers to build applications with pre-recorded files. The future of scientific computing is interactive and streaming; how many Nobel Prizes are hidden on a dusty hard drive that a scientist didn’t have time or resources to analyze? In this talk, NVIDIA and the SETI institute will present their joint work in building scalable, real time, high performance, and AI ready sensor processing pipelines at the Allen Telescope Array. Our goal is to provide all scientific computing developers with the tools and tips to connect high speed sensors to GPU compute and lower the time to scientific insights.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Dask in Production</title><link href="https://pyvideo.org/scipy-2024/dask-in-production.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Matthew Rocklin</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/dask-in-production.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Distributed systems are neat to demo, but hard to use in reality.&lt;/p&gt;
&lt;p&gt;This talk goes through lessons learned running 100,000s of Dask clusters and 1,000,000,000s of Python functions for users in critical production settings across many companies and research groups.&lt;/p&gt;
&lt;p&gt;We'll cover lessons learned like …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Distributed systems are neat to demo, but hard to use in reality.&lt;/p&gt;
&lt;p&gt;This talk goes through lessons learned running 100,000s of Dask clusters and 1,000,000,000s of Python functions for users in critical production settings across many companies and research groups.&lt;/p&gt;
&lt;p&gt;We'll cover lessons learned like ...&lt;/p&gt;
&lt;p&gt;GIL Vigilance is Good
Kubernetes is too heavyweight if all you want is lots of jobs
ARM is underused
Docker doesn't work well for data science folks
Availability-Zones are key for spot/GPU availability
Adaptive is underused (but hard)
Most workloads are small
Most workloads are fast
Most users don't scale up properly
Most people overestimate costs
These lessons will be motivated by tons of metadata collected and aggregated from real-world workloads.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Delivering state of the art imaging data science to aid research and development</title><link href="https://pyvideo.org/scipy-2024/delivering-state-of-the-art-imaging-data-science-to-aid-research-and-development.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Aakash Varambhia</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/delivering-state-of-the-art-imaging-data-science-to-aid-research-and-development.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Johnson Matthey (JM) leads in sustainable technologies, employing advanced science to address global challenges in energy, chemicals, and automotive sectors. Our cutting-edge research and development (R&amp;amp;D) facilities include state-of-the-art characterization tools, handling diverse datasets like images, timeseries, 3D tomograms, spectra, and digital twins. With the rising demand for …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Johnson Matthey (JM) leads in sustainable technologies, employing advanced science to address global challenges in energy, chemicals, and automotive sectors. Our cutting-edge research and development (R&amp;amp;D) facilities include state-of-the-art characterization tools, handling diverse datasets like images, timeseries, 3D tomograms, spectra, and digital twins. With the rising demand for data-driven insights, Python has emerged as a vital tool in enhancing decision-making processes. We showcase our utilization of the open-source community to construct our data science research platform, marking a significant step forward in our innovation journey.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Echostack: A scalable open-source software suite for echosounder data processing</title><link href="https://pyvideo.org/scipy-2024/echostack-a-scalable-open-source-software-suite-for-echosounder-data-processing.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Wu-Jung Lee</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/echostack-a-scalable-open-source-software-suite-for-echosounder-data-processing.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Water column sonar data collected by echosounders are essential for fisheries and marine ecosystem research, enabling the detection, classification, and quantification of fish and zooplankton from many different ocean observing platforms. However, the broad usage of these data has been hindered by the lack of modular software tools that …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Water column sonar data collected by echosounders are essential for fisheries and marine ecosystem research, enabling the detection, classification, and quantification of fish and zooplankton from many different ocean observing platforms. However, the broad usage of these data has been hindered by the lack of modular software tools that allow flexible composition of data processing workflows that incorporate powerful analytical tools in the scientific Python ecosystem. We address this gap by developing Echostack, a suite of open-source Python software packages that leverage existing distributed computing and cloud-interfacing libraries to support intuitive and scalable data access, processing, and interpretation. These tools can be used individually or orchestrated together, which we demonstrate in example use cases for a fisheries acoustic-trawl survey.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Effective Mentoring Strategies for an Inclusive Community</title><link href="https://pyvideo.org/scipy-2024/effective-mentoring-strategies-for-an-inclusive-community.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Anita Sarma</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/effective-mentoring-strategies-for-an-inclusive-community.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Join us for the Diversity Keynote Luncheon. Lunch will be provided in the foyer of the ballroom.&lt;/p&gt;
&lt;p&gt;Dr. Anita Sarma is a Professor in the School of Electrical Engineering and Computer Science. She received her Ph.D. in Computer Science from the University of California, Irvine and was a …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Join us for the Diversity Keynote Luncheon. Lunch will be provided in the foyer of the ballroom.&lt;/p&gt;
&lt;p&gt;Dr. Anita Sarma is a Professor in the School of Electrical Engineering and Computer Science. She received her Ph.D. in Computer Science from the University of California, Irvine and was a postdoctoral fellow at Carnegie Mellon University. Her research aims to understand the cognitive processes of humans and build inclusive technology to help diverse users. Together with her collaborators and students she has co-authored more than 100 conference and journal articles and has received numerous awards. She received the OSU Breaking Barriers Research award (2021) and the Google Inclusion award for her work in creating inclusive software. She co-leads the GenderMag project and the SocioeconomicMag project.&lt;/p&gt;
</content><category term="SciPy 2024"></category><category term="Keynote"></category></entry><entry><title>Expanding the OME ecosystem for imaging data management</title><link href="https://pyvideo.org/scipy-2024/expanding-the-ome-ecosystem-for-imaging-data-management.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Erick Martins Ratamero</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/expanding-the-ome-ecosystem-for-imaging-data-management.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Image analysis is ubiquitous across many areas of biomedical research, resulting in terabytes of image data that must be hosted by both research institutions and data repositories for sharing and reproducibility. Common solutions for data hosting are required to improve interoperability and accessibility of bioimage data, while maintaining the …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Image analysis is ubiquitous across many areas of biomedical research, resulting in terabytes of image data that must be hosted by both research institutions and data repositories for sharing and reproducibility. Common solutions for data hosting are required to improve interoperability and accessibility of bioimage data, while maintaining the flexibility to address each institution's unique requirements regarding sharing and infrastructure. OMERO is an open-source solution for image data management which can be customized and hosted by individual institutions. OMERO runs a server-based application with web browser and command line options for accessing and viewing image data, based on the widely used OME data model for microscopy data. Multiple OMERO deployments might be used to provide core delivery, facilitate internal research, or serve as a public data repository. The omero-cli-transfer package facilitates data transfer between these OMERO instances and provides new methods for importing datasets. Another open-source package, ezomero, improves the usability of OMERO in a research environment by providing easier access to OMERO's Python interface. Along with existing OMERO plugins built for other analysis and viewing software, this positions OMERO to be a hub for image storage, analysis, and sharing.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Explainable AI for Climate Science: Opening the black box to reveal earth</title><link href="https://pyvideo.org/scipy-2024/explainable-ai-for-climate-science-opening-the-black-box-to-reveal-earth.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Elizabeth Barnes</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/explainable-ai-for-climate-science-opening-the-black-box-to-reveal-earth.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Earth’s climate is chaotic and noisy. Finding usable signals amidst all of the noise can be challenging: be it predicting if it will rain, knowing which direction a hurricane will go, understanding the implications of melting Arctic ice, or detecting the impacts of humans on the earth’s …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Earth’s climate is chaotic and noisy. Finding usable signals amidst all of the noise can be challenging: be it predicting if it will rain, knowing which direction a hurricane will go, understanding the implications of melting Arctic ice, or detecting the impacts of humans on the earth’s surface. Here, I will demonstrate how explainable artificial intelligence (XAI) techniques can sift through vast amounts of climate data and push the bounds of scientific discovery: allowing scientists to ask “why?” but now with the power of machine learning.&lt;/p&gt;
&lt;p&gt;Dr. Elizabeth (Libby) Barnes is a Professor of Atmospheric Science at Colorado State University. She joined the CSU faculty in 2013 after obtaining dual B.S. degrees (Honors) in Physics and Mathematics from the University of Minnesota, obtaining her Ph.D. in Atmospheric Science from the University of Washington, and spending a year as a NOAA Climate &amp;amp; Global Change Fellow at the Lamont-Doherty Earth Observatory. Professor Barnes' research is largely focused on climate variability, predictability, and change and the data analysis tools used to understand it.&lt;/p&gt;
&lt;p&gt;Dr. Barnes' current research topics of interest include earth system predictability, subseasonal-to-decadal (S2D) prediction, climate intervention research, and data science methods for earth system research (e.g. machine learning, causal discovery). She teaches graduate courses on fundamental atmospheric dynamics and data science and statistical analysis methods. Professor Barnes is involved in a number of research community activities. In addition to being a member of the National Academies's Committee on Earth Science and Applications from Space, on the National Academies' Board on Atmospheric Science and Climate, a funded member of the NSF AI Institute for Research on Trustworthy AI in Weather, Climate and Coastal Oceanography (AI2ES), and on the Steering Committee of the CSU Data Science Research Institute, she recently finished being the lead of the NOAA MAPP S2S Prediction Task Force (2016-2020).&lt;/p&gt;
&lt;p&gt;Dr. Barnes received the AGU Macelwane Medal and became a Fellow of the AGU in 2021, received the AGU Turco Lectureship for 2020, AMS Clarence Leroy Meisinger Award for 2020, and was awarded an NSF CAREER grant in 2018. She received the George T. Abell Outstanding Early-Career Faculty Award in 2016 and was recognized for her teaching and mentoring by being awarded an Honorable Mention for the CSU Graduate Advising and Mentorship Award in 2017 and being named the Outstanding Professor of the Year Award in 2016 and 2022 by the graduate students of the Department of Atmospheric Science. In 2014 she was the recipient of an AGU James R. Holton Junior Scientist Award.&lt;/p&gt;
&lt;p&gt;Women's History Month: A conversation with Dr. Elizabeth Barnes&lt;/p&gt;
</content><category term="SciPy 2024"></category><category term="Keynote"></category></entry><entry><title>Free, public, standardized Zarr stores of geospatial data in the cloud for all!</title><link href="https://pyvideo.org/scipy-2024/free-public-standardized-zarr-stores-of-geospatial-data-in-the-cloud-for-all.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Christine Smit</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/free-public-standardized-zarr-stores-of-geospatial-data-in-the-cloud-for-all.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At the NASA Goddard Earth Sciences (GES) Data and Information Services Center (DISC), we're doing the heavy lifting to make large geospatial datasets easily accessible from the cloud. No more downloading data. No more worrying about quirky metadata or missing dimensions. No more concatenating hundreds or thousands of files …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At the NASA Goddard Earth Sciences (GES) Data and Information Services Center (DISC), we're doing the heavy lifting to make large geospatial datasets easily accessible from the cloud. No more downloading data. No more worrying about quirky metadata or missing dimensions. No more concatenating hundreds or thousands of files together. Just fire up your Jupyter notebook somewhere in Amazon Web Services (AWS)'s US-West-2 region, get some free temporary AWS credentials, open our Zarr stores, and start doing your science.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>From no CPython C API experience to shipping a new DType in NumPy 2.0</title><link href="https://pyvideo.org/scipy-2024/from-no-cpython-c-api-experience-to-shipping-a-new-dtype-in-numpy-20.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Nathan Goldbaum</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/from-no-cpython-c-api-experience-to-shipping-a-new-dtype-in-numpy-20.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Support for string data in NumPy has long been a sore spot for the community. At the beginning of 2023 I was given the task to solve that problem by writing a new UTF-8 variable-length string DType leveraging the new NumPy DType API. I will offer my personal narrative …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Support for string data in NumPy has long been a sore spot for the community. At the beginning of 2023 I was given the task to solve that problem by writing a new UTF-8 variable-length string DType leveraging the new NumPy DType API. I will offer my personal narrative of how I accomplished that goal over the course of 2023 and offer my experience as a model for others to take on difficult projects in the scientific python ecosystem, offering tips for how to get help when needed and contribute productively to an established open source community.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>From Spyder to DataLab: 15 years of scientific software crafting in Python</title><link href="https://pyvideo.org/scipy-2024/from-spyder-to-datalab-15-years-of-scientific-software-crafting-in-python.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Pierre Raybaut</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/from-spyder-to-datalab-15-years-of-scientific-software-crafting-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk provides an overview of the evolution of scientific software in Python, with a focus on the speaker's journey from creating Spyder (&lt;a class="reference external" href="https://www.spyder-ide.org/"&gt;https://www.spyder-ide.org/&lt;/a&gt;), the Scientific Python IDE, to developing DataLab (&lt;a class="reference external" href="https://datalab-platform.com/"&gt;https://datalab-platform.com/&lt;/a&gt;), a platform for signal and image processing. The speaker will share insights …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk provides an overview of the evolution of scientific software in Python, with a focus on the speaker's journey from creating Spyder (&lt;a class="reference external" href="https://www.spyder-ide.org/"&gt;https://www.spyder-ide.org/&lt;/a&gt;), the Scientific Python IDE, to developing DataLab (&lt;a class="reference external" href="https://datalab-platform.com/"&gt;https://datalab-platform.com/&lt;/a&gt;), a platform for signal and image processing. The speaker will share insights into the challenges and opportunities encountered in developing and maintaining these projects, and discuss how they have contributed to the scientific Python ecosystem. The talk will also explore the evolving needs of both the scientific and industrial communities during this period, and why desktop applications remain relevant in the era of web-based tools.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>geosnap: The Geospatial Neighborhood Analysis Package</title><link href="https://pyvideo.org/scipy-2024/geosnap-the-geospatial-neighborhood-analysis-package.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Eli Knaap</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/geosnap-the-geospatial-neighborhood-analysis-package.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The representation, synthesis, modeling, and visualization of neighborhoods is a fundamental pursuit across a range of social sciences.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Great Tables for Everyone</title><link href="https://pyvideo.org/scipy-2024/great-tables-for-everyone.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Richard Iannone</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/great-tables-for-everyone.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Do you find yourself copying your data into Word, just to make a table? If this is you (and this was us) it’s both frustrating and prone to errors. And even though every aspect of a typical analysis can be scripted, it often turns out that the table-making …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Do you find yourself copying your data into Word, just to make a table? If this is you (and this was us) it’s both frustrating and prone to errors. And even though every aspect of a typical analysis can be scripted, it often turns out that the table-making part is elusive. We made Great Tables to enable complete publishing workflows. This Python package lets you easily generate publication-quality tables with the structure you want, many options for formatting values, and plenty of freedom for styling. Importantly, Great Tables closely integrates with Pandas and Polars DataFrames in order to handle a wide range of analyses.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>How the Scientific Python ecosystem helps answering fundamental questions of the Universe</title><link href="https://pyvideo.org/scipy-2024/how-the-scientific-python-ecosystem-helps-answering-fundamental-questions-of-the-universe.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Vangelis Kourlitis</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/how-the-scientific-python-ecosystem-helps-answering-fundamental-questions-of-the-universe.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The ATLAS experiment at CERN explores vast amounts of physics data to answer the most fundamental questions of the Universe. The prevalence of Python in scientific computing motivated ATLAS to adopt it for its data analysis workflows while enhancing users' experience. This talk will describe to a broad audience …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The ATLAS experiment at CERN explores vast amounts of physics data to answer the most fundamental questions of the Universe. The prevalence of Python in scientific computing motivated ATLAS to adopt it for its data analysis workflows while enhancing users' experience. This talk will describe to a broad audience how a large scientific collaboration leverages the power of the Scientific Python ecosystem to tackle domain-specific challenges and advance our understanding of the Cosmos. Through a simplified example of the renowned Higgs boson discovery, attendees will gain insights into the utilization of Python libraries to discriminate a signal in immersive noise, through tasks such as data cleaning, feature engineering, statistical interpretation and visualization at scale.&lt;/p&gt;
&lt;p&gt;GitHub repository for the talk: &lt;a class="reference external" href="https://github.com/ekourlit/scipy2024-ATLAS-demo"&gt;https://github.com/ekourlit/scipy2024-ATLAS-demo&lt;/a&gt;&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>How to bootstrap a Data Warehouse with DuckDB</title><link href="https://pyvideo.org/scipy-2024/how-to-bootstrap-a-data-warehouse-with-duckdb.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Guen Prawiroatmodjo</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/how-to-bootstrap-a-data-warehouse-with-duckdb.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A Data Warehouse (DW) is a powerful tool to manage your scientific data, training data, logs, or any other type of relational data. Most Data Warehouses are cloud-based and built to scale to petabyte workflows, but might not be optimal for smaller workloads that need a fast iteration cycle …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A Data Warehouse (DW) is a powerful tool to manage your scientific data, training data, logs, or any other type of relational data. Most Data Warehouses are cloud-based and built to scale to petabyte workflows, but might not be optimal for smaller workloads that need a fast iteration cycle. Likewise, a collection of CSV files and python scripts can become painful to share and maintain. This is where DuckDB comes in! DuckDB is a fast, in-process database that you can run on your laptop, supports a rich SQL dialect, and you can push to the cloud with just a single line of code. In this talk, we’ll show you how to bootstrap a Data Warehouse on your laptop using open source, including ETL (extract-transform-load) data pipelines, dashboard visualization, and sharing via the cloud.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>How to foster an open source culture within your data science team</title><link href="https://pyvideo.org/scipy-2024/how-to-foster-an-open-source-culture-within-your-data-science-team.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Eric Ma</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/how-to-foster-an-open-source-culture-within-your-data-science-team.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, I will discuss how one can foster a culture of open source contributions at one's company. Based on my successes and failures as a data scientist working in the biotech space, I will describe two key ideas (fostering internal open source and articulating value to key …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, I will discuss how one can foster a culture of open source contributions at one's company. Based on my successes and failures as a data scientist working in the biotech space, I will describe two key ideas (fostering internal open source and articulating value to key senior leadership) as being on the critical path to generating buy-in within the organization.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>HyperSpy - Your Multidimensional Data Analysis Toolbox</title><link href="https://pyvideo.org/scipy-2024/hyperspy-your-multidimensional-data-analysis-toolbox.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Joshua Taillon</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/hyperspy-your-multidimensional-data-analysis-toolbox.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;HyperSpy is a community-developed open-source library providing a framework to facilitate interactive and reproducible analyses of multidimensional datasets. Born out of the electron microscopy scientific community and building on the extensive scientific Python environment, HyperSpy provides tools to efficiently explore, manipulate, and visualize complex datasets of arbitrary dimensionality, including …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;HyperSpy is a community-developed open-source library providing a framework to facilitate interactive and reproducible analyses of multidimensional datasets. Born out of the electron microscopy scientific community and building on the extensive scientific Python environment, HyperSpy provides tools to efficiently explore, manipulate, and visualize complex datasets of arbitrary dimensionality, including those larger than a system's memory. After 14 years of development, HyperSpy recently celebrated its 2.0 version release. This presentation will (re)introduce HyperSpy's features and community, with a focus on recent efforts paring the library into a domain-agnostic core and a robust ecosystem of extensions providing specific scientific functionality.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Ibis: because SQL is everywhere and so is Python</title><link href="https://pyvideo.org/scipy-2024/ibis-because-sql-is-everywhere-and-so-is-python.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Gil Forsyth</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/ibis-because-sql-is-everywhere-and-so-is-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tabular data is ubiquitous, and pandas has been the de facto tool in Python for analyzing it. However, as data size scales, analysis using pandas may become untenable. Luckily, modern analytical databases (like DuckDB) are able to analyze this same tabular data, but perform orders-of-magnitude faster than pandas, all …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tabular data is ubiquitous, and pandas has been the de facto tool in Python for analyzing it. However, as data size scales, analysis using pandas may become untenable. Luckily, modern analytical databases (like DuckDB) are able to analyze this same tabular data, but perform orders-of-magnitude faster than pandas, all while using less memory. Many of these systems only provide a SQL interface though; something far different from pandas’ dataframe interface, requiring a rewrite of your analysis code.&lt;/p&gt;
&lt;p&gt;This talk will lay out the current database / data landscape as it relates to the SciPy stack, and explore how Ibis (an open-source, pure Python, dataframe interface library) can help decouple interfaces from engines, to improve both performance and portability. We'll examine other solutions for interacting with SQL from Python and discuss some of their strengths and weaknesses.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Ibis + DuckDB geospatial: a match made on Earth</title><link href="https://pyvideo.org/scipy-2024/ibis-duckdb-geospatial-a-match-made-on-earth.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Naty Clementi</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/ibis-duckdb-geospatial-a-match-made-on-earth.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Geospatial data is becoming more present in data workflows today, and plenty of Python tools allow us to work with it. In the past year, a new contender emerged: DuckDB introduced an extension for analyzing geospatial data. Everyone in the data world has been buzzing about DuckDB (~15k stars …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Geospatial data is becoming more present in data workflows today, and plenty of Python tools allow us to work with it. In the past year, a new contender emerged: DuckDB introduced an extension for analyzing geospatial data. Everyone in the data world has been buzzing about DuckDB (~15k stars on GitHub), and now this duck quacks geospatial data too. But wait a minute, isn’t DuckDB all SQL? Yes, but fear not, Ibis has you covered! Ibis is a Python library that provides a dataframe-like interface, enabling users to write Python code to construct SQL expressions that can be executed on multiple backends, like DuckDB. In this talk, you will learn how to leverage the benefits of DuckDB geospatial while remaining in the Python ecosystem (yes, we will do a live demo). This is an introductory talk; everyone is welcome, and no previous experience with spatial databases or geospatial workflows is needed.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Injecting Python Functions into a Template-Driven CUDA C++ Framework</title><link href="https://pyvideo.org/scipy-2024/injecting-python-functions-into-a-template-driven-cuda-c-framework.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Braxton Cuneo</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/injecting-python-functions-into-a-template-driven-cuda-c-framework.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Non-Python codebases that use metaprogramming present significant challenges to cross-language development. These challenges are further compounded with the inclusion of GPU processing. While common methods of Python/GPU interoperation are covered by popular Python frameworks, these frameworks do not trivialize this use case.&lt;/p&gt;
&lt;p&gt;In this talk, we will discuss …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Non-Python codebases that use metaprogramming present significant challenges to cross-language development. These challenges are further compounded with the inclusion of GPU processing. While common methods of Python/GPU interoperation are covered by popular Python frameworks, these frameworks do not trivialize this use case.&lt;/p&gt;
&lt;p&gt;In this talk, we will discuss the process of integrating a Python code for Monte Carlo particle transport (MCDC) (&lt;a class="reference external" href="https://github.com/CEMeNT-PSAAP/MCDC"&gt;https://github.com/CEMeNT-PSAAP/MCDC&lt;/a&gt;) with a template-based CUDA C++ framework which applies inversion of control (Harmonize) (&lt;a class="reference external" href="https://github.com/CEMeNT-PSAAP/harmonize"&gt;https://github.com/CEMeNT-PSAAP/harmonize&lt;/a&gt;). We will discuss managing the complexity of cross-language dependency injection, relevant implementation strategies, and pitfalls to avoid.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Introducing nanoarrow: the world's tiniest Arrow Implementation</title><link href="https://pyvideo.org/scipy-2024/introducing-nanoarrow-the-worlds-tiniest-arrow-implementation.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Dewey Dunnington</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/introducing-nanoarrow-the-worlds-tiniest-arrow-implementation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;nanoarrow, a newly developed subproject of Apache Arrow, is squarely focused on unlocking connectivity among Python packages and the libraries they wrap using the features and rich type support of the Arrow columnar format. The vision of nanoarrow is that it should be trivial for a library to implement …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;nanoarrow, a newly developed subproject of Apache Arrow, is squarely focused on unlocking connectivity among Python packages and the libraries they wrap using the features and rich type support of the Arrow columnar format. The vision of nanoarrow is that it should be trivial for a library to implement an Arrow-based interface: nanoarrow and its bindings provide tools to produce, consume, and transport tabular data between processes using the Arrow IPC format or between libraries using the Arrow C ABI. For Python maintainers this means less glue code that runs faster so that developers can focus on feature development.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Introduction to Causal Inference with Machine Learning</title><link href="https://pyvideo.org/scipy-2024/introduction-to-causal-inference-with-machine-learning.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Hajime Takeda</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/introduction-to-causal-inference-with-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Causal inference has traditionally been used in fields such as economics, health studies, and social sciences. In recent years, algorithms combining causal inference and machine learning have been a hot topic. Libraries like EconML and CausalML, for instance, are good Python tools that facilitate the easy execution of causal …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Causal inference has traditionally been used in fields such as economics, health studies, and social sciences. In recent years, algorithms combining causal inference and machine learning have been a hot topic. Libraries like EconML and CausalML, for instance, are good Python tools that facilitate the easy execution of causal analysis in areas like economics, human behavior, and marketing. In this talk, I will explain key concepts of causal inference with machine learning, show practical examples, and offer some practical tips. Attendees will learn how to apply machine learning to causal analysis effectively, boosting their research and decision-making.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>ITK-Wasm: Universal spatial analysis and visualization</title><link href="https://pyvideo.org/scipy-2024/itk-wasm-universal-spatial-analysis-and-visualization.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Matt McCormick</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/itk-wasm-universal-spatial-analysis-and-visualization.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;ITK-Wasm combines the Insight Toolkit (ITK) and WebAssembly to enable high-performance spatial analysis across programming languages and hardware architectures.&lt;/p&gt;
&lt;p&gt;ITK-Wasm Python packages work in a web browser via Pyodide but also in system-level environments. We describe how ITK-Wasm bridges WebAssembly with Scientific Python through simple fundamental Python and NumPy-based …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;ITK-Wasm combines the Insight Toolkit (ITK) and WebAssembly to enable high-performance spatial analysis across programming languages and hardware architectures.&lt;/p&gt;
&lt;p&gt;ITK-Wasm Python packages work in a web browser via Pyodide but also in system-level environments. We describe how ITK-Wasm bridges WebAssembly with Scientific Python through simple fundamental Python and NumPy-based data structures and Pythonic function interfaces. These interfaces can be accelerated through GPU implementations when available.&lt;/p&gt;
&lt;p&gt;We discuss how ITK-Wasm's integration of the WebAssembly Component Model launches Scientific Python into a new world of interoperability, enabling the creation of accessible and sustainable multi-language projects that are easily distributed anywhere.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Keynote: Particles, People, and Pull Requests</title><link href="https://pyvideo.org/scipy-2024/keynote-particles-people-and-pull-requests.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Kyle Cranmer</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/keynote-particles-people-and-pull-requests.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;I will tell the story of how the statistical challenges in the search for the Higgs boson and exotic new physics at the Large Hadron Collider led to new approaches to collaborative, open science. The story centers around computational and sociological challenges where software and cyberinfrastructure play a key …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;I will tell the story of how the statistical challenges in the search for the Higgs boson and exotic new physics at the Large Hadron Collider led to new approaches to collaborative, open science. The story centers around computational and sociological challenges where software and cyberinfrastructure play a key role. I will highlight a few important changes in perspective that were critical for progress including embracing declarative specifications, pivoting from reproducibility to reuse, and the abstraction that led to the field of simulation-based inference.&lt;/p&gt;
&lt;p&gt;Kyle Cranmer is the David R. Anderson Director of the University of Wisconsin-Madison’s Data Science Institute and a Professor of Physics with courtesy appointments in Statistics and Computer Science. He is also the Editor in Chief of the journal Machine Learning Science and Technology. Before moving to Madison, Cranmer was a Professor of Physics and Data Science at NYU from 2007 – 2022, where he also served as the Executive Director of the Moore-Sloan Data Science Environment at NYU. He obtained his Ph.D. in Physics from the University of Wisconsin-Madison in 2005. He was awarded the Presidential Early Career Award for Science and Engineering in 2007, the National Science Foundation's Career Award in 2009, and became a Fellow of the American Physical Society in 2021 for his work at the Large Hadron Collider. Professor Cranmer developed a framework that enables collaborative statistical modeling, which was used extensively for the discovery of the Higgs boson in 2012. He has been an advocate for open science, open source software, and shared cyberinfrastructure. At UW-Madison he has established an Open Source Program Office and actively collaborates with groups like NumFOCUS and the Academic Data Science Alliance to strengthen academic contributions to open source.&lt;/p&gt;
</content><category term="SciPy 2024"></category><category term="Keynote"></category></entry><entry><title>LlamaBot: a Pythonic interface to Large Language Models</title><link href="https://pyvideo.org/scipy-2024/llamabot-a-pythonic-interface-to-large-language-models.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Eric Ma</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/llamabot-a-pythonic-interface-to-large-language-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, I will present LlamaBot, a Pythonic and modular set of components to build command line and backend tools that leverage large language models (LLMs). During this talk, I will showcase the core design philosophy, internal architecture and dependencies, and live demo command-line applications built using LlamaBot …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, I will present LlamaBot, a Pythonic and modular set of components to build command line and backend tools that leverage large language models (LLMs). During this talk, I will showcase the core design philosophy, internal architecture and dependencies, and live demo command-line applications built using LlamaBot that use both open source and API-access-only LLMs. Finally, I will conclude with a roadmap for LlamaBot development, and an invitation to contribute and shape its development during the Sprints.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Lonboard: Fast, interactive geospatial vector data visualization in Jupyter</title><link href="https://pyvideo.org/scipy-2024/lonboard-fast-interactive-geospatial-vector-data-visualization-in-jupyter.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Kyle Barron</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/lonboard-fast-interactive-geospatial-vector-data-visualization-in-jupyter.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Lonboard (&lt;a class="reference external" href="https://developmentseed.org/lonboard/latest/"&gt;https://developmentseed.org/lonboard/latest/&lt;/a&gt;) is a new Python library for geospatial vector data visualization that can be 50x faster than existing alternatives like ipyleaflet (&lt;a class="reference external" href="https://github.com/jupyter-widgets/ipyleaflet"&gt;https://github.com/jupyter-widgets/ipyleaflet&lt;/a&gt;) or pydeck (&lt;a class="reference external" href="https://github.com/visgl/deck.gl/tree/master/bindings/pydeck"&gt;https://github.com/visgl/deck.gl/tree/master/bindings/pydeck&lt;/a&gt;). This talk will explain why this …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Lonboard (&lt;a class="reference external" href="https://developmentseed.org/lonboard/latest/"&gt;https://developmentseed.org/lonboard/latest/&lt;/a&gt;) is a new Python library for geospatial vector data visualization that can be 50x faster than existing alternatives like ipyleaflet (&lt;a class="reference external" href="https://github.com/jupyter-widgets/ipyleaflet"&gt;https://github.com/jupyter-widgets/ipyleaflet&lt;/a&gt;) or pydeck (&lt;a class="reference external" href="https://github.com/visgl/deck.gl/tree/master/bindings/pydeck"&gt;https://github.com/visgl/deck.gl/tree/master/bindings/pydeck&lt;/a&gt;). This talk will explain why this library is so fast, how it integrates into existing workflows, and planned future improvements.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>LPython: Novel, Fast, Retargetable Python Compiler</title><link href="https://pyvideo.org/scipy-2024/lpython-novel-fast-retargetable-python-compiler.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Ondřej Čertík</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/lpython-novel-fast-retargetable-python-compiler.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We are developing a modern open-source Python compiler called LPython
(&lt;a class="reference external" href="https://lpython.org/"&gt;https://lpython.org/&lt;/a&gt;) that can execute user's code interactively in Jupyter to
allow exploratory work (much like CPython, MATLAB or Julia) as well as compile to binaries with the goal to run user's code on modern architectures such as …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We are developing a modern open-source Python compiler called LPython
(&lt;a class="reference external" href="https://lpython.org/"&gt;https://lpython.org/&lt;/a&gt;) that can execute user's code interactively in Jupyter to
allow exploratory work (much like CPython, MATLAB or Julia) as well as compile to binaries with the goal to run user's code on modern architectures such as multi-core CPU, GPU, as well as unfamiliar, new architectures like GSI's APU, which features programmable compute-in memory. We aim to provide the best possible performance for numerical array oriented code. The compiler itself is written in C++ for robustness
and speed.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Making Research Data Flow with Python</title><link href="https://pyvideo.org/scipy-2024/making-research-data-flow-with-python.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Josh Borrow</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/making-research-data-flow-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Many tools exist for large-scale data transfer (tens of terabytes or more), but they often don't match the needs of scientific data flows. In this talk, I'll explain how we built the 'librarian' framework with FastAPI, postgres, and Globus to ease this challenge. Designed for the Simons Observatory's petabyte-scale …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Many tools exist for large-scale data transfer (tens of terabytes or more), but they often don't match the needs of scientific data flows. In this talk, I'll explain how we built the 'librarian' framework with FastAPI, postgres, and Globus to ease this challenge. Designed for the Simons Observatory's petabyte-scale data transfer, I'll cover building reliable web services, flexible development with dependency injection, effective testing with pytest, and deployment using NERSC's Spin. I hope to demystify web and database programming for a scientific audience.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>mrfmsim: a modular simulation platform for magnetic resonance force microscopy experiments</title><link href="https://pyvideo.org/scipy-2024/mrfmsim-a-modular-simulation-platform-for-magnetic-resonance-force-microscopy-experiments.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Peter Sun</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/mrfmsim-a-modular-simulation-platform-for-magnetic-resonance-force-microscopy-experiments.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We present mrfmsim, an open-source framework that facilitates the design, simulation, and signal validation of magnetic resonance force microscopy experiments. The mrfmsim framework uses directed acyclic graphs (DAGs) to model experiments and employs a plugin system that adds custom experiments and functionalities. Differing from common DAG-powered workflow packages, mrfmsim …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We present mrfmsim, an open-source framework that facilitates the design, simulation, and signal validation of magnetic resonance force microscopy experiments. The mrfmsim framework uses directed acyclic graphs (DAGs) to model experiments and employs a plugin system that adds custom experiments and functionalities. Differing from common DAG-powered workflow packages, mrfmsim allows flexible customizations of experiments post-definition without rewriting the internal model, such as optimized looping. In the talk, we present the challenges in building simulation packages for experiments undergoing continuous development in a graduate research setting. We discuss the current one-off approach that led to error-prone code and how modularity, extendibility, and readability can speed up the development cycle.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>New Developments in Open Source Computational Economics</title><link href="https://pyvideo.org/scipy-2024/new-developments-in-open-source-computational-economics.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Sebastian Benthall</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/new-developments-in-open-source-computational-economics.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk discusses recent developments in open source computational economics, with a focus on the Econ-ARK project and dynamic stochastic optimization problems. Economics is often concerned with agents making choices across periods of time and interacting through a market. Historically, these problems have been solved using dynamic programming methods …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk discusses recent developments in open source computational economics, with a focus on the Econ-ARK project and dynamic stochastic optimization problems. Economics is often concerned with agents making choices across periods of time and interacting through a market. Historically, these problems have been solved using dynamic programming methods that are plagued by the curse of dimensionality. In practice, economics models were either dramatically simplified for tractability or solved to only rough approximation. Recent work has shown how deep learning can be used to solve these problems in a much more efficient way. Today, more models are computationally feasible, and we should expect general computing methods to continue to expand this horizon. Thus, what's needed is a portable way of representing economic models which is agnostic to solution methods. I'll present early-stage efforts to produce such a language as a flavor of language that is compatible with Sympy.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>No-Code-Change GPU Acceleration for Your Pandas and NetworkX Workflows</title><link href="https://pyvideo.org/scipy-2024/no-code-change-gpu-acceleration-for-your-pandas-and-networkx-workflows.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Vyas Ramasubramani</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/no-code-change-gpu-acceleration-for-your-pandas-and-networkx-workflows.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;With datasets growing in both complexity and volume, the demand for more efficient data processing has never been higher. Pandas and NetworkX, the go-to Python libraries for tabular and graph data processing, are very popular for their ease of use and flexibility. However, they often struggle to keep pace …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;With datasets growing in both complexity and volume, the demand for more efficient data processing has never been higher. Pandas and NetworkX, the go-to Python libraries for tabular and graph data processing, are very popular for their ease of use and flexibility. However, they often struggle to keep pace with the demands of large-scale data analysis.&lt;/p&gt;
&lt;p&gt;This talk introduces new open-source GPU accelerators from the NVIDIA RAPIDS project for Pandas and NetworkX, and will demonstrate how you can enable them for your workflows to experience massive speedups – up to 150x in pandas and 600x in NetworkX – without code changes.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Orchestrating Bioinformatics Workflows Across a Heterogeneous Toolset with Flyte</title><link href="https://pyvideo.org/scipy-2024/orchestrating-bioinformatics-workflows-across-a-heterogeneous-toolset-with-flyte.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Pryce Turner</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/orchestrating-bioinformatics-workflows-across-a-heterogeneous-toolset-with-flyte.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While Python excels at prototyping and iterating quickly, it’s not always performant enough for whole-genome scale data processing. Flyte, an open-source Python-based workflow orchestrator, presents an excellent way to tie together the myriad tools required to run bioinformatics workflows. Flyte is a k8s native orchestrator, meaning all dependencies …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While Python excels at prototyping and iterating quickly, it’s not always performant enough for whole-genome scale data processing. Flyte, an open-source Python-based workflow orchestrator, presents an excellent way to tie together the myriad tools required to run bioinformatics workflows. Flyte is a k8s native orchestrator, meaning all dependencies are captured and versioned in container images. It also allows you to define custom types in Python representing genomic datasets, enabling a powerful way to enforce compatibility across tools. Computational biologists, or any scientists processing data with a heterogeneous toolset, stand to benefit from a common orchestration layer that is opinionated yet flexible.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Pandas + Dask DataFrame 2.0 - Comparison to Spark, DuckDB and Polars</title><link href="https://pyvideo.org/scipy-2024/pandas-dask-dataframe-20-comparison-to-spark-duckdb-and-polars.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>James Bourbeau</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/pandas-dask-dataframe-20-comparison-to-spark-duckdb-and-polars.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dask is a library for distributed computing with Python that integrates tightly with pandas. Historically, Dask was the easiest choice to use (it’s just pandas) but struggled to achieve robust performance (there were many ways to accidentally perform poorly). The re-implementation of the DataFrame API addresses all of …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dask is a library for distributed computing with Python that integrates tightly with pandas. Historically, Dask was the easiest choice to use (it’s just pandas) but struggled to achieve robust performance (there were many ways to accidentally perform poorly). The re-implementation of the DataFrame API addresses all of the pain points that users ran into. We will look into how Dask is a lot faster now, how it performs on benchmarks that is struggled with in the past and how it compares to other tools like Spark, DuckDB and Polars.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Performant and Portable High-Performance Computing at Scale via Python and Numba</title><link href="https://pyvideo.org/scipy-2024/performant-and-portable-high-performance-computing-at-scale-via-python-and-numba.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Joanna Piper Morgan</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/performant-and-portable-high-performance-computing-at-scale-via-python-and-numba.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Monte Carlo / Dynamic Code (MC/DC) is a performant and scalable Monte Carlo radiation transport simulation package with GPU and CPU support. It is written entirely in Python and uses Numba to accelerate Python code to CPU and GPU targets. This allows MC/DC to be a portable, easily …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Monte Carlo / Dynamic Code (MC/DC) is a performant and scalable Monte Carlo radiation transport simulation package with GPU and CPU support. It is written entirely in Python and uses Numba to accelerate Python code to CPU and GPU targets. This allows MC/DC to be a portable, easily installable, single language source code ideal for rapid numerical methods exploration at scale. We will discuss the benefits and drawbacks of such a scheme and make comparisons to traditionally compiled codes as well as those written using other modern high-level languages (i.e., Julia).&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>PIXIE: Blending Just-in-time and Ahead-of-time compilation</title><link href="https://pyvideo.org/scipy-2024/pixie-blending-just-in-time-and-ahead-of-time-compilation.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Stuart Archibald</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/pixie-blending-just-in-time-and-ahead-of-time-compilation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Speeding up Python code traditionally involves the use of Just-In-Time (JIT) or Ahead-Of-Time (AOT) compilation. There are tradeoffs to both approaches, however. As part of the Numba project's aim to create a compiler toolkit, the PIXIE project is being developed. It offers a multiple-language consuming, extensible toolchain, that produces …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Speeding up Python code traditionally involves the use of Just-In-Time (JIT) or Ahead-Of-Time (AOT) compilation. There are tradeoffs to both approaches, however. As part of the Numba project's aim to create a compiler toolkit, the PIXIE project is being developed. It offers a multiple-language consuming, extensible toolchain, that produces AOT compiled binary extension modules. These PIXIE based extension modules contain CPU-specific function dispatch for AOT use and also support something similar to Link-Time-Optimization (LTO) for use in situations such as JIT compilation and/or cross module optimization. PIXIE modules are easy to load and call from Python, and can be inlined into Numba JIT compilation, giving Python developers access to the benefits of both AOT and JIT.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Pooch: a friend to fetch your data files</title><link href="https://pyvideo.org/scipy-2024/pooch-a-friend-to-fetch-your-data-files.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Santiago Soler</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/pooch-a-friend-to-fetch-your-data-files.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pooch is a Python library that can download and locally cache files from the web without hassle. Novices can use it to simply download files in one line of code and focus on the data. Package maintainers can use it to provide sample datasets to their users, in examples …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Pooch is a Python library that can download and locally cache files from the web without hassle. Novices can use it to simply download files in one line of code and focus on the data. Package maintainers can use it to provide sample datasets to their users, in examples and tutorials, as libraries like SciPy, scikit-image, napari and MetPy do. During this talk, we'll show you how you can use the different features that Pooch offers and also how you can extend its capabilities by writing your own downloaders or post-processors.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Python for early-stage design of sustainable aviation fuels</title><link href="https://pyvideo.org/scipy-2024/python-for-early-stage-design-of-sustainable-aviation-fuels.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Ali Martz</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/python-for-early-stage-design-of-sustainable-aviation-fuels.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Aviation accounts for 2% of global greenhouse gas emissions, and reliance on liquid petroleum-based fuels makes this sector challenging to decarbonize. We seek to accelerate the development of sustainable aviation fuels using an early-stage design tool with a data-driven approach. We developed our strategy using the Python-based optimization packages …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Aviation accounts for 2% of global greenhouse gas emissions, and reliance on liquid petroleum-based fuels makes this sector challenging to decarbonize. We seek to accelerate the development of sustainable aviation fuels using an early-stage design tool with a data-driven approach. We developed our strategy using the Python-based optimization packages BoTorch and Ax, and also rely on Pandas. We will discuss how to down-select from many possible fuel components to a specified number of chemical species and identify which combinations are most promising for a novel sustainable aviation fuel. We will also present its integration in our open-source web tool supporting biofuel research.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Safe, fast, and easy time series preprocessing with Temporian</title><link href="https://pyvideo.org/scipy-2024/safe-fast-and-easy-time-series-preprocessing-with-temporian.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Mathieu Guillame-Bert</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/safe-fast-and-easy-time-series-preprocessing-with-temporian.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Temporal data is ubiquitous in data science and plays a vital role in machine learning pipelines and business decisions. Preprocessing temporal data using generic data tools can be tedious, lead to inefficient computation, and be prone to errors.
Temporian is an open-source library for safe, simple, and efficient preprocessing …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Temporal data is ubiquitous in data science and plays a vital role in machine learning pipelines and business decisions. Preprocessing temporal data using generic data tools can be tedious, lead to inefficient computation, and be prone to errors.
Temporian is an open-source library for safe, simple, and efficient preprocessing and feature engineering of temporal data. It supports common temporal data types, including non-uniform sampled, multi-variate, multi-index, and multi-source data. Temporian favors interactive development in notebooks and integration with other machine learning tools, and can run at scale using distributed computing.
This talk, aimed at data scientists and machine learning practitioners, will showcase Temporian’s key features along with its powerful API, and demonstrate its advantages over generic data preprocessing libraries for handling temporal data.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Scaling your data science workflows with Modin</title><link href="https://pyvideo.org/scipy-2024/scaling-your-data-science-workflows-with-modin.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Doris Lee</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/scaling-your-data-science-workflows-with-modin.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;pandas is one of the most commonly used data science libraries in Python, with a convenient set of APIs for data cleaning, preparation, analysis, and exploration. However, despite its widespread adoption, pandas suffers from severe memory and performance issues on even moderately sized datasets. Modin is an open-source project …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;pandas is one of the most commonly used data science libraries in Python, with a convenient set of APIs for data cleaning, preparation, analysis, and exploration. However, despite its widespread adoption, pandas suffers from severe memory and performance issues on even moderately sized datasets. Modin is an open-source project that serves as a fast, scalable drop-in replacement for pandas (&lt;a class="reference external" href="https://github.com/modin-project/modin"&gt;https://github.com/modin-project/modin&lt;/a&gt;). By changing just a single line of code, Modin seamlessly speeds up pandas workflow on a laptop or in a cluster. Originally developed at UC Berkeley, Modin has been downloaded more than 17 million times and is used by leading data science teams across industries.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>SciPy 2024 Tools Plenary, Day 1</title><link href="https://pyvideo.org/scipy-2024/scipy-2024-tools-plenary-day-1.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Dan Allan</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/scipy-2024-tools-plenary-day-1.html</id><content type="html"></content><category term="SciPy 2024"></category></entry><entry><title>SciPy Tools Plenary, Day 2</title><link href="https://pyvideo.org/scipy-2024/scipy-tools-plenary-day-2.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Sanket Verma</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/scipy-tools-plenary-day-2.html</id><content type="html"></content><category term="SciPy 2024"></category></entry><entry><title>Simplifying analysis of hierarchical HDF5 and NetCDF4 files with xarray-datatree</title><link href="https://pyvideo.org/scipy-2024/simplifying-analysis-of-hierarchical-hdf5-and-netcdf4-files-with-xarray-datatree.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Eniola Awowale</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/simplifying-analysis-of-hierarchical-hdf5-and-netcdf4-files-with-xarray-datatree.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Xarray-datatree [1], is a Python package that supports HDFs (Hierarchical Data Format) with hierarchical group structures by creating a tree-like hierarchical data structure in xarray. When an HDF file is opened with Datatree, a DataTree object is created that contains all of the groups in the file. The tree-like …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Xarray-datatree [1], is a Python package that supports HDFs (Hierarchical Data Format) with hierarchical group structures by creating a tree-like hierarchical data structure in xarray. When an HDF file is opened with Datatree, a DataTree object is created that contains all of the groups in the file. The tree-like structure allows each group to be accessed once a DataTree object is instantiated. This eliminates the need for a user to go through each group and subgroup to access observational data.&lt;/p&gt;
&lt;p&gt;We will present our use case for Datatree in NASA’s Harmony Level 2 Subsetter (HL2SS). HL2SS provides variable and dimension subsetting for Earth observation data from different NASA data centers. To subset hierarchical datasets without Datatree, HL2SS flattens the entire data structure into a new file by copying all of the grouped and subgrouped variables into the root group. With this new file, a variable or dimension subset is conducted. However, the flattened and subsetted file has to be in the same hierarchical structure of the original file, so it is unflattened, its attributes are copied, and the variables are grouped back to preserve the original group hierarchy. With the open_datatree() function, HL2SS can open datasets containing multiple groups at once and have all of their group hierarchies preserved. This functionality has significant benefits towards optimizing the workflow in HL2SS, since it would eliminate the need to flatten and unflatten grouped datasets.&lt;/p&gt;
&lt;p&gt;[1] &lt;a class="reference external" href="https://github.com/xarray-contrib/datatree"&gt;https://github.com/xarray-contrib/datatree&lt;/a&gt;&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Sparse arrays in scipy.sparse</title><link href="https://pyvideo.org/scipy-2024/sparse-arrays-in-scipysparse.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Dan Schult</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/sparse-arrays-in-scipysparse.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;SciPy package scipy.sparse is moving from its matrix API to an array API. This will allow sizes other than 2D, and clean up treatment of the multiplication operator. This talk will start by describing the changes and their impacts. We will then discuss the process of revamping an …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;SciPy package scipy.sparse is moving from its matrix API to an array API. This will allow sizes other than 2D, and clean up treatment of the multiplication operator. This talk will start by describing the changes and their impacts. We will then discuss the process of revamping an API without messing up existing user code too much. And the trade-offs between slow changes over many releases vs. faster, perhaps breaking changes. And choosing whether to just make a new package instead. The talk should be useful for users of scipy.sparse and also for packages considering a major API change.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Starsim: A flexible framework for agent-based modeling of health and disease</title><link href="https://pyvideo.org/scipy-2024/starsim-a-flexible-framework-for-agent-based-modeling-of-health-and-disease.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Cliff Kerr</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/starsim-a-flexible-framework-for-agent-based-modeling-of-health-and-disease.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Agent-based models (ABMs) are powerful tools for understanding how people behave and interact. However, many ABMs are slow, cumbersome to use, or both. Here we introduce Starsim (&lt;a class="reference external" href="http://starsim.org/"&gt;http://starsim.org/&lt;/a&gt;), an open-source, high-performance ABM specialized for modeling different diseases (such as HIV, STIs, and tuberculosis). Built on NumPy, Numba …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Agent-based models (ABMs) are powerful tools for understanding how people behave and interact. However, many ABMs are slow, cumbersome to use, or both. Here we introduce Starsim (&lt;a class="reference external" href="http://starsim.org/"&gt;http://starsim.org/&lt;/a&gt;), an open-source, high-performance ABM specialized for modeling different diseases (such as HIV, STIs, and tuberculosis). Built on NumPy, Numba, and SciPy, Starsim's performance rivals ABMs implemented in Java or C++, but with the convenience provided by Python: specifically, the ability to quickly implement and refine new disease modules. Starsim can also be extended to other applications in which people interact on timescales from days to decades, including economics and social science.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>STUMPY: Modern Time Series Analysis with Matrix Profiles</title><link href="https://pyvideo.org/scipy-2024/stumpy-modern-time-series-analysis-with-matrix-profiles.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Sean Law</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/stumpy-modern-time-series-analysis-with-matrix-profiles.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Traditional time series analysis techniques have found success in a variety of data mining tasks. However, they often require years of experience to master and the recent development of straightforward, easy-to-use analysis tools has been lacking. We address these needs with STUMPY, a scientific Python library that implements a …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Traditional time series analysis techniques have found success in a variety of data mining tasks. However, they often require years of experience to master and the recent development of straightforward, easy-to-use analysis tools has been lacking. We address these needs with STUMPY, a scientific Python library that implements a novel yet intuitive approach for discovering patterns, anomalies, and other insights from any time series data. This presentation will cover the necessary background needed to follow the live interactive demo, requires no prior experience, and promises a simple, powerful, and scalable time series analysis package that will complement your current toolset.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Supporting Greater Interactivity in the IPython Visualization Ecosystem</title><link href="https://pyvideo.org/scipy-2024/supporting-greater-interactivity-in-the-ipython-visualization-ecosystem.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Nathan Martindale</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/supporting-greater-interactivity-in-the-ipython-visualization-ecosystem.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Interactive visualizations are invaluable tools for building intuition and supporting rapid exploration of datasets and models. Numerous libraries in Python support interactivity, and workflows that combine Jupyter and IPyWidgets in particular make it straightforward to build data analysis tools on the fly. However, the field is missing the ability …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Interactive visualizations are invaluable tools for building intuition and supporting rapid exploration of datasets and models. Numerous libraries in Python support interactivity, and workflows that combine Jupyter and IPyWidgets in particular make it straightforward to build data analysis tools on the fly. However, the field is missing the ability to arbitrarily overlay widgets and plots on top of others to support more flexible details-on-demand techniques. This work discusses some limitations of the base IPyWidgets library, explains the benefits of IPyVuetify and how it addresses these limitations, and finally presents a new open-source solution that builds on IPyVuetify to provide easily integrated widget overlays in Jupyter.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>The power of community in solving scientific Python’s most challenging problems</title><link href="https://pyvideo.org/scipy-2024/the-power-of-community-in-solving-scientific-pythons-most-challenging-problems.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Leah Wasser</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/the-power-of-community-in-solving-scientific-pythons-most-challenging-problems.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Scientific software drives open research. However, developing and maintaining a Python package is a tricky endeavor. You need to navigate a thorny packaging ecosystem, often in an academic environment that doesn’t traditionally value software. pyOpenSci has learned that an inclusive community can be empowered to make Python packaging …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Scientific software drives open research. However, developing and maintaining a Python package is a tricky endeavor. You need to navigate a thorny packaging ecosystem, often in an academic environment that doesn’t traditionally value software. pyOpenSci has learned that an inclusive community can be empowered to make Python packaging more accessible, and that constructive peer review supports maintainers in creating better software, while also providing academic credit. In this talk you’ll learn:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;How to build consensus around thorny topics like packaging.&lt;/li&gt;
&lt;li&gt;Where to find beginner-friendly packaging support.&lt;/li&gt;
&lt;li&gt;How constructive peer review can support better code.&lt;/li&gt;
&lt;li&gt;How to get involved with pyOpenSci.&lt;/li&gt;
&lt;/ol&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>The Right Tool for the Job</title><link href="https://pyvideo.org/scipy-2024/the-right-tool-for-the-job.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Julia Silge</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/the-right-tool-for-the-job.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There are many programming languages that we might choose for scientific computing, and we each bring a complex set of preferences and experiences to such a decision. There are significant barriers to learning about other programming languages outside our comfort zone, and seeing another person or community make a …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There are many programming languages that we might choose for scientific computing, and we each bring a complex set of preferences and experiences to such a decision. There are significant barriers to learning about other programming languages outside our comfort zone, and seeing another person or community make a different choice can be baffling. In this talk, hear about the costs that arise from exploring or using multiple programming languages, what we can gain by being open to different languages, and how curiosity and interest in other programming languages supports sharing across communities. We’ll explore these three points with practical examples from software built for flexible storage and model deployment, as well as a brand new project for scientific computing.&lt;/p&gt;
&lt;p&gt;Julia Silge is a data scientist and engineering manager at Posit PBC, where she leads a team of developers building fluent, cohesive open source software for data science in Python and R. She is a tool builder, author, international keynote speaker, and real-world data science practitioner. She holds a PhD in astrophysics and serves on the technical advisory committee of the US Bureau of Labor Statistics. You can find her online at her blog and YouTube.&lt;/p&gt;
</content><category term="SciPy 2024"></category><category term="Keynote"></category></entry><entry><title>Towards MDAnalysis 3.0</title><link href="https://pyvideo.org/scipy-2024/towards-mdanalysis-30.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Irfan Alibay</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/towards-mdanalysis-30.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;MDAnalysis (&lt;a class="reference external" href="https://www.mdanalysis.org"&gt;https://www.mdanalysis.org&lt;/a&gt;) is one of the most widely used open-source Python libraries for molecular simulation analysis, with applications ranging from understanding the interaction of drugs with proteins to the design of novel materials. With over 200 contributors and 18 years of development, MDAnalysis has established a …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;MDAnalysis (&lt;a class="reference external" href="https://www.mdanalysis.org"&gt;https://www.mdanalysis.org&lt;/a&gt;) is one of the most widely used open-source Python libraries for molecular simulation analysis, with applications ranging from understanding the interaction of drugs with proteins to the design of novel materials. With over 200 contributors and 18 years of development, MDAnalysis has established a mature, stable API and a broad user community. Here we present the current status of the library’s capabilities as it approaches its next major release. We also detail ongoing work to address modern challenges in the ever-evolving landscape of molecular simulation, such as handling increasingly large simulation datasets and meeting the tenets of FAIR.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>ultrack: large-scale versatile cell tracking in Python</title><link href="https://pyvideo.org/scipy-2024/ultrack-large-scale-versatile-cell-tracking-in-python.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Jordão Bragantini</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/ultrack-large-scale-versatile-cell-tracking-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Accurate cell tracking is essential to various biological studies. In this talk, we present Ultrack, a novel Python package for cell tracking that considers a set of multiple segmentation hypotheses and picks the segments that are most consistent over time, making it less susceptible to mistakes when traditional segmentation …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Accurate cell tracking is essential to various biological studies. In this talk, we present Ultrack, a novel Python package for cell tracking that considers a set of multiple segmentation hypotheses and picks the segments that are most consistent over time, making it less susceptible to mistakes when traditional segmentation fails.
The package supports various imaging modalities, from small 2D videos to terabyte-scale 3D time-lapses or multicolored datasets in any napari-compatible image format (e.g. tif, zarr, czi, etc.).
It is available at &lt;a class="reference external" href="https://github.com/royerlab/ultrack"&gt;https://github.com/royerlab/ultrack&lt;/a&gt;&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Using Satellite Imagery to Identify Harmful Algal Blooms and Protect Public Health</title><link href="https://pyvideo.org/scipy-2024/using-satellite-imagery-to-identify-harmful-algal-blooms-and-protect-public-health.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Emily Dorne</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/using-satellite-imagery-to-identify-harmful-algal-blooms-and-protect-public-health.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk illustrates how machine learning models to detect harmful algal blooms from satellite imagery can help water quality managers make informed decisions around public health warnings for lakes and reservoirs. Rooted in the development of the open source package CyFi, this talk includes insights around identifying when your …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk illustrates how machine learning models to detect harmful algal blooms from satellite imagery can help water quality managers make informed decisions around public health warnings for lakes and reservoirs. Rooted in the development of the open source package CyFi, this talk includes insights around identifying when your model is getting the right answer for the wrong reasons, the upsides of using decision tree models with satellite imagery, and how to help non-technical users build confidence in machine learning models. The intended audience is those interested in using satellite imagery to monitor and respond to the world around us.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Vector space embeddings and data maps for cyber defense</title><link href="https://pyvideo.org/scipy-2024/vector-space-embeddings-and-data-maps-for-cyber-defense.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Benoit Hamelin</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/vector-space-embeddings-and-data-maps-for-cyber-defense.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Vast amounts of information of interest to cyber defense organizations comes in the form of unstructured data; from host-based telemetry and malware binaries, to phishing emails and network packet sequences. All of this data is extremely challenging to analyze. In recent years there have been huge advances in the …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Vast amounts of information of interest to cyber defense organizations comes in the form of unstructured data; from host-based telemetry and malware binaries, to phishing emails and network packet sequences. All of this data is extremely challenging to analyze. In recent years there have been huge advances in the methodology for converting unstructured media into vectors. However, leveraging such techniques for cyber defense data remains a challenge.&lt;/p&gt;
&lt;p&gt;Imposing structure on unstructured data allows us to leverage powerful data science and machine learning tools. Structure can be imposed in multiple ways, but vector space representations, with a meaningful distance measure, have proven to be one of the most fruitful.&lt;/p&gt;
&lt;p&gt;In this talk, we will demonstrate a number of techniques for embedding cyber defense data into vector spaces. We will then discuss how to leverage manifold learning techniques, clustering, and interactive data visualization to broaden our understanding of the data and enrich it with expert feedback.&lt;/p&gt;
&lt;p&gt;At the Tutte Institute for Mathematics and Computing (TIMC), we believe in the importance of reproducibility and in making research techniques accessible to the broader cyber defense community. To that end, this talk will leverage several open source libraries and techniques that we have developed at TIMC (&lt;a class="reference external" href="https://github.com/TutteInstitute/"&gt;https://github.com/TutteInstitute/&lt;/a&gt;): Vectorizers, UMAP, HDBSCAN, ThisNotThat and DataMapPlot.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>Warp: Advancing Simulation AI with Differentiable GPU Computing in Python</title><link href="https://pyvideo.org/scipy-2024/warp-advancing-simulation-ai-with-differentiable-gpu-computing-in-python.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Eric Heiden</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/warp-advancing-simulation-ai-with-differentiable-gpu-computing-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we introduce NVIDIA Warp, an open-source Python framework designed for accelerated differentiable computing. Warp enhances Python functions with just-in-time (JIT) compilation, allowing for efficient execution on CPUs and GPUs. The talk’s focus is on Warp’s application in physics simulation, perception, robotics, and geometry processing …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we introduce NVIDIA Warp, an open-source Python framework designed for accelerated differentiable computing. Warp enhances Python functions with just-in-time (JIT) compilation, allowing for efficient execution on CPUs and GPUs. The talk’s focus is on Warp’s application in physics simulation, perception, robotics, and geometry processing, along with its capability to integrate with machine-learning frameworks like PyTorch and JAX. Participants will learn the basics of Warp, including its JIT compilation process and the runtime library that supports various spatial computing operations. These concepts will be illustrated with hands-on projects based on research from institutions like MIT and UCLA, providing practical experience in using Warp to address computational challenges. Targeted at academics, researchers, and professionals in computational fields, the course is designed to inspire attendees and equip them with the knowledge and skills to use Warp in their work, enhancing their projects with efficient spatial computing.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>When is a compiled language like Rust beneficial for Data Scientists?</title><link href="https://pyvideo.org/scipy-2024/when-is-a-compiled-language-like-rust-beneficial-for-data-scientists.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Akshay Gupta</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/when-is-a-compiled-language-like-rust-beneficial-for-data-scientists.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Over the past year, there has been an increase in the number of libraries that leverage Rust and pyo3 to significantly increase performance. What's the catch? In this talk, we will discuss how the Data Science team at Capital One has been thinking about the power of Rust-backed Python …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Over the past year, there has been an increase in the number of libraries that leverage Rust and pyo3 to significantly increase performance. What's the catch? In this talk, we will discuss how the Data Science team at Capital One has been thinking about the power of Rust-backed Python and whether the benefits justify the complexity.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry><entry><title>xCDAT (Xarray Climate Data Analysis Tools)</title><link href="https://pyvideo.org/scipy-2024/xcdat-xarray-climate-data-analysis-tools.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Tom Vo</name></author><id>tag:pyvideo.org,2024-07-08:/scipy-2024/xcdat-xarray-climate-data-analysis-tools.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;xCDAT(Xarray Climate Data Analysis Tools) (&lt;a class="reference external" href="https://github.com/XCDAT/xcdat"&gt;https://github.com/XCDAT/xcdat&lt;/a&gt;) is an open-source Python package that extends Xarray for climate data analysis on structured grids. This talk will cover a brief history of xCDAT, the value this package presents to the climate science community, and a general overview …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;xCDAT(Xarray Climate Data Analysis Tools) (&lt;a class="reference external" href="https://github.com/XCDAT/xcdat"&gt;https://github.com/XCDAT/xcdat&lt;/a&gt;) is an open-source Python package that extends Xarray for climate data analysis on structured grids. This talk will cover a brief history of xCDAT, the value this package presents to the climate science community, and a general overview of key features with technical examples. xCDAT’s scope focuses on routine climate research analysis operations such as loading, averaging, and regridding data on structured grids (e.g., rectilinear, curvilinear). Some key features include temporal averaging, geospatial averaging, horizontal regridding, vertical regridding, and robust interpretation and handling of metadata and bounds for coordinates.&lt;/p&gt;
</content><category term="SciPy 2024"></category></entry></feed>