<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_florian-hartl.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2016-08-24T00:00:00+00:00</updated><entry><title>Large Scale CTR Prediction Lessons Learned</title><link href="https://pyvideo.org/pydata-san-francisco-2016/large-scale-ctr-prediction-lessons-learned.html" rel="alternate"></link><published>2016-08-24T00:00:00+00:00</published><updated>2016-08-24T00:00:00+00:00</updated><author><name>Florian Hartl</name></author><id>tag:pyvideo.org,2016-08-24:pydata-san-francisco-2016/large-scale-ctr-prediction-lessons-learned.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData SF 2016&lt;/p&gt;
&lt;p&gt;Starting with a basic setup for click-through rate (CTR) prediction, we will step by step improve on it by incorporating the lessons we've learned from operating and scaling such a mission-critical system. The presented lessons will be related to infrastructure, model comprehension, and specifics like how to deal with thresholds. They should be applicable to most ML models used in production.&lt;/p&gt;
&lt;p&gt;After briefly introducing Yelp and more specifically click-through rate (CTR) prediction at Yelp, we will start out with a basic setup for model-based predictions in a production system. From there we will point out deficiencies of said setup in various areas, some of which arise especially in large scale environments or when predicting CTRs.&lt;/p&gt;
</summary></entry></feed>