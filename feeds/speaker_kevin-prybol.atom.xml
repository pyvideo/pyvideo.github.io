<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_kevin-prybol.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2016-09-15T00:00:00+00:00</updated><entry><title>Introduction to Zeppelin Notebooks and PySpark 2.0</title><link href="https://pyvideo.org/pydata-carolinas-2016/introduction-to-zeppelin-notebooks-and-pyspark-20.html" rel="alternate"></link><published>2016-09-15T00:00:00+00:00</published><updated>2016-09-15T00:00:00+00:00</updated><author><name>Kevin Prybol</name></author><id>tag:pyvideo.org,2016-09-15:pydata-carolinas-2016/introduction-to-zeppelin-notebooks-and-pyspark-20.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Apache Zeppelin is interactive data analytics environment for
distributed data processing system. This talk will give a brief
overview of what Zeppelin is and where Zeppelin fits into the larger
data science/big data ecosystem, discuss how it differs from Jupyter
and cover several of Zeppelin's key features via a live demo use the
integrated (and just released) PySpark 2.0 interpreter .&lt;/p&gt;
&lt;p&gt;Apache Zeppelin is interactive, multi-purpose, data analytics
environment for distributed data processing system. It provides
beautiful interactive web-based interface, data visualization,
collaborative work environment and many other nice features to make
your data analytics more fun and enjoyable. This talk will provide a
brief overview (via live demo) of some of Zeppelin's key features such
as it's pluggable architecture for backend integration, drag and drop
visualizations, dynamic forms, notebook persistence, Shiro and
notebook authorization, and it's ability to share variables BETWEEN
contexts )E.g. the results of a Flink paragraph can be passed to a
Spark paragraph; the best tool can be used for the job can be used at
each step in analytics pipeline and a data scientist who loves Scala
Flink can easily work with a data scientist who loves pyspark.)&lt;/p&gt;
</summary></entry></feed>