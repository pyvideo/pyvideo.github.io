<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_amicodialessia.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-04-21T00:00:00+00:00</updated><entry><title>In git we trust</title><link href="https://pyvideo.org/pycon-italia-2018/in-git-we-trust.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Simone Basso</name></author><id>tag:pyvideo.org,2018-04-21:pycon-italia-2018/in-git-we-trust.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tutti giorni molti di noi usano git avendo a che fare con la sua
complessità.&lt;/p&gt;
&lt;p&gt;Alzi la mano chi non ha mai avuto un conflitto su un merge. O chi ha
iniziato a sudare freddo pensando di aver perso ore di lavoro.&lt;/p&gt;
&lt;p&gt;L’obbiettivo di questo talk è quello di provare a togliere il velo di
mistero a ciò che succede sotto il cofano quando utilizziamo git, per
usarlo con maggior consapevolezza e produttività, soprattutto quando le
cose prendono una piega sbagliata.&lt;/p&gt;
&lt;p&gt;Il tutto strizzando l’occhio al nostro linguaggio preferito: Python&lt;/p&gt;
&lt;p&gt;Il tour comprenderà:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;introduzione&lt;/li&gt;
&lt;li&gt;objects&lt;/li&gt;
&lt;li&gt;reference&lt;/li&gt;
&lt;li&gt;esempi&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Un minimo di conoscenza di git è consigliata :) .&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 12:00 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="git"></category><category term="#amicodialessia"></category><category term="devops"></category></entry><entry><title>Scaling your Data infrastructure</title><link href="https://pyvideo.org/pycon-italia-2018/scaling-your-data-infrastructure.html" rel="alternate"></link><published>2018-04-20T00:00:00+00:00</published><updated>2018-04-20T00:00:00+00:00</updated><author><name>Christian Barra</name></author><id>tag:pyvideo.org,2018-04-20:pycon-italia-2018/scaling-your-data-infrastructure.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;This talk aims to answer a few questions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;What do you do when you need to move your model from your laptop to
production?&lt;/li&gt;
&lt;li&gt;Is &lt;tt class="docutils literal"&gt;big data == I need to use JVM&lt;/tt&gt; the right assumption?&lt;/li&gt;
&lt;li&gt;How can I put my jupyter notebook in production?&lt;/li&gt;
&lt;li&gt;How do you apply the best software engineering practices (testing and
ci for example) inside your data science process?&lt;/li&gt;
&lt;li&gt;How do you “decouple” your data scientists, developers and devops
teams?&lt;/li&gt;
&lt;li&gt;How do you guarantee the reproducibility of your models?&lt;/li&gt;
&lt;li&gt;How do you scale your training process when does not fit in memory
anymore?&lt;/li&gt;
&lt;li&gt;How do you serve your models and provide an easy rollback system?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Agenda:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The Data Science workflow&lt;/li&gt;
&lt;li&gt;Scaling is not just a matter of the size of your Data&lt;/li&gt;
&lt;li&gt;Scaling when the size of your Data matters&lt;/li&gt;
&lt;li&gt;DDS, Dockerized Data Science&lt;/li&gt;
&lt;li&gt;Cassiny&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ll share my experience highlighting some of the challenges I faced and
the solutions I came up to answer these questions.&lt;/p&gt;
&lt;p&gt;During this presentation I will mention libraries like jupyter, atom,
scikit- learn, dask, ray, parquet, arrow and many others.&lt;/p&gt;
&lt;p&gt;The principles and best practices I will share are something that you
can apply, more or less easily, if you are running or in the process to
run a production system based on the Python stack.&lt;/p&gt;
&lt;p&gt;This talk will focus on (my) best practices to run the Python Data stack
together and I will also talk about Cassiny, an open source project I
started, that aims to simplify your life if you want to use a completely
Python based solution in your data science workflow.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 20 April&lt;/strong&gt; at 11:00 &lt;a class="reference external" href="/en/sprints/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="Jupyter"></category><category term="CloudComputing"></category><category term="pydata"></category><category term="#lessonslearned"></category><category term="Big-Data"></category><category term="S3"></category><category term="Data-Scientist"></category><category term="#amicodialessia"></category><category term="java"></category><category term="docker"></category><category term="cloud"></category></entry></feed>