<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_raphael-cohen.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-06-05T00:00:00+00:00</updated><entry><title>Conversation Intelligence</title><link href="https://pyvideo.org/pycon-israel-2018/conversation-intelligence.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Raphael Cohen</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/conversation-intelligence.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Conversation Intelligence: Extracting Insights from Conversations&lt;/p&gt;
&lt;p&gt;Sales conversations are a valuable and still underutilized asset for organizations. Recording and analyzing these conversations allow companies to quickly train new representatives, identify optimal behaviour, share and enforce best practices and also propagate customer requests and pain points to other parts of the organization helping product designers prioritize the best features. To create value from recorded conversations one needs a Conversation Intelligence (CI) stack. We outline the different layers of our CI stack, namely Diarization (also known as Speaker Separation), Automatic Speech Recognition (ASR) and various Natural Language Processing (NLP), Deep Learning and data science algorithms for extracting insights. CI is a relatively new field because until recently conversations were not amenable to automated analysis at scale due to the high bar of applying speech recognition. However, recent developments in ASR technology (based on Deep Learning) have given rise to significantly higher accuracy rates and with that the ability to robustly extract information from conversations. We review recent advances as well the cutting-edge approaches we use for Speaker Separation which is critical to understanding the roles various speakers play in a conversation, review latest methods for embedding a segment of speech for speaker clustering and review overall system structure for a multi-modal solution. On top of these we demonstrate how both standard and novel NLP and Data Science approaches can help reveal conversational insights including: weak language, inclusive language or identifying customer propensity to buy. The insights are drawn from over 2 million sales calls we analyzed at Chorus.ai to help our customersâ€™ sales reps have better conversations and close more deals.&lt;/p&gt;
</summary></entry><entry><title>Lightning Talks - Part 1</title><link href="https://pyvideo.org/pydata-meetups/lightning-talks-part-1.html" rel="alternate"></link><published>2017-02-16T00:00:00+00:00</published><updated>2017-02-16T00:00:00+00:00</updated><author><name>Uri Goren</name></author><id>tag:pyvideo.org,2017-02-16:pydata-meetups/lightning-talks-part-1.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="7%" /&gt;
&lt;col width="27%" /&gt;
&lt;col width="66%" /&gt;
&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;00:00&lt;/td&gt;
&lt;td&gt;Uri Goren&lt;/td&gt;
&lt;td&gt;Basic Bayesian statistics for churn analysis&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;08:49&lt;/td&gt;
&lt;td&gt;Ohad Zadok&lt;/td&gt;
&lt;td&gt;Visualization of Neural networks&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;14:56&lt;/td&gt;
&lt;td&gt;Tal perry&lt;/td&gt;
&lt;td&gt;Recurrent neural networks in 10 minutes or less&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;26:00&lt;/td&gt;
&lt;td&gt;Nathaniel Shimoni&lt;/td&gt;
&lt;td&gt;Model validation methods (Kaggle)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;35:20&lt;/td&gt;
&lt;td&gt;Raphael Cohen&lt;/td&gt;
&lt;td&gt;Wow, that's awesome! Detecting emotion in call&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</summary><category term="lightning talks"></category></entry></feed>