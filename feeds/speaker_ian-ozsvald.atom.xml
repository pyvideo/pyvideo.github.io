<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_ian-ozsvald.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-07-13T00:00:00+00:00</updated><entry><title>A starter data science process for software engineers</title><link href="https://pyvideo.org/pylondinium-2019/a-starter-data-science-process-for-software-engineers.html" rel="alternate"></link><published>2019-06-15T00:00:00+00:00</published><updated>2019-06-15T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2019-06-15:pylondinium-2019/a-starter-data-science-process-for-software-engineers.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk is aimed at software engineers who'd like to start a data science journey but don't know where to start. We'll use an efficient strategy to find and visualize relationships which will let you quickly derisk your own ideas and then justify more ambitious research projects.&lt;/p&gt;
</summary></entry><entry><title>A gentle introduction to Pandas timeseries and Seaborn</title><link href="https://pyvideo.org/pydata-london-2019/a-gentle-introduction-to-pandas-timeseries-and-seaborn.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2019-07-13:pydata-london-2019/a-gentle-introduction-to-pandas-timeseries-and-seaborn.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;For Pandas users who want to learn about datetimes, time series plots and light analysis, datetime manipulation and resampling.&lt;/p&gt;
</summary></entry><entry><title>Keynote: Citizen Science with Python</title><link href="https://pyvideo.org/pylondinium-2018/keynote-citizen-science-with-python.html" rel="alternate"></link><published>2018-06-10T00:00:00+00:00</published><updated>2018-06-10T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2018-06-10:pylondinium-2018/keynote-citizen-science-with-python.html</id><summary type="html"></summary></entry><entry><title>On the Diagramatic Diagnosis of Data</title><link href="https://pyvideo.org/pycon-uk-2018/on-the-diagramatic-diagnosis-of-data.html" rel="alternate"></link><published>2018-09-15T00:00:00+00:00</published><updated>2018-09-15T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2018-09-15:pycon-uk-2018/on-the-diagramatic-diagnosis-of-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Tools to make your data analysis and machine learning both easier and more reliable&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;The wrong way to start your machine learning project is to “chuck
everything into a model to see what happens”. The better way is to
visualise your data to expose the relationships that you expect, to
confirm that your data looks correct and to identify problems that are
likely to make your life difficult.&lt;/div&gt;
&lt;div class="line"&gt;We’ll review ways to quickly and visually diagnose your data, to check
it meets your assumptions and to prepare it for discussion with your
colleagues. We’ll look at tools including Pandas, Seaborn and Pandas
Profiling. At the end you’ll have new tools to help you confidently
investigate new data with your associates.&lt;/div&gt;
&lt;/div&gt;
</summary></entry><entry><title>Citizen Science with Python</title><link href="https://pyvideo.org/europython-2018/citizen-science-with-python.html" rel="alternate"></link><published>2018-07-27T00:00:00+00:00</published><updated>2018-07-27T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2018-07-27:europython-2018/citizen-science-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;You could make a difference in the world with a little science and
Python. We’ll look at several data-driven humanitarian and healthcare
projects developed using Python and, all going well, run some audience
experiments. By the end of the talk I hope you’ll be looking to run your
own experiments with the scientific Python stack.&lt;/p&gt;
</summary></entry><entry><title>Creating correct and capable classifiers</title><link href="https://pyvideo.org/pydata-london-2018/creating-correct-and-capable-classifiers.html" rel="alternate"></link><published>2018-04-28T00:00:00+00:00</published><updated>2018-04-28T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2018-04-28:pydata-london-2018/creating-correct-and-capable-classifiers.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Iteratively building a classifier requires a mix of skill, diagnostic
ability and guesswork. I'll lay out a framework that helps you build
reliable classifiers with greater confidence and less random guesswork.
Tools demonstrated will include sklearn, YellowBrick, ELI5,
pandas_profiling and skopt.&lt;/p&gt;
</summary></entry><entry><title>Creating correct and capable classifiers</title><link href="https://pyvideo.org/pydata-amsterdam-2018/creating-correct-and-capable-classifiers.html" rel="alternate"></link><published>2018-05-26T00:00:00+00:00</published><updated>2018-05-26T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2018-05-26:pydata-amsterdam-2018/creating-correct-and-capable-classifiers.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Iteratively building a classifier requires a mix of skill, diagnostic ability and guesswork. I'll lay out a framework that helps you build reliable classifiers with greater confidence and less random guesswork. Tools demonstrated will include sklearn, YellowBrick, Shapley and pandas_profiling.&lt;/p&gt;
</summary></entry><entry><title>Machine learning libraries you'd wish you'd known about</title><link href="https://pyvideo.org/pycon-uk-2017/machine-learning-libraries-youd-wish-youd-known-about.html" rel="alternate"></link><published>2017-10-28T15:00:00+01:00</published><updated>2017-10-28T15:00:00+01:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2017-10-28:pycon-uk-2017/machine-learning-libraries-youd-wish-youd-known-about.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Diagnosing, explaining and scaling machine learning is hard. I'll talk about a set of libraries that have helped me to understand when and how a model is failing, helped me communicate why it is working to non-technical users, automated the search for better models and helped me to scale my modeling.&lt;/p&gt;
&lt;p&gt;I'll discuss YellowBrick, LIME, ELI5, TPOT and Dask. These libraries will make it more likely that you deliver trustworthy and reliable systems that will actually make it past R&amp;amp;D and into Production. The talk will be rooted in my experience delivering client projects and participating in Kaggle competitions.&lt;/p&gt;
</summary></entry><entry><title>Ship It!</title><link href="https://pyvideo.org/pydata-london-2015/ship-it.html" rel="alternate"></link><published>2015-06-21T00:00:00+00:00</published><updated>2015-06-21T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2015-06-21:pydata-london-2015/ship-it.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Building and shipping working data science products is hard - learn
from 10 years of Ian's experience to find efficient ways through the
mess of bad data, difficult team communication and poorly maintained
code through to successfully deployed projects.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Building and shipping working data science products is hard - learn from
10 years of Ian's experience to find efficient ways through the mess of
bad data, difficult team communication and poorly maintained code
through to successfully deployed projects. The talk will include ways of
getting data, cleaning and debugging it, approaches to deployment and
various tips I've picked up along the way that'll save you time. If you
frequently start new projects or you're involved in deploying working
systems then this talk should have something for you.&lt;/p&gt;
</summary></entry><entry><title>The High Performance Python Landscape</title><link href="https://pyvideo.org/pydata-london-2014/the-high-performance-python-landscape.html" rel="alternate"></link><published>2014-02-22T00:00:00+00:00</published><updated>2014-02-22T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2014-02-22:pydata-london-2014/the-high-performance-python-landscape.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A Python programmer has many options to profile and optimize CPU-bound
and data-bound systems, common solutions include Cython, numpy and PyPy.
Increasingly we have single-core solutions that should take advantage of
many cores and clusters. This talk reviews the current state of the art,
looking at the compromises and outcomes of the current approaches and
reviews upcoming solutions like Numba, Pythran and PyPy’s numpy.
Thoughts will be shared on how current hindrances might be improved.&lt;/p&gt;
</summary></entry><entry><title>Machine learning with ventilator data to improve reporting on critically ill newborn infants</title><link href="https://pyvideo.org/pydata-london-2017/machine-learning-with-ventilator-data-to-improve-reporting-on-critically-ill-newborn-infants.html" rel="alternate"></link><published>2017-05-06T00:00:00+00:00</published><updated>2017-05-06T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2017-05-06:pydata-london-2017/machine-learning-with-ventilator-data-to-improve-reporting-on-critically-ill-newborn-infants.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Description
Mechanical ventilators are widely used in intensive care, they are sophisticated but Doctors do not have time to analyse the copious traces of data in a neonatal unit. We are providing an easy-to-interpret summary of this time-series data using visualisation and machine learning. This is an open source collaboration with the NHS, All results are open.&lt;/p&gt;
&lt;p&gt;Abstract
Mechanical ventilators are widely used in intensive care. Even two decades ago they were be primarily mechanical devices whose &amp;quot;only&amp;quot; task was to inflate the patient’s lung. Recently, however, they have become equipped with powerful computers that provide sophisticated ventilator modes. Data provided by the ventilators are almost never downloaded, stored or analysed. The data is complex, high frequency and requires time-intensive scrutiny to review. Doctors do not have time to analyse these traces in a neonatal unit.&lt;/p&gt;
&lt;p&gt;We are providing a simple and easy-to-interpret summary of 100Hz dual-channel ventilator data to improve the quality of care of young infants by time-poor staff. This involves signal processing, visualisation, building a gold standard and machine learning to segment breaths and summarise a baby's behaviour. This builds on our talk at PyDataLondon Meetup 30 in January 2017. Our goal is to open source the research so that others can benefit from the processes that we develop. We invite feedback from the audience to help improve our methods.&lt;/p&gt;
&lt;p&gt;Anyone interested in time series data, automated labeling, scikit-learn, Bokeh and medical applications will find this talk of interest. Both the highs and lows of our current approaches will be discussed.&lt;/p&gt;
&lt;p&gt;This is a collaboration between Dr Gusztav Belteki (Cambridge University Hopsitals NHS Foundation Turst), Ian Ozsvald (ModelInsight) and Giles Weaver (ModelInsight).&lt;/p&gt;
</summary></entry><entry><title>The High Performance Python Landscape</title><link href="https://pyvideo.org/pycon-uk-2014/the-high-performance-python-landscape.html" rel="alternate"></link><published>2014-10-14T00:00:00+00:00</published><updated>2014-10-14T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2014-10-14:pycon-uk-2014/the-high-performance-python-landscape.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Presented by: Ian Ozsvald&lt;/p&gt;
&lt;p&gt;A Python programmer has many options to profile and optimize CPU-bound and data-bound systems, common solutions include Cython, numpy and PyPy. Increasingly we have single-core solutions that should take advantage of many cores and clusters. This talk reviews the current state of the art, looking at the compromises and outcomes of the current approaches and reviews upcoming solutions like Numba, Pythran and PyPy’s numpy and STM. Thoughts will be shared on how current hindrances might be improved.&lt;/p&gt;
</summary></entry><entry><title>Using Machine Learning to solve a classification problem with scikit-learn</title><link href="https://pyvideo.org/pycon-uk-2016/using-machine-learning-to-solve-a-classification-problem-with-scikit-learn.html" rel="alternate"></link><published>2016-09-18T00:00:00+00:00</published><updated>2016-09-18T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2016-09-18:pycon-uk-2016/using-machine-learning-to-solve-a-classification-problem-with-scikit-learn.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Ian Ozsvald&lt;/p&gt;
&lt;p&gt;This talk is aimed at developers who want to use machine learning to solve their own binary (2 class) classification task. No prior machine learning or math experience is required. This talk will cover feature engineering (including a robust solution to 'the problem of null data'), predicting the right class with a Random Forest, cross-validating to avoid over-fitting, diagnosing problems in the classifier and approaches to deploying the classifier in the real world. My goal is to provide you with a process that you can take back to the office to try with your own data. It'll be backed by reproducible working code.&lt;/p&gt;
</summary></entry><entry><title>Data Cleaning on Text to Prepare for Analysis and Machine Learning</title><link href="https://pyvideo.org/euroscipy-2015/data-cleaning-on-text-to-prepare-for-analysis-and-machine-learning.html" rel="alternate"></link><published>2015-10-05T00:00:00+00:00</published><updated>2015-10-05T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2015-10-05:euroscipy-2015/data-cleaning-on-text-to-prepare-for-analysis-and-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dirty data makes analysis and machine learning harder (or impossible!) and more prone to failure. I'll talk on the techniques we use at ModelInsight to fix badly encoded, inconsistent and hard-to-parse text data that enable us to prepare real-world industrial data for research.&lt;/p&gt;
</summary></entry><entry><title>Statistically Speculating on the Source of Sneezes and Sniffles</title><link href="https://pyvideo.org/pydata-london-2016/ian-ozsvald-statistically-speculating-on-the-source-of-sneezes-and-sniffles.html" rel="alternate"></link><published>2016-05-31T00:00:00+00:00</published><updated>2016-05-31T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2016-05-31:pydata-london-2016/ian-ozsvald-statistically-speculating-on-the-source-of-sneezes-and-sniffles.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Berlin 2016&lt;/p&gt;
&lt;p&gt;Since April 2015 our group has studied the Allergic Rhinitis of a subject with the goal of building a machine learned model that predicts the need for antihistamines. Approximately 30% of the world's population suffers from allergies, we aim to provide a methodology for others to identify the drivers of their own symptoms. This is a &amp;quot;citizen science&amp;quot; project, currently focused on one individual and a year's worth of self-reported antihistamine usage, sneezing data and geolocated points. We'll discuss the available external data (including the London Air project's pollution readings, weather, diet, exercise and commute data), exploratory data analysis, our approach to feature engineering from time-series and text sources and our modeling progress. The data logging iPhone app and data preparation tools are all open sourced. Python tools discussed include scikit-learn, seaborn, statsmodels and textract. We'll also review our distributed working practices.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://speakerdeck.com/ianozsvald/statistically-solving-sniffles-step-by-step-a-work-in-progress"&gt;https://speakerdeck.com/ianozsvald/statistically-solving-sniffles-step-by-step-a-work-in-progress&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More information: &lt;a class="reference external" href="http://ianozsvald.com/2016/05/07/statistically-solving-sneezes-and-sniffles-a-work-in-progress-report-at-pydatalondon-2016/"&gt;http://ianozsvald.com/2016/05/07/statistically-solving-sneezes-and-sniffles-a-work-in-progress-report-at-pydatalondon-2016/&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>Statistically Solving Sneezes and Sniffles Step by Step</title><link href="https://pyvideo.org/pydata-london-2016/ian-ozsvald-giles-weaver-statistically-solving-sneezes-and-sniffles-step-by-step.html" rel="alternate"></link><published>2016-05-11T00:00:00+00:00</published><updated>2016-05-11T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2016-05-11:pydata-london-2016/ian-ozsvald-giles-weaver-statistically-solving-sneezes-and-sniffles-step-by-step.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData London 2016&lt;/p&gt;
&lt;p&gt;Since April 2015 our group has studied the Allergic Rhinitis of a subject with the goal of building a machine learned model that predicts the need for antihistamines. Approximately 30% of the world's population suffers from allergies, we aim to provide a methodology for others to identify the drivers of their own symptoms.&lt;/p&gt;
&lt;p&gt;This is a &amp;quot;citizen science&amp;quot; project, currently focused on one individual and a year's worth of self-reported antihistamine usage, sneezing data and geolocated points. We'll discuss the available external data (including the London Air project's pollution readings, weather, diet, exercise and commute data), exploratory data analysis, our approach to feature engineering from time-series and text sources and our modeling progress.&lt;/p&gt;
&lt;p&gt;The data logging iPhone app and data preparation tools are all open sourced. Python tools discussed include scikit-learn, statsmodels, glueviz, textract and t-sne. We'll also review our distributed working practices.&lt;/p&gt;
&lt;p&gt;Slides available here: &lt;a class="reference external" href="https://speakerdeck.com/ianozsvald/statistically-solving-sniffles-step-by-step-a-work-in-progress"&gt;https://speakerdeck.com/ianozsvald/statistically-solving-sniffles-step-by-step-a-work-in-progress&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>Cleaning Confused Collections of Characters</title><link href="https://pyvideo.org/pydata-paris-2015/cleaning-confused-collections-of-characters.html" rel="alternate"></link><published>2015-04-10T00:00:00+00:00</published><updated>2015-04-10T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2015-04-10:pydata-paris-2015/cleaning-confused-collections-of-characters.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Success in data science projects depends upon clean input data. Text
data is often badly encoded, lacks data types and is inconsistent. Aimed
at the intermediate Pythonista I’ll talk about the time saving tools I
use in ModelInsight to clean and normalise my data so you can easily
work on new projects.&lt;/p&gt;
</summary></entry><entry><title>Experiences making CPU-bound tasks run much faster</title><link href="https://pyvideo.org/europython-2011/experiences-making-cpu-bound-tasks-run-much-faste.html" rel="alternate"></link><published>2011-07-18T00:00:00+00:00</published><updated>2011-07-18T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2011-07-18:europython-2011/experiences-making-cpu-bound-tasks-run-much-faste.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Ian Ozsvald - 22 June 2011 in &amp;quot;Training Pizza
Margherita &amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;UPDATE - post-event I've created a &lt;a class="reference external" href="http://ianozsvald.com/2011/06/29/high-performance-python-tutorial-v0-1%20-from-my-4-hour-tutorial-at-europython-2011/"&gt;49 page PDF write-
up&lt;/a&gt;
which summarises the 4 hour tutorial&lt;/p&gt;
&lt;p&gt;As a long-time R&amp;amp;D consultant I'm often working to make slow,
experimental code run faster for tasks like physics simulation, flood
modeling and natural language processing. Python allows a smooth
progression from rough-and-ready (but slow) algorithms through to finely
tuned tasks that efficiently use as much CPU power as you can bring to
bear. Speed-ups of 10-500* can be expected for the Mandelbrot code
we'll use.&lt;/p&gt;
&lt;p&gt;In this talk I'll cover a set of libraries that make CPU-bound tasks run
much faster. We'll begin with a look at profiling using RunSnakeRun and
line_profiler to identify our bottleneck. We'll take a look at slow
algorithms in Python and how they can run faster using numpy and
numexpr.&lt;/p&gt;
&lt;p&gt;Next we'll cover the use of multiprocessing to utilise multiple CPU
cores along with Cython or ShedSkin to easily use C code in a friendly
Python wrapper. Multiprocessing on a quad-core system can often provide
a 4* speed-up for the right tasks. Next parallelpython will let us run
our code on a network of machines.&lt;/p&gt;
&lt;p&gt;Finally we'll look at pyCUDA to utilise an NVIDIA GPU. CUDA can give the
best improvements for mathematical problems (over 100* on the right
tasks) but works on a narrower set of problems.&lt;/p&gt;
&lt;p&gt;How it'll work: The tutorial will be hands on, you'll be converting
example files from normal Python to faster variants using the tools
below. All of it is optional, you'll get the most benefit by having
everything installed. We'll work in groups and open discussion is
encouraged.&lt;/p&gt;
&lt;p&gt;NOTE - you are expected to have all these tools installed &lt;em&gt;before&lt;/em&gt; the
tutorial (if you don't, you might find it hard to follow what's going
on!).&lt;/p&gt;
&lt;p&gt;I'll be using Python 2.7.1 on a Macbook (Snow Leopard). All of these
tools run on Windows and Linux, as long as your versions are fairly
recent everything should run just fine.&lt;/p&gt;
&lt;p&gt;My versions (roughly ordered by importance):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Python 2.7.1&lt;/li&gt;
&lt;li&gt;RunSnakeRun 2.0.1b6 (with wxPython 2.8.12.0 Unicode)&lt;/li&gt;
&lt;li&gt;line_profiler (1.0b2)&lt;/li&gt;
&lt;li&gt;Cython 0.14.1&lt;/li&gt;
&lt;li&gt;ShedSkin 0.7.1&lt;/li&gt;
&lt;li&gt;numpy 1.5.1&lt;/li&gt;
&lt;li&gt;numexpr 1.4.2&lt;/li&gt;
&lt;li&gt;ParallelPython 1.6.1&lt;/li&gt;
&lt;li&gt;pyCUDA HEAD from git as of 14th June 2011 (with CUDA 4.0 drivers)&lt;/li&gt;
&lt;li&gt;PyPy 1.5&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some background reading:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://ianozsvald.com/2010/07/14/22937-faster-python-math-using-pycuda/"&gt;http://ianozsvald.com/2010/07/14/22937-faster-python-math-using-pycuda/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://ianozsvald.com/2008/11/17/making-python-math-196-faster-with-shedskin/"&gt;http://ianozsvald.com/2008/11/17/making-python-math-196-faster-with-shedskin/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="cython"></category><category term="git"></category><category term="multiprocessing"></category><category term="network"></category><category term="numpy"></category><category term="nvidia"></category><category term="profiling"></category><category term="pycuda"></category><category term="runsnakerun"></category><category term="tutorial"></category><category term="windows"></category><category term="wxpython"></category></entry><entry><title>High Performance Python I</title><link href="https://pyvideo.org/pycon-us-2012/high-performance-python-i.html" rel="alternate"></link><published>2012-03-08T00:00:00+00:00</published><updated>2012-03-08T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2012-03-08:pycon-us-2012/high-performance-python-i.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;At EuroPython 2011 I ran a very hands-on tutorial for High Performance
Python techniques. This updated tutorial will cover profiling, PyPy,
Cython, numpy, NumExpr, ShedSkin, multiprocessing, ParallelPython and
pyCUDA. Here's a 55 page PDF write-up of the EuroPython material:
&lt;a class="reference external" href="http://ianozsvald.com/2011/07/25"&gt;http://ianozsvald.com/2011/07/25&lt;/a&gt;
/high-performance-python-tutorial-v0-2-from-europython-2011/&lt;/p&gt;
</summary></entry><entry><title>Applied Parallel Computing with Python</title><link href="https://pyvideo.org/pycon-us-2013/applied-parallel-computing-with-python.html" rel="alternate"></link><published>2013-03-14T00:00:00+00:00</published><updated>2013-03-14T00:00:00+00:00</updated><author><name>Ian Ozsvald</name></author><id>tag:pyvideo.org,2013-03-14:pycon-us-2013/applied-parallel-computing-with-python.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;In this tutorial we shall review three different and distinct approaches
to parallel computing which can be used to solve problems in all manner
of domains, including machine learning, natural language processing,
finance, and computer vision. The first two approaches to be reviewed
will be embarrassingly parallel in nature while the third approach will
leverage fine-grain parallelism.&lt;/p&gt;
</summary><category term="tutorial"></category></entry></feed>