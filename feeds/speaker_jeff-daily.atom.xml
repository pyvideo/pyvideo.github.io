<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Jeff Daily</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_jeff-daily.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2024-09-18T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Friday Afternoon Lightning Talks</title><link href="https://pyvideo.org/pycon-us-2011/pycon-2011--friday-afternoon-lightning-talks.html" rel="alternate"></link><published>2011-03-11T00:00:00+00:00</published><updated>2011-03-11T00:00:00+00:00</updated><author><name>Paul Smith</name></author><id>tag:pyvideo.org,2011-03-11:/pycon-us-2011/pycon-2011--friday-afternoon-lightning-talks.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Friday afternoon lightning talks&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Friday afternoon lightning talks&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;00:00 Paul Smith - Raising money for Japan&lt;/li&gt;
&lt;li&gt;02:24 Jeff Daily - The Global Arrays Parallel Programming Toolkit&lt;/li&gt;
&lt;li&gt;08:30 Matt Harrison - My insecurity problem&lt;/li&gt;
&lt;li&gt;13:10 Pete Fein - Hacking for Freedom&lt;/li&gt;
&lt;li&gt;18:40 Robert Brewer - logging.statistics&lt;/li&gt;
&lt;li&gt;27:30 …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;Friday afternoon lightning talks&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Friday afternoon lightning talks&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;00:00 Paul Smith - Raising money for Japan&lt;/li&gt;
&lt;li&gt;02:24 Jeff Daily - The Global Arrays Parallel Programming Toolkit&lt;/li&gt;
&lt;li&gt;08:30 Matt Harrison - My insecurity problem&lt;/li&gt;
&lt;li&gt;13:10 Pete Fein - Hacking for Freedom&lt;/li&gt;
&lt;li&gt;18:40 Robert Brewer - logging.statistics&lt;/li&gt;
&lt;li&gt;27:30 Nathan Nichols - Lessons Learned Writing DSLs for Automated
Content Generation&lt;/li&gt;
&lt;li&gt;33:15 Giles Thomas - Why Resolver switched from IronPython to CPython
japan, qtile, pyparsing, logging.statistics, resolver, cpython,
ironpython&lt;/li&gt;
&lt;/ul&gt;
</content><category term="PyCon US 2011"></category><category term="lightning talks"></category><category term="cpython"></category><category term="ironpython"></category><category term="japan"></category><category term="logging.statistics"></category><category term="pycon"></category><category term="pycon2011"></category><category term="pyparsing"></category><category term="qtile"></category></entry><entry><title>AOTriton: Ahead of Time Triton Kernel Libraries on ROCm</title><link href="https://pyvideo.org/pytorch-conference-2024/aotriton-ahead-of-time-triton-kernel-libraries-on-rocm.html" rel="alternate"></link><published>2024-09-18T00:00:00+00:00</published><updated>2024-09-18T00:00:00+00:00</updated><author><name>Jeff Daily</name></author><id>tag:pyvideo.org,2024-09-18:/pytorch-conference-2024/aotriton-ahead-of-time-triton-kernel-libraries-on-rocm.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Scaled dot product attention provides significant acceleration of the transformer layer through fusion of the multihead attention layer. There are several different algorithms to achieve this but tiled attention through scaled dot product attention via Flash Attention is a very popular approach. In PyTorch on the ROCm platform this …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Scaled dot product attention provides significant acceleration of the transformer layer through fusion of the multihead attention layer. There are several different algorithms to achieve this but tiled attention through scaled dot product attention via Flash Attention is a very popular approach. In PyTorch on the ROCm platform this is currently achieved through ahead of time compiled (AOT) Triton kernels in a linkable archive. AMD’s work to enable and package these kernels is done through AOTriton, which aims to use Triton’s compiler and GPU kernels for faster development. AOTriton maintains an optimized set of tiling sizes and other parameters to provide optimized, pre-compiled Triton kernels. The differences between JIT and AOT are few but are very important. Despite this, prototyping kernels in Triton is much faster than template-based C++ libraries. In this presentation we will go into detail on the interaction layer between PyTorch and AOTriton, the structure of AOTriton and how to add new triton kernels to AOTriton.&lt;/p&gt;
</content><category term="PyTorch Conference 2024"></category><category term="Lightning Talk"></category></entry></feed>