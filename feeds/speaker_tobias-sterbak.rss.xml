<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 11 Oct 2019 00:00:00 +0000</lastBuildDate><item><title>Tutorial: Managing the end-to-end machine learning lifecycle with MLFlow</title><link>https://pyvideo.org/pydata-berlin-2019/tutorial-managing-the-end-to-end-machine-learning-lifecycle-with-mlflow.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Speaker: Tobias Sterbak&lt;/p&gt;
&lt;p&gt;Track:PyData
Machine learning requires experimenting with datasets, data preparation steps, and algorithms. Deploy models to a production system and retrain it on new data. MLflow is an open source platform for managing the end-to-end machine learning lifecycle.&lt;/p&gt;
&lt;p&gt;Recorded at the PyConDE &amp;amp; PyData Berlin 2019 conference.
&lt;a class="reference external" href="https://pycon.de"&gt;https://pycon.de&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More details at the conference page: &lt;a class="reference external" href="https://de.pycon.org/program/PC38WB"&gt;https://de.pycon.org/program/PC38WB&lt;/a&gt;
Twitter:  &lt;a class="reference external" href="https://twitter.com/pydataberlin"&gt;https://twitter.com/pydataberlin&lt;/a&gt;
Twitter:  &lt;a class="reference external" href="https://twitter.com/pyconde"&gt;https://twitter.com/pyconde&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tobias Sterbak</dc:creator><pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-11:pydata-berlin-2019/tutorial-managing-the-end-to-end-machine-learning-lifecycle-with-mlflow.html</guid></item><item><title>“Why Should I Trust You?” - Debugging black-box text classifiers</title><link>https://pyvideo.org/pydata-amsterdam-2018/why-should-i-trust-you-debugging-black-box-text-classifiers.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Classifying text is a common use case for machine learning algorithms. But despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction. We will use eli5 and the LIME algorithm to explain text classifiers.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tobias Sterbak</dc:creator><pubDate>Sat, 26 May 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-05-26:pydata-amsterdam-2018/why-should-i-trust-you-debugging-black-box-text-classifiers.html</guid><category>eli5</category><category>lime</category></item></channel></rss>