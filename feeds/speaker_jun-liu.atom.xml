<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Jun Liu</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_jun-liu.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2022-07-11T00:00:00+00:00</updated><subtitle></subtitle><entry><title>An Introduction to Distributed Hybrid Hyperparameter Optimization</title><link href="https://pyvideo.org/scipy-2022/an-introduction-to-distributed-hybrid-hyperparameter-optimization.html" rel="alternate"></link><published>2022-07-11T00:00:00+00:00</published><updated>2022-07-11T00:00:00+00:00</updated><author><name>Jun Liu</name></author><id>tag:pyvideo.org,2022-07-11:/scipy-2022/an-introduction-to-distributed-hybrid-hyperparameter-optimization.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Hyperparameter optimization in machine learning is commonly done on single search spaces, where the same search method is applied to all parameters. We introduce the concept of hybrid search space to combine various existing tuning methods in one optimization task through Fugue-tune. We will also demo how it simplifies â€¦&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Hyperparameter optimization in machine learning is commonly done on single search spaces, where the same search method is applied to all parameters. We introduce the concept of hybrid search space to combine various existing tuning methods in one optimization task through Fugue-tune. We will also demo how it simplifies the usage of Optuna and scales out on Spark.&lt;/p&gt;
</content><category term="SciPy 2022"></category></entry></feed>