<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_byron-v-galbraith.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2012-07-18T00:00:00+00:00</updated><entry><title>Unlock: A Python-based framework for rapid development of practical brain-computer interface applications</title><link href="https://pyvideo.org/scipy-2012/unlock-a-python-based-framework-for-rapid-develo.html" rel="alternate"></link><published>2012-07-18T00:00:00+00:00</published><updated>2012-07-18T00:00:00+00:00</updated><author><name>Byron V. Galbraith</name></author><id>tag:pyvideo.org,2012-07-18:scipy-2012/unlock-a-python-based-framework-for-rapid-develo.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Unlock Project aims to provide brain-computer interface (BCI)
technologies to individuals suffering from locked-in syndrome, the
complete or near- complete loss of voluntary motor function. While
several BCI techniques have been demonstrated as feasible in a
laboratory setting, limited effort has been devoted to translating that
research into a system for viable home use. This is in large part due to
the complexity of existing BCI software packages which are geared toward
clinical use by domain experts. With Unlock, we have developed a
Python-based modular framework that greatly simplifies the time and
programming expertise needed to develop BCI applications and
experiments. Furthermore, the entire Unlock system, including data
acquisition, brain signal decoding, user interface display, and device
actuation, can run on a single laptop, offering exceptional portability
for this class of BCI.&lt;/p&gt;
&lt;p&gt;In this talk, I will present the Unlock framework, starting with a
high-level overview of the system then touching on the acquisition,
communication, decoding, and visualization components. Emphasis will be
placed on the app developer API with several examples from our current
work with steady-state visually evoked potentials (SSVEP).&lt;/p&gt;
</summary><category term="General"></category></entry></feed>