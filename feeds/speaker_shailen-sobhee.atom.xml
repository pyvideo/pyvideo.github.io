<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_shailen-sobhee.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-07-10T00:00:00+00:00</updated><entry><title>Accelerate your Deep Learning Inferencing with the Intel® DL Boost technology</title><link href="https://pyvideo.org/europython-2019/accelerate-your-deep-learning-inferencing-with-the-intelr-dl-boost-technology.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Shailen Sobhee</name></author><id>tag:pyvideo.org,2019-07-10:europython-2019/accelerate-your-deep-learning-inferencing-with-the-intelr-dl-boost-technology.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Learn about Intel® Deep Learning Boost, also known as Vector Neural
Network Instructions (VNNI), a new set of AVX-512 instructions, that are
designed to deliver significantly more efficient Deep Learning
(Inference) acceleration. Through this technology, I will show you how
you can perform low-precision (INT8) inference much faster on hardware
that support the VNNI instruction set (for example, the 2nd generation
Intel Xeon Scalable processors, codenamed, Cascade Lake). In the live
Jupyter notebook session, you can will be able to see the benefits of
this new hardware technology.&lt;/p&gt;
&lt;p&gt;Note: This is an advanced talk. Knowledge about Deep Learning,
Inferencing and basic awareness of hardware instruction sets would be
desirable.&lt;/p&gt;
</summary><category term="Data Science"></category><category term="Deep Learning"></category><category term="Performance"></category><category term="python"></category></entry><entry><title>Supercharge your Deep Learning algorithms with optimized software</title><link href="https://pyvideo.org/europython-2019/supercharge-your-deep-learning-algorithms-with-optimized-software.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Shailen Sobhee</name></author><id>tag:pyvideo.org,2019-07-10:europython-2019/supercharge-your-deep-learning-algorithms-with-optimized-software.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, you will learn various optimization techniques to improve
the runtime performance of your deep learning algorithms on Intel
architecture. The presentation will cover how to accelerate the training
of your deep neural networks with Tensorflow thanks to the highly
optimized Intel® Math Kernel Library (Intel® MKL) and how we boost
inferencing with Intel® nGraph and with the Intel® Distribution of
OpenVINO™.&lt;/p&gt;
</summary><category term="Data Science"></category><category term="Deep Learning"></category><category term="Open-Source"></category></entry><entry><title>Python Profiling with Intel® VTune™ Amplifier</title><link href="https://pyvideo.org/europython-2017/python-profiling-with-intelr-vtunetm-amplifier.html" rel="alternate"></link><published>2017-07-10T00:00:00+00:00</published><updated>2017-07-10T00:00:00+00:00</updated><author><name>Shailen Sobhee</name></author><id>tag:pyvideo.org,2017-07-10:europython-2017/python-profiling-with-intelr-vtunetm-amplifier.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python has grown in both significance and popularity in the last
years, especially in the field of high performance computing and
machine learning. When it comes to performance, there are numerous
ways of profiling and measuring code performance—with each analysis
tool having its own strengths and weaknesses. In this talk, we will
introduce a rich GUI application (Intel® VTune™ Amplifier) which can
be used to analyze the runtime performance of one’s Python
application, and fully understand where the performance bottlenecks
are in one’s code.  With this application, one may also analyze the
call-stacks and get quick visual clues where one’s Python application
is spending time or wasting CPU cycles.&lt;/p&gt;
</summary></entry></feed>