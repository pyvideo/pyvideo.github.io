<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_hpc.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2016-07-14T00:00:00+00:00</updated><entry><title>Scegliere le armi per la battaglia del calcolo intensivo</title><link href="https://pyvideo.org/europython-2013/scegliere-le-armi-per-la-battaglia-del-calcolo-intensivo.html" rel="alternate"></link><published>2013-07-05T00:00:00+00:00</published><updated>2013-07-05T00:00:00+00:00</updated><author><name>Enrico Franchi</name></author><id>tag:pyvideo.org,2013-07-05:europython-2013/scegliere-le-armi-per-la-battaglia-del-calcolo-intensivo.html</id><summary type="html"></summary><category term="bigdata"></category><category term="optimization"></category><category term="data-analysis"></category><category term="hpc"></category><category term="performance"></category><category term="scientific-computing"></category></entry><entry><title>Never get in a battle of bits without ammunition.</title><link href="https://pyvideo.org/europython-2013/never-get-in-a-battle-of-bits-without-ammunition.html" rel="alternate"></link><published>2013-07-04T00:00:00+00:00</published><updated>2013-07-04T00:00:00+00:00</updated><author><name>Enrico Franchi</name></author><id>tag:pyvideo.org,2013-07-04:europython-2013/never-get-in-a-battle-of-bits-without-ammunition.html</id><summary type="html"></summary><category term="cython"></category><category term="C/C++"></category><category term="nosql"></category><category term="mongodb"></category><category term="numeric"></category><category term="iPython"></category><category term="optimization"></category><category term="Algorithms"></category><category term="data-analysis"></category><category term="hpc"></category><category term="performance"></category><category term="scientific-computing"></category><category term="numpy"></category></entry><entry><title>Uno sguardo agli internal di RestFS</title><link href="https://pyvideo.org/europython-2013/uno-sguardo-agli-internal-di-restfs.html" rel="alternate"></link><published>2013-07-02T00:00:00+00:00</published><updated>2013-07-02T00:00:00+00:00</updated><author><name>Fabrizio Manfredi</name></author><id>tag:pyvideo.org,2013-07-02:europython-2013/uno-sguardo-agli-internal-di-restfs.html</id><summary type="html"></summary><category term="clustering"></category><category term="HTTP"></category><category term="parallelization"></category><category term="distributed"></category><category term="twisted"></category><category term="REST"></category><category term="optimization"></category><category term="Algorithms"></category><category term="scalability"></category><category term="async"></category><category term="hpc"></category><category term="performance"></category></entry><entry><title>JupyterHub as an Interactive Supercomputing Gateway</title><link href="https://pyvideo.org/scipy-2016/jupyterhub-as-an-interactive-supercomputing-gateway-scipy-2016-michael-milligan.html" rel="alternate"></link><published>2016-07-14T00:00:00+00:00</published><updated>2016-07-14T00:00:00+00:00</updated><author><name>Michael Milligan</name></author><id>tag:pyvideo.org,2016-07-14:scipy-2016/jupyterhub-as-an-interactive-supercomputing-gateway-scipy-2016-michael-milligan.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At the Minnesota Supercomputing Institute we are exploring ways to provide the immediacy and flexibility of interactive computing within the batch-scheduled, tightly controlled world of traditional cluster supercomputing. As Jupyter Notebook has gained in popularity, the steps needed to use it within such an environment have proven to be a barrier to entry even as increasingly powerful Python tools have developed to take advantage of large computational resources. JupyterHub to the rescue! Except out of the box, it doesn't know anything about resource types, job submission, and so on. We developed BatchSpawner and friends as a general JupyterHub backend for batch-scheduled environments. In this talk I will walk through how we have deployed JupyterHub to provide a user-friendly gateway to interactive supercomputing.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="hpc"></category><category term="jupyterhub"></category><category term="jupyter"></category><category term="jupyter notebook"></category><category term="supercomputing"></category></entry><entry><title>QuTiP: An open-source Python framework for the dynamics of open quantum systems</title><link href="https://pyvideo.org/scipy-2012/qutip-an-open-source-python-framework-for-the-dy.html" rel="alternate"></link><published>2012-07-19T00:00:00+00:00</published><updated>2012-07-19T00:00:00+00:00</updated><author><name>Paul Nation</name></author><id>tag:pyvideo.org,2012-07-19:scipy-2012/qutip-an-open-source-python-framework-for-the-dy.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We present QuTiP, an object-oriented open-source framework for solving
the dynamics of open quantum systems. The QuTiP framework is written in
a combination of Python and Cython, and using SciPy, NumPy and
matplotlib to provide an environment for computational quantum mechanics
that is easy and efficient to use. Arbitrary quantum systems, including
time-dependent systems, may be built up from operators and states
defined by a quantum object class, and then passed on to a choice of
unitary and dissipative evolution solvers. We give an overview of the
basic structure for the framework and the techniques used in its
implementation. We also present a few selected examples from
contemporary research on quantum mechanics that illustrate the strengths
of the framework, and the types of calculation that can be performed.
The framework described here is particularly well suited to the fields
of quantum optics, superconducting circuit devices, nanomechanics, and
trapped ions, while also being ideal as an educational tool.&lt;/p&gt;
&lt;p&gt;For more information see &lt;a class="reference external" href="http://qutip.googlecode.com"&gt;http://qutip.googlecode.com&lt;/a&gt;.&lt;/p&gt;
</summary><category term="hpc"></category></entry><entry><title>Bringing High Performance to Python/Numpy Without Changing a Single Line of Code.</title><link href="https://pyvideo.org/scipy-2012/bringing-high-performance-to-pythonnumpy-without.html" rel="alternate"></link><published>2012-07-18T00:00:00+00:00</published><updated>2012-07-18T00:00:00+00:00</updated><author><name>Brian Vinter</name></author><id>tag:pyvideo.org,2012-07-18:scipy-2012/bringing-high-performance-to-pythonnumpy-without.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Recent years have provided a wealth of projects showing that using
Python for scientific applications outperforms even popular choices such
as Matlab. A major factor driving these successes is the efficient
utilization of multi- cores, GPUs for general-purpose computation and
scaling computations to clusters.&lt;/p&gt;
&lt;p&gt;However, often these advances sacrifice some of the high-productivity
features of Python by introducing new language constructs, enforcing new
language semantics and/or enforcing explicit data types. The result is
that the user will have to rewrite existing Python applications to use
the Python extension.&lt;/p&gt;
&lt;p&gt;In order to use GPGPUs in Python, a popular approach is to embed
CUDA/OpenCL code kernels directly in the Python application. The
programming productivity of this approach is better and more readable
than C/C++ applications but it is still inferior to native Python code.
Furthermore, the approach enforces hardware specific programming and
thus requires intimate knowledge of the underlying hardware and the
CUDA/OpenCL programming model.&lt;/p&gt;
&lt;p&gt;Copenhagen Vector Byte Code (cphVB) strives to provide a
high-performance back-end for Numerical Python (NumPy) without reducing
the high-productivity of Python/NumPy. Without any involvement of the
user, cphVB will transform regular sequential Python/NumPy applications
into high-performance applications. The cphVB runtime system is capable
of utilizing a broad range of computing platforms efficiently, e.g.
Multi-core CPUs, GPGPUs and clusters of such machines.&lt;/p&gt;
&lt;p&gt;cphVB consists of a bridge that translates NumPy array operations into
cphVB vector operations. The bridge will send these vector operations to
a Vector Engine that performs the actual execution of the operations.
cphVB comes with a broad range of Vector Engines optimized to specific
hardware architectures, such as multi-core CPUs, GPGPU and clusters of
said architectures. Thus, cphVB provides a high-productivity,
high-performance framework that support legacy NumPy applications
without changing a single line of code.&lt;/p&gt;
</summary><category term="hpc"></category></entry><entry><title>Copperhead: Data Parallel Python</title><link href="https://pyvideo.org/scipy-2012/copperhead-data-parallel-python.html" rel="alternate"></link><published>2012-07-18T00:00:00+00:00</published><updated>2012-07-18T00:00:00+00:00</updated><author><name>Bryan Catanzaro</name></author><id>tag:pyvideo.org,2012-07-18:scipy-2012/copperhead-data-parallel-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Copperhead is a data parallel language embedded in Python, which aims to
provide both a productive programming environment as well as excellent
computational efficiency on heterogeneous parallel hardware. Copperhead
programs are written in a small, restricted subset of Python, using
standard constructs like map and reduce, along with traditional data
parallel primitives like scan and sort. Copperhead programs are written
in standard Python modules and interoperate with existing Python
numerical and visualization libraries such as NumPy, SciPy, and
Matplotlib. The Copperhead runtime compiles Copperhead programs to
target either CUDA-enabled GPUs or multicore CPUs using OpenMP or
Threading Building Blocks. On several example applications from Computer
Vision and Machine Learning, Copperhead programs achieve between 45-100%
of the performance of hand-coded CUDA code, running on NVIDIA GPUs. In
this talk, we will discuss the subset of Python that forms the
Copperhead language, the open source Copperhead runtime and compiler,
and selected example programs.&lt;/p&gt;
</summary><category term="hpc"></category></entry><entry><title>Implicit Multicore Parallelism using CnC-Python</title><link href="https://pyvideo.org/scipy-2012/implicit-multicore-parallelism-using-cnc-python.html" rel="alternate"></link><published>2012-07-18T00:00:00+00:00</published><updated>2012-07-18T00:00:00+00:00</updated><author><name>Shams Imam</name></author><id>tag:pyvideo.org,2012-07-18:scipy-2012/implicit-multicore-parallelism-using-cnc-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We introduce CnC-Python (CP), an approach to implicit multicore
parallelism for Python programmers based on a high-level macro data-flow
programming model called Concurrent Collections (CnC). With the advent
of the multi-core era, it is clear that improvements in application
performance will primarily come from increased parallelism. Extracting
parallelism from applications often involves the use of low-level
primitives such as locks and threads. CP is implicitly parallel and
enables programmers to achieve task, data and pipeline parallelism in a
declarative fashion while only being required to describe the program as
a coordination graph with serial Python code for individual nodes
(steps). Thus, CP makes parallel programming accessible to a broad class
of programmers who are not trained in parallel programming. The CP
runtime requires that Python objects communicated between steps be
picklable, but imposes no restriction on the Python idioms used within
the serial code. Most data structures of interest to the SciPy
community, including NumPy arrays, are included in the class of
picklable data structures in Python.&lt;/p&gt;
&lt;p&gt;The CnC model is especially effective in exploiting parallelism in
scientific applications in which the dependences can be represented as
arbitrary directed acyclic graphs (&amp;quot;dag parallelism&amp;quot;). Such applications
include, but are not limited to, tiled implementations of iterative
linear algebra algorithms such as Cholesky decomposition, Gauss-Jordan
elimination, Jacobi method, and Successive Over-Relaxation (SOR). Rather
than using explicit threads and locks to exploit parallelism, the
CnC-Python programmer decomposes their algorithm into individual
computation steps and identifies data and control dependences among the
steps to create such computation DAGs. Given the DAG (in the form of
declarative constraints), it is the responsibility of the CP runtime to
extract parallelism and performance from the application. By liberating
the scientific programmer, who is not necessarily trained to write
explicitly parallel programs, from the nuances of parallel programming,
CP provides a high-productivity path for scientific programmers to
achieve multi-core parallelism in Python.&lt;/p&gt;
&lt;p&gt;LINKS: CnC-Python: &lt;a class="reference external" href="http://cnc-python.rice.edu"&gt;http://cnc-python.rice.edu&lt;/a&gt; Concurrent Collections:
&lt;a class="reference external" href="http://habanero.rice.edu/cnc"&gt;http://habanero.rice.edu/cnc&lt;/a&gt;&lt;/p&gt;
</summary><category term="hpc"></category></entry><entry><title>Numba Python bytecode to LLVM translator</title><link href="https://pyvideo.org/scipy-2012/numba-python-bytecode-to-llvm-translator.html" rel="alternate"></link><published>2012-07-18T00:00:00+00:00</published><updated>2012-07-18T00:00:00+00:00</updated><author><name>Jon Riehl</name></author><id>tag:pyvideo.org,2012-07-18:scipy-2012/numba-python-bytecode-to-llvm-translator.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Numba is a Python bytecode to LLVM translator that allows creation of
fast, machine code from Python functions. The Low Level Virtual Machine
(LLVM) project is rapidly becoming a hardware-industry standard for the
intermediate representation (IR) of compiled codes. Numba's high-level
translator to the LLVM IR provides Python the ability to take advantage
of the machine code generated by the hardware manufacturers
contributions to LLVM. Numba translates a Python function comprised of a
subset of Python syntax to machine code using simple type inference and
the creation of multiple machine-code versions. In this talk, I will
describe the design of Numba, illustrate its applications to multiple
domains and discuss the enhancements to NumPy and SciPy that can benefit
from this tool.&lt;/p&gt;
</summary><category term="hpc"></category></entry><entry><title>OpenMG: A New Multigrid Implementation in Python</title><link href="https://pyvideo.org/scipy-2012/openmg-a-new-multigrid-implementation-in-python.html" rel="alternate"></link><published>2012-07-18T00:00:00+00:00</published><updated>2012-07-18T00:00:00+00:00</updated><author><name>Akand W. Islam</name></author><id>tag:pyvideo.org,2012-07-18:scipy-2012/openmg-a-new-multigrid-implementation-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Here, include a talk summary of no longer than 500 words. Aspects such
as relevance to Python in science, applicability, and novelty will be
considered by the program committee.&lt;/p&gt;
&lt;p&gt;In most large-scale computations, systems of equations arise in the form
Au=b, where A is a linear operation to be performed on the unknown data
u, producing the known right-hand-side, b, which represents some
constraint of known or assumed behavior of the system being modeled.
Since u can have a many millions to billions elements, direct solution
is too slow. A multigrid solver solves partially at full resolution, and
then solves directly only at low resolution. This creates a correction
vector, which is then interpolated to full resolution, where it corrects
the partial solution.&lt;/p&gt;
&lt;p&gt;This project aims to create an open-source multigrid solver library,
written only in Python. The existing PyAMG multigrid implementation–a
highly versatile, highly configurable, black-box solver–is fully
sequential, and is difficult to read and modify due to its C core.
OpenMG is a pure Python experimentation environment for developing
multigrid optimizations, not a new production solver library. By making
the code simple and modular, we make the alogrithmic details clear. We
thereby create an opportunity for education and experimental
optimization of the partial solver (Jacobi, Gauss Seidel, SOR, etc.),
the restriction mechanism, the prolongation mechanism, and the direct
solver, using GPGPU, multiple CPUs, MPI, or grid computing. The
resulting solver is tested on an implicit pressure reservoir simulation
problem with satisfactory results.&lt;/p&gt;
</summary><category term="hpc"></category></entry><entry><title>PySAL: A Python Library for Exploratory Spatial Data Analysis and Geocomputation</title><link href="https://pyvideo.org/scipy-2012/pysal-a-python-library-for-exploratory-spatial-d.html" rel="alternate"></link><published>2012-07-18T00:00:00+00:00</published><updated>2012-07-18T00:00:00+00:00</updated><author><name>Sergio Rey</name></author><id>tag:pyvideo.org,2012-07-18:scipy-2012/pysal-a-python-library-for-exploratory-spatial-d.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk presents an overview and update of PySAL. PySAL is designed to
support the development of high level applications in exploratory
spatial data analysis and geocomputation. The library includes a
comprehensive suite of modules that cover the entire spatial data
analysis research stack from geospatial data processing and integration,
to exploratory spatial data analysis, spatial dynamics, regionalization,
and spatial econometrics. A selection of these modules are illustrated
drawing on research in spatial criminology, epidemiology and urban
inequality dynamics. A number of geovisualization packages that have
been implemented using PySAL as an analytical core are also
demonstrated. Future plans for additional modules and enhancements are
also discussed.&lt;/p&gt;
</summary><category term="hpc"></category></entry><entry><title>ROFL: a functional Python dialect for science</title><link href="https://pyvideo.org/scipy-2012/rofl-a-functional-python-dialect-for-science.html" rel="alternate"></link><published>2012-07-18T00:00:00+00:00</published><updated>2012-07-18T00:00:00+00:00</updated><author><name>Jonathan Riehl</name></author><id>tag:pyvideo.org,2012-07-18:scipy-2012/rofl-a-functional-python-dialect-for-science.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Current parallel programming models leave a lot to be desired and fail
to maintain pace with improvements in hardware architecture. For many
scientific research groups these models only widen the gap between
equations and scalable parallel code. The Resilient Optimizing Flow
Language (ROFL) is a data-flow language designed with the purpose of
solving the problems of both domain abstraction and efficient
parallelism. Using a functional, declarative variant of the Python
language, ROFL takes scientific equations and optimizes for both scalar
and parallel execution.&lt;/p&gt;
&lt;p&gt;ROFL is closely tied to Python and the SciPy libraries. ROFL uses Python
expression syntax, is implemented in Python, and emits optimized Python
code. ROFL's implementation in Python allows ROFL to be embedded in
Python. Using Python as a target language makes ROFL extensible and
portable. By removing imperative loop constructs and focusing on
integration with the NumPy and SciPy libraries, ROFL both supports and
encourages data parallelism.&lt;/p&gt;
&lt;p&gt;In this presentation, we introduce the ROFL language, and demonstrate by
example how ROFL enables scientists to focus more on the equations they
are solving, and less on task and data parallelism.&lt;/p&gt;
</summary><category term="hpc"></category></entry><entry><title>SciPy + MapReduce with Disco</title><link href="https://pyvideo.org/scipy-2012/scipy-mapreduce-with-disco.html" rel="alternate"></link><published>2012-07-18T00:00:00+00:00</published><updated>2012-07-18T00:00:00+00:00</updated><author><name>Al Barrentine</name></author><id>tag:pyvideo.org,2012-07-18:scipy-2012/scipy-mapreduce-with-disco.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;MapReduce has become one of two dominant paradigms in distributed
computing (along with MPI). Yet many times, implementing an algorithm as
a MapReduce job - especially in Python - forces us to sacrifice
efficiency (BLAS routines, etc.) in favor of data parallelism.&lt;/p&gt;
&lt;p&gt;In my work, which involves writing distributed learning algorithms for
processing terabytes of Twitter data at SocialFlow, I've come to
advocate a form of &amp;quot;vectorized MapReduce&amp;quot; which integrates efficient
numerical libraries like numpy/scipy into the MapReduce setting,
yielding both faster per-machine performance and reduced I/O, which is
often a major bottleneck. I'll also highlight some features of Disco (a
Python/Erlang MapReduce implementation from Nokia) which make it a very
compelling choice for writing scientific MapReduce jobs in Python.&lt;/p&gt;
</summary><category term="hpc"></category></entry><entry><title>Solving the import problem: Scalable Dynamic Loading Network File Systems</title><link href="https://pyvideo.org/scipy-2012/solving-the-import-problem-scalable-dynamic-load.html" rel="alternate"></link><published>2012-07-18T00:00:00+00:00</published><updated>2012-07-18T00:00:00+00:00</updated><author><name>Aron Ahmadia</name></author><id>tag:pyvideo.org,2012-07-18:scipy-2012/solving-the-import-problem-scalable-dynamic-load.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The most common programming paradigm for scientific computing, SPMD
(Single Program Multiple Data), catastrophically interacts with the
loading strategies of dynamically linked executables and
network-attached file systems on even moderately sized high performance
computing clusters. This difficulty is further exacerbated by
&amp;quot;function-shipped&amp;quot; I/O on modern supercomputer compute nodes, preventing
the deployment of simple solutions. In this talk, we introduce a
two-component solution: collfs, a set of low-level MPI-collective file
operations that can selectively shadow file system access in a library,
and walla, a set of Python import hooks for seamlessly enabling parallel
dynamic loading scalable to tens of thousands of cores.&lt;/p&gt;
</summary><category term="hpc"></category></entry><entry><title>MiG - A Complete Grid Middleware (mostly) in Python</title><link href="https://pyvideo.org/europython-2011/mig-a-complete-grid-middleware-mostly-in-pyth.html" rel="alternate"></link><published>2011-07-21T00:00:00+00:00</published><updated>2011-07-21T00:00:00+00:00</updated><author><name>Jonas Bardino</name></author><id>tag:pyvideo.org,2011-07-21:europython-2011/mig-a-complete-grid-middleware-mostly-in-pyth.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Jonas Bardino - 22 June 2011 in &amp;quot;Track Tagliatelle &amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Grid computing was all the buzz in the beginning of the millennium and
still has serious attention in different forms although many of the
original grand promises were never delivered. The general level of
ambitions have instead slowly but steadily degraded to those of the
latest buzz word, Cloud.&lt;/p&gt;
&lt;p&gt;We as a project have proven that most of the original promises &lt;em&gt;can&lt;/em&gt;
actually be delivered and we have done so using Python almost solely as
the implementation language. The choice of Python provided us with a
stable and versatile base for quickly getting this far and it
significantly eases extending and maintaining our middleware in the
future. MiG is currently about 50000 lines of source code but it still
offers more features than competing grid systems with millions of lines
of code.&lt;/p&gt;
&lt;p&gt;Apart from introducing the open source MiG middleware and summarizing
how we got here, this talk will outline some of the core technologies
used to reach that goal and underline why it can make a lot of sense to
choose Python for complex HPC projects like MiG, too. Talk keywords
include Network Programming, Open Source Python projects, Science and
Math and Web-based Systems. There's no special intended audience, but a
certain level of Python knowledge and experience may be an advantage.
Please refer to &lt;a class="reference external" href="http://code.google.com/p/migrid/"&gt;http://code.google.com/p/migrid/&lt;/a&gt; for further MiG
information.&lt;/p&gt;
</summary><category term="forms"></category><category term="hpc"></category><category term="network"></category><category term="science"></category></entry><entry><title>Best Practices for Python in the Cloud</title><link href="https://pyvideo.org/europython-2011/best-practices-for-python-in-the-cloud.html" rel="alternate"></link><published>2011-07-18T00:00:00+00:00</published><updated>2011-07-18T00:00:00+00:00</updated><author><name>Gisle Aas</name></author><id>tag:pyvideo.org,2011-07-18:europython-2011/best-practices-for-python-in-the-cloud.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Gisle Aas - 21 June 2011 in &amp;quot;Track Lasagne&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Abstract: Whether you’re an independent developer or development manager
in a large company, “the cloud” is on everyone’s mind. But just because
it’s in the cloud, doesn’t mean development and deployment is
effortless. The cloud presents infrastructure and development challenges
in a new way.&lt;/p&gt;
&lt;p&gt;In this presentation, ActiveState's Gisle Aas will share best practices
in building and deploying a Python-centric LAMP stack(s) on the cloud
for a range of web-based applications from simple Django site to HPC GPU
Clusters.&lt;/p&gt;
&lt;p&gt;Based on ActiveState’s experiences, Gisle will discuss the challenges
faced and lessons learned in building an infrastructure to deploy web
applications to the cloud with Python.&lt;/p&gt;
&lt;p&gt;You will learn about:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Which packages are critical for a secure, Python-centric LAMP stack
(and what it takes to build them)!&lt;/li&gt;
&lt;li&gt;Tips for developing, deploying, and scaling Python applicaitons in
the cloud&lt;/li&gt;
&lt;li&gt;How to use Python to connect and build infrastructure to support and
manage your deployment&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="cloud"></category><category term="deploy"></category><category term="deployment"></category><category term="django"></category><category term="gpu"></category><category term="hpc"></category><category term="infrastructure"></category><category term="lamp"></category><category term="packages"></category><category term="scaling"></category><category term="web"></category></entry><entry><title>Python for High Performance and Scientific Computing</title><link href="https://pyvideo.org/europython-2011/python-for-high-performance-and-scientific-comput.html" rel="alternate"></link><published>2011-07-13T00:00:00+00:00</published><updated>2011-07-13T00:00:00+00:00</updated><author><name>Andreas Schreiber</name></author><id>tag:pyvideo.org,2011-07-13:europython-2011/python-for-high-performance-and-scientific-comput.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Andreas Schreiber - 23 June 2011 in &amp;quot;Track Lasagne&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python is an accepted high-level scripting language with a growing
community in academia and industry. It is used in a lot of scientific
applications in many different scientific fields and in more and more
industries, for example, in engineering or life science). In all fields,
the use of Python for high- performance and parallel computing is
increasing. Several organizations and companies are providing tools or
support for Python development. This includes libraries for scientific
computing, parallel computing, and MPI. Python is also used on many core
architectures and GPUs, for which specific Python interpreters are being
developed. A related topic is the performance of the various interpreter
and compiler implementations for Python. The talk gives an overview of
Python’s use in HPC and Scientific Computing and gives information on
many topics, such as Python on massively parallel systems, GPU
programming with Python, scientific libraries in Python, and Python
interpreter performance issues. The talk will include examples for
scientific codes and applications from many domains.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://bit.ly/k94rC4"&gt;Slides&lt;/a&gt;&lt;/p&gt;
</summary><category term="community"></category><category term="engineering"></category><category term="gpu"></category><category term="hpc"></category><category term="interpreters"></category><category term="parallel"></category><category term="performance"></category><category term="python,"></category><category term="scientific"></category></entry><entry><title>Python for High Performance Computing</title><link href="https://pyvideo.org/pycon-us-2011/pycon-2011--python-for-high-performance-computing.html" rel="alternate"></link><published>2011-03-11T00:00:00+00:00</published><updated>2011-03-11T00:00:00+00:00</updated><author><name>William Scullin</name></author><id>tag:pyvideo.org,2011-03-11:pycon-us-2011/pycon-2011--python-for-high-performance-computing.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python for High Performance Computing&lt;/p&gt;
&lt;p&gt;Presented by William Scullin&lt;/p&gt;
&lt;p&gt;Python is becoming increasingly popular within the high performance
computing community. While it initially gained traction as a scripting
language, Python's role has continued to expand with Python applications
for science scaling to hundreds of thousands of cores and bindings to
high performance libraries becoming commonplace. This talk is meant as
an overview of Python's role in the HPC space.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;This talk is focused on raising awareness of Python in the high
performance computing space. Specific topics include:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;building the Python interpreter for speed&lt;/li&gt;
&lt;li&gt;an overview of bindings to numerical libraries&lt;/li&gt;
&lt;li&gt;using GPUs and accelerators with Python&lt;/li&gt;
&lt;li&gt;scaling codes with MPI&lt;/li&gt;
&lt;li&gt;issues when scaling on very large systems&lt;/li&gt;
&lt;li&gt;an overview of successful science codes&lt;/li&gt;
&lt;li&gt;a live demonstration of Python running on 163,840 cores&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="gpu"></category><category term="highperformancecomputing"></category><category term="hpc"></category><category term="mpi"></category><category term="pycon"></category><category term="pycon2011"></category></entry></feed>