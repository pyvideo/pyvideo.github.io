<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 12 Jul 2019 00:00:00 +0000</lastBuildDate><item><title>How we run GraphQL APIs in production on our Kubernetes cluster</title><link>https://pyvideo.org/europython-2019/how-we-run-graphql-apis-in-production-on-our-kubernetes-cluster.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk I would like to share the workflow and tools we use to
build, deploy and operate GraphQL APIs on our on-premise Kubernetes
cluster.&lt;/p&gt;
&lt;p&gt;I will share code and command examples explaining how we are operating
our applications since our recent transition from REST APIs on Web
servers to GraphQL APIs containers on Kubernetes.&lt;/p&gt;
&lt;p&gt;This talk will not be about the difference between REST and GraphQL but
focus on the workflow, tools and experience we gained in switching our
run time environments and API models.&lt;/p&gt;
&lt;p&gt;At Numberly, we have built and are operating our own on-premise
Kubernetes cluster so we will also be talking about its capabilities and
share some of the experience we gained in doing so.&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Proposed agenda:&lt;/div&gt;
&lt;div class="line"&gt;- Our previous workflow and its limitations&lt;/div&gt;
&lt;div class="line"&gt;- How we designed our Kubernetes cluster, its capabilities and the
choices we made&lt;/div&gt;
&lt;div class="line"&gt;- Developer workflow, environments management and deployment&lt;/div&gt;
&lt;div class="line"&gt;- Our GraphQL stack, featuring a sample application&lt;/div&gt;
&lt;div class="line"&gt;- What we're still working on to improve&lt;/div&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexys Jacob</dc:creator><pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-12:europython-2019/how-we-run-graphql-apis-in-production-on-our-kubernetes-cluster.html</guid><category>APIs</category><category>Best Practice</category><category>Case Study</category><category>Docker</category><category>Infrastructure</category></item><item><title>Beyond Jupyter Notebooks - Building your own Data Science platform with Python &amp; Docker</title><link>https://pyvideo.org/pycon-de-2018/beyond-jupyter-notebooks-building-your-own-data-science-platform-with-python-docker.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Interactive notebooks like Jupyter have become more and more popular in
the recent past and build the core of many data scientist's workplace.
Being accessed via web browser they allow scientists to easily structure
their work by combining code and documentation.&lt;/p&gt;
&lt;p&gt;Yet notebooks often lead to isolated and disposable analysis artefacts.
Keeping the computation inside those notebooks does not allow for
convenient concurrent model training, model exposure or scheduled model
retraining.&lt;/p&gt;
&lt;p&gt;Those issues can be addressed by taking advantage of recent developments
in the discipline of software engineering. Over the past years
containerization became the technology of choice for crafting and
deploying applications. Building a data science platform that allows for
easy access (via notebooks), flexibility and reproducibility (via
containerization) combines the best of both worlds and addresses Data
Scientist's hidden needs.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joshua Görner</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/beyond-jupyter-notebooks-building-your-own-data-science-platform-with-python-docker.html</guid><category>Artificial Intelligence</category><category>Algorithms</category><category>Data Science</category><category>DevOps</category><category>Infrastructure</category><category>Jupyter</category><category>Machine Learning</category><category>Programming</category><category>Python</category></item><item><title>Big Data Systems Performance: The Little Shop of Horrors</title><link>https://pyvideo.org/pycon-de-2018/big-data-systems-performance-the-little-shop-of-horrors.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The confusion around terms such as like NoSQL, Big Data, Data Science,
Spark, SQL, and Data Lakes often creates more fog than clarity. However,
clarity about the underlying technologies is crucial to designing the
best technical solution in any field relying on huge amounts of data
including data science, machine learning, but also more traditional
analytical systems such as data integration, data warehousing,
reporting, and OLAP.&lt;/p&gt;
&lt;p&gt;In my presentation, I will show that often at least three dimensions are
cluttered and confused in discussions when it comes to data management:
First, buzzwords (labels &amp;amp; terms like &amp;quot;big data&amp;quot;, &amp;quot;AI&amp;quot;, &amp;quot;data lake&amp;quot;);
second, data design patterns (principles &amp;amp; best practices like:
selection push-down, materialization, indexing); and Third, software
platforms (concrete implementations &amp;amp; frameworks like: Python, DBMS,
Spark, and NoSQL-systems).&lt;/p&gt;
&lt;p&gt;Only by keeping these three dimensions apart, it is possible to create
technically-sound architectures in the field of big data analytics.&lt;/p&gt;
&lt;p&gt;I will show concrete examples, which through a simple redesign and wise
choice of the right tools and technologies, run thereby up to 1000 times
faster. This in turn triggers tremendous savings in terms of development
time, hardware costs, and maintenance effort.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jens Dittrich</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/big-data-systems-performance-the-little-shop-of-horrors.html</guid><category>Algorithms</category><category>Big Data</category><category>Data Science</category><category>Infrastructure</category><category>Parallel Programming</category><category>Programming</category><category>Python</category><category>Science</category></item><item><title>Cloud chat bot for lazy people</title><link>https://pyvideo.org/pycon-de-2018/cloud-chat-bot-for-lazy-people.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At work we established Slack years ago as our chat application and by
now quite a percentage of communication goes through it. As a result it
got much easier to contact one person or a group simultaneously. And
this is good as we can share our knowledge save each other time. But it
also introduced a category of questions in the chat which only require
simple tedious tasks to get the answer and then post it as a response.
One possibility is to educate and point others to the place where they
can find the answer or what tasks they have to do. The other one is use
a chat bot for this. Both ways have advantages and for the bot it is
that you can import a specific type of response more easily into a
conversation without first gathering the information and copy and paste
it. I am a developer and service operator and one category of questions
which fits this is the category of service health questions, like &amp;quot;Does
service X has a problem right now?&amp;quot;. Hence, I will use a bot to answer
them. First I will show you how you can create a python bot for the
Azure bot service. With it the questioner then can either directly use
the bot to answer his question or you can just create the response for
him without going to the service health monitoring. In this case the
service health information has to be obtained from a Prometheus
monitoring service and then transformed into a chat message.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Björn Meier</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/cloud-chat-bot-for-lazy-people.html</guid><category>DevOps</category><category>Infrastructure</category></item><item><title>Data science complexity and solutions in real industrial projects</title><link>https://pyvideo.org/pycon-de-2018/data-science-complexity-and-solutions-in-real-industrial-projects.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As data scientists we usually like to apply fancy machine learning
models to well-groomed datasets. Everyone working on industrial problems
will eventually learn, that this does not reflect reality. The amount of
time spent on modeling is small compared to data gathering, -warehousing
and -cleaning. Even after training and deployment of the model, the work
is not done. Continuous monitoring of the performance and input data is
still necessary.&lt;/p&gt;
&lt;p&gt;In this talk I discuss how important data handling is for successful
data science projects. Each milestone, from finding the business case to
continuously monitoring the performance of the solution, is addressed.
This is exemplary shown on a project, with the goal of improving a
productive system.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Artur Miller</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/data-science-complexity-and-solutions-in-real-industrial-projects.html</guid><category>Algorithms</category><category>Big Data</category><category>Data Science</category><category>Infrastructure</category><category>Machine Learning</category></item><item><title>Observe all your applications</title><link>https://pyvideo.org/pycon-de-2018/observe-all-your-applications.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;You just deployed your new version of an application or micro-service;
how do you know everything works as expected? You run your comprehensive
test suite to verify functional correctness for known scenarios and
performance tests before deploying, but does your application really
work at the moment or is it just responding with error messages to all
incoming requests?&lt;/p&gt;
&lt;p&gt;I’m part of the team that runs a huge infrastructure for the SAP HANA
development. This infrastructure is vital for nearly all development &amp;amp;
testing activities of SAP HANA. As this infrastructure is powered by
multiple in-house developed applications, we immediately want to know if
an application starts to fail and we need to be able to quickly diagnose
what caused the failure.&lt;/p&gt;
&lt;p&gt;This talk will give you an overview how we monitor our full stack from
the 2000 physical machines up to the 10,000 parallel running Python
application processes, micro-service instances and batch processing
jobs. It includes a review about the used tools, bad and good examples
of instrumentation in Python code, the resulting visualisation and an
outlook on upcoming improvements.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Christoph Heer</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/observe-all-your-applications.html</guid><category>DevOps</category><category>Infrastructure</category><category>Networks</category><category>Programming</category><category>Python</category></item><item><title>Python on the blockchain: Triumphs and tribulations in a crypto startup</title><link>https://pyvideo.org/pycon-de-2018/python-on-the-blockchain-triumphs-and-tribulations-in-a-crypto-startup.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While many cryptographic components of blockchain protocols can be
extremely complex, blockchain systems themselves are relatively easy to
understand when viewed from a distance. To take the example of Bitcoin,
users store digital currency in hardware or software wallets, and use
private keys to sign and broadcast transactions. Broadcasted
transactions are grouped together into a block through a cryptographic
process known as mining, with miners rewarded through the collection of
transaction fees and the issuance of new coins. The mined block of
transactions is appended to the existing chain, and verified by a global
network of nodes. This process repeats in perpetuity, with each newly
added block adding to the trustedness and security of data stored on the
chain.&lt;/p&gt;
&lt;p&gt;Increased interest in and demand for cryptocurrencies has brought about
a need for places where digital assets can easily be bought, sold or
traded. Our platform, Bitpanda, accomplishes this with a backend written
in Python, and relying heavily on Django and MySQL databases. In our
presentation, we begin by providing a brief overview of how blockchains
work. Following this, we describe the Python architecture that (e.g.)
generates cryptocurrency wallets, builds, signs and sends transactions,
and monitors blockchains for new, relevant data. Key challenges,
solutions and failures encountered during the development of the system,
and growth of our team, are presented.&lt;/p&gt;
&lt;p&gt;Throughout our talk, we also highlight a number of broader social
implications of blockchains, and our work with them. More specifically,
we describe the need for open-innovation based approaches to blockchain
development, the value of open-source within the blockchain community,
and the current lack of critical discourse surrounding the potential
uses of blockchains as mechanisms of surveillance and control.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Danny McDonald</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/python-on-the-blockchain-triumphs-and-tribulations-in-a-crypto-startup.html</guid><category>Business &amp; Start-Ups</category><category>Community</category><category>Django</category><category>Infrastructure</category><category>Python</category></item><item><title>Python with and without Pants</title><link>https://pyvideo.org/pycon-de-2018/python-with-and-without-pants.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;What is the best outfit for comfortable, but highly productive
programming at home? While this is definitely an important question,
this talk will focus on a topic that is slightly more controversial:
monorepos and their build tools. Specifically, the talk will have a
closer look at Pants (&lt;a class="reference external" href="https://www.pantsbuild.org"&gt;https://www.pantsbuild.org&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Pants is a build system for large or rapidly growing code bases. It
supports all stages of a typical build ( bootstrapping, dependency
resolution, compilation, linting, ...) and allows users to organize
their code via targets for binaries, libraries, and tests. For Python
programmers, pants is especially interesting, as it makes the
manipulation and distribution of hermetically sealed Python environments
painless - so called PEXes.&lt;/p&gt;
&lt;p&gt;The talk will motivate Pants and its usage in the context of a large
company- wide monorepo. It will then focus on important Python-centric
features, and shortly explain how those work under the hood. The talk
will conclude with a discussion of usecases for Pants outside of a
monorepo, i.e. for the rest of us.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Stephan Erb</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/python-with-and-without-pants.html</guid><category>DevOps</category><category>Infrastructure</category></item><item><title>Where the heck is my memory?</title><link>https://pyvideo.org/pycon-de-2018/where-the-heck-is-my-memory.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Memory management is something the common Python user doesn’t need to
bother with because the gory details of it are hidden deep within the
interpreter itself. The garbage collector takes out the trash and we can
spend our precious time bothering with more important things on our
minds. Living in this encapsulated utopia is nice but sometimes it is
worth it to peak behind the curtains to unleash the full power of your
application. In this talk I want to show you when it is necessary to
face this harsh world and convince you that it is in fact not as scary
as it may seem. Using real life examples, I’m going to show you how to
use the garbage collector and open source tooling to get control over
the memory you might not even know you had at your disposal.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Florian Jetter</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/where-the-heck-is-my-memory.html</guid><category>Big Data</category><category>DevOps</category><category>Infrastructure</category></item><item><title>Cython to speed up your Python code</title><link>https://pyvideo.org/pycon-de-2018/cython-to-speed-up-your-python-code.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;a class="reference external" href="http://cython.org"&gt;Cython&lt;/a&gt; is not only a very fast and comfortable
way to talk to native code and libraries, it is also a widely used tool
for speeding up Python code. The Cython compiler translates Python code
to C or C++ code, and applies many static optimisations that make Python
code run visibly faster than in the interpreter. But even better, it
supports static type annotations that allow direct use of C/C++ data
types and functions, which the compiler uses to convert and optimise the
code into fast, native C. The tight integration of all three languages,
Python, C and C++, makes it possible to freely mix Python features like
generators and comprehensions with C/C++ features like native data
types, pointer arithmetic or manually tuned memory management in the
same code.&lt;/p&gt;
&lt;p&gt;This talk by a core developer introduces the Cython compiler by
interactive code examples, and shows how you can use it to speed up your
real-world Python code. You will learn how you can profile a Python
module and use Cython to compile and optimise it into a fast binary
extension module. All of that, without losing the ability to run it
through common development tools like code checkers or coverage test
tools.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Stefan Behnel</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/cython-to-speed-up-your-python-code.html</guid><category>Big Data</category><category>Infrastructure</category><category>Jupyter</category><category>Parallel Programming</category></item><item><title>Distributed Hyperparameter search with sklearn and kubernetes</title><link>https://pyvideo.org/pycon-de-2018/distributed-hyperparameter-search-with-sklearn-and-kubernetes.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While sklearn provides a good interface to do hyperparameter search on
large &amp;amp; complex model (pipelines), doing these can take up a lot of
time. The traditional way usually includes one beefy machine and a lot
of waiting. In other cases, people tend to “manually” schedule parameter
ranges between nodes, but that can also be problematic since these won't
talk to each other. Kubernetes itself is currently the most prominent
scheduler and shines at distributing task, but is a pretty complex
system in itself.&lt;/p&gt;
&lt;p&gt;In this talk, I will show how you can harness the scheduling of
kubernetes for distributing hyperparameter search with sklearn onto a
cluster of nodes. This can be achieved quite easily and with just a few
changes to the original code, so the Data Scientist won't be bothered by
complex kubernetes internals.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jakob Karalus</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/distributed-hyperparameter-search-with-sklearn-and-kubernetes.html</guid><category>Algorithms</category><category>Big Data</category><category>Data Science</category><category>DevOps</category><category>Infrastructure</category><category>Machine Learning</category></item><item><title>How type annotations make your code better</title><link>https://pyvideo.org/pycon-de-2018/how-type-annotations-make-your-code-better.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Type annotations still not received that amount of popularity, that
should. People still finding them hard and sometimes ambiguous to use.
But if you start new project in Python in 2018 you should consider using
type annotations in your code and this short talk describes why.&lt;/p&gt;
&lt;p&gt;I'll go over examples, where type annotations helped my team to create
less complex code, and how using type annotations changing your mind for
projecting &amp;amp; implementing features for your project.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Igor Davydenko</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/how-type-annotations-make-your-code-better.html</guid><category>Infrastructure</category><category>Web</category></item><item><title>IoT using Python on Linux: Lessons Learned</title><link>https://pyvideo.org/pycon-de-2018/iot-using-python-on-linux-lessons-learned.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In a distributed sensor network system with a Java based Cloud
application, mobile apps and a proprietary radio protocol accompanying
it we developed an IoT appliance that connects the existing radio
infrastructure to the Cloud service developed in-house.&lt;/p&gt;
&lt;p&gt;Using CPython 3.5 + Debian GNU/Linux 9 on an ARMv7 platform, we
developed the following features:&lt;/p&gt;
&lt;p&gt;Over the course of this project, we learned a lot about Test Driven
Development of Python apps in teams and DevOps in the IoT space. We
would now like to share our experience developing a Python application
for a headless IoT device and the things we would liked to have known
upfront.&lt;/p&gt;
&lt;p&gt;The talk is held both by Matthias Schmidt (Senior Architect at diva-e)
and Thomas Keppler (Software Developer at diva-e).&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Keppler</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/iot-using-python-on-linux-lessons-learned.html</guid><category>DevOps</category><category>Infrastructure</category><category>Networks</category><category>Programming</category><category>Python</category></item><item><title>Python Dependency Management</title><link>https://pyvideo.org/pycon-de-2018/python-dependency-management.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;For a long time there were &lt;tt class="docutils literal"&gt;pip&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;virtualenv&lt;/tt&gt; which were used
together with &lt;tt class="docutils literal"&gt;requirements.txt&lt;/tt&gt; files to manage Python dependencies.
Nowadays there are various other tools that help you improve the
workflow.&lt;/p&gt;
&lt;p&gt;We will have a look at popular projects like&lt;/p&gt;
&lt;p&gt;After the talk you will be able to decide for yourself which approach
suits your usecases best and don't have to rely on rants postet on
reddit.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Patrick Muehlbauer</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/python-dependency-management.html</guid><category>Infrastructure</category></item><item><title>Selinon - dynamic distributed task flows</title><link>https://pyvideo.org/pycon-de-2018/selinon-dynamic-distributed-task-flows.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you ever tried to define and process complex workflows for data
processing? If the answer is yes, you might have struggled to find the
right framework for that. You've probably came across Celery - popular
task flow management for Python. Celery is great, but it does not
provide enough flexibility and dynamic features needed badly in complex
flows. As we discovered all the limitations, we decided to implement
Selinon.&lt;/p&gt;
&lt;p&gt;Have you ever tried to define and process complex workflows for data
processing? If the answer is yes, you might have struggled to find the
right framework for that. You've probably came across Celery - popular
task flow management for Python. Celery is great, but it does not
provide enough flexibility and dynamic features needed badly in complex
flows. As we discovered all the limitations, we decided to implement
Selinon.&lt;/p&gt;
&lt;p&gt;Selinon enhances Celery task flow management and allows you to create
and model task flows in your distributed environment that can
dynamically change behavior based on computed results in your cluster,
automatically resolve tasks that need to be executed in case of
selective task runs, automatic tracing mechanism and many others.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Fridolín Pokorný</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/selinon-dynamic-distributed-task-flows.html</guid><category>Big Data</category><category>Infrastructure</category><category>Parallel Programming</category><category>Programming</category><category>Python</category></item><item><title>Continuous Delivery starts at your Development Environment</title><link>https://pyvideo.org/pycon-italia-2018/continuous-delivery-starts-at-your-development-environment.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Continuous Delivery is the automation of our deployment and QA, isn’t
it? The industrialized software production chain that solves all our
problems. Well, kind of. It’s more than that. Because: You still have
pain when …&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;You bring new developers on board (e.g. for installing Docker and
friends, IDEs and command line tools).&lt;/li&gt;
&lt;li&gt;Your development machine behaves weird or needs an upgrade. (Can you
simply re-install it and continue working without losing a day or a
week of productivity?)&lt;/li&gt;
&lt;li&gt;You need to explain to your colleagues, or even convince them, how to
configure which of their tools?&lt;/li&gt;
&lt;li&gt;Everyone turns to you (or your admin wizard) when there are troubles
to get some tools or projects running.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This talks explains how to bootstrap a super-efficient startup, SMB, or
just any development team that needs a development infrastructure.
You’ll see a demo of The Foreman, Puppet, Ansible and optionally FreeIPA
and virtualization technology, which gets you from zero to 100 in just a
few hours. This talk explains how you do infrastructure like software
development. Everything under control. Everything under version control.&lt;/p&gt;
&lt;p&gt;Come join the show, and take home the recipe that tells you how to step
up the next level of Continuous Delivery! - If you’re a beginner fear
not: this talk starts with an introduction to CI/CD and brings you up to
speed quickly.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Sunday 22 April&lt;/strong&gt; at 15:30 &lt;a class="reference external" href="/en/sprints/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Peter Bittner</dc:creator><pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-22:pycon-italia-2018/continuous-delivery-starts-at-your-development-environment.html</guid><category>infrastructure</category><category>continuous-delivery</category><category>agile</category><category>ansible</category><category>puppet</category><category>free-software</category><category>FreeIPA</category><category>infrastructure-as-code</category></item><item><title>Infrastructure as Code with Terraform</title><link>https://pyvideo.org/pycon-italia-2017/infrastructure-as-code-with-terraform.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;ul class="simple"&gt;
&lt;li&gt;what is infrastructure as code&lt;/li&gt;
&lt;li&gt;best practices&lt;/li&gt;
&lt;li&gt;benefits&lt;/li&gt;
&lt;li&gt;introduction to terraform&lt;/li&gt;
&lt;li&gt;practical demo for a sample flask application&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/tramwaj29/iac-with-terraform"&gt;https://github.com/tramwaj29/iac-with-terraform&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Justyna Janczyszyn</dc:creator><pubDate>Sat, 08 Apr 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-04-08:pycon-italia-2017/infrastructure-as-code-with-terraform.html</guid><category>infrastructure</category><category>devops</category><category>provisioning</category><category>terraform</category><category>deployment</category><category>infrastructure-as-code</category></item><item><title>Snakes on a cloud: the OpenStack project</title><link>https://pyvideo.org/europython-2011/snakes-on-a-cloud-the-openstack-project.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Thierry Carrez - 23 June 2011 in &amp;quot;Track Lasagne&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;OpenStack is an innovative open source project written in Python, backed
by Rackspace Hosting and NASA, building a massively-scalable and
reliable cloud computing platform.&lt;/p&gt;
&lt;p&gt;The first part of this talk will clarify the place of OpenStack in the
general &amp;quot;cloud&amp;quot; landscape and explain why a fully open cloud
infrastructure stack is necessary to avoid vendor lock-in. We'll then
focus on the OpenStack project goals, its developer community, its open
design and release processes, and the developer tools it chose.&lt;/p&gt;
&lt;p&gt;The second part of the talk will present into more technical details the
different components of OpenStack: Nova (compute) and Swift (storage),
including the Python libraries that are used (libvirt, SQLAlchemy,
eventlet…). A Q&amp;amp;A session at the end of the talk will give the audience
a chance to clear any remaining dark area.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thierry Carrez</dc:creator><pubDate>Sun, 24 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-24:europython-2011/snakes-on-a-cloud-the-openstack-project.html</guid><category>cloud</category><category>design</category><category>hosting</category><category>infrastructure</category><category>openstack</category><category>python,</category></item><item><title>What is Google App Engine?</title><link>https://pyvideo.org/europython-2011/what-is-google-app-engine.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] wesley chun - 23 June 2011 in &amp;quot;Track Tagliatelle&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Google App Engine is a unique hosting platform that lets you build
applications and run them in Google's data centers using the massive
global infrastructure built to run the Internet's most powerful company.
App Engine offers a development environment that uses familiar
technologies (Java and Python) and provides a powerful and robust set of
APIs to users while maintaining security and independence from other
apps running in the cloud. It is always free to get started so you can
try it out with no risk, and if you need additional computing resources,
you can purchase additional computing resources beyond the free quota
limits. (If you enable billing and trust us with your credit card, we
will extend your free quotas even further; you won't get charged until
you exceed those &lt;em&gt;extended&lt;/em&gt; quotas.) Scale your application to millions
of users and pay only for what you use at competitive market pricing.&lt;/p&gt;
&lt;p&gt;In this session, we provide an update of the newest features found in
the most recent releases of the App Engine platform. We also share some
suggestions for best practices to existing App Engine developers.&lt;/p&gt;
&lt;p&gt;Beginners to the App Engine platform will be interested in the
introductory workshop which may be offered (see description below).&lt;/p&gt;
&lt;p&gt;Google App Engine workshop&lt;/p&gt;
&lt;p&gt;In this tutorial, we'll give you a comprehensive introduction to the
platform in two/three components:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;1-hour Introduction to Cloud computing and Google App Engine seminar&lt;/li&gt;
&lt;li&gt;3-hour App Engine hands-on workshop/codelab&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the first hour, we review Cloud Computing as an industry and where
Google App Engine fits into the picture. Specifically, we discuss App
Engine as a PaaS solution because of the inherent challenges of building
web and other applications. We'll outline the architecture of App
Engine, what it's major components are, introduce its features and APIs,
discuss the service and how it works (including information on the free
quotas), present some information about current users and usage,
including integration with Google Apps, and finally, give an overview of
its enterprise edition called Google App Engine for Business.&lt;/p&gt;
&lt;p&gt;After the approximately one-hour lecture, we'll show you how to create
applications that run on App Engine by building a simple but real web
application from the ground up via a hands-on coding laboratory.
Although based on the online tutorial, this codelab goes up and beyond
what's in the documentation: you will get a more detailed step-by-step
instructions to replicate that example as well as have the opportunity
to extend your application with some of the newer APIs that come with
App Engine. The codelab will cover the Users service, non-relational
Datastore, and Memcache APIs. Time-permitting, we'll also discuss some
of the newest features found in recent App Engine releases.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Wesley J. Chun</dc:creator><pubDate>Sun, 24 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-24:europython-2011/what-is-google-app-engine.html</guid><category>architecture</category><category>cloud</category><category>google</category><category>hosting</category><category>infrastructure</category><category>memcache</category><category>security</category><category>web</category></item><item><title>Playing tasks with Django-Celery</title><link>https://pyvideo.org/europython-2011/playing-tasks-with-django-celery.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Mauro Rocco - 22 June 2011 in &amp;quot;Track Tagliatelle &amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Celery is an open source task queueing system based on distributed
message passing.&lt;/p&gt;
&lt;p&gt;I will talk about the tools that Celery offers for task distribution and
how to monitor and manage the system using a Django web interface. This
talk will also focus on how we use Celery at Jamendo and our real
solutions to some common issues you may encounter when developing a
back-office based on Celery.&lt;/p&gt;
&lt;p&gt;The talk will cover the following topics:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;A brief overview of Celery and the AMPQ protocol AMPQ protocol
overview, Celery introduction: Celery, RabbitMQ code examples&lt;/li&gt;
&lt;li&gt;The impact of Celery on the Jamendo work-flow; examples with real
tasks. Here I will talk about the Jamendo back-office infrastructure
and some of our common tasks. I will discuss the improvements made by
introducing a new back-office system based on Celery. I will show
some code snippets and go over some real scenarios.&lt;/li&gt;
&lt;li&gt;Overview of the Django Celery admin interface and some Jamendo
extensions. Let's talk about the Django-Celery interface that allows
one to monitor or schedule tasks directly from the Django admin. I
will explain which common additional features are necessary and how
to add them.&lt;/li&gt;
&lt;li&gt;Common &amp;quot;gotchas&amp;quot; we encountered while working with Celery and how we
solved them.&lt;/li&gt;
&lt;li&gt;Global task locks&lt;/li&gt;
&lt;li&gt;Centralized logging: be able to read all the logs of all celery
workers on different servers and filter them for real-time debugging&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mauro Rocco</dc:creator><pubDate>Thu, 21 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-21:europython-2011/playing-tasks-with-django-celery.html</guid><category>celery</category><category>distributed</category><category>django</category><category>infrastructure</category><category>queueing</category><category>rabbitmq</category><category>real-time</category><category>web</category></item><item><title>Building a hosting platform with Python</title><link>https://pyvideo.org/europython-2011/building-a-hosting-platform-with-python.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Andrew Godwin - 20 June 2011 in &amp;quot;Track Lasagne&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At ep.io we built a Python hosting platform from the ground up, designed
to run large numbers of web applications on a small number of physical
machines both securely and in a reasonably scalable way. This talk will
show you how we built our infrastructure - using Redis, eventlet,
PostgreSQL and more - and what lessons we learnt from our first few
thousand deploys.&lt;/p&gt;
&lt;p&gt;See how we split services into multiple processes and greenthreads; the
pains of building a cooperatively-multitasking PTY module; how Redis
isn't the answer to everything, but is still very useful; how to
persuade third-party software to work securely in a shared environment;
and how important it is to have good logging, especially when you have
more than five servers.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Godwin</dc:creator><pubDate>Wed, 20 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-20:europython-2011/building-a-hosting-platform-with-python.html</guid><category>ep.io</category><category>hosting</category><category>infrastructure</category><category>postgresql</category><category>redis</category><category>scalable</category><category>web</category></item><item><title>Best Practices for Python in the Cloud</title><link>https://pyvideo.org/europython-2011/best-practices-for-python-in-the-cloud.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Gisle Aas - 21 June 2011 in &amp;quot;Track Lasagne&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Abstract: Whether you’re an independent developer or development manager
in a large company, “the cloud” is on everyone’s mind. But just because
it’s in the cloud, doesn’t mean development and deployment is
effortless. The cloud presents infrastructure and development challenges
in a new way.&lt;/p&gt;
&lt;p&gt;In this presentation, ActiveState's Gisle Aas will share best practices
in building and deploying a Python-centric LAMP stack(s) on the cloud
for a range of web-based applications from simple Django site to HPC GPU
Clusters.&lt;/p&gt;
&lt;p&gt;Based on ActiveState’s experiences, Gisle will discuss the challenges
faced and lessons learned in building an infrastructure to deploy web
applications to the cloud with Python.&lt;/p&gt;
&lt;p&gt;You will learn about:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Which packages are critical for a secure, Python-centric LAMP stack
(and what it takes to build them)!&lt;/li&gt;
&lt;li&gt;Tips for developing, deploying, and scaling Python applicaitons in
the cloud&lt;/li&gt;
&lt;li&gt;How to use Python to connect and build infrastructure to support and
manage your deployment&lt;/li&gt;
&lt;/ul&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Gisle Aas</dc:creator><pubDate>Mon, 18 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-18:europython-2011/best-practices-for-python-in-the-cloud.html</guid><category>cloud</category><category>deploy</category><category>deployment</category><category>django</category><category>gpu</category><category>hpc</category><category>infrastructure</category><category>lamp</category><category>packages</category><category>scaling</category><category>web</category></item><item><title>Ubuntu and the opportunistic programming</title><link>https://pyvideo.org/europython-2011/ubuntu-and-the-opportunistic-programming.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Paolo Sammicheli - 20 June 2011 in &amp;quot;Track Tagliatelle&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We will show the tools and the infrastructure that makes easy creating
own python project in Ubuntu and distributing it to millions of users.
It will be shown several tools: Launchpad, Quickly and and the Ubuntu's
PPA (personal package archiving).&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Paolo Sammicheli</dc:creator><pubDate>Thu, 14 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-14:europython-2011/ubuntu-and-the-opportunistic-programming.html</guid><category>infrastructure</category></item><item><title>How Python is guiding infrastructure construction in Africa (#84)</title><link>https://pyvideo.org/pycon-us-2010/how-python-is-guiding-infrastructure-construction.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;How Python is guiding infrastructure construction in Africa&lt;/p&gt;
&lt;p&gt;Presented by Roy Hyunjin Han (InvisibleRoads)&lt;/p&gt;
&lt;p&gt;A whirlwind tour of the roles of different Python modules in the
architecture of a geospatial infrastructure planning system.&lt;/p&gt;
&lt;p&gt;We used Python to transform an elaborate, multistep process for finding
and connecting households in villages into a single, streamlined
planning experience. I'll explain how Python's freely available
libraries empowered a small team of developers under a minimal budget
and timeframe. Now just imagine if we had to do the same thing with
Java.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Roy Hyunjin Han</dc:creator><pubDate>Fri, 19 Feb 2010 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2010-02-19:pycon-us-2010/how-python-is-guiding-infrastructure-construction.html</guid><category>africa</category><category>casestudy</category><category>infrastructure</category><category>pycon</category><category>pycon2010</category></item><item><title>Actors: What, Why, and How (#161)</title><link>https://pyvideo.org/pycon-us-2010/pycon-2010--actors--what--why--and-how---161.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Actors: What, Why and How&lt;/p&gt;
&lt;p&gt;Presented by Donovan Preston&lt;/p&gt;
&lt;p&gt;Since the dawn of concurrency research, there have been two camps:
shared everything, and shared nothing. Most modern applications use
threads for concurrency, a shared everything architecture.&lt;/p&gt;
&lt;p&gt;Actors, however, use a shared nothing architecture where lightweight
processes communicate with each other using message passing. Actors can
change their state, create a new Actor, send a message to any Actor it
has the Address of, and wait for a specific kind of message to arrive in
it's mailbox.&lt;/p&gt;
&lt;p&gt;We will discuss the benefits of using the Actor architecture and
strategies for implementing an Actor system in Python.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://bitbucket.org/fzzzy/python-%20actors/"&gt;http://bitbucket.org/fzzzy/python-actors/&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Donovan Preston</dc:creator><pubDate>Fri, 19 Feb 2010 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2010-02-19:pycon-us-2010/pycon-2010--actors--what--why--and-how---161.html</guid><category>concurrency</category><category>eventlet</category><category>infrastructure</category><category>pycon</category><category>pycon2010</category><category>rest</category><category>scaling</category><category>wsgi</category></item></channel></rss>