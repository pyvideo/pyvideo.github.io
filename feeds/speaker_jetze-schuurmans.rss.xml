<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 26 May 2018 00:00:00 +0000</lastBuildDate><item><title>(Re)training word embeddings for a specific domain</title><link>https://pyvideo.org/pydata-amsterdam-2018/retraining-word-embeddings-for-a-specific-domain.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Word embeddings (like GloVe, fastText and word2vec) are very powerful for capturing general word semantics. What if your use case is domain specific? Will your embeddings still work? If they donâ€™t, how do you retrain them?&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jetze Schuurmans</dc:creator><pubDate>Sat, 26 May 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-05-26:pydata-amsterdam-2018/retraining-word-embeddings-for-a-specific-domain.html</guid></item></channel></rss>