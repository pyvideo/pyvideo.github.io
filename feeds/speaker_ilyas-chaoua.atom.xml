<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - ilyas chaoua</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_ilyas-chaoua.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2022-06-03T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Managing large-scale ML pipelines with MLflow and serverless computing.</title><link href="https://pyvideo.org/pycon-italia-2022/managing-large-scale-ml-pipelines-with-mlflow-and-serverless-computing.html" rel="alternate"></link><published>2022-06-03T00:00:00+00:00</published><updated>2022-06-03T00:00:00+00:00</updated><author><name>ilyas chaoua</name></author><id>tag:pyvideo.org,2022-06-03:/pycon-italia-2022/managing-large-scale-ml-pipelines-with-mlflow-and-serverless-computing.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Managing large-scale Machine Learning pipelines with MLflow and
serverless computing. - PyCon Italia 2022&lt;/p&gt;
&lt;p&gt;MLOps aims to manage the machine learning (ML) lifecycle including
experimentation, reproducibility, deployment, and model registry. Come
to discover how in Vedrai - one of the top AI startups in Europe - we
enhance and maintain ML pipelines …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Managing large-scale Machine Learning pipelines with MLflow and
serverless computing. - PyCon Italia 2022&lt;/p&gt;
&lt;p&gt;MLOps aims to manage the machine learning (ML) lifecycle including
experimentation, reproducibility, deployment, and model registry. Come
to discover how in Vedrai - one of the top AI startups in Europe - we
enhance and maintain ML pipelines models in production reliably and
efficiently using MLOps. Problem:&lt;/p&gt;
&lt;p&gt;One difficulty of employing Machine Learning (ML) within organizations
is managing the model’s lifecycle. Moving from experimenting to
deployment in production environments is operated by different steps:
Preparing and Analysing Data, Training, Deployment, Monitoring, and
Governance of ML models. So, it is crucial to possess a platform to
manage and organize the ML lifecycle.&lt;/p&gt;
&lt;p&gt;Solution:&lt;/p&gt;
&lt;p&gt;In Vedrai, we combined the strength of the MLflow framework and the
resilience of AWS serverless services to manage, deploy, and scale our
ML models in production. MLflow is an open-source framework for tracking
the entire ML lifecycle from training to deployment. Among the
functions, it offers model tracking, packaging, and serving. Whereas,
deploying ML applications is an infrastructure affair that needs to be
scalable with minimum server management, which makes AWS serverless
services a great choice.&lt;/p&gt;
&lt;p&gt;Value:&lt;/p&gt;
&lt;p&gt;MLflow enforces the model’s reproducibility and robustness at the same
time allowing more centralized experimentation. AWS serverless services
allow training and inferencing pipelines to run without provisioning or
managing servers while only paying for the time it takes to run.&lt;/p&gt;
&lt;p&gt;Summary:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;State of the art of MLOps.&lt;/li&gt;
&lt;li&gt;Record and query experiments with MLflow Tracking.&lt;/li&gt;
&lt;li&gt;Package data science code with MLflow Projects.&lt;/li&gt;
&lt;li&gt;Store ML models with MLflow Models Registry.&lt;/li&gt;
&lt;li&gt;Deploy ML models in the AWS environment.&lt;/li&gt;
&lt;li&gt;Future MLOps challenges.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Speaker: ilyas chaoua&lt;/p&gt;
</content><category term="PyCon Italia 2022"></category><category term="architecture"></category><category term="aws"></category><category term="best practice"></category><category term="deep learning"></category><category term="devops"></category><category term="docker"></category><category term="infrastructure"></category><category term="machine learning"></category><category term="open source"></category><category term="operations"></category><category term="packaging"></category><category term="performance"></category><category term="scaling"></category></entry></feed>