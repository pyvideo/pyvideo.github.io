<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_anthon-van-der-neut.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2016-08-05T00:00:00+00:00</updated><entry><title>Beyond scraping</title><link href="https://pyvideo.org/europython-2016/beyond-scraping.html" rel="alternate"></link><published>2016-08-05T00:00:00+00:00</published><updated>2016-08-05T00:00:00+00:00</updated><author><name>Anthon van der Neut</name></author><id>tag:pyvideo.org,2016-08-05:europython-2016/beyond-scraping.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Anthon van der Neut - Beyond scraping
[EuroPython 2016]
[20 July 2016]
[Bilbao, Euskadi, Spain]
(&lt;a class="reference external" href="https://ep2016.europython.eu//conference/talks/beyond-scraping-getting-data-from-dynamic-heavily-javascript-driven-websites"&gt;https://ep2016.europython.eu//conference/talks/beyond-scraping-getting-data-from-dynamic-heavily-javascript-driven-websites&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;This talk show how a to create a simple, evolving, client server
architecture combining  zeromq, selenium and beautifulsoup, which
allows you to scrape data even from variable dynamic sites like
Sporcle and KhanAcademy. Once the page analysis has been implemented
regular &amp;quot;downloads&amp;quot; can easily be deployed without cluttering your
desktop,  your headless server and/or anonymously.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Scraping  static websites can be done with &lt;cite&gt;urllib2&lt;/cite&gt; from the standard
library, or with some slightly more sophisticated packages like
&lt;cite&gt;requests&lt;/cite&gt;.
However as soon as JavaScript comes into play on the website you want
to download information from, for things like logging in via openid or
constructing the pages content, you almost always have to fall back to
driving a real browser.
For web sites with variable content this is can be  time consuming and
cumbersome process.&lt;/p&gt;
&lt;p&gt;This talk show how a to create a simple, evolving, client server
architecture combining  zeromq, selenium and beautifulsoup, which
allows you to scrape data from sites like Sporcle, StackOverflow and
KhanAcademy. Once the page analysis has been implemented regular
&amp;quot;downloads&amp;quot; can easily be deployed without cluttering your desktop,
your headless server and/or anonymously.&lt;/p&gt;
&lt;p&gt;The described client server setup allows you to restart your changed
analysis program without having to redo all the previous steps of
logging in and stepping through instructions to get back to the page
where you got &amp;quot;stuck&amp;quot; earlier on. This often decreases the time
between entering a possible fix in your HTML analysis code en testing
it, down to less than a second from a few tens of seconds in case you
have to restart a browser.&lt;/p&gt;
&lt;p&gt;Using such a setup you have time to focus on writing robust code
instead of code that breaks  with every little change the sites
designers make.&lt;/p&gt;
</summary></entry></feed>