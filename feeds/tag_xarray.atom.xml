<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_xarray.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-05-03T00:00:00+00:00</updated><entry><title>Meet dask and distributed: the unsung heroes of Python scientific data ecosystem.</title><link href="https://pyvideo.org/pycon-italia-2019/meet-dask-and-distributed-the-unsung-heroes-of-python-scientific-data-ecosystem.html" rel="alternate"></link><published>2019-05-03T00:00:00+00:00</published><updated>2019-05-03T00:00:00+00:00</updated><author><name>Alessandro Amici</name></author><id>tag:pyvideo.org,2019-05-03:pycon-italia-2019/meet-dask-and-distributed-the-unsung-heroes-of-python-scientific-data-ecosystem.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Thanks to its world-class data tools and libraries, like Numpy, Pandas,
Jupyter, Matplotlib and xarray, Python is becoming the language of
choice in many scientific communities from Physics to Climate Science,
from Earth Observation to Economy.&lt;/p&gt;
&lt;p&gt;A turn-key but less-know component of the scientific ecosystem is the
dask library that enable seamless parallel, distributed and GPU
computing in most cases without code changes.&lt;/p&gt;
&lt;p&gt;We will use climate science as an typical example of a discipline where
simple tasks become easily big data problems and where mastering xarray,
dask and dask.distributed is the key to turn them back into simple
tasks, possibly on a large cluster of VMs (that you can easily provision
from your preferred cloud provider).&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://gitpitch.com/alexamici/talks/master?p=PyConX-2019"&gt;https://gitpitch.com/alexamici/talks/master?p=PyConX-2019&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1704"&gt;https://python.it/feedback-1704&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 17:15 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="Jupyter"></category><category term="dask.distributed"></category><category term="Big-Data"></category><category term="xarray"></category><category term="dask"></category><category term="climate-change"></category><category term="earth-obeservation"></category><category term="pandas"></category></entry><entry><title>Democratizing Distributed Computing with Dask and JupyterHub</title><link href="https://pyvideo.org/pycon-us-2018/democratizing-distributed-computing-with-dask-and-jupyterhub.html" rel="alternate"></link><published>2018-05-12T00:00:00+00:00</published><updated>2018-05-12T00:00:00+00:00</updated><author><name>Matthew Rocklin</name></author><id>tag:pyvideo.org,2018-05-12:pycon-us-2018/democratizing-distributed-computing-with-dask-and-jupyterhub.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We use JupyterHub, XArray, Dask, and Kubernetes to build a cloud-based system to enable scientists to analyze and manage large datasets.  We use this in practice to serve a broad community of atmospheric and climate scientists.&lt;/p&gt;
&lt;p&gt;Atmospheric and climate scientists analyze large volumes of observational and simulated data to better understand our planet.  They have historically used tools like NumPy and SciPy along with Jupyter notebooks to combine efficient computation with accessibility.  However, as datasets increase in size and collaboration extends to new populations of scientists these tools begin to feel their age.  In this talk we use more recent libraries to build a modern deployment for academic scientists.  In particular we use the following tools:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Dask:&lt;/strong&gt; to parallelize and scale NumPy computations&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;XArray&lt;/strong&gt;: as a self-discribing data model and tool kit for labeled and index arrays&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JupyterLab:&lt;/strong&gt; to enable more APIs for users beyond the classic notebook&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JupyterHub:&lt;/strong&gt; to manage users and maintain environments for a new population of cloud-friendly users&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kubernetes:&lt;/strong&gt; to manage everything and deploy easily on cloud hardware&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This talk will focus less on how these libraries work and will instead be a case study of using them together in an operational setting.  During the talk we will build up and deploy a running system that the audience can then use to access distributed computing resources.&lt;/p&gt;
</summary><category term="jupyterhub"></category><category term="xarray"></category><category term="dask"></category><category term="kubernetes"></category></entry></feed>