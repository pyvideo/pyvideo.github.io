<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - UAI 2020</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/event_uai-2020.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-08-03T00:00:00+00:00</updated><subtitle></subtitle><entry><title>99% of Worker-Master Communication in Distributed Optimization Is Not Needed</title><link href="https://pyvideo.org/uai-2020/99-of-worker-master-communication-in-distributed-optimization-is-not-needed.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Konstantin Mishchenko</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/99-of-worker-master-communication-in-distributed-optimization-is-not-needed.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;99% of Worker-Master Communication in Distributed Optimization Is Not Needed&lt;/p&gt;
&lt;p&gt;Konstantin Mishchenko (KAUST)*; Filip Hanzely (KAUST); Peter Richtarik (KAUST)&lt;/p&gt;
&lt;p&gt;In this paper we discuss sparsification of worker-to-server communication in large distributed systems. We improve upon algorithms that fit the following template: a local gradient estimate is computed independently by …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;99% of Worker-Master Communication in Distributed Optimization Is Not Needed&lt;/p&gt;
&lt;p&gt;Konstantin Mishchenko (KAUST)*; Filip Hanzely (KAUST); Peter Richtarik (KAUST)&lt;/p&gt;
&lt;p&gt;In this paper we discuss sparsification of worker-to-server communication in large distributed systems. We improve upon algorithms that fit the following template: a local gradient estimate is computed independently by each worker, then communicated to a master, which subsequently performs averaging. The average is broadcast back to the workers, which use it to perform a gradient-type step to update the local version of the model. We observe that the above template is fundamentally inefficient in that too much data is unnecessarily communicated from the workers to the server, which slows down the overall system. We propose a fix based on a new update-sparsification method we develop in this work, which we suggest be used on top of existing methods. Namely, we develop a new variant of parallel block coordinate descent based on independent sparsification of the local gradient estimates before communication. We demonstrate that with only $m/n$ blocks sent by each of $n$ workers, where $m$ is the total number of parameter blocks, the theoretical iteration complexity of the underlying distributed methods is essentially unaffected. As an illustration, this means that when $n=100$ parallel workers are used, the communication of 99% blocks is redundant, and hence a waste of time. Our theoretical claims are supported through extensive numerical experiments which demonstrate an almost perfect match with our theory on a number of synthetic and real datasets.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>A Practical Riemannian Algorithm for Computing Dominant Generalized Eigenspace</title><link href="https://pyvideo.org/uai-2020/a-practical-riemannian-algorithm-for-computing-dominant-generalized-eigenspace.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Zhiqiang Xu</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/a-practical-riemannian-algorithm-for-computing-dominant-generalized-eigenspace.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;A Practical Riemannian Algorithm for Computing Dominant Generalized Eigenspace&lt;/p&gt;
&lt;p&gt;Zhiqiang Xu (Baidu)*; Ping Li (Baidu Research)&lt;/p&gt;
&lt;p&gt;Dominant generalized eigenspace computation, concerned with how to find one of the top-k generalized eigenspaces of a pair of real symmetric matrices, is one of the fundamental problems in scientific computing, data analysis …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;A Practical Riemannian Algorithm for Computing Dominant Generalized Eigenspace&lt;/p&gt;
&lt;p&gt;Zhiqiang Xu (Baidu)*; Ping Li (Baidu Research)&lt;/p&gt;
&lt;p&gt;Dominant generalized eigenspace computation, concerned with how to find one of the top-k generalized eigenspaces of a pair of real symmetric matrices, is one of the fundamental problems in scientific computing, data analysis, and statistics. In this work, we propose a practical Riemannian algorithm based on the first-order optimization on generalized Stiefel manifolds while efficiently leveraging second-order information. Particularly, we use inexact Riemannian gradients which result from running a fast least-squares solver to approximate matrix multiplications for avoiding costly matrix inversions involved therein. We also conduct a theoretical analysis that is different than existing ones, achieving a unified linear convergence rate regardless of the conventional generalized eigenvalue gap which is the key parameter to the currently dichotomized analysis: gap-dependent or gap-free. The resulting linear rate, albeit not optimal, remains valid in full generality. Despite the simplicity, empirically, our algorithm as a block generalized eigensolver remarkably outperforms existing solvers.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>A Simple Online Algorithm for Competing with Dynamic Comparators</title><link href="https://pyvideo.org/uai-2020/a-simple-online-algorithm-for-competing-with-dynamic-comparators.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Yu-Jie Zhang</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/a-simple-online-algorithm-for-competing-with-dynamic-comparators.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;A Simple Online Algorithm for Competing with Dynamic Comparators&lt;/p&gt;
&lt;p&gt;Yu-Jie Zhang (Nanjing University); Peng Zhao (Nanjing University)*; Zhi-Hua  Zhou (Nanjing University)&lt;/p&gt;
&lt;p&gt;Online learning in dynamic environments has recently drawn considerable attention, where dynamic regret is usually employed to compare decisions of online algorithms to dynamic comparators. In previous works …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;A Simple Online Algorithm for Competing with Dynamic Comparators&lt;/p&gt;
&lt;p&gt;Yu-Jie Zhang (Nanjing University); Peng Zhao (Nanjing University)*; Zhi-Hua  Zhou (Nanjing University)&lt;/p&gt;
&lt;p&gt;Online learning in dynamic environments has recently drawn considerable attention, where dynamic regret is usually employed to compare decisions of online algorithms to dynamic comparators. In previous works, dynamic regret bounds are typically established in terms of regularity of comparators $C_T$ or that of online functions $V_T$. Recently, Jadbabaie et al. [2015] propose an algorithm that can take advantage of both regularities and enjoy an $tilde{O}(sqrt{1+D_T} + min{sqrt{(1+D_T)C_T}, (1+D_T)^{1/3}V_T^{1/3}T^{1/3}})$ dynamic regret, where $D_T$ is an additional quantity to measure the niceness of environments. The regret bound adapts to the smaller regularity of problem environments and is tighter than all existing dynamic regret guarantees. Nevertheless, their algorithm involves non-convex programming at each iteration, and thus requires burdensome computations. In this paper, we design a simple algorithm based on the online ensemble, which provably enjoys the same (even slightly stronger) guarantee as the state-of-the-art rate, yet is much more efficient because our algorithm does not involve any non-convex problem solving. Empirical studies also verify the efficacy and efficiency.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>A SUPER* Algorithm to Optimize Paper Bidding in Peer Review</title><link href="https://pyvideo.org/uai-2020/a-super-algorithm-to-optimize-paper-bidding-in-peer-review.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Tanner Fiez</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/a-super-algorithm-to-optimize-paper-bidding-in-peer-review.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A SUPER* Algorithm to Optimize Paper Bidding in Peer Review&lt;/p&gt;
&lt;p&gt;Tanner Fiez (University of Washington)*; Nihar Shah (CMU); Lillian  Ratliff (University of Washington)&lt;/p&gt;
&lt;p&gt;A number of applications involve  sequential arrival of users, and require showing each user an ordering of items. A prime example is the bidding process in …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A SUPER* Algorithm to Optimize Paper Bidding in Peer Review&lt;/p&gt;
&lt;p&gt;Tanner Fiez (University of Washington)*; Nihar Shah (CMU); Lillian  Ratliff (University of Washington)&lt;/p&gt;
&lt;p&gt;A number of applications involve  sequential arrival of users, and require showing each user an ordering of items. A prime example is the bidding process in conference peer review where reviewers enter the system sequentially, each reviewer needs to be shown the list of submitted papers, and the reviewer then &amp;quot;bids&amp;quot; to review some papers. The order of the papers shown has a significant impact on the bids due to primacy effects. In deciding on the ordering of the list of papers to show, there are two competing goals: (i) obtaining sufficiently many bids for each paper, and (ii) satisfying reviewers by showing them relevant items. In this paper, we develop a framework to study this problem in a principled manner. We present an algorithm called SUPER*, inspired by the A* algorithm, for this goal. Theoretically, we show a local optimality guarantee of our algorithm and prove that popular baselines are considerably suboptimal. Moreover, under a community model for the similarities, we prove that SUPER* is near-optimal whereas the popular baselines are considerably suboptimal. In experiments on real data from ICLR 2018 and synthetic data, we find that SUPER* considerably outperforms baselines deployed in existing systems, consistently reducing the number of papers with fewer than requisite bids by 50-75% or more, and is also robust to various real world complexities.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Active Learning of Conditional Mean Embeddings via Bayesian Optimisation</title><link href="https://pyvideo.org/uai-2020/active-learning-of-conditional-mean-embeddings-via-bayesian-optimisation.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Sayak Ray Chowdhury</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/active-learning-of-conditional-mean-embeddings-via-bayesian-optimisation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Active Learning of Conditional Mean Embeddings via Bayesian Optimisation&lt;/p&gt;
&lt;p&gt;Sayak Ray Chowdhury (Indian Institute of Science)*; Rafael Oliveira (The University of Sydney); Fabio Ramos (NVIDIA, The University of Sydney)&lt;/p&gt;
&lt;p&gt;We consider the problem of sequentially optimising the conditional expectation of an objective function, with both the conditional distribution and …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Active Learning of Conditional Mean Embeddings via Bayesian Optimisation&lt;/p&gt;
&lt;p&gt;Sayak Ray Chowdhury (Indian Institute of Science)*; Rafael Oliveira (The University of Sydney); Fabio Ramos (NVIDIA, The University of Sydney)&lt;/p&gt;
&lt;p&gt;We consider the problem of sequentially optimising the conditional expectation of an objective function, with both the conditional distribution and the objective function assumed to be fixed but unknown. Assuming that the objective function belongs to a reproducing kernel Hilbert space (RKHS), we provide a novel upper confidence bound (UCB) based algorithm CME-UCB via estimation of the conditional mean embeddings (CME), and derive its regret bound. Along the way, we derive novel approximation guarantees for the CME estimates. Finally, experiments are carried out in a synthetic example and in a likelihood-free inference application that highlight the useful insights of the proposed method.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Adapting Text Embeddings for Causal Inference</title><link href="https://pyvideo.org/uai-2020/adapting-text-embeddings-for-causal-inference.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Victor Veitch</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/adapting-text-embeddings-for-causal-inference.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Adapting Text Embeddings for Causal Inference&lt;/p&gt;
&lt;p&gt;Victor Veitch (Columbia University)*; Dhanya Sridhar (Columbia University); David Blei (Columbia University)&lt;/p&gt;
&lt;p&gt;Does adding a theorem to a paper affect its chance of acceptance? Does labeling a post with the author’s gender affect the post popularity? This paper develops a method to …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Adapting Text Embeddings for Causal Inference&lt;/p&gt;
&lt;p&gt;Victor Veitch (Columbia University)*; Dhanya Sridhar (Columbia University); David Blei (Columbia University)&lt;/p&gt;
&lt;p&gt;Does adding a theorem to a paper affect its chance of acceptance? Does labeling a post with the author’s gender affect the post popularity? This paper develops a method to estimate such causal effects from observational text data, adjusting for confounding features of the text such as the subject or writing quality. We assume that the text suffices for causal adjustment but that, in practice, it is prohibitively high-dimensional. To address this challenge, we develop causally sufficient embeddings, low- dimensional document representations that preserve sufficient information for causal identification and allow for efficient estimation of causal effects. Causally sufficient embeddings combine two ideas. The first is supervised dimensionality reduction: causal adjustment requires only the aspects of text that are predictive of both the treatment and outcome. The second is efficient language modeling: representations of text are designed to dispose of linguistically irrelevant information, and this information is also causally irrelevant. Our method adapts language models (specifically, word embeddings and topic models) to learn document embeddings that are able to predict both treatment and outcome. We study causally sufficient embeddings with semi-synthetic datasets and find that they improve causal estimation over related embedding methods. We illustrate the methods by answering the two motivating questions---the effect of a theorem on paper acceptance and the effect of a gender label on post popularity. Code and data available at github.com/vveitch/causal-text-embeddings-tf2.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Adversarial Learning for 3D Matching</title><link href="https://pyvideo.org/uai-2020/adversarial-learning-for-3d-matching.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Wei Xing</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/adversarial-learning-for-3d-matching.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Adversarial Learning for 3D Matching&lt;/p&gt;
&lt;p&gt;Wei Xing (University of Illinois at Chicago)*; Brian Ziebart (UIC)&lt;/p&gt;
&lt;p&gt;Structured prediction of objects in spaces that are inherently difficult to search or compactly characterize is a particularly challenging task. For example, though bipartite matchings in two dimensions can be tractably optimized and learned …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Adversarial Learning for 3D Matching&lt;/p&gt;
&lt;p&gt;Wei Xing (University of Illinois at Chicago)*; Brian Ziebart (UIC)&lt;/p&gt;
&lt;p&gt;Structured prediction of objects in spaces that are inherently difficult to search or compactly characterize is a particularly challenging task. For example, though bipartite matchings in two dimensions can be tractably optimized and learned, the higher-dimensional generalization—3D matchings—are NP-hard to optimally obtain and the set of potential solutions cannot be compactly characterized. Though approximation is therefore necessary, prevalent structured prediction methods inherit the weaknesses they possess in the two-dimensional setting either suffering from inconsistency or intractability—even when the approximations are sufficient. In this paper, we explore extending an adversarial approach to learning bipartite matchings that avoids these weaknesses to the three dimensional setting. We assess the benefits compared to margin-based methods on a three-frame tracking problem.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Amortized Bayesian Optimization over Discrete Spaces</title><link href="https://pyvideo.org/uai-2020/amortized-bayesian-optimization-over-discrete-spaces.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Kevin Swersky</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/amortized-bayesian-optimization-over-discrete-spaces.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Amortized Bayesian Optimization over Discrete Spaces&lt;/p&gt;
&lt;p&gt;Kevin Swersky (Google Brain)*; Yulia Rubanova (University of Toronto); David Dohan (Google); Kevin Murphy (Google)&lt;/p&gt;
&lt;p&gt;Bayesian optimization is a principled approach for globally optimizing expensive, black-box functions by using a surrogate model of the objective. However, each step of Bayesian optimization involves solving …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Amortized Bayesian Optimization over Discrete Spaces&lt;/p&gt;
&lt;p&gt;Kevin Swersky (Google Brain)*; Yulia Rubanova (University of Toronto); David Dohan (Google); Kevin Murphy (Google)&lt;/p&gt;
&lt;p&gt;Bayesian optimization is a principled approach for globally optimizing expensive, black-box functions by using a surrogate model of the objective. However, each step of Bayesian optimization involves solving an inner optimization problem, in which we maximize an acquisition function  derived from the surrogate model to decide where to query next. This inner problem can be challenging to solve, particularly in discrete spaces, such as protein sequences or molecular graphs, where gradient-based optimization cannot be used. Our key insight is that we can train a generative model to generate candidates that maximize the acquisition function. This is faster than standard model-free local search methods, since we can amortize the cost of learning the model across multiple rounds of Bayesian optimization. We therefore call this Amortized Bayesian Optimization. On several challenging discrete design problems, we show this method generally outperforms other methods at optimizing the inner acquisition function, resulting in more efficient optimization of the outer black-box objective.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Amortized Nesterov's Momentum: A Robust Momentum and Its Application to Deep Learning</title><link href="https://pyvideo.org/uai-2020/amortized-nesterovs-momentum-a-robust-momentum-and-its-application-to-deep-learning.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Kaiwen Zhou</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/amortized-nesterovs-momentum-a-robust-momentum-and-its-application-to-deep-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Amortized Nesterov's Momentum: A Robust Momentum and Its Application to Deep Learning&lt;/p&gt;
&lt;p&gt;Kaiwen Zhou (The Chinese University of Hong Kong)*; Yanghua Jin (Preferred Networks); Qinghua Ding (CUHK); James Cheng (CUHK)&lt;/p&gt;
&lt;p&gt;This work proposes a novel momentum technique, the Amortized Nesterov's Momentum, for stochastic convex optimization. The proposed method can …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Amortized Nesterov's Momentum: A Robust Momentum and Its Application to Deep Learning&lt;/p&gt;
&lt;p&gt;Kaiwen Zhou (The Chinese University of Hong Kong)*; Yanghua Jin (Preferred Networks); Qinghua Ding (CUHK); James Cheng (CUHK)&lt;/p&gt;
&lt;p&gt;This work proposes a novel momentum technique, the Amortized Nesterov's Momentum, for stochastic convex optimization. The proposed method can be regarded as a smooth transition between Nesterov's method and mirror descent. By tuning only a single parameter, users can trade Nesterov's acceleration for robustness, that is, the variance control of the stochastic noise. Motivated by the recent success of using momentum in deep learning, we conducted extensive experiments to evaluate this new momentum in deep learning tasks. The results suggest that it can serve as a favorable alternative for Nesterov's momentum.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Amortized variance reduction for doubly stochastic objective</title><link href="https://pyvideo.org/uai-2020/amortized-variance-reduction-for-doubly-stochastic-objective.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Ayman Boustati</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/amortized-variance-reduction-for-doubly-stochastic-objective.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Amortized variance reduction for doubly stochastic objective&lt;/p&gt;
&lt;p&gt;Ayman Boustati (University of Warwick)*; Sattar Vakili (Prowler.io); James Hensman (PROWLER.io); ST John (PROWLER.io)&lt;/p&gt;
&lt;p&gt;Approximate inference in complex probabilistic models such as deep Gaussian processes requires the optimisation of doubly stochastic objective functions. These objectives incorporate randomness both from …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Amortized variance reduction for doubly stochastic objective&lt;/p&gt;
&lt;p&gt;Ayman Boustati (University of Warwick)*; Sattar Vakili (Prowler.io); James Hensman (PROWLER.io); ST John (PROWLER.io)&lt;/p&gt;
&lt;p&gt;Approximate inference in complex probabilistic models such as deep Gaussian processes requires the optimisation of doubly stochastic objective functions. These objectives incorporate randomness both from mini-batch subsampling of the data and from Monte Carlo estimation of expectations. If the gradient variance is high, the stochastic optimisation problem becomes difficult with a slow rate of convergence. Control variates can be used to reduce the variance, but past approaches do not take into account how mini-batch stochasticity affects sampling stochasticity, resulting in sub-optimal variance reduction. We propose a new approach in which we use a recognition network to cheaply approximate the optimal control variate for each mini-batch, with no additional model gradient computations. We illustrate the properties of this proposal and test its performance on logistic regression and deep Gaussian processes.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>An Interpretable and Sample Efficient Deep Kernel for Gaussian Process</title><link href="https://pyvideo.org/uai-2020/an-interpretable-and-sample-efficient-deep-kernel-for-gaussian-process.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Yijue Dai</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/an-interpretable-and-sample-efficient-deep-kernel-for-gaussian-process.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;An Interpretable and Sample Efficient Deep Kernel for Gaussian Process&lt;/p&gt;
&lt;p&gt;Yijue Dai (The Chinese University of Hong Kong, Shenzhen)*; Tianjian Zhang (The Chinese University of Hong Kong, Shenzhen); Zhidi Lin (The Chinese University of Hong Kong, Shenzhen); Feng Yin (The Chinese University of Hong Kong, Shenzhen); Sergios Theodoridis (National …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;An Interpretable and Sample Efficient Deep Kernel for Gaussian Process&lt;/p&gt;
&lt;p&gt;Yijue Dai (The Chinese University of Hong Kong, Shenzhen)*; Tianjian Zhang (The Chinese University of Hong Kong, Shenzhen); Zhidi Lin (The Chinese University of Hong Kong, Shenzhen); Feng Yin (The Chinese University of Hong Kong, Shenzhen); Sergios Theodoridis (National and Kapodistrian University of Athens); Shuguang Cui (The Chinese University of Hong Kong, Shenzhen )&lt;/p&gt;
&lt;p&gt;We propose a novel Gaussian process kernel that takes advantage of a deep neural network (DNN) structure but retains good interpretability. The resulting kernel is capable of addressing four major issues of the previous works of similar art, i.e., the optimality, explainability, model complexity, and sample efficiency. Our kernel design procedure comprises three steps: (1) Derivation of an optimal kernel with a non-stationary dot product structure that minimizes the prediction/test mean-squared-error (MSE); (2) Decomposition of this optimal kernel as a linear combination of shallow DNN subnetworks with the aid of multi-way feature interaction detection; (3) Updating the hyper-parameters of the subnetworks via an alternating rationale until convergence. The designed kernel does not sacrifice interpretability for optimality. On the contrary, each subnetwork explicitly demonstrates the interaction of a set of features in a transformation function, leading to a solid path toward explainable kernel learning. We test the proposed kernel with both synthesized and real-world data sets, and the proposed kernel is superior to its competitors in terms of prediction performance in most cases. Moreover, it tends to maintain the prediction performance and be robust to data over-fitting issue, when reducing the number of samples. &amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Automated Dependence Plots</title><link href="https://pyvideo.org/uai-2020/automated-dependence-plots.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>David Inouye</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/automated-dependence-plots.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Automated Dependence Plots&lt;/p&gt;
&lt;p&gt;David Inouye (Purdue University)*; Liu Leqi (Carnegie Mellon University); Joon Sik Kim (Carnegie Mellon University); Bryon Aragam (University of Chicago); Pradeep Ravikumar (Carnegie Mellon University)&lt;/p&gt;
&lt;p&gt;In practical applications of machine learning, it is necessary to look beyond standard metrics such as test accuracy in order to …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Automated Dependence Plots&lt;/p&gt;
&lt;p&gt;David Inouye (Purdue University)*; Liu Leqi (Carnegie Mellon University); Joon Sik Kim (Carnegie Mellon University); Bryon Aragam (University of Chicago); Pradeep Ravikumar (Carnegie Mellon University)&lt;/p&gt;
&lt;p&gt;In practical applications of machine learning, it is necessary to look beyond standard metrics such as test accuracy in order to validate various qualitative properties of a model. Partial dependence plots (PDP), including instance-specific PDPs (i.e., ICE plots), have been widely used as a visual tool to understand or validate a model. Yet, current PDPs suffer from two main drawbacks: (1) a user must manually sort or select interesting plots, and (2) PDPs are usually limited to plots along a single feature. To address these drawbacks, we formalize a method for automating the selection of interesting PDPs and extend PDPs beyond showing single features to show the model response along arbitrary directions, for example in raw feature space or a latent space arising from some generative model. We demonstrate the usefulness of our automated dependence plots (ADP) across multiple use-cases and datasets including model selection, bias detection, understanding out-of-sample behavior, and exploring the latent space of a generative model. The code is available at&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Batch norm with entropic regularization turns deterministic autoencoders into generative models</title><link href="https://pyvideo.org/uai-2020/batch-norm-with-entropic-regularization-turns-deterministic-autoencoders-into-generative-models.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Amur Ghose</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/batch-norm-with-entropic-regularization-turns-deterministic-autoencoders-into-generative-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Batch norm with entropic regularization turns deterministic autoencoders into generative models&lt;/p&gt;
&lt;p&gt;Amur Ghose (UWaterloo)*; Abdullah Rashwan (University of Waterloo); Pascal Poupart (University of Waterloo)&lt;/p&gt;
&lt;p&gt;The variational autoencoder is a well defined deep generative model that utilizes an encoder-decoder framework where an encoding neural network outputs a non-deterministic code for …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Batch norm with entropic regularization turns deterministic autoencoders into generative models&lt;/p&gt;
&lt;p&gt;Amur Ghose (UWaterloo)*; Abdullah Rashwan (University of Waterloo); Pascal Poupart (University of Waterloo)&lt;/p&gt;
&lt;p&gt;The variational autoencoder is a well defined deep generative model that utilizes an encoder-decoder framework where an encoding neural network outputs a non-deterministic code for reconstructing an input. The encoder achieves this by sampling from a distribution for every input, instead of outputting a deterministic code per input. The great advantage of this process is that it allows the use of the network as a generative model for sampling from the data distribution beyond provided samples for training. We show in this work that utilizing batch normalization as a source for non-determinism suffices to turn deterministic autoencoders into generative models on par with variational ones, so long as we add a suitable entropic regularization to the training objective.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Batch simulations and uncertainty quantification in Gaussian process surrogate approximate Bayesian</title><link href="https://pyvideo.org/uai-2020/batch-simulations-and-uncertainty-quantification-in-gaussian-process-surrogate-approximate-bayesian.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Marko Jarvenpaa</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/batch-simulations-and-uncertainty-quantification-in-gaussian-process-surrogate-approximate-bayesian.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Batch simulations and uncertainty quantification in Gaussian process surrogate approximate Bayesian computation&lt;/p&gt;
&lt;p&gt;Marko Jarvenpaa (University of Oslo)*; Aki Vehtari (Aalto University); Pekka Marttinen (Aalto University)&lt;/p&gt;
&lt;p&gt;The computational efficiency of approximate Bayesian computation (ABC) has been improved by using surrogate models such as Gaussian processes (GP). In one such promising …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Batch simulations and uncertainty quantification in Gaussian process surrogate approximate Bayesian computation&lt;/p&gt;
&lt;p&gt;Marko Jarvenpaa (University of Oslo)*; Aki Vehtari (Aalto University); Pekka Marttinen (Aalto University)&lt;/p&gt;
&lt;p&gt;The computational efficiency of approximate Bayesian computation (ABC) has been improved by using surrogate models such as Gaussian processes (GP). In one such promising framework the discrepancy between the simulated and observed data is modelled with a GP which is further used to form a model-based estimator for the intractable posterior. In this article we improve this approach in several ways. We develop batch-sequential Bayesian experimental design strategies to parallellise the expensive simulations. In earlier work only sequential strategies have been used. Current surrogate-based ABC methods also do not fully account the uncertainty due to the limited budget of simulations as they output only a point estimate of the ABC posterior. We propose a numerical method to fully quantify the uncertainty in, for example, ABC posterior moments. We also provide some new analysis on the GP modelling assumptions in the resulting improved framework called Bayesian ABC and discuss its connection to Bayesian quadrature (BQ) and Bayesian optimisation (BO). Experiments with toy and real-world simulation models demonstrate advantages of the proposed techniques. &amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Bayesian Online Prediction of Change Points</title><link href="https://pyvideo.org/uai-2020/bayesian-online-prediction-of-change-points.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Diego Agudelo-España</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/bayesian-online-prediction-of-change-points.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Bayesian Online Prediction of Change Points&lt;/p&gt;
&lt;p&gt;Diego Agudelo-España (MPI for Intelligent Systems, Tübingen)*; Sebastian Gomez-Gonzalez (Max Planck Institute for Intelligent Systems); Stefan Bauer (MPI IS); Bernhard Schölkopf (MPI for Intelligent Systems, Tübingen); Jan Peters (TU Darmstadt + Max Planck Institute for Intelligent Systems)&lt;/p&gt;
&lt;p&gt;Online detection of instantaneous changes in the …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Bayesian Online Prediction of Change Points&lt;/p&gt;
&lt;p&gt;Diego Agudelo-España (MPI for Intelligent Systems, Tübingen)*; Sebastian Gomez-Gonzalez (Max Planck Institute for Intelligent Systems); Stefan Bauer (MPI IS); Bernhard Schölkopf (MPI for Intelligent Systems, Tübingen); Jan Peters (TU Darmstadt + Max Planck Institute for Intelligent Systems)&lt;/p&gt;
&lt;p&gt;Online detection of instantaneous changes in the generative process of a data sequence generally focuses on retrospective inference of such change points without considering their future occurrences. We extend the Bayesian Online Change Point Detection algorithm to also infer the number of time steps until the next change point (i.e., the residual time). This enables to handle observation models which depend on the total segment duration, which is useful to model data sequences with temporal scaling. The resulting inference algorithm for segment detection can be deployed in an online fashion, and we illustrate applications to synthetic and to two medical real-world data sets.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Bounded Rationality in Las Vegas: Probabilistic Finite Automata Play Multi-Armed Bandits</title><link href="https://pyvideo.org/uai-2020/bounded-rationality-in-las-vegas-probabilistic-finite-automata-play-multi-armed-bandits.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Xinming Liu</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/bounded-rationality-in-las-vegas-probabilistic-finite-automata-play-multi-armed-bandits.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Bounded Rationality in Las Vegas: Probabilistic Finite Automata Play Multi-Armed Bandits&lt;/p&gt;
&lt;p&gt;Xinming Liu (Cornell University)*; Joseph Halpern (Cornell University)&lt;/p&gt;
&lt;p&gt;While traditional economics assumes that humans are fully rational agents who always maximize their expected utility, in practice, we constantly observe apparently irrational behavior. One explanation is that people have …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Bounded Rationality in Las Vegas: Probabilistic Finite Automata Play Multi-Armed Bandits&lt;/p&gt;
&lt;p&gt;Xinming Liu (Cornell University)*; Joseph Halpern (Cornell University)&lt;/p&gt;
&lt;p&gt;While traditional economics assumes that humans are fully rational agents who always maximize their expected utility, in practice, we constantly observe apparently irrational behavior. One explanation is that people have limited computational power, so that they are, quite rationally, making the best decisions they can, given their computational limitations.  To test this hypothesis, we consider the multi-armed bandit (MAB) problem. We examine a simple strategy for playing an MAB that can be implemented easily by a probabilistic finite automaton (PFA). Roughly speaking, the PFA sets certain expectations, and plays an arm as long as it meets them. If the PFA has sufficiently many states, it performs near-optimally. Its performance degrades gracefully as the number of states decreases. Moreover, the PFA acts in a &amp;quot;&amp;quot;human-like&amp;quot;&amp;quot; way, exhibiting a number of standard human biases, like an optimism bias and a negativity bias.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Bounding the expected run-time of nonconvex optimization with early stopping</title><link href="https://pyvideo.org/uai-2020/bounding-the-expected-run-time-of-nonconvex-optimization-with-early-stopping.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Thomas Flynn</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/bounding-the-expected-run-time-of-nonconvex-optimization-with-early-stopping.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Bounding the expected run-time of nonconvex optimization with early stopping&lt;/p&gt;
&lt;p&gt;Thomas Flynn (Brookhaven National Laboratory)*; Kwangmin Yu (Brookhaven National Laboratory); Abid Malik (Brookhaven National Laboratory); Nicholas D'Imperio (Brookhaven National Laboratory); Shinjae Yoo (Brookhaven National Laboratory)&lt;/p&gt;
&lt;blockquote&gt;
This work examines the convergence of stochastic gradient-based optimization algorithms that use early stopping …&lt;/blockquote&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Bounding the expected run-time of nonconvex optimization with early stopping&lt;/p&gt;
&lt;p&gt;Thomas Flynn (Brookhaven National Laboratory)*; Kwangmin Yu (Brookhaven National Laboratory); Abid Malik (Brookhaven National Laboratory); Nicholas D'Imperio (Brookhaven National Laboratory); Shinjae Yoo (Brookhaven National Laboratory)&lt;/p&gt;
&lt;blockquote&gt;
This work examines the convergence of stochastic gradient-based optimization algorithms that use early stopping based on a validation function. The form of early stopping we consider is that optimization terminates when the norm of the gradient  of a validation function falls below a threshold. We derive conditions that guarantee this stopping rule is well-defined, and provide bounds on the expected number of iterations and gradient evaluations needed to meet this criterion. The guarantee accounts for the distance between the training and validation sets, measured with the Wasserstein distance. We develop the approach in the general setting of a first-order optimization algorithm, with possibly biased update directions subject to a geometric drift condition. We then derive bounds on the expected running time for early stopping variants of several algorithms, including stochastic gradient descent (SGD), decentralized SGD (DSGD), and the stochastic variance reduced gradient (SVRG) algorithm. Finally, we consider the generalization properties of the iterate returned by early stopping.&amp;quot;&lt;/blockquote&gt;
</content><category term="UAI 2020"></category></entry><entry><title>C-MI-GAN : Estimation of Conditional Mutual Information using MinMax formulation</title><link href="https://pyvideo.org/uai-2020/c-mi-gan-estimation-of-conditional-mutual-information-using-minmax-formulation.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Arnab Mondal</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/c-mi-gan-estimation-of-conditional-mutual-information-using-minmax-formulation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;C-MI-GAN : Estimation of Conditional Mutual Information using MinMax formulation&lt;/p&gt;
&lt;p&gt;Arnab Mondal (IIT Delhi)*; Arnab  Bhattacharjee (IIT Delhi); Sudipto Mukherjee (University of Washington); Himanshu Asnani (TIFR); Sreeram Kannan (University of Washington); Prathosh A P (Indian Institute of Technology Delhi)&lt;/p&gt;
&lt;p&gt;Estimation of information theoretic quantities such as mutual information and its …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;C-MI-GAN : Estimation of Conditional Mutual Information using MinMax formulation&lt;/p&gt;
&lt;p&gt;Arnab Mondal (IIT Delhi)*; Arnab  Bhattacharjee (IIT Delhi); Sudipto Mukherjee (University of Washington); Himanshu Asnani (TIFR); Sreeram Kannan (University of Washington); Prathosh A P (Indian Institute of Technology Delhi)&lt;/p&gt;
&lt;p&gt;Estimation of information theoretic quantities such as mutual information and its conditional variant has drawn interest in recent times owing to their multifaceted applications. Newly proposed neural estimators for these quantities have overcome severe drawbacks of classical $k$NN-based estimators in high dimensions. In this work, we focus on conditional mutual information (CMI) estimation by utilizing its formulation as a textit{minmax} optimization problem. Such a formulation leads to a joint training procedure similar to that of generative adversarial networks. We find that our proposed estimator provides better estimates than the existing approaches on a variety of simulated datasets comprising linear and non-linear relations between variables. As an application of CMI estimation, we deploy our estimator for conditional independence (CI) testing on real data and obtain better results than state-of-the-art CI testers.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Causal screening in dynamical systems</title><link href="https://pyvideo.org/uai-2020/causal-screening-in-dynamical-systems.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Søren Wengel Mogensen</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/causal-screening-in-dynamical-systems.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Causal screening in dynamical systems&lt;/p&gt;
&lt;p&gt;Søren Wengel Mogensen (University of Copenhagen)*&lt;/p&gt;
&lt;p&gt;Many classical algorithms output graphical representations of causal structures by testing conditional independence among a set of random variables. In dynamical systems, local independence can be used analogously as a testable implication of the underlying data-generating process. We …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Causal screening in dynamical systems&lt;/p&gt;
&lt;p&gt;Søren Wengel Mogensen (University of Copenhagen)*&lt;/p&gt;
&lt;p&gt;Many classical algorithms output graphical representations of causal structures by testing conditional independence among a set of random variables. In dynamical systems, local independence can be used analogously as a testable implication of the underlying data-generating process. We suggest some inexpensive methods for causal screening which provide output with a sound causal interpretation under the assumption of ancestral faithfulness. The popular model class of linear Hawkes processes is used to provide an example of a dynamical causal model. We argue that for sparse causal graphs the output will often be close to complete. We give examples of this framework and apply it to a challenging biological system.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Collapsible IDA: Collapsing Parental Sets for Locally Estimating Possible Causal Effects</title><link href="https://pyvideo.org/uai-2020/collapsible-ida-collapsing-parental-sets-for-locally-estimating-possible-causal-effects.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Yue Liu</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/collapsible-ida-collapsing-parental-sets-for-locally-estimating-possible-causal-effects.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Collapsible IDA: Collapsing Parental Sets for Locally Estimating Possible Causal Effects&lt;/p&gt;
&lt;p&gt;Yue Liu (Peking University); Zhuangyan Fang (Peking University); Yangbo He (Peking University)*; Zhi Geng (Peking University)&lt;/p&gt;
&lt;p&gt;It is clear that some causal effects cannot be identified from observational data when the causal directed acyclic graph is absent. In …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Collapsible IDA: Collapsing Parental Sets for Locally Estimating Possible Causal Effects&lt;/p&gt;
&lt;p&gt;Yue Liu (Peking University); Zhuangyan Fang (Peking University); Yangbo He (Peking University)*; Zhi Geng (Peking University)&lt;/p&gt;
&lt;p&gt;It is clear that some causal effects cannot be identified from observational data when the causal directed acyclic graph is absent. In such cases, IDA is a useful framework which estimates all possible causal effects by adjusting for all possible parental sets. In this paper, we combine the adjustment set selection procedure with the original IDA framework. Our goal is to find a common set that can be subtracted from all possible parental sets without influencing the back-door adjustment. To this end, we first introduce graphical conditions to decide whether a treatment's neighbor or parent in a completed partially directed acyclic graph (CPDAG) can be subtracted and then provide a procedure to construct a subtractable set from those subtractable vertices. We next combine the procedure with the IDA framework and provide a fully local modification of IDA. Experimental results show that, with our modification, both the number of possible parental sets and the size of each possible parental set enumerated by the modified IDA decrease, making it possible to estimate all possible causal effects more efficiently.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Complete Dictionary Learning via norm Maximization</title><link href="https://pyvideo.org/uai-2020/complete-dictionary-learning-via-norm-maximization.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Yifei Shen</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/complete-dictionary-learning-via-norm-maximization.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Complete Dictionary Learning via norm Maximization&lt;/p&gt;
&lt;p&gt;Yifei Shen (HKUST)*; Ye Xue (HKUST); Jun Zhang (Hong Kong Polytechnic University); Khaled Letaief (HKUST); Vincent Lau (University of Science and Technology)&lt;/p&gt;
&lt;p&gt;Dictionary learning is a classic representation learning method that has been widely applied in signal processing and data analytics. In this …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Complete Dictionary Learning via norm Maximization&lt;/p&gt;
&lt;p&gt;Yifei Shen (HKUST)*; Ye Xue (HKUST); Jun Zhang (Hong Kong Polytechnic University); Khaled Letaief (HKUST); Vincent Lau (University of Science and Technology)&lt;/p&gt;
&lt;p&gt;Dictionary learning is a classic representation learning method that has been widely applied in signal processing and data analytics. In this paper, we investigate a family of maximization approaches for the complete dictionary learning problem from theoretical and algorithmic aspects. Specifically, we prove that the global maximizers of these formulations are very close to the true dictionary with high probability, even when Gaussian noise is present. Based on the generalized power method (GPM), an efficient algorithm is then developed for the $ell_p$-based formulations. We further show the efficacy of the developed algorithm: for the population GPM algorithm over the sphere constraint, it first quickly enters the neighborhood of a global maximizer, and then converges linearly in this region. Extensive experiments will demonstrate that the $ell_p$-based approaches enjoy a higher computational efficiency and better robustness than conventional approaches and $p=3$ performs the best.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Complex Markov Logic Networks: Expressivity and Liftability</title><link href="https://pyvideo.org/uai-2020/complex-markov-logic-networks-expressivity-and-liftability.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Ondrej Kuzelka</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/complex-markov-logic-networks-expressivity-and-liftability.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Complex Markov Logic Networks: Expressivity and Liftability&lt;/p&gt;
&lt;p&gt;Ondrej Kuzelka (CTU in Prague)*&lt;/p&gt;
&lt;p&gt;We study expressivity of Markov logic networks (MLNs). We introduce complex MLNs, which use complex-valued weights, and show that, unlike standard MLNs with real-valued weights, complex MLNs are&amp;quot;&amp;quot;fully expressive&amp;quot;&amp;quot;. We then observe that discrete Fourier transform …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Complex Markov Logic Networks: Expressivity and Liftability&lt;/p&gt;
&lt;p&gt;Ondrej Kuzelka (CTU in Prague)*&lt;/p&gt;
&lt;p&gt;We study expressivity of Markov logic networks (MLNs). We introduce complex MLNs, which use complex-valued weights, and show that, unlike standard MLNs with real-valued weights, complex MLNs are&amp;quot;&amp;quot;fully expressive&amp;quot;&amp;quot;. We then observe that discrete Fourier transform can be computed using weighted first order model counting (WFOMC) with complex weights and use this observation to design an algorithm for computing &amp;quot;&amp;quot;relational marginal polytopes&amp;quot;&amp;quot; which needs substantially less calls to a WFOMC oracle than an existing recent algorithm.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Constraint-Based Causal Discovery using Partial Ancestral Graphs in the presence of Cycles</title><link href="https://pyvideo.org/uai-2020/constraint-based-causal-discovery-using-partial-ancestral-graphs-in-the-presence-of-cycles.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Joris M. Mooij</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/constraint-based-causal-discovery-using-partial-ancestral-graphs-in-the-presence-of-cycles.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Constraint-Based Causal Discovery using Partial Ancestral Graphs in the presence of Cycles&lt;/p&gt;
&lt;p&gt;Joris M. Mooij (University of Amsterdam)*; Tom Claassen (Radboud University Nijmegen)&lt;/p&gt;
&lt;p&gt;While feedback loops are known to play important roles in many complex systems, their existence is ignored in a large part of the causal discovery literature …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Constraint-Based Causal Discovery using Partial Ancestral Graphs in the presence of Cycles&lt;/p&gt;
&lt;p&gt;Joris M. Mooij (University of Amsterdam)*; Tom Claassen (Radboud University Nijmegen)&lt;/p&gt;
&lt;p&gt;While feedback loops are known to play important roles in many complex systems, their existence is ignored in a large part of the causal discovery literature, as systems are typically assumed to be acyclic from the outset. When applying causal discovery algorithms designed for the acyclic setting on data generated by a system that involves feedback, one would not expect to obtain correct results. In this work, we show that---surprisingly---the output of the Fast Causal Inference (FCI) algorithm is correct if it is applied to observational data generated by a system that involves feedback. More specifically, we prove that for observational data generated by a simple and sigma-faithful Structural Causal Model (SCM), FCI is sound and complete, and can be used to consistently estimate (i) the presence and absence of causal relations, (ii) the presence and absence of direct causal relations, (iii) the absence of confounders, and (iv) the absence of specific cycles in the causal graph of the SCM. We extend these results to constraint-based causal discovery algorithms that exploit certain forms of background knowledge, including the causally sufficient setting (e.g., the PC algorithm) and the Joint Causal Inference setting (e.g., the FCI-JCI algorithm).&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Coresets for Estimating Means and Mean Square Error with Limited Greedy Samples</title><link href="https://pyvideo.org/uai-2020/coresets-for-estimating-means-and-mean-square-error-with-limited-greedy-samples.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Saeed Vahidian</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/coresets-for-estimating-means-and-mean-square-error-with-limited-greedy-samples.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Coresets for Estimating Means and Mean Square Error with Limited Greedy Samples&lt;/p&gt;
&lt;p&gt;Saeed Vahidian (University of California San Diego); Baharan Mirzasoleiman (Stanford University); Alexander Cloninger (University of California San Diego)*&lt;/p&gt;
&lt;blockquote&gt;
In a number of situations, collecting a function value for every data point may be prohibitively expensive, and random …&lt;/blockquote&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Coresets for Estimating Means and Mean Square Error with Limited Greedy Samples&lt;/p&gt;
&lt;p&gt;Saeed Vahidian (University of California San Diego); Baharan Mirzasoleiman (Stanford University); Alexander Cloninger (University of California San Diego)*&lt;/p&gt;
&lt;blockquote&gt;
In a number of situations, collecting a function value for every data point may be prohibitively expensive, and random sampling ignores any structure in the underlying data. We introduce a scalable optimization algorithm with no correction steps (in contrast to Frank–Wolfe and its variants), a variant of gradient ascent for coreset selection in graphs, that greedily selects a weighted subset of vertices that are deemed most important to sample. Our algorithm estimates the mean of the function by taking a weighted sum only at these vertices, and we provably bound the estimation error in terms of the location and weights of the selected vertices in the graph. In addition, we consider the case where nodes have different selection costs and provide bounds on the quality of the low-cost selected coresets. We demonstrate the benefits of our algorithm on the semi-supervised node classification of graph convolutional neural network, point clouds and structured graphs, as well as sensor placement where the cost of placing sensors depends on the location of the placement. We also elucidate that the empirical convergence of our proposed method is faster than random selection and various clustering methods while still respecting sensor placement cost. The paper concludes with validation of the developed algorithm on both synthetic and real datasets, demonstrating that it outperforms the current state of the art.&amp;quot;&lt;/blockquote&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Deriving Bounds And Inequality Constraints Using Logical Relations Among Counterfactuals</title><link href="https://pyvideo.org/uai-2020/deriving-bounds-and-inequality-constraints-using-logical-relations-among-counterfactuals.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Noam Finkelstein</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/deriving-bounds-and-inequality-constraints-using-logical-relations-among-counterfactuals.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Deriving Bounds And Inequality Constraints Using Logical Relations Among Counterfactuals&lt;/p&gt;
&lt;p&gt;Noam Finkelstein (Johns Hopkins University)*; Ilya Shpitser (Johns Hopkins University)&lt;/p&gt;
&lt;blockquote&gt;
Causal parameters may not be point identified in the presence of unobserved
confounding. However, information about non-identified parameters, in the form
of bounds, may still be recovered from the …&lt;/blockquote&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Deriving Bounds And Inequality Constraints Using Logical Relations Among Counterfactuals&lt;/p&gt;
&lt;p&gt;Noam Finkelstein (Johns Hopkins University)*; Ilya Shpitser (Johns Hopkins University)&lt;/p&gt;
&lt;blockquote&gt;
Causal parameters may not be point identified in the presence of unobserved
confounding. However, information about non-identified parameters, in the form
of bounds, may still be recovered from the observed data in some cases. We
develop a new general method for obtaining bounds on causal parameters using
rules of probability and restrictions on counterfactuals implied by causal
graphical models. We additionally provide inequality constraints on
functionals of the observed data law implied by such causal models. Our
approach is motivated by the observation that logical relations between
identified and non-identified counterfactual events often yield information
about non-identified events. We show that this approach is powerful enough to
recover known sharp bounds and tight inequality constraints, and to derive
novel bounds and constraints.&amp;quot;&lt;/blockquote&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Differentially Private Small Dataset Release Using Random Projections</title><link href="https://pyvideo.org/uai-2020/differentially-private-small-dataset-release-using-random-projections.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Lovedeep Gondara</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/differentially-private-small-dataset-release-using-random-projections.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Differentially Private Small Dataset Release Using Random Projections&lt;/p&gt;
&lt;p&gt;Lovedeep Gondara (Simon Fraser University)*; Ke Wang (Simon Fraser University)&lt;/p&gt;
&lt;p&gt;Small datasets form a significant portion of releasable data in high sensitivity domains such as healthcare. But, providing differential privacy for small dataset release is a hard task, where current state-of-the-art …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Differentially Private Small Dataset Release Using Random Projections&lt;/p&gt;
&lt;p&gt;Lovedeep Gondara (Simon Fraser University)*; Ke Wang (Simon Fraser University)&lt;/p&gt;
&lt;p&gt;Small datasets form a significant portion of releasable data in high sensitivity domains such as healthcare. But, providing differential privacy for small dataset release is a hard task, where current state-of-the-art methods suffer from severe utility loss. As a solution, we propose DPRP (Differentially Private Data Release via Random Projections), a reconstruction based approach for releasing differentially private small datasets. DPRP has several key advantages over the state-of-the-art. Using seven diverse real-life datasets, we show that DPRP outperforms the current state-of-the-art on a variety of tasks, under varying conditions, and for all privacy budgets.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Differentially Private Top-k Selection via Stability on Unknown Domain</title><link href="https://pyvideo.org/uai-2020/differentially-private-top-k-selection-via-stability-on-unknown-domain.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Ricardo Silva Carvalho</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/differentially-private-top-k-selection-via-stability-on-unknown-domain.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Differentially Private Top-k Selection via Stability on Unknown Domain&lt;/p&gt;
&lt;p&gt;Ricardo Silva Carvalho (Simon Fraser University)*; Ke Wang (SFU); Lovedeep Gondara (Simon Fraser University); Chunyan Miao (NTU)&lt;/p&gt;
&lt;p&gt;We propose a new method that satisfies approximate differential privacy for top-$k$ selection with unordered output in the unknown data domain setting …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Differentially Private Top-k Selection via Stability on Unknown Domain&lt;/p&gt;
&lt;p&gt;Ricardo Silva Carvalho (Simon Fraser University)*; Ke Wang (SFU); Lovedeep Gondara (Simon Fraser University); Chunyan Miao (NTU)&lt;/p&gt;
&lt;p&gt;We propose a new method that satisfies approximate differential privacy for top-$k$ selection with unordered output in the unknown data domain setting, not relying on the full knowledge of the domain universe. Our algorithm only requires looking at the top-$bar{k}$ elements for any given $bar{k} geq k$, thus, enforcing the principle of minimal privilege. Unlike previous methods, our privacy parameter $varepsilon$ does not scale with $k$, giving improved applicability for scenarios of very large $k$. Moreover, our novel construction, which combines the sparse vector technique and stability efficiently, can be applied as a general framework to any type of query, thus being of independent interest. We extensively compare our algorithm to previous work of top-$k$ selection on the unknown domain, and show, both analytically and on experiments, settings where we outperform the current state-of-the-art.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Discovering contemporaneous and lagged causal relations in autocorrelated nonlinear time series</title><link href="https://pyvideo.org/uai-2020/discovering-contemporaneous-and-lagged-causal-relations-in-autocorrelated-nonlinear-time-series.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Jakob Runge</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/discovering-contemporaneous-and-lagged-causal-relations-in-autocorrelated-nonlinear-time-series.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Discovering contemporaneous and lagged causal relations in autocorrelated nonlinear time series datasets&lt;/p&gt;
&lt;p&gt;Jakob Runge (German Aerospace Agency)*&lt;/p&gt;
&lt;p&gt;The paper introduces a novel conditional independence (CI) based method for linear and nonlinear, lagged and contemporaneous causal discovery from observational time series in the causally sufficient case. Existing CI-based methods such …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Discovering contemporaneous and lagged causal relations in autocorrelated nonlinear time series datasets&lt;/p&gt;
&lt;p&gt;Jakob Runge (German Aerospace Agency)*&lt;/p&gt;
&lt;p&gt;The paper introduces a novel conditional independence (CI) based method for linear and nonlinear, lagged and contemporaneous causal discovery from observational time series in the causally sufficient case. Existing CI-based methods such as the PC algorithm and also common methods from other frameworks suffer from low recall and partially inflated false positives for strong autocorrelation which is an ubiquitous challenge in time series. The novel method, PCMCI$^+$, extends PCMCI [Runge et al., 2019b] to include discovery of contemporaneous links. PCMCI$^+$ improves the reliability of CI tests by optimizing the choice of conditioning sets and even benefits from autocorrelation. The method is order-independent and consistent in the oracle case. A broad range of numerical experiments demonstrates that PCMCI$^+$ has higher adjacency detection power and especially more contemporaneous orientation recall compared to other methods while better controlling false positives. Optimized conditioning sets also lead to much shorter runtimes than the PC algorithm. PCMCI$^+$ can be of considerable use in many real world application scenarios where often time resolutions are too coarse to resolve time delays and strong autocorrelation is present.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Distortion estimates for approximate Bayesian inference</title><link href="https://pyvideo.org/uai-2020/distortion-estimates-for-approximate-bayesian-inference.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Hanwen Xing</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/distortion-estimates-for-approximate-bayesian-inference.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Distortion estimates for approximate Bayesian inference&lt;/p&gt;
&lt;p&gt;Hanwen Xing (University of Oxford)*; Geoff Nicholls (University of Oxford); Jeong (Kate) Lee (University of Auckland)&lt;/p&gt;
&lt;p&gt;Current literature on posterior approximation for Bayesian inference offers many alternative methods. Does our chosen approximation scheme work well on the observed data? The best existing generic …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Distortion estimates for approximate Bayesian inference&lt;/p&gt;
&lt;p&gt;Hanwen Xing (University of Oxford)*; Geoff Nicholls (University of Oxford); Jeong (Kate) Lee (University of Auckland)&lt;/p&gt;
&lt;p&gt;Current literature on posterior approximation for Bayesian inference offers many alternative methods. Does our chosen approximation scheme work well on the observed data? The best existing generic diagnostic tools treating this kind of question by looking at performance averaged over data space, or otherwise lack diagnostic detail. However, if the approximation is bad for most data, but good at the observed data, then we may discard a useful approximation. We give graphical diagnostics for posterior approximation at the observed data. We estimate a &amp;quot;distortion map&amp;quot; that acts on univariate marginals of the approximate posterior to move them closer to the exact posterior, without recourse to the exact posterior.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Divergence-Based Motivation for Online EM and Combining Hidden Variable Models</title><link href="https://pyvideo.org/uai-2020/divergence-based-motivation-for-online-em-and-combining-hidden-variable-models.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Ehsan Amid</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/divergence-based-motivation-for-online-em-and-combining-hidden-variable-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Divergence-Based Motivation for Online EM and Combining Hidden Variable Models&lt;/p&gt;
&lt;p&gt;Ehsan Amid (UCSC &amp;amp; Google)*; Manfred K. Warmuth (UC Santa Cruz &amp;amp; Google Inc.)&lt;/p&gt;
&lt;p&gt;Expectation-Maximization (EM) is a prominent approach for parameter estimation of hidden (aka latent) variable models. Given the full batch of data, EM forms an upper-bound of the …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Divergence-Based Motivation for Online EM and Combining Hidden Variable Models&lt;/p&gt;
&lt;p&gt;Ehsan Amid (UCSC &amp;amp; Google)*; Manfred K. Warmuth (UC Santa Cruz &amp;amp; Google Inc.)&lt;/p&gt;
&lt;p&gt;Expectation-Maximization (EM) is a prominent approach for parameter estimation of hidden (aka latent) variable models. Given the full batch of data, EM forms an upper-bound of the negative log-likelihood of the model at each iteration and updates to the minimizer of this upper-bound. We first provide a &amp;quot;model level&amp;quot; interpretation of the EM upper-bound as a sum of relative entropy divergences to a set of singleton models induced by the batch of observations. Our alternative motivation unifies the &amp;quot;observation level&amp;quot; and the &amp;quot;model level&amp;quot;&amp;quot; view of the EM. As a result, we formulate an online version of the EM algorithm by adding an analogous inertia term which is a relative entropy divergence to the old model. Our motivation is more widely applicable than the previous approaches and leads to simple online updates for mixture of exponential distributions, hidden Markov models, and the first known online update for Kalman filters. Additionally, the finite sample form of the inertia term lets us derive online updates when there is no closed-form solution. Finally, we extend the analysis to the distributed setting where we motivate a systematic way of combining multiple hidden variable models. Experimentally, we validate the results on synthetic as well as real-world datasets.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Dueling Posterior Sampling for Preference-Based Reinforcement Learning</title><link href="https://pyvideo.org/uai-2020/dueling-posterior-sampling-for-preference-based-reinforcement-learning.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Ellen Novoseller</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/dueling-posterior-sampling-for-preference-based-reinforcement-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Dueling Posterior Sampling for Preference-Based Reinforcement Learning&lt;/p&gt;
&lt;p&gt;Ellen Novoseller (California Institute of Technology)*; Yibing Wei (California Institute of Technology); Yanan Sui (Tsinghua University); Yisong Yue (Caltech); Joel Burdick (Caltech)&lt;/p&gt;
&lt;p&gt;In preference-based reinforcement learning (RL), an agent interacts with the environment while receiving preferences instead of absolute feedback. While there …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Dueling Posterior Sampling for Preference-Based Reinforcement Learning&lt;/p&gt;
&lt;p&gt;Ellen Novoseller (California Institute of Technology)*; Yibing Wei (California Institute of Technology); Yanan Sui (Tsinghua University); Yisong Yue (Caltech); Joel Burdick (Caltech)&lt;/p&gt;
&lt;p&gt;In preference-based reinforcement learning (RL), an agent interacts with the environment while receiving preferences instead of absolute feedback. While there is increasing research activity in preference-based RL, the design of formal frameworks that admit tractable theoretical analysis remains an open challenge. Building upon ideas from preference-based bandit learning and posterior sampling in RL, we present DUELING POSTERIOR SAMPLING (DPS), which employs preference-based posterior sampling to learn both the system dynamics and the underlying utility function that governs the preference feedback. As preference feedback is provided on trajectories rather than individual state-action pairs, we develop a Bayesian approach for the credit assignment problem, translating  preferences to a posterior distribution over state-action reward models. We prove an asymptotic Bayesian no-regret rate for DPS with a Bayesian linear regression credit assignment model. This is the first regret guarantee for preference-based RL to our knowledge. We also discuss possible avenues for extending the proof methodology to  other credit assignment models. Finally, we evaluate the approach empirically, showing competitive performance against existing baselines.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Efficient Rollout Strategies for Bayesian Optimization</title><link href="https://pyvideo.org/uai-2020/efficient-rollout-strategies-for-bayesian-optimization.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Eric Lee</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/efficient-rollout-strategies-for-bayesian-optimization.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Efficient Rollout Strategies for Bayesian Optimization&lt;/p&gt;
&lt;p&gt;Eric Lee (Cornell University)*; David Eriksson (Uber AI); David Bindel (Cornell University); Bolong Cheng (SigOpt); Mike Mccourt (SigOpt)&lt;/p&gt;
&lt;p&gt;Bayesian optimization (BO) is a class of sample-efficient global optimization methods, where a probabilistic model conditioned on previous observations is used to determine future evaluations …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Efficient Rollout Strategies for Bayesian Optimization&lt;/p&gt;
&lt;p&gt;Eric Lee (Cornell University)*; David Eriksson (Uber AI); David Bindel (Cornell University); Bolong Cheng (SigOpt); Mike Mccourt (SigOpt)&lt;/p&gt;
&lt;p&gt;Bayesian optimization (BO) is a class of sample-efficient global optimization methods, where a probabilistic model conditioned on previous observations is used to determine future evaluations via the optimization of an acquisition function.
Most acquisition functions are myopic, meaning that they only consider the impact of the next function evaluation. Non-myopic acquisition functions consider the impact of the next h function evaluations and are typically computed through rollout, in which h steps of BO are simulated. These rollout acquisition functions are defined as h-dimensional integrals, and are expensive to compute and optimize. We show that a combination of quasi-Monte Carlo, common random numbers, and control variates significantly reduce the computational burden of rollout. We then formulate a policy-search based approach that removes the need to optimize the rollout acquisition function. Finally, we discuss the qualitative behavior of rollout policies in the setting of multi-modal objectives and model error.
&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>EiGLasso: Scalable Estimation of Cartesian Product of Sparse Inverse Covariance Matrices</title><link href="https://pyvideo.org/uai-2020/eiglasso-scalable-estimation-of-cartesian-product-of-sparse-inverse-covariance-matrices.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Jun Ho Yoon</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/eiglasso-scalable-estimation-of-cartesian-product-of-sparse-inverse-covariance-matrices.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;EiGLasso: Scalable Estimation of Cartesian Product of Sparse Inverse Covariance Matrices&lt;/p&gt;
&lt;p&gt;Jun Ho Yoon (Carnegie Mellon University)*; Seyoung Kim ()&lt;/p&gt;
&lt;p&gt;In this paper, we address the problem of jointly estimating dependencies across samples and dependencies across multiple features, where each set of dependencies is modeled as an inverse covariance matrix …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;EiGLasso: Scalable Estimation of Cartesian Product of Sparse Inverse Covariance Matrices&lt;/p&gt;
&lt;p&gt;Jun Ho Yoon (Carnegie Mellon University)*; Seyoung Kim ()&lt;/p&gt;
&lt;p&gt;In this paper, we address the problem of jointly estimating dependencies across samples and dependencies across multiple features, where each set of dependencies is modeled as an inverse covariance matrix. In particular, we study a matrix-variate Gaussian distribution with the Kronecker-sum of sample-wise and feature-wise inverse covariances. While this Kronecker-sum model has been studied as an intuitively more appealing convex alternative to the Kronecker-product of two inverse covariance matrices, the existing methods do not scale to large datasets. We introduce a highly-efficient optimization method for estimating the Kronecker-sum structured inverse covariance matrix from matrix-variate data. In addition, we describe an alternative simpler approach for handling the non-identifiability of parameters than the strategies proposed in previous works. Using simulated and real data, we demonstrate our approach leads to one or two orders-of-magnitude speedup of the previous methods.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Election Control by Manipulating Issue Significance</title><link href="https://pyvideo.org/uai-2020/election-control-by-manipulating-issue-significance.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Andrew Estornell</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/election-control-by-manipulating-issue-significance.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Election Control by Manipulating Issue Significance&lt;/p&gt;
&lt;p&gt;Andrew Estornell (Washington University in St Louis)*; Sanmay Das (Washington University in St. Louis); Edith Elkind (Oxford University); Yevgeniy Vorobeychik (Washington University in St. Louis)&lt;/p&gt;
&lt;p&gt;Integrity of elections is vital to democratic systems, but it is frequently threatened by malicious actors.
The study …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Election Control by Manipulating Issue Significance&lt;/p&gt;
&lt;p&gt;Andrew Estornell (Washington University in St Louis)*; Sanmay Das (Washington University in St. Louis); Edith Elkind (Oxford University); Yevgeniy Vorobeychik (Washington University in St. Louis)&lt;/p&gt;
&lt;p&gt;Integrity of elections is vital to democratic systems, but it is frequently threatened by malicious actors.
The study of algorithmic complexity of the problem of manipulating election outcomes by changing its structural features is known as election control Rothe [2016].
One means of election control that has been proposed, pertinent to the spatial voting model, is to select a subset of issues that determine voter preferences over candidates.
We study a variation of this model in which voters have judgments about relative importance of issues, and a malicious actor can manipulate these judgments.
We show that computing effective manipulations in this model is NP-hard even with two candidates or binary issues.
However, we demonstrate that the problem becomes tractable with a constant number of voters or issues.
Additionally, while it remains intractable when voters can vote stochastically, we exhibit an important special case in which stochastic voting behavior enables tractable manipulation.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Estimation Rates for Sparse Linear Cyclic Causal Models</title><link href="https://pyvideo.org/uai-2020/estimation-rates-for-sparse-linear-cyclic-causal-models.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Jan-Christian Huetter</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/estimation-rates-for-sparse-linear-cyclic-causal-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Estimation Rates for Sparse Linear Cyclic Causal Models&lt;/p&gt;
&lt;p&gt;Jan-Christian Huetter (Broad Institute)*; Philippe Rigollet (MIT)&lt;/p&gt;
&lt;p&gt;Causal models are fundamental tools to understand complex systems and predict the effect of interventions on such systems. However, despite an extensive literature in the population (or infinite-sample) case, where distributions are assumed to …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Estimation Rates for Sparse Linear Cyclic Causal Models&lt;/p&gt;
&lt;p&gt;Jan-Christian Huetter (Broad Institute)*; Philippe Rigollet (MIT)&lt;/p&gt;
&lt;p&gt;Causal models are fundamental tools to understand complex systems and predict the effect of interventions on such systems. However, despite an extensive literature in the population (or infinite-sample) case, where distributions are assumed to be known, little is known about the statistical rates of convergence of various methods, even for the simplest models. In this work, allowing for cycles, we study linear structural equations models with homoscedastic Gaussian noise and in the presence of interventions that make the model identifiable. More specifically, we present statistical rates of estimation for both the LLC estimator introduced by Hyttinen, Eberhardt and Hoyer and a novel two-step penalized maximum likelihood estimator. We establish asymptotic near minimax optimality for the maximum likelihood estimator over a class of sparse causal graphs in the case of near-optimally chosen interventions. Moreover, we find evidence for practical advantages of this estimator compared to LLC in synthetic numerical experiments.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Fair Contextual Multi-Armed Bandits: Theory and Experiments</title><link href="https://pyvideo.org/uai-2020/fair-contextual-multi-armed-bandits-theory-and-experiments.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Yifang Chen</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/fair-contextual-multi-armed-bandits-theory-and-experiments.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Fair Contextual Multi-Armed Bandits: Theory and Experiments&lt;/p&gt;
&lt;p&gt;Yifang Chen (Baidu Research); Alex Cuellar (MIT); Haipeng Luo (University of Southern California); Jignesh Modi (University of Southern California); Heramb Nemlekar (UNIVERSITY OF SOUTHERN CALIFORNIA); Stefanos Nikolaidis (University of Southern California)*&lt;/p&gt;
&lt;p&gt;When an AI system interacts with multiple users, it frequently needs …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Fair Contextual Multi-Armed Bandits: Theory and Experiments&lt;/p&gt;
&lt;p&gt;Yifang Chen (Baidu Research); Alex Cuellar (MIT); Haipeng Luo (University of Southern California); Jignesh Modi (University of Southern California); Heramb Nemlekar (UNIVERSITY OF SOUTHERN CALIFORNIA); Stefanos Nikolaidis (University of Southern California)*&lt;/p&gt;
&lt;p&gt;When an AI system interacts with multiple users, it frequently needs to make allocation decisions. For instance, a virtual agent decides whom to pay attention to in a group, or a factory robot selects a worker to deliver a part.
Demonstrating fairness in decision making is essential for such systems to be broadly accepted. We introduce a Multi-Armed Bandit algorithm with fairness constraints, where fairness is defined as a minimum rate at which a task or a resource is assigned to a user. The proposed algorithm uses contextual information about the users and the task and makes no assumptions on how the losses capturing the performance of different users are generated. We provide theoretical guarantees of performance and empirical results from simulation and an online user study. The results highlight the benefit of accounting for contexts in fair decision making, especially when users perform better at some contexts and worse at others. &amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Faster algorithms for Markov equivalence</title><link href="https://pyvideo.org/uai-2020/faster-algorithms-for-markov-equivalence.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Zhongyi Hu</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/faster-algorithms-for-markov-equivalence.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Faster algorithms for Markov equivalence&lt;/p&gt;
&lt;p&gt;Zhongyi Hu (University of Oxford)*; Robin Evans (Oxford)&lt;/p&gt;
&lt;p&gt;Maximal ancestral graphs (MAGs) have many desirable properties; in particular they can fully describe conditional independences from directed acyclic graphs (DAGs) in the presence of latent and selection variables. However, different MAGs may encode the same …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Faster algorithms for Markov equivalence&lt;/p&gt;
&lt;p&gt;Zhongyi Hu (University of Oxford)*; Robin Evans (Oxford)&lt;/p&gt;
&lt;p&gt;Maximal ancestral graphs (MAGs) have many desirable properties; in particular they can fully describe conditional independences from directed acyclic graphs (DAGs) in the presence of latent and selection variables. However, different MAGs may encode the same conditional independences, and are said to be emph{Markov equivalent}. Thus identifying necessary and sufficient conditions for equivalence is essential for structure learning. Several criteria for this already exist, but in this paper we give a new non-parametric characterization in terms of the heads and tails that arise in the parameterization for discrete models. We also provide a polynomial time algorithm ($O(ne^{2})$, where $n$ and $e$ are the number of vertices and edges respectively) to verify equivalence.  Moreover, we extend our criterion to ADMGs and summary graphs and propose an algorithm that converts an ADMG or summary graph to an equivalent MAG in polynomial time ($O(n^{2}e)$).  Hence by combining both algorithms, we can also verify equivalence between two summary graphs or ADMGs.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Finite-Memory Near-Optimal Learning for Markov Decision Processes with Long-Run Average Reward</title><link href="https://pyvideo.org/uai-2020/finite-memory-near-optimal-learning-for-markov-decision-processes-with-long-run-average-reward.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Jan Kretinsky</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/finite-memory-near-optimal-learning-for-markov-decision-processes-with-long-run-average-reward.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Finite-Memory Near-Optimal Learning for Markov Decision Processes with Long-Run Average Reward&lt;/p&gt;
&lt;p&gt;Jan Kretinsky (TU Munich)*; Fabian Michel (TU Munich); Lukas Michel (TU Munich); Guillermo Perez (UAntwerpen)&lt;/p&gt;
&lt;p&gt;We consider learning policies online in Markov decision processes with the long-run average reward (a.k.a. mean payoff). To ensure implementability of …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Finite-Memory Near-Optimal Learning for Markov Decision Processes with Long-Run Average Reward&lt;/p&gt;
&lt;p&gt;Jan Kretinsky (TU Munich)*; Fabian Michel (TU Munich); Lukas Michel (TU Munich); Guillermo Perez (UAntwerpen)&lt;/p&gt;
&lt;p&gt;We consider learning policies online in Markov decision processes with the long-run average reward (a.k.a. mean payoff). To ensure implementability of the policies, we focus on policies with finite memory. Firstly, we show that near optimality can be achieved almost surely, using an unintuitive gadget we call forgetfulness. Secondly, we extend the approach to a setting with partial knowledge of the system topology, introducing two optimality measures and providing near-optimal algorithms also for these cases.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Flexible Approximate Inference via Stratified Normalizing Flows</title><link href="https://pyvideo.org/uai-2020/flexible-approximate-inference-via-stratified-normalizing-flows.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Chris Cundy</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/flexible-approximate-inference-via-stratified-normalizing-flows.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Flexible Approximate Inference via Stratified Normalizing Flows&lt;/p&gt;
&lt;p&gt;Chris Cundy (Stanford University)*; Stefano  Ermon (Stanford University)&lt;/p&gt;
&lt;p&gt;A major obstacle to forming posterior distributions in machine learning is the difficulty of evaluating partition functions. Monte-Carlo approaches are unbiased, but can suffer from high variance. Variational methods are biased, but tend to …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Flexible Approximate Inference via Stratified Normalizing Flows&lt;/p&gt;
&lt;p&gt;Chris Cundy (Stanford University)*; Stefano  Ermon (Stanford University)&lt;/p&gt;
&lt;p&gt;A major obstacle to forming posterior distributions in machine learning is the difficulty of evaluating partition functions. Monte-Carlo approaches are unbiased, but can suffer from high variance. Variational methods are biased, but tend to have lower variance. We develop an approximate inference procedure that allows explicit control of the bias/variance tradeoff, interpolating between the sampling and the variational regime. We use a normalizing flow to map the integrand onto a uniform distribution. We then randomly sample regions from a partition of this uniform distribution and fit simpler, local variational approximations in the image of these regions through the flow. When a partition with only one region is used, we recover standard variational inference, and in the limit of an infinitely fine partition we recover Monte-Carlo sampling. We show experiments validating the effectiveness of our approach.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Flexible Prior Elicitation via the Prior Predictive Distribution</title><link href="https://pyvideo.org/uai-2020/flexible-prior-elicitation-via-the-prior-predictive-distribution.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Marcelo Hartmann</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/flexible-prior-elicitation-via-the-prior-predictive-distribution.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Flexible Prior Elicitation via the Prior Predictive Distribution&lt;/p&gt;
&lt;p&gt;Marcelo Hartmann (University of Helsinki)*; Georgi Agiashvili (University of Helsinki); Paul Bürkner (Aalto University); Arto Klami (University of Helsinki)&lt;/p&gt;
&lt;blockquote&gt;
The prior distribution for the unknown model parameters plays a crucial role in the process of statistical inference based on Bayesian methods …&lt;/blockquote&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Flexible Prior Elicitation via the Prior Predictive Distribution&lt;/p&gt;
&lt;p&gt;Marcelo Hartmann (University of Helsinki)*; Georgi Agiashvili (University of Helsinki); Paul Bürkner (Aalto University); Arto Klami (University of Helsinki)&lt;/p&gt;
&lt;blockquote&gt;
The prior distribution for the unknown model parameters plays a crucial role in the process of statistical inference based on Bayesian methods. However, specifying suitable priors is often difficult even when detailed prior knowledge is available in principle. The challenge is to express quantitative information in the form of a probability distribution. Prior elicitation addresses this question by extracting subjective information from an expert and transforming it into a valid prior. Most existing methods, however, require information to be provided on the unobservable parameters, whose effect on the data generating process is often complicated and hard to understand. We propose an alternative approach that only requires knowledge about the observable outcomes - knowledge which is often much easier for experts to provide.  Building upon a principled statistical framework, our approach utilizes the prior predictive distribution implied by the model to automatically transform experts judgements about plausible outcome values to suitable priors on the parameters. We also provide computational strategies to perform inference and guidelines to facilitate practical use.&lt;/blockquote&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Generalized Policy Elimination: an efficient algorithm for Nonparametric Contextual Bandits</title><link href="https://pyvideo.org/uai-2020/generalized-policy-elimination-an-efficient-algorithm-for-nonparametric-contextual-bandits.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Aurelien Bibaut</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/generalized-policy-elimination-an-efficient-algorithm-for-nonparametric-contextual-bandits.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;dl class="docutils"&gt;
&lt;dt&gt;&amp;quot;We  propose   the  Generalized   Policy  Elimination  (GPE)   algorithm,  an&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;oracle-efficient  contextual bandit  (CB) algorithm  inspired by  the Policy
Elimination   algorithm   of   cite{dudik2011}.    We   prove   the   first
regret-optimality  guarantee theorem  for an  oracle-efficient CB  algorithm
competing  against   a  nonparametric  class  with   infinite  VC-dimension.
Specifically, we show that GPE is …&lt;/p&gt;&lt;/dd&gt;&lt;/dl&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;dl class="docutils"&gt;
&lt;dt&gt;&amp;quot;We  propose   the  Generalized   Policy  Elimination  (GPE)   algorithm,  an&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;oracle-efficient  contextual bandit  (CB) algorithm  inspired by  the Policy
Elimination   algorithm   of   cite{dudik2011}.    We   prove   the   first
regret-optimality  guarantee theorem  for an  oracle-efficient CB  algorithm
competing  against   a  nonparametric  class  with   infinite  VC-dimension.
Specifically, we show that GPE is regret-optimal (up to logarithmic factors)
for policy classes with integrable entropy.&lt;/p&gt;
&lt;p class="last"&gt;For classes  with larger entropy, we  show that the core  techniques used to
analyze GPE  can be  used to design  an $varepsilon$-greedy  algorithm with
regret bound  matching that of the  best algorithms to date.   We illustrate
the  applicability of  our algorithms  and theorems  with examples  of large
nonparametric policy  classes, for  which the relevant  optimization oracles
can be efficiently implemented.&amp;quot;&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Graphical continuous Lyapunov models</title><link href="https://pyvideo.org/uai-2020/graphical-continuous-lyapunov-models.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Gherardo Varando</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/graphical-continuous-lyapunov-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Graphical continuous Lyapunov models&lt;/p&gt;
&lt;p&gt;Gherardo Varando (University of Copenhagen)*; Niels Richard Hansen ()&lt;/p&gt;
&lt;p&gt;The linear Lyapunov equation of a covariance matrix parametrizes the
equilibrium covariance matrix of a stochastic process. This parametrization can
be interpreted as a new graphical model class, and we show how the model class
behaves under …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Graphical continuous Lyapunov models&lt;/p&gt;
&lt;p&gt;Gherardo Varando (University of Copenhagen)*; Niels Richard Hansen ()&lt;/p&gt;
&lt;p&gt;The linear Lyapunov equation of a covariance matrix parametrizes the
equilibrium covariance matrix of a stochastic process. This parametrization can
be interpreted as a new graphical model class, and we show how the model class
behaves under marginalization and introduce a method for structure learning via
$ell_1$-penalized loss minimization. Our proposed method is demonstrated to
outperform alternative structure learning algorithms in a simulation study, and
we illustrate its application for protein phosphorylation network reconstruction.
&amp;quot;
&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Hidden Markov Nonlinear ICA: Unsupervised Learning from Nonstationary Time Series</title><link href="https://pyvideo.org/uai-2020/hidden-markov-nonlinear-ica-unsupervised-learning-from-nonstationary-time-series.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Hermanni Hälvä</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/hidden-markov-nonlinear-ica-unsupervised-learning-from-nonstationary-time-series.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Hidden Markov Nonlinear ICA: Unsupervised Learning from  Nonstationary Time Series&lt;/p&gt;
&lt;p&gt;Hermanni Hälvä (University of Helsinki)*; Aapo Hyvarinen (Univ. Paris-Saclay &amp;amp; Univ. Helsinki)&lt;/p&gt;
&lt;p&gt;Recent advances in nonlinear Independent Component Analysis (ICA) provide a principled framework for unsupervised feature learning and disentanglement. The central idea in such works is that the latent …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Hidden Markov Nonlinear ICA: Unsupervised Learning from  Nonstationary Time Series&lt;/p&gt;
&lt;p&gt;Hermanni Hälvä (University of Helsinki)*; Aapo Hyvarinen (Univ. Paris-Saclay &amp;amp; Univ. Helsinki)&lt;/p&gt;
&lt;p&gt;Recent advances in nonlinear Independent Component Analysis (ICA) provide a principled framework for unsupervised feature learning and disentanglement. The central idea in such works is that the latent components are assumed to be independent conditional on some observed auxiliary variables, such as the time-segment index. This requires manual segmentation of data into non-stationary segments which is computationally expensive, inaccurate and often impossible. These models are thus not fully unsupervised. We remedy these limitations by combining nonlinear ICA with a Hidden Markov Model, resulting in a model where a latent state acts in place of the observed segment-index. We prove identifiability of the proposed model for a general mixing nonlinearity, such as a neural network. We also show how maximum likelihood estimation of the model can be done using the expectation-maximization algorithm. Thus, we achieve a new nonlinear ICA framework which is unsupervised, more efficient, as well as able to model underlying temporal dynamics.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>High Dimensional Discrete Integration over the Hypergrid</title><link href="https://pyvideo.org/uai-2020/high-dimensional-discrete-integration-over-the-hypergrid.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Raj Kumar Maity</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/high-dimensional-discrete-integration-over-the-hypergrid.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;High Dimensional Discrete Integration over the Hypergrid&lt;/p&gt;
&lt;p&gt;Raj Kumar Maity (University of Massachusetts Amherst); Arya Mazumdar (University of Massachusetts Amherst)*; Soumyabrata Pal (Umass Amherst)&lt;/p&gt;
&lt;p&gt;Recently Ermon et al. (2013) pioneered a way to practically compute approximations to large scale counting or discrete integration problems by using random hashes. The …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;High Dimensional Discrete Integration over the Hypergrid&lt;/p&gt;
&lt;p&gt;Raj Kumar Maity (University of Massachusetts Amherst); Arya Mazumdar (University of Massachusetts Amherst)*; Soumyabrata Pal (Umass Amherst)&lt;/p&gt;
&lt;p&gt;Recently Ermon et al. (2013) pioneered a way to practically compute approximations to large scale counting or discrete integration problems by using random hashes. The hashes are used to reduce the counting problem into many separate discrete optimization problems. The optimization problems then can be solved by an NP-oracle such as commercial SAT solvers or integer linear programming (ILP) solvers. In particular,  Ermon et al. showed that if the domain of integration is   then it is possible to obtain a solution within  a factor of $16$ of the optimal (16-approximation) by this technique.&lt;/p&gt;
&lt;p&gt;In many crucial counting tasks, such as computation of partition function of ferromagnetic Potts model, the domain of integration is naturally   the hypergrid. The straightforward extension of Ermon et al.'s method allows a  approximation for this problem. For large values of, this is undesirable. In this paper, we show an improved technique to obtain an approximation factor of  to this problem. We are able to achieve this by using an idea of optimization over multiple bins of the hash functions, that can be easily implemented by inequality constraints, or even in unconstrained way. The NP oracle in this setting can be simulated by using an ILP solver as in Ermon et. al. We provide simulation results to support the theoretical guarantees of our algorithms.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>How Private Are Commonly-Used Voting Rules?</title><link href="https://pyvideo.org/uai-2020/how-private-are-commonly-used-voting-rules.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Ao Liu</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/how-private-are-commonly-used-voting-rules.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;How Private Are Commonly-Used Voting Rules?&lt;/p&gt;
&lt;p&gt;Ao LIU (Rensselaer Polytechnic Institute); Yun Lu (University of Edinburgh)*; Lirong Xia (RPI); Vassilis Zikas (University of Edinburgh)&lt;/p&gt;
&lt;p&gt;Differential privacy has been widely applied to provide privacy guarantees by adding random noise to the function output. However, it inevitably fails in many high-stakes …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;How Private Are Commonly-Used Voting Rules?&lt;/p&gt;
&lt;p&gt;Ao LIU (Rensselaer Polytechnic Institute); Yun Lu (University of Edinburgh)*; Lirong Xia (RPI); Vassilis Zikas (University of Edinburgh)&lt;/p&gt;
&lt;p&gt;Differential privacy has been widely applied to provide privacy guarantees by adding random noise to the function output. However, it inevitably fails in many high-stakes voting scenarios, where  voting rules are required to be deterministic.
In this work, we present the first framework for answering the question:
How private are commonly-used voting rules?
Our answers are two-fold. First, we show that deterministic voting rules provide sufficient privacy in the sense of distributional differential privacy (DDP). We show that assuming the adversarial observer has uncertainty about individual votes, even publishing the histogram of votes achieves good DDP. Second, we introduce the notion of exact privacy to compare the privacy preserved in various commonly-studied voting rules, and obtain dichotomy theorems of exact DDP within a large subset of voting rules called generalized scoring rules.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>IDA with Background Knowledge</title><link href="https://pyvideo.org/uai-2020/ida-with-background-knowledge.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Zhuangyan Fang</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/ida-with-background-knowledge.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;IDA with Background Knowledge&lt;/p&gt;
&lt;p&gt;Zhuangyan Fang (Peking University); Yangbo He (Peking University)*&lt;/p&gt;
&lt;p&gt;In this paper, we consider the problem of estimating all possible causal effects from observational data with two types of background knowledge: direct causal information and non-ancestral information. Following the IDA framework, we first provide locally valid …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;IDA with Background Knowledge&lt;/p&gt;
&lt;p&gt;Zhuangyan Fang (Peking University); Yangbo He (Peking University)*&lt;/p&gt;
&lt;p&gt;In this paper, we consider the problem of estimating all possible causal effects from observational data with two types of background knowledge: direct causal information and non-ancestral information. Following the IDA framework, we first provide locally valid orientation rules for maximal partially directed acyclic graphs (PDAGs), which are widely used to represent background knowledge. Based on the proposed rules, we present a fully local algorithm to estimate all possible causal effects with direct causal information. Furthermore, we consider non-ancestral information and prove that it can be equivalently transformed into direct causal information, meaning that we can also locally estimate all possible causal effects with non-ancestral information. The test results on both synthetic and real-world data sets show that our methods are efficient and stable.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Identifying causal effects in maximally oriented partially directed acyclic graphs</title><link href="https://pyvideo.org/uai-2020/identifying-causal-effects-in-maximally-oriented-partially-directed-acyclic-graphs.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Emilija Perkovic</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/identifying-causal-effects-in-maximally-oriented-partially-directed-acyclic-graphs.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Identifying causal effects in maximally oriented partially directed acyclic graphs&lt;/p&gt;
&lt;p&gt;Emilija Perkovic (University of Washington)*&lt;/p&gt;
&lt;p&gt;We develop a necessary and sufficient causal identification criterion for maximally oriented partially directed acyclic graphs (MPDAGs). MPDAGs as a class of graphs include directed acyclic graphs (DAGs), completed partially directed acyclic graphs (CPDAGs …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Identifying causal effects in maximally oriented partially directed acyclic graphs&lt;/p&gt;
&lt;p&gt;Emilija Perkovic (University of Washington)*&lt;/p&gt;
&lt;p&gt;We develop a necessary and sufficient causal identification criterion for maximally oriented partially directed acyclic graphs (MPDAGs). MPDAGs as a class of graphs include directed acyclic graphs (DAGs), completed partially directed acyclic graphs (CPDAGs), and CPDAGs with added background knowledge. As such, they represent the type of graph that can be learned from observational data and background knowledge under the assumption of no latent variables. Our identification criterion can be seen as a generalization of the g-formula of Robins (1986). We further obtain a generalization of the truncated factorization formula for DAGs (Pearl, 2009) and compare our criterion to the generalized adjustment criterion of Perkovic et al. (2017)  which is sufficient, but not necessary for causal identification.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Improved Vector Pruning in Exact Algorithms for Solving POMDPs</title><link href="https://pyvideo.org/uai-2020/improved-vector-pruning-in-exact-algorithms-for-solving-pomdps.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Eric Hansen</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/improved-vector-pruning-in-exact-algorithms-for-solving-pomdps.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Improved Vector Pruning in Exact Algorithms for Solving POMDPs&lt;/p&gt;
&lt;p&gt;Eric Hansen (Mississippi State University)*; Thomas Bowman (Mississippi State University)&lt;/p&gt;
&lt;p&gt;Exact dynamic programming algorithms for solving partially observable Markov decision processes (POMDPs) rely on a subroutine that removes, or “prunes,” dominated vectors from vector sets that represent piecewise-linear and convex …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Improved Vector Pruning in Exact Algorithms for Solving POMDPs&lt;/p&gt;
&lt;p&gt;Eric Hansen (Mississippi State University)*; Thomas Bowman (Mississippi State University)&lt;/p&gt;
&lt;p&gt;Exact dynamic programming algorithms for solving partially observable Markov decision processes (POMDPs) rely on a subroutine that removes, or “prunes,” dominated vectors from vector sets that represent piecewise-linear and convex value functions. The subroutine solves many linear programs, where the size of the linear programs is proportional to both the number of undominated vectors in the set and their dimension, which severely limits scalability. Recent work improves the performance of this subroutine by limiting the number of constraints in the linear programs it solves by incrementally generating relevant constraints. In this paper, we show how to similarly limit the number of variables. By reducing the size of the linear programs in both ways, we further improve the performance of exact algorithms for POMDPs, especially in solving problems with larger state spaces.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Iterative Channel Estimation for Discrete Denoising under Channel Uncertainty</title><link href="https://pyvideo.org/uai-2020/iterative-channel-estimation-for-discrete-denoising-under-channel-uncertainty.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Hongjoon Ahn</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/iterative-channel-estimation-for-discrete-denoising-under-channel-uncertainty.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Iterative Channel Estimation for Discrete Denoising under Channel Uncertainty&lt;/p&gt;
&lt;p&gt;Hongjoon Ahn (SKKU); Taesup Moon (Sungkyunkwan University)*&lt;/p&gt;
&lt;p&gt;We propose a novel iterative channel estimation (ICE) algorithm that essentially removes the critical known noisy channel assumption for universal discrete denoising problem. Our algorithm is based on Neural DUDE (N-DUDE), a recently …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Iterative Channel Estimation for Discrete Denoising under Channel Uncertainty&lt;/p&gt;
&lt;p&gt;Hongjoon Ahn (SKKU); Taesup Moon (Sungkyunkwan University)*&lt;/p&gt;
&lt;p&gt;We propose a novel iterative channel estimation (ICE) algorithm that essentially removes the critical known noisy channel assumption for universal discrete denoising problem. Our algorithm is based on Neural DUDE (N-DUDE), a recently proposed neural network-based discrete denoiser, and it estimates the channel transition matrix as well as the neural network parameters in an alternating manner until convergence. While we do not make any probabilistic assumption on the underlying clean data, our ICE resembles Expectation-Maximization (EM) with variational approximation, and it takes advantage of the property that N-DUDE can always induce a marginal posterior distribution of the clean data. We carefully validate the channel estimation quality of ICE, and with extensive experiments on several radically different types of data, we show the ICE equipped neural network-based denoisers can perform emph{universally} well regardless of the uncertainties in both the channel and the clean source. Moreover, we show ICE becomes extremely robust to its hyperparameters, and show the denoisers with ICE significantly outperform the strong baseline that can handle the channel uncertainties for denoising, the widely used Baum-Welch (BW) algorithm for hidden Markov models (HMM).&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Joint Stochastic Approximation and Its Application to Learning Discrete Latent Variable Models</title><link href="https://pyvideo.org/uai-2020/joint-stochastic-approximation-and-its-application-to-learning-discrete-latent-variable-models.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Zhijian Ou</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/joint-stochastic-approximation-and-its-application-to-learning-discrete-latent-variable-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Joint Stochastic Approximation and Its Application to Learning Discrete Latent Variable Models&lt;/p&gt;
&lt;p&gt;Zhijian Ou (&amp;quot;&amp;quot;Department of Electronic Engineering, Tsinghua University&amp;quot;&amp;quot;)*; Yunfu Song (Tsinghua University)&lt;/p&gt;
&lt;p&gt;Although with progress in introducing auxiliary amortized inference models, learning discrete latent variable models is still challenging. In this paper, we show that the annoying …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Joint Stochastic Approximation and Its Application to Learning Discrete Latent Variable Models&lt;/p&gt;
&lt;p&gt;Zhijian Ou (&amp;quot;&amp;quot;Department of Electronic Engineering, Tsinghua University&amp;quot;&amp;quot;)*; Yunfu Song (Tsinghua University)&lt;/p&gt;
&lt;p&gt;Although with progress in introducing auxiliary amortized inference models, learning discrete latent variable models is still challenging. In this paper, we show that the annoying difficulty of obtaining reliable stochastic gradients for the inference model and the drawback of indirectly optimizing the target log-likelihood can be gracefully addressed in a new method based on stochastic approximation (SA) theory of the Robbins-Monro type. Specifically, we propose to directly maximize the target log-likelihood and simultaneously minimize the inclusive divergence between the posterior and the inference model. The resulting learning algorithm is called joint SA (JSA). To the best of our knowledge, JSA represents the first method that couples an SA version of the EM (expectation-maximization) algorithm (SAEM) with an adaptive MCMC procedure. Experiments on several benchmark generative modeling and structured prediction tasks show that JSA consistently outperforms recent competitive algorithms, with faster convergence, better final likelihoods, and lower variance of gradient estimates.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Kernel Conditional Moment Test via Maximum Moment Restriction</title><link href="https://pyvideo.org/uai-2020/kernel-conditional-moment-test-via-maximum-moment-restriction.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Krikamol Muandet</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/kernel-conditional-moment-test-via-maximum-moment-restriction.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Kernel Conditional Moment Test via Maximum Moment Restriction&lt;/p&gt;
&lt;p&gt;Krikamol Muandet (Max Planck Institute for Intelligent Systems)*; Wittawat Jitkrittum (Google); Jonas Kübler (MPI for Intelligent Systems, Tübingen)&lt;/p&gt;
&lt;p&gt;We propose a new family of specification tests called kernel conditional moment (KCM) tests. Our tests are built on a novel representation of …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Kernel Conditional Moment Test via Maximum Moment Restriction&lt;/p&gt;
&lt;p&gt;Krikamol Muandet (Max Planck Institute for Intelligent Systems)*; Wittawat Jitkrittum (Google); Jonas Kübler (MPI for Intelligent Systems, Tübingen)&lt;/p&gt;
&lt;p&gt;We propose a new family of specification tests called kernel conditional moment (KCM) tests. Our tests are built on a novel representation of conditional moment restrictions in a reproducing kernel Hilbert space (RKHS) called conditional moment embedding (CMME). After transforming the conditional moment restrictions into a continuum of unconditional counterparts, the test statistic is defined as the maximum moment restriction (MMR) within the unit ball of the RKHS. We show that the MMR not only fully characterizes the original conditional moment restrictions, leading to consistency in both hypothesis testing and parameter estimation, but also has an analytic expression that is easy to compute as well as closed-form asymptotic distributions. Our empirical studies show that the KCM test has a promising finite-sample performance compared to existing tests.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Kidney Exchange with Inhomogeneous Edge Existence Uncertainty</title><link href="https://pyvideo.org/uai-2020/kidney-exchange-with-inhomogeneous-edge-existence-uncertainty.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>hoda bidkhori</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/kidney-exchange-with-inhomogeneous-edge-existence-uncertainty.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Kidney Exchange with Inhomogeneous Edge Existence Uncertainty&lt;/p&gt;
&lt;p&gt;hoda bidkhori (University of Pittsburgh); John Dickerson (University of Maryland)*; Duncan McElfresh (University of Maryland); Ke Ren (University of Pittsburgh)&lt;/p&gt;
&lt;p&gt;Patients with end-stage renal failure often find kidney donors who are willing to donate a life-saving kidney, but who are medically incompatible …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Kidney Exchange with Inhomogeneous Edge Existence Uncertainty&lt;/p&gt;
&lt;p&gt;hoda bidkhori (University of Pittsburgh); John Dickerson (University of Maryland)*; Duncan McElfresh (University of Maryland); Ke Ren (University of Pittsburgh)&lt;/p&gt;
&lt;p&gt;Patients with end-stage renal failure often find kidney donors who are willing to donate a life-saving kidney, but who are medically incompatible with the patients.&lt;/p&gt;
&lt;p&gt;Kidney exchanges are organized barter markets that allow such incompatible patient-donor pairs to enter as a single agent---where the patient is endowed with a donor &amp;quot;item&amp;quot;---and engage in trade with other similar agents, such that all agents &amp;quot;give&amp;quot; a donor organ if and only if they receive an organ in return. In practice, organized trades occur in large cyclic or chain-like structures, with multiple agents participating in the exchange event. Planned trades can fail for a variety of reasons, such as unforeseen logistical challenges, or changes in patient or donor health. These failures cause major inefficiency in fielded exchanges, as if even one individual trade fails in a planned cycle or chain, all or most of the resulting cycle or chain fails}. Ad-hoc, as well as optimization-based methods, have been developed to handle failure uncertainty; nevertheless, the majority of the existing methods use very simplified assumptions about failure uncertainty and/or are not scalable for real-world kidney exchanges.&lt;/p&gt;
&lt;p&gt;Motivated by kidney exchange, we study a stochastic cycle and chain packing problem, where we aim to identify structures in a directed graph to maximize the expectation of matched edge weights. All edges are subject to failure, and the failures can have nonidentical probabilities. To the best of our knowledge, the state-of-the-art approaches are only tractable when failure probabilities are identical. We formulate a relevant non-convex optimization problem and propose a tractable mixed-integer linear programming reformulation to solve it. In addition, we propose a model that integrates both risks and the expected utilities of the matching by incorporating conditional value at risk  into the objective function, providing a robust formulation for this problem. Subsequently, we propose a sample-average-approximation (SAA) based approach to solve this problem. We test our approaches on data from the United Network for Organ Sharing (UNOS) and compare against state-of-the-art approaches.  Our model provides better performance with the same running time as a leading deterministic approach (PICEF). Our CVaR extensions with an SAA-based method improves the worst-case performance substantially compared to existing models.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Lagrangian Decomposition for Neural Network Verification</title><link href="https://pyvideo.org/uai-2020/lagrangian-decomposition-for-neural-network-verification.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Rudy Bunel</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/lagrangian-decomposition-for-neural-network-verification.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Lagrangian Decomposition for Neural Network Verification&lt;/p&gt;
&lt;p&gt;Rudy Bunel (); Alessandro De Palma (University of Oxford)*; Alban Desmaison (University of Oxford); Krishnamurthy Dvijotham (DeepMind); Pushmeet Kohli (DeepMind); Philip Torr (University of Oxford); M. Pawan Kumar (University of Oxford)&lt;/p&gt;
&lt;p&gt;A fundamental component of neural network verification is the computation of bounds on …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Lagrangian Decomposition for Neural Network Verification&lt;/p&gt;
&lt;p&gt;Rudy Bunel (); Alessandro De Palma (University of Oxford)*; Alban Desmaison (University of Oxford); Krishnamurthy Dvijotham (DeepMind); Pushmeet Kohli (DeepMind); Philip Torr (University of Oxford); M. Pawan Kumar (University of Oxford)&lt;/p&gt;
&lt;p&gt;A fundamental component of neural network verification is the computation of bounds on the values their outputs can take. Previous methods have either used off-the-shelf solvers, discarding the problem structure, or relaxed the problem even further, making the bounds unnecessarily loose. We propose a novel approach based on Lagrangian Decomposition. Our formulation admits an efficient supergradient ascent algorithm, as well as an improved proximal algorithm. Both the algorithms offer three advantages: (i) they yield bounds that are provably at least as tight as previous dual algorithms relying on Lagrangian relaxations; (ii) they are based on operations analogous to forward/backward pass of neural networks layers and are therefore easily parallelizable, amenable to GPU implementation and able to take advantage of the convolutional structure of problems; and (iii) they allow for anytime stopping while still providing valid bounds. Empirically, we show that we obtain bounds comparable with off-the-shelf solvers in a fraction of their running time, and obtain tighter bounds in the same time as previous dual algorithms. This results in an overall speed-up when employing the bounds for formal verification. Code for our algorithms is available at &lt;a class="reference external" href="https://github.com/oval-group/decomposition-plnn-bounds"&gt;https://github.com/oval-group/decomposition-plnn-bounds&lt;/a&gt;.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Learning Behaviors with Uncertain Human Feedback</title><link href="https://pyvideo.org/uai-2020/learning-behaviors-with-uncertain-human-feedback.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Xu He</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/learning-behaviors-with-uncertain-human-feedback.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Learning Behaviors with Uncertain Human Feedback&lt;/p&gt;
&lt;p&gt;Xu He (Nanyang Technological University)*; Haipeng Chen (Dartmouth College); Bo An (Nanyang Technological University)&lt;/p&gt;
&lt;p&gt;Human feedback is widely used to train agents in many domains. However, previous works rarely consider the uncertainty when humans provide feedback, especially in cases that the optimal actions …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Learning Behaviors with Uncertain Human Feedback&lt;/p&gt;
&lt;p&gt;Xu He (Nanyang Technological University)*; Haipeng Chen (Dartmouth College); Bo An (Nanyang Technological University)&lt;/p&gt;
&lt;p&gt;Human feedback is widely used to train agents in many domains. However, previous works rarely consider the uncertainty when humans provide feedback, especially in cases that the optimal actions are not obvious to the trainers. For example, the reward of a sub-optimal action can be stochastic and sometimes exceeds that of the optimal action, which is common in games or real-world. Trainers are likely to provide positive feedback to sub-optimal actions, negative feedback to the optimal actions and even do not provide feedback in some confusing situations. Existing works, which utilize the Expectation Maximization (EM) algorithm and treat the feedback model as hidden parameters, do not consider uncertainties in the learning environment and human feedback. To address this challenge, we introduce a novel feedback model that considers the uncertainty of human feedback. However, this incurs intractable calculus in the EM algorithm. To this end, we propose a novel approximate EM algorithm, in which we approximate the expectation step with the Gradient Descent method. Experimental results in both synthetic scenarios and two real-world scenarios with human participants demonstrate the superior performance of our proposed approach.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Learning by Repetition: Stochastic Multi-armed Bandits under Priming Effect</title><link href="https://pyvideo.org/uai-2020/learning-by-repetition-stochastic-multi-armed-bandits-under-priming-effect.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Priyank Agrawal</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/learning-by-repetition-stochastic-multi-armed-bandits-under-priming-effect.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Learning by Repetition: Stochastic Multi-armed Bandits under Priming Effect&lt;/p&gt;
&lt;p&gt;Priyank Agrawal (University of Illinois at Urbana-Champaign)*; Theja Tulabandula (University of Illinois at Chicago)&lt;/p&gt;
&lt;p&gt;We study the effect of persistence of engagement on learning in a stochastic multi-armed bandit setting. In advertising and recommendation systems, repetition effect includes a wear-in …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Learning by Repetition: Stochastic Multi-armed Bandits under Priming Effect&lt;/p&gt;
&lt;p&gt;Priyank Agrawal (University of Illinois at Urbana-Champaign)*; Theja Tulabandula (University of Illinois at Chicago)&lt;/p&gt;
&lt;p&gt;We study the effect of persistence of engagement on learning in a stochastic multi-armed bandit setting. In advertising and recommendation systems, repetition effect includes a wear-in period, where the user's propensity to reward the platform via a click or purchase depends on how frequently they see the recommendation in the recent past. It also includes a counteracting wear-out period, where the user's propensity to respond positively is dampened if the recommendation was shown too many times recently. Priming effect can be naturally modelled as a temporal constraint on the strategy space, since the reward for the current action depends on historical actions taken by the platform. We provide novel algorithms that achieves sublinear regret in time and the relevant wear-in/wear-out parameters. The effect of priming on the regret upper bound is also additive, and we get back a guarantee that matches popular algorithms such as the UCB1 and Thompson sampling when there is no priming effect. Our work complements recent work on modeling time varying rewards, delays and corruptions in bandits, and extends the usage of rich behavior models in sequential decision making settings.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Learning Joint Nonlinear Effects from Single-variable Interventions in the Presence</title><link href="https://pyvideo.org/uai-2020/learning-joint-nonlinear-effects-from-single-variable-interventions-in-the-presence.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Sorawit Saengkyongam</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/learning-joint-nonlinear-effects-from-single-variable-interventions-in-the-presence.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Learning Joint Nonlinear Effects from Single-variable Interventions in the Presence of Hidden Confounders&lt;/p&gt;
&lt;p&gt;Sorawit  Saengkyongam (University College London)*; Ricardo Silva (University College London)&lt;/p&gt;
&lt;p&gt;We propose an approach to estimate the effect of multiple simultaneous interventions in the presence of hidden confounders. To overcome the problem of hidden confounding, we …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Learning Joint Nonlinear Effects from Single-variable Interventions in the Presence of Hidden Confounders&lt;/p&gt;
&lt;p&gt;Sorawit  Saengkyongam (University College London)*; Ricardo Silva (University College London)&lt;/p&gt;
&lt;p&gt;We propose an approach to estimate the effect of multiple simultaneous interventions in the presence of hidden confounders. To overcome the problem of hidden confounding, we consider the setting where we have access to not only the observational data but also sets of single-variable interventions in which each of the treatment variables is intervened on separately. We prove identifiability under the assumption that the data is generated from a nonlinear continuous structural causal model with additive Gaussian noise. In addition, we propose a simple parameter estimation method by pooling all the data from different regimes and jointly maximizing the combined likelihood. We also conduct comprehensive experiments to verify the identifiability result as well as to compare the performance of our approach against a baseline on both synthetic and real-world data.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Learning LWF Chain Graphs: A Markov Blanket Discovery Approach</title><link href="https://pyvideo.org/uai-2020/learning-lwf-chain-graphs-a-markov-blanket-discovery-approach.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Mohammad Ali Javidian</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/learning-lwf-chain-graphs-a-markov-blanket-discovery-approach.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Learning LWF Chain Graphs: A Markov Blanket Discovery Approach&lt;/p&gt;
&lt;p&gt;Mohammad Ali Javidian (University of South Carolina)*; Marco Valtorta (University of South Carolina); Pooyan Jamshidi (University of South Carolina)&lt;/p&gt;
&lt;p&gt;This paper provides a graphical characterization of Markov blankets in chain
graphs (CGs) under the Lauritzen-Wermuth-Frydenberg (LWF) interpretation.  The characterization is …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Learning LWF Chain Graphs: A Markov Blanket Discovery Approach&lt;/p&gt;
&lt;p&gt;Mohammad Ali Javidian (University of South Carolina)*; Marco Valtorta (University of South Carolina); Pooyan Jamshidi (University of South Carolina)&lt;/p&gt;
&lt;p&gt;This paper provides a graphical characterization of Markov blankets in chain
graphs (CGs) under the Lauritzen-Wermuth-Frydenberg (LWF) interpretation.  The characterization is different from the well-known one for Bayesian networks and generalizes it.  We provide a novel scalable and sound algorithm
for Markov blanket discovery in LWF CGs and prove that the Grow-Shrink algorithm, the IAMB algorithm, and its variants are still correct for Markov blanket discovery in LWF CGs under the same assumptions as for Bayesian networks. We provide a sound and scalable constraint-based framework for learning the structure of LWF CGs from faithful causally sufficient data and prove its correctness when the Markov blanket discovery algorithms in this paper are used. Our proposed algorithms compare positively/competitively against the state-of-the-art  LCD (Learn Chain graphs via Decomposition) algorithm, depending on the algorithm that is used for Markov blanket discovery. Our proposed algorithms make a broad range of inference/learning problems computationally
tractable and more reliable because they exploit locality.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Learning to learn generative programs with Memoised Wake-Sleep</title><link href="https://pyvideo.org/uai-2020/learning-to-learn-generative-programs-with-memoised-wake-sleep.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Luke Hewitt</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/learning-to-learn-generative-programs-with-memoised-wake-sleep.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Learning to learn generative programs with Memoised Wake-Sleep&lt;/p&gt;
&lt;p&gt;Luke Hewitt ( Massachusetts Institute of Technology)*; Tuan Anh Le (MIT); Joshua Tenenbaum (MIT)&lt;/p&gt;
&lt;p&gt;We study a class of neuro-symbolic generative models in which neural networks are used both for inference and as priors over symbolic, data-generating programs. As generative models, these …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Learning to learn generative programs with Memoised Wake-Sleep&lt;/p&gt;
&lt;p&gt;Luke Hewitt ( Massachusetts Institute of Technology)*; Tuan Anh Le (MIT); Joshua Tenenbaum (MIT)&lt;/p&gt;
&lt;p&gt;We study a class of neuro-symbolic generative models in which neural networks are used both for inference and as priors over symbolic, data-generating programs. As generative models, these programs capture compositional structures in a naturally explainable form. To tackle the challenge of performing program induction as an ‘inner-loop’ to learning, we propose the Memoised Wake-Sleep (MWS) algorithm, which extends Wake Sleep by explicitly storing and reusing the best programs discovered by the inference network throughout training. We use MWS to learn accurate, explainable models in three challenging domains: stroke-based character modelling, cellular automata, and few-shot learning in a novel dataset of real-world string concepts.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Locally Masked Convolution for Autoregressive Models</title><link href="https://pyvideo.org/uai-2020/locally-masked-convolution-for-autoregressive-models.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Ajay Jain</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/locally-masked-convolution-for-autoregressive-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Locally Masked Convolution for Autoregressive Models&lt;/p&gt;
&lt;p&gt;Ajay Jain (UC Berkeley)*; Pieter Abbeel (UC Berkeley); Deepak Pathak (CMU, FAIR)&lt;/p&gt;
&lt;p&gt;High-dimensional generative models have many applications including image compression, multimedia generation, anomaly detection and data completion. State-of-the-art estimators for natural images are autoregressive, decomposing the joint distribution over pixels into a …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Locally Masked Convolution for Autoregressive Models&lt;/p&gt;
&lt;p&gt;Ajay Jain (UC Berkeley)*; Pieter Abbeel (UC Berkeley); Deepak Pathak (CMU, FAIR)&lt;/p&gt;
&lt;p&gt;High-dimensional generative models have many applications including image compression, multimedia generation, anomaly detection and data completion. State-of-the-art estimators for natural images are autoregressive, decomposing the joint distribution over pixels into a product of conditionals parameterized by a deep neural network, e.g. a convolutional neural network such as the PixelCNN. However, PixelCNNs only model a single decomposition of the joint, and only a single generation order is efficient. For tasks such as image completion, these models are unable to use much of the observed context. To generate data in arbitrary orders, we introduce LMConv: a simple modification to the standard 2D convolution that allows arbitrary masks to be applied to the weights at each location in the image. Using LMConv, we learn an ensemble of distribution estimators that share parameters but differ in generation order, achieving improved performance on whole-image density estimation (2.89 bpd on unconditional CIFAR10), as well as globally coherent image completions. Code is available at &lt;a class="reference external" href="https://ajayjain.github.io/lmconv"&gt;https://ajayjain.github.io/lmconv&lt;/a&gt;.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>MaskAAE: Latent space optimization for Adversarial Auto-Encoders</title><link href="https://pyvideo.org/uai-2020/maskaae-latent-space-optimization-for-adversarial-auto-encoders.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>TODO</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/maskaae-latent-space-optimization-for-adversarial-auto-encoders.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;MaskAAE: Latent space optimization for Adversarial Auto-Encoders&lt;/p&gt;
&lt;p&gt;Arnab Mondal (IIT Delhi)*; Sankalan Pal Chowdhury (IIT Delhi); Aravind Jayendran (Flipkart Internet Private Limited); Himanshu Asnani (TIFR); Parag Singla (IIT Delhi); Prathosh A P (Indian Institute of Technology Delhi)&lt;/p&gt;
&lt;p&gt;The field of neural generative models is dominated by the highly successful …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;MaskAAE: Latent space optimization for Adversarial Auto-Encoders&lt;/p&gt;
&lt;p&gt;Arnab Mondal (IIT Delhi)*; Sankalan Pal Chowdhury (IIT Delhi); Aravind Jayendran (Flipkart Internet Private Limited); Himanshu Asnani (TIFR); Parag Singla (IIT Delhi); Prathosh A P (Indian Institute of Technology Delhi)&lt;/p&gt;
&lt;p&gt;The field of neural generative models is dominated by the highly successful Generative Adversarial Networks (GANs) despite their challenges, such as training instability and mode collapse. Auto-Encoders (AE) with regularized latent space provide an alternative framework for generative models, albeit their performance levels have not reached that of GANs. In this work, we hypothesise that the dimensionality of the AE model's latent space has a critical effect on the quality of generated data. Under the assumption that nature generates data by sampling from a &lt;tt class="docutils literal"&gt;true&lt;/tt&gt; generative latent space followed by a deterministic  function,  we show that the optimal performance is obtained when the dimensionality of the latent space of the AE-model matches with that of the &lt;tt class="docutils literal"&gt;true&lt;/tt&gt; generative latent space. Further, we propose an algorithm called the Mask Adversarial Auto-Encoder (MaskAAE), in which the dimensionality of the latent space of an adversarial auto encoder is brought closer to that of the &lt;tt class="docutils literal"&gt;true&lt;/tt&gt; generative latent space, via a procedure to mask the spurious latent dimensions. We demonstrate through experiments on synthetic and several real-world datasets that the proposed formulation yields betterment in the generation quality.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>MASSIVE: Tractable and Robust Bayesian Learning of Many-Dimensional Instrumental Variable Models</title><link href="https://pyvideo.org/uai-2020/massive-tractable-and-robust-bayesian-learning-of-many-dimensional-instrumental-variable-models.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Ioan Gabriel Bucur</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/massive-tractable-and-robust-bayesian-learning-of-many-dimensional-instrumental-variable-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;MASSIVE: Tractable and Robust Bayesian Learning of Many-Dimensional Instrumental Variable Models&lt;/p&gt;
&lt;p&gt;Ioan Gabriel Bucur (Radboud University Nijmegen)*; Tom Claassen (Radboud University Nijmegen); Tom Heskes (Radboud University)&lt;/p&gt;
&lt;p&gt;The recent availability of huge, many-dimensional data sets, like those arising from genome-wide association studies (GWAS), provides many opportunities for strengthening causal inference …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;MASSIVE: Tractable and Robust Bayesian Learning of Many-Dimensional Instrumental Variable Models&lt;/p&gt;
&lt;p&gt;Ioan Gabriel Bucur (Radboud University Nijmegen)*; Tom Claassen (Radboud University Nijmegen); Tom Heskes (Radboud University)&lt;/p&gt;
&lt;p&gt;The recent availability of huge, many-dimensional data sets, like those arising from genome-wide association studies (GWAS), provides many opportunities for strengthening causal inference. One popular approach is to utilize these many-dimensional measurements as instrumental variables (instruments) for improving the causal effect estimate between other pairs of variables. Unfortunately, searching for proper instruments in a many-dimensional set of candidates is a daunting task due to the intractable model space and the fact that we cannot directly test which of these candidates are valid, so most existing search methods either rely on overly stringent modeling assumptions or fail to capture the inherent model uncertainty in the selection process. We show that, as long as at least some of the candidates are (close to) valid, without knowing a priori which ones, they collectively still pose enough restrictions on the target interaction to obtain a reliable causal effect estimate. We propose a general and efficient causal inference algorithm that accounts for model uncertainty by performing Bayesian model averaging over the most promising many-dimensional instrumental variable models, while at the same time employing weaker assumptions regarding the data generating process. We showcase the efficiency, robustness and predictive performance of our algorithm through experimental results on both simulated and real-world data.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Measurement Dependence Inducing Latent Causal Models</title><link href="https://pyvideo.org/uai-2020/measurement-dependence-inducing-latent-causal-models.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Alex Markham</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/measurement-dependence-inducing-latent-causal-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Measurement Dependence Inducing Latent Causal Models&lt;/p&gt;
&lt;p&gt;Alex Markham (University of Vienna)*; Moritz Grosse-Wentrup (University of Vienna)&lt;/p&gt;
&lt;p&gt;We consider the task of causal structure learning over measurement dependence inducing latent (MeDIL) causal models.
We show that this task can be framed in terms of the graph theoretic problem of finding …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Measurement Dependence Inducing Latent Causal Models&lt;/p&gt;
&lt;p&gt;Alex Markham (University of Vienna)*; Moritz Grosse-Wentrup (University of Vienna)&lt;/p&gt;
&lt;p&gt;We consider the task of causal structure learning over measurement dependence inducing latent (MeDIL) causal models.
We show that this task can be framed in terms of the graph theoretic problem of finding edge clique covers,resulting in an algorithm for returning minimal MeDIL causal models (minMCMs).
This algorithm is non-parametric, requiring no assumptions about linearity or Gaussianity.
Furthermore, despite rather weak assumptions aboutthe class of MeDIL causal models, we show that minimality in minMCMs implies some rather specific and interesting properties.
By establishing MeDIL causal models as a semantics for edge clique covers, we also provide a starting point for future work further connecting causal structure learning to developments in graph theory and network science.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Model-Augmented Conditional Mutual Information Estimation for Feature Selection</title><link href="https://pyvideo.org/uai-2020/model-augmented-conditional-mutual-information-estimation-for-feature-selection.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Alan Yang</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/model-augmented-conditional-mutual-information-estimation-for-feature-selection.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Model-Augmented Conditional Mutual Information Estimation for Feature Selection&lt;/p&gt;
&lt;p&gt;Alan Yang (University of Illinois at Urbana-Champaign)*; AmirEmad Ghassami (UIUC); Maxim Raginsky (University of Illinois); Negar Kiyavash (École Polytechnique Fédérale de Lausanne); Elyse Rosenbaum (University of Illinois at Urbana-Champaign)&lt;/p&gt;
&lt;p&gt;Markov blanket feature selection, while theoretically optimal, is generally challenging to implement …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Model-Augmented Conditional Mutual Information Estimation for Feature Selection&lt;/p&gt;
&lt;p&gt;Alan Yang (University of Illinois at Urbana-Champaign)*; AmirEmad Ghassami (UIUC); Maxim Raginsky (University of Illinois); Negar Kiyavash (École Polytechnique Fédérale de Lausanne); Elyse Rosenbaum (University of Illinois at Urbana-Champaign)&lt;/p&gt;
&lt;p&gt;Markov blanket feature selection, while theoretically optimal, is generally challenging to implement. This is due to the shortcomings of existing approaches to conditional independence (CI) testing, which tend to struggle either with the curse of dimensionality or computational complexity. We propose a novel two-step approach which facilitates Markov blanket feature selection in high dimensions. First, neural networks are used to map features to low-dimensional representations. In the second step, CI testing is performed by applying the $k$-NN conditional mutual information estimator to the learned feature maps. The mappings are designed to ensure that mapped samples both preserve information and share similar information about the target variable if and only if they are close in Euclidean distance. We show that these properties boost the performance of the $k$-NN estimator in the second step. The performance of the proposed method is evaluated on both synthetic and real data.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Multitask Soft Option Learning</title><link href="https://pyvideo.org/uai-2020/multitask-soft-option-learning.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Maximilian Igl</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/multitask-soft-option-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Multitask Soft Option Learning&lt;/p&gt;
&lt;p&gt;Maximilian Igl (Oxford)*; Andrew Gambardella (University of Oxford); Jinke He (Delft University of Technology); Nantas Nardelli (University of Oxford); N Siddharth (Unversity of Oxford); Wendelin Boehmer (University of Oxford); Shimon Whiteson (University of Oxford)&lt;/p&gt;
&lt;p&gt;We present Multitask Soft Option Learning (MSOL), a hierarchical multitask framework …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Multitask Soft Option Learning&lt;/p&gt;
&lt;p&gt;Maximilian Igl (Oxford)*; Andrew Gambardella (University of Oxford); Jinke He (Delft University of Technology); Nantas Nardelli (University of Oxford); N Siddharth (Unversity of Oxford); Wendelin Boehmer (University of Oxford); Shimon Whiteson (University of Oxford)&lt;/p&gt;
&lt;p&gt;We present Multitask Soft Option Learning (MSOL), a hierarchical multitask framework based on Planning as Inference. MSOL extends the concept of options, using separate variational posteriors for each task, regularized by a shared prior. This “soft” version of options avoids several instabilities during training in a multitask setting, and provides a natural way to learn both intra-option policies and their terminations. Furthermore, it allows fine-tuning of options for new tasks without forgetting their learned policies, leading to faster training without reducing the expressiveness of the hierarchical policy. We demonstrate empirically that MSOL significantly outperforms both hierarchical and flat transfer-learning baselines.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Mutual Information Based Knowledge Transfer Under State-Action Dimension Mismatch</title><link href="https://pyvideo.org/uai-2020/mutual-information-based-knowledge-transfer-under-state-action-dimension-mismatch.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Michael Wan</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/mutual-information-based-knowledge-transfer-under-state-action-dimension-mismatch.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Mutual Information Based Knowledge Transfer Under State-Action Dimension Mismatch&lt;/p&gt;
&lt;p&gt;Michael Wan (University of Illinois at Urbana-Champaign)*; Tanmay Gangwani (University of Illinois, Urbana Champaign); Jian Peng (University of Illinois at Urbana-Champaign)&lt;/p&gt;
&lt;p&gt;Deep reinforcement learning (RL) algorithms have achieved great success on a wide variety of sequential decision-making tasks. However, many …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Mutual Information Based Knowledge Transfer Under State-Action Dimension Mismatch&lt;/p&gt;
&lt;p&gt;Michael Wan (University of Illinois at Urbana-Champaign)*; Tanmay Gangwani (University of Illinois, Urbana Champaign); Jian Peng (University of Illinois at Urbana-Champaign)&lt;/p&gt;
&lt;p&gt;Deep reinforcement learning (RL) algorithms have achieved great success on a wide variety of sequential decision-making tasks. However, many of these algorithms suffer from high sample complexity when learning from scratch using environmental rewards, due to issues such as credit-assignment and high-variance gradients, among others. Transfer learning, in which knowledge gained on a source task is applied to more efficiently learn a different but related target task, is a promising approach to improve the sample complexity in RL. Prior work has considered using pre-trained teacher policies to enhance the learning of the student policy, albeit with the constraint that the teacher and the student MDPs share the state-space or the action-space. In this paper, we propose a new framework for transfer learning where the teacher and the student can have arbitrarily different state- and action-spaces. To handle this mismatch, we produce embeddings which can systematically extract knowledge from the teacher policy and value networks, and blend it into the student networks. To train the embeddings, we use a task-aligned loss and show that the representations could be enriched further by adding a mutual information loss. Using a set of challenging simulated robotic locomotion tasks involving many-legged centipedes, we demonstrate successful transfer learning in situations when the teacher and student have different state- and action-spaces.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Neural Likelihoods via Cumulative Distribution Functions</title><link href="https://pyvideo.org/uai-2020/neural-likelihoods-via-cumulative-distribution-functions.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Pawel Chilinski</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/neural-likelihoods-via-cumulative-distribution-functions.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Neural Likelihoods via Cumulative Distribution Functions&lt;/p&gt;
&lt;p&gt;Pawel Chilinski (UCL)*; Ricardo Silva (University College London)&lt;/p&gt;
&lt;p&gt;We leverage neural networks as universal approximators of monotonic functions to build a parameterization of conditional cumulative distribution functions (CDFs). By the application of automatic differentiation with respect to response variables and then to parameters …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Neural Likelihoods via Cumulative Distribution Functions&lt;/p&gt;
&lt;p&gt;Pawel Chilinski (UCL)*; Ricardo Silva (University College London)&lt;/p&gt;
&lt;p&gt;We leverage neural networks as universal approximators of monotonic functions to build a parameterization of conditional cumulative distribution functions (CDFs). By the application of automatic differentiation with respect to response variables and then to parameters of this CDF representation, we are able to build black box CDF and density estimators. A suite of families is introduced as alternative constructions for the multivariate case. At one extreme, the simplest construction is a competitive density estimator against state-of-the-art deep learning methods, although it does not provide an easily computable representation of multivariate CDFs. At the other extreme, we have a flexible construction from which multivariate CDF evaluations and marginalizations can be obtained by a simple forward pass in a deep neural net, but where the computation of the likelihood scales exponentially with dimensionality. Alternatives in between the extremes are discussed. We evaluate the different representations empirically on a variety of tasks involving tail area probabilities, tail dependence and (partial) density estimation.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>No-regret Exploration in Contextual Reinforcement Learning</title><link href="https://pyvideo.org/uai-2020/no-regret-exploration-in-contextual-reinforcement-learning.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Aditya Modi</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/no-regret-exploration-in-contextual-reinforcement-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;No-regret Exploration in Contextual Reinforcement Learning&lt;/p&gt;
&lt;p&gt;Aditya Modi (Univ. of Michigan Ann Arbor)*; Ambuj Tewari (University of Michigan)&lt;/p&gt;
&lt;p&gt;We consider the recently proposed reinforcement learning (RL) framework of Contextual Markov Decision Processes (CMDP), where the agent interacts with a (potentially adversarial) sequence of episodic tabular MDPs. In addition, a …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;No-regret Exploration in Contextual Reinforcement Learning&lt;/p&gt;
&lt;p&gt;Aditya Modi (Univ. of Michigan Ann Arbor)*; Ambuj Tewari (University of Michigan)&lt;/p&gt;
&lt;p&gt;We consider the recently proposed reinforcement learning (RL) framework of Contextual Markov Decision Processes (CMDP), where the agent interacts with a (potentially adversarial) sequence of episodic tabular MDPs. In addition, a context vector determining the MDP parameters is available to the agent at the start of each episode, thereby allowing it to learn a context-dependent near-optimal policy. In this paper, we propose a no-regret online RL algorithm in the setting where the MDP parameters are obtained from the context using generalized linear mappings (GLMs). We propose and analyze optimistic and randomized exploration methods which make (time and space) efficient online updates. The GLM based model subsumes previous work in this area and also improves previous known bounds in the special case where the contextual mapping is linear. In addition, we demonstrate a generic template to derive confidence sets using an online learning oracle and give a lower bound for the setting.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Non Parametric Graph Learning for Bayesian Graph Neural Networks</title><link href="https://pyvideo.org/uai-2020/non-parametric-graph-learning-for-bayesian-graph-neural-networks.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Soumyasundar Pal</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/non-parametric-graph-learning-for-bayesian-graph-neural-networks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Non Parametric Graph Learning for Bayesian Graph Neural Networks&lt;/p&gt;
&lt;p&gt;Soumyasundar Pal (McGill University)*; Saber Malekmohammadi (Huawei Noah's Ark Lab); Florence Regol (McGill University); Yingxue Zhang (Huawei Technologies Canada); Yishi Xu (Mila); Mark Coates (McGill University)&lt;/p&gt;
&lt;p&gt;Graphs are ubiquitous in modelling relational
structures. Recent endeavours in machine learning
for graph …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Non Parametric Graph Learning for Bayesian Graph Neural Networks&lt;/p&gt;
&lt;p&gt;Soumyasundar Pal (McGill University)*; Saber Malekmohammadi (Huawei Noah's Ark Lab); Florence Regol (McGill University); Yingxue Zhang (Huawei Technologies Canada); Yishi Xu (Mila); Mark Coates (McGill University)&lt;/p&gt;
&lt;p&gt;Graphs are ubiquitous in modelling relational
structures. Recent endeavours in machine learning
for graph structured data have led to many
architectures and learning algorithms. However,
the graph used by these algorithms is often
constructed based on inaccurate modelling
assumptions and/or noisy data. As a result, it
fails to represent the true relationships between
nodes. A Bayesian framework which targets
posterior inference of the graph by considering
it as a random quantity can be beneficial. In
this paper, we propose a novel non-parametric
graph model for constructing the posterior distribution
of graph adjacency matrices. The proposed
model is flexible in the sense that it can
effectively take into account the output of graph
based learning algorithms that target specific
tasks. In addition, model inference scales well
to large graphs. We demonstrate the advantages
of this model in three different problem settings:
node classification, link prediction and
recommendation.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>OCEAN: Online Task Inference for Compositional Tasks with Context Adaptation</title><link href="https://pyvideo.org/uai-2020/ocean-online-task-inference-for-compositional-tasks-with-context-adaptation.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Hongyu Ren</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/ocean-online-task-inference-for-compositional-tasks-with-context-adaptation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;OCEAN: Online Task Inference for Compositional Tasks with Context Adaptation&lt;/p&gt;
&lt;p&gt;Hongyu Ren (Stanford University)*; Yuke Zhu (University of Texas - Austin); Jure Leskovec (Stanford University); Animashree Anandkumar (Caltech); Animesh Garg (University of Toronto, Vector Institute, Nvidia)&lt;/p&gt;
&lt;p&gt;Real-world tasks often exhibit a compositional structure that contains a sequence of simpler sub-tasks …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;OCEAN: Online Task Inference for Compositional Tasks with Context Adaptation&lt;/p&gt;
&lt;p&gt;Hongyu Ren (Stanford University)*; Yuke Zhu (University of Texas - Austin); Jure Leskovec (Stanford University); Animashree Anandkumar (Caltech); Animesh Garg (University of Toronto, Vector Institute, Nvidia)&lt;/p&gt;
&lt;p&gt;Real-world tasks often exhibit a compositional structure that contains a sequence of simpler sub-tasks. For instance, opening a door requires reaching, grasping, rotating, and pulling the door knob. Such compositional tasks require an agent to reason about the sub-task at hand while orchestrating global behavior accordingly. This can be cast as an online task inference problem, where the current task identity, represented by a context variable, is estimated from the agent's past experiences with probabilistic inference. Previous approaches have employed simple latent distributions, e.g., Gaussian, to model a single context for the entire task. However, this formulation lacks the expressiveness to capture the composition and transition of the sub-tasks. We propose a variational inference framework OCEAN to perform online task inference for compositional tasks. OCEAN models global and local context variables in a joint latent space, where the global variables represent a mixture of sub-tasks required for the task, while the local variables capture the transitions between the sub-tasks. Our framework supports flexible latent distributions based on prior knowledge of the task structure and can be trained in an unsupervised manner. Experimental results show that OCEAN provides more effective task inference with sequential context adaptation and thus leads to a performance boost on complex, multi-stage tasks.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>On Counterfactual Explanations under Predictive Multiplicity</title><link href="https://pyvideo.org/uai-2020/on-counterfactual-explanations-under-predictive-multiplicity.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Martin Pawelczyk</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/on-counterfactual-explanations-under-predictive-multiplicity.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;On Counterfactual Explanations under Predictive Multiplicity&lt;/p&gt;
&lt;p&gt;Martin Pawelczyk (University of Tuebingen)*; Klaus Broelemann (Schufa Holding AG); Gjergji. Kasneci (  University of Tuebingen)&lt;/p&gt;
&lt;p&gt;Counterfactual explanations are usually obtainedby identifying the smallest change made to an input to change a prediction made by a fixed model (hereafter called sparse methods). Recent work …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;On Counterfactual Explanations under Predictive Multiplicity&lt;/p&gt;
&lt;p&gt;Martin Pawelczyk (University of Tuebingen)*; Klaus Broelemann (Schufa Holding AG); Gjergji. Kasneci (  University of Tuebingen)&lt;/p&gt;
&lt;p&gt;Counterfactual explanations are usually obtainedby identifying the smallest change made to an input to change a prediction made by a fixed model (hereafter called sparse methods). Recent work, however, has revitalized an old insight: there often does not exist one superior solution to a prediction problem with respect to commonly used measures of interest (e.g. error rate). In fact, often multiple different classifiers give almost equal solutions. This phenomenon is known as predictive multiplicity (Breiman, 2001; Marx et al., 2019). In this work, we derive a general upper bound for the costs of counterfactual explanations under predictive multiplicity. Most notably, it depends on a discrepancy notion between two classifiers, which describes how differently they treat negatively predicted individuals. We then compare sparse and data support approaches empirically on real-world data. The results show that data support methods are more robust to multiplicity of different models. At the same time, we show that those methods have provably higher cost of generating counterfactual explanations under one fixed model. In summary, our theoretical and empirical results challenge the commonly held view that counterfactual recommendations should be sparse in general.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>On the design of consequential ranking algorithms</title><link href="https://pyvideo.org/uai-2020/on-the-design-of-consequential-ranking-algorithms.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Behzad Tabibian</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/on-the-design-of-consequential-ranking-algorithms.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;On the design of consequential ranking algorithms&lt;/p&gt;
&lt;p&gt;Behzad Tabibian (Max Planck Inst. for Intelligent Systems)*; Vicenç Gómez (Universitat Pompeu Fabra); Abir De (IIT Bombay); Bernhard Schölkopf (MPI for Intelligent Systems, Tübingen); Manuel Gomez Rodriguez (MPI-SWS)&lt;/p&gt;
&lt;p&gt;Ranking models are typically designed to optimize some measure of immediate utility to the …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;On the design of consequential ranking algorithms&lt;/p&gt;
&lt;p&gt;Behzad Tabibian (Max Planck Inst. for Intelligent Systems)*; Vicenç Gómez (Universitat Pompeu Fabra); Abir De (IIT Bombay); Bernhard Schölkopf (MPI for Intelligent Systems, Tübingen); Manuel Gomez Rodriguez (MPI-SWS)&lt;/p&gt;
&lt;p&gt;Ranking models are typically designed to optimize some measure of immediate utility to the users. As a result, they have been unable to anticipate an increasing number of undesirable long-term consequences of their proposed rankings, from fueling the spread of misinformation and increasing polarization to degrading social discourse. Can we design ranking models that anticipate the consequences of their proposed rankings and are able to avoid the undesirable ones? In this paper, we first introduce a joint representation of rankings and user dynamics using Markov decision processes. Then, we show that this representation greatly simplifies the construction of consequential ranking models that trade off the
immediate utility and the long-term welfare. In particular, we can obtain optimal consequential rankings by applying weighted sampling on the rankings provided by models that maximize measures of immediate utility. However, in practice, such a strategy may be inefficient and impractical, specially in high dimensional scenarios. To overcome this, we introduce an efficient gradient-based algorithm to learn parameterized consequential ranking models that effectively approximate optimal ones. We illustrate our methodology using synthetic and real data gathered from Reddit and show that our consequential rankings may mitigate the spread of misinformation and improve the civility of online discussions.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>On the Relationship Between Probabilistic Circuits and Determinantal Point Processes</title><link href="https://pyvideo.org/uai-2020/on-the-relationship-between-probabilistic-circuits-and-determinantal-point-processes.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Honghua Zhang</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/on-the-relationship-between-probabilistic-circuits-and-determinantal-point-processes.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;On the Relationship Between Probabilistic Circuits and Determinantal Point Processes&lt;/p&gt;
&lt;p&gt;Honghua Zhang (University of California, Los Angeles)*; Steven Holtzen (University of California, Los Angeles); Guy Van den Broeck (UCLA)&lt;/p&gt;
&lt;p&gt;Scaling probabilistic models to large realistic problems and datasets is a key challenge in machine learning. Central to this effort …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;On the Relationship Between Probabilistic Circuits and Determinantal Point Processes&lt;/p&gt;
&lt;p&gt;Honghua Zhang (University of California, Los Angeles)*; Steven Holtzen (University of California, Los Angeles); Guy Van den Broeck (UCLA)&lt;/p&gt;
&lt;p&gt;Scaling probabilistic models to large realistic problems and datasets is a key challenge in machine learning. Central to this effort is the development of tractable probabilistic models (TPMs): models whose structure guarantees efficient probabilistic inference algorithms. The current landscape of TPMs is fragmented: there exist various kinds of TPMs with different strengths and weaknesses. Two of the most prominent classes of TPMs are determinantal point processes (DPPs) and probabilistic circuits (PCs). This paper provides the first systematic study of their relationship. We propose a unified analysis and shared language for discussing DPPs and PCs. Then we establish theoretical barriers for the unification of these two families, and prove that there are cases where DPPs have no compact representation as a class of PCs. We close with a perspective on the central problem of unifying these tractable models.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>One-Bit Compressed Sensing via One-Shot Hard Thresholding</title><link href="https://pyvideo.org/uai-2020/one-bit-compressed-sensing-via-one-shot-hard-thresholding.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Jie Shen</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/one-bit-compressed-sensing-via-one-shot-hard-thresholding.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;One-Bit Compressed Sensing via One-Shot Hard Thresholding&lt;/p&gt;
&lt;p&gt;Jie Shen (Stevens Institute of Technology)*&lt;/p&gt;
&lt;p&gt;This paper concerns the problem of 1-bit compressed sensing, where the goal is to estimate a sparse signal from a few of its binary measurements. We study a non-convex sparsity-constrained program and present a novel and …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;One-Bit Compressed Sensing via One-Shot Hard Thresholding&lt;/p&gt;
&lt;p&gt;Jie Shen (Stevens Institute of Technology)*&lt;/p&gt;
&lt;p&gt;This paper concerns the problem of 1-bit compressed sensing, where the goal is to estimate a sparse signal from a few of its binary measurements. We study a non-convex sparsity-constrained program and present a novel and concise analysis that moves away from the widely used notion of Gaussian width. We show that with high probability a simple algorithm is guaranteed to produce an accurate approximation to the normalized signal of interest under the L2-metric. On top of that, we establish an ensemble of new results that address norm estimation, support recovery, and model misspecification. On the computational side, it is shown that the non-convex program can be solved via one-step hard thresholding which is dramatically efficient in terms of time complexity and memory footprint. On the statistical side, it is shown that our estimator enjoys a near-optimal error rate under standard conditions. The theoretical results are further substantiated by numerical experiments.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Online Parameter-Free Learning of Multiple Low Variance Tasks</title><link href="https://pyvideo.org/uai-2020/online-parameter-free-learning-of-multiple-low-variance-tasks.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Giulia Denevi</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/online-parameter-free-learning-of-multiple-low-variance-tasks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Online Parameter-Free Learning of Multiple Low Variance Tasks&lt;/p&gt;
&lt;p&gt;Giulia Denevi (IIT/UNIGE); Massimiliano Pontil (IIT)*; Dimitrios Stamos (University College London)&lt;/p&gt;
&lt;p&gt;We propose a method to learn a common bias vector for a growing sequence of low-variance tasks. Unlike state-of-the-art approaches, our method does not require tuning any hyper-parameter. Our …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Online Parameter-Free Learning of Multiple Low Variance Tasks&lt;/p&gt;
&lt;p&gt;Giulia Denevi (IIT/UNIGE); Massimiliano Pontil (IIT)*; Dimitrios Stamos (University College London)&lt;/p&gt;
&lt;p&gt;We propose a method to learn a common bias vector for a growing sequence of low-variance tasks. Unlike state-of-the-art approaches, our method does not require tuning any hyper-parameter. Our approach is presented in the non-statistical setting and can be of two variants. The “aggressive” one updates the bias after each datapoint, the “lazy” one updates the bias only at the end of each task. We derive an across-tasks regret bound for the method. When compared to state-of-the-art approaches, the aggressive variant returns faster rates, the lazy one recovers standard rates, but with no need of tuning hyper-parameters. We then adapt the methods to the statistical setting: the aggressive variant becomes a multi-task learning method, the lazy one a meta-learning method. Experiments confirm the effectiveness of our methods in practice.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Optimal Statistical Hypothesis Testing for Social Choice</title><link href="https://pyvideo.org/uai-2020/optimal-statistical-hypothesis-testing-for-social-choice.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Lirong Xia</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/optimal-statistical-hypothesis-testing-for-social-choice.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Optimal Statistical Hypothesis Testing for Social Choice&lt;/p&gt;
&lt;p&gt;Lirong Xia (RPI)*&lt;/p&gt;
&lt;p&gt;We address the following question in this paper: “What are the most robust statistical methods for social choice?” By leveraging the theory of uniformly least favorable distributions in the Neyman-Pearson framework to finite models and randomized tests, we characterize …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Optimal Statistical Hypothesis Testing for Social Choice&lt;/p&gt;
&lt;p&gt;Lirong Xia (RPI)*&lt;/p&gt;
&lt;p&gt;We address the following question in this paper: “What are the most robust statistical methods for social choice?” By leveraging the theory of uniformly least favorable distributions in the Neyman-Pearson framework to finite models and randomized tests, we characterize uniformly most powerful (UMP) tests, which is a well-accepted statistical optimality w.r.t. robustness, for testing whether a given alternative is the winner under Mallows’ model and under Condorcet’s model, respectively.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Ordering Variables for Weighted Model Integration</title><link href="https://pyvideo.org/uai-2020/ordering-variables-for-weighted-model-integration.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Vincent Derkinderen</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/ordering-variables-for-weighted-model-integration.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Ordering Variables for Weighted Model Integration&lt;/p&gt;
&lt;p&gt;Vincent Derkinderen (KU Leuven)*; Evert Heylen (KU Leuven); Pedro Zuidberg Dos Martires (KU Leuven); Samuel Kolb (KU Leuven); Luc de Raedt (KU Leuven university)&lt;/p&gt;
&lt;p&gt;State-of-the-art probabilistic inference algorithms, such as variable elimination and search-based  approaches, rely heavily on  the order in which variables …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Ordering Variables for Weighted Model Integration&lt;/p&gt;
&lt;p&gt;Vincent Derkinderen (KU Leuven)*; Evert Heylen (KU Leuven); Pedro Zuidberg Dos Martires (KU Leuven); Samuel Kolb (KU Leuven); Luc de Raedt (KU Leuven university)&lt;/p&gt;
&lt;p&gt;State-of-the-art probabilistic inference algorithms, such as variable elimination and search-based  approaches, rely heavily on  the order in which variables are marginalized. Finding the optimal ordering is an NP-complete problem. This computational hardness has led to heuristics to find adequate variable orderings. However, these heuristics have mostly been targeting discrete random variables. We show how variable ordering heuristics from the discrete domain can be ported to the discrete-continuous domain. We equip the state-of-the-art F-XSDD(BR) solver for  discrete-continuous  problems  with  such heuristics. Additionally, we propose a novel heuristic called bottom-up min-fill (BU-MiF), yielding a solver capable of determining good variable orderings without having to rely on the user to provide such an ordering. We empirically demonstrate its performance on a set of benchmark problems.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>PAC-Bayesian Contrastive Unsupervised Representation Learning</title><link href="https://pyvideo.org/uai-2020/pac-bayesian-contrastive-unsupervised-representation-learning.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Kento Nozawa</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/pac-bayesian-contrastive-unsupervised-representation-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;PAC-Bayesian Contrastive Unsupervised Representation Learning&lt;/p&gt;
&lt;p&gt;Kento Nozawa (The University of Tokyo and RIKEN)*; Pascal Germain (Université Laval); Benjamin Guedj (Inria and University College London)&lt;/p&gt;
&lt;p&gt;Contrastive unsupervised representation learning (CURL) is the state-of-the-art technique to learn representations (as a set of features) from unlabelled data. While CURL has collected several …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;PAC-Bayesian Contrastive Unsupervised Representation Learning&lt;/p&gt;
&lt;p&gt;Kento Nozawa (The University of Tokyo and RIKEN)*; Pascal Germain (Université Laval); Benjamin Guedj (Inria and University College London)&lt;/p&gt;
&lt;p&gt;Contrastive unsupervised representation learning (CURL) is the state-of-the-art technique to learn representations (as a set of features) from unlabelled data. While CURL has collected several empirical successes recently, theoretical understanding of its performance was still missing. In a recent work, Arora et al. (2019) provide the first generalisation bounds for CURL, relying on a Rademacher complexity. We extend their framework to the flexible PAC-Bayes setting, allowing to deal with the non-iid setting. We present PAC-Bayesian generalisation bounds for CURL, which are then used to derive a new representation learning algorithm. Numerical experiments on real-life datasets illustrate that our algorithm achieves competitive accuracy, and yields non-vacuous generalisation bounds.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Permutation-Based Causal Structure Learning with Unknown Intervention Targets</title><link href="https://pyvideo.org/uai-2020/permutation-based-causal-structure-learning-with-unknown-intervention-targets.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Chandler Squires</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/permutation-based-causal-structure-learning-with-unknown-intervention-targets.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Permutation-Based Causal Structure Learning with Unknown Intervention Targets&lt;/p&gt;
&lt;p&gt;Chandler Squires (Massachusetts Institute of Technology)*; Yuhao Wang (University of Cambridge); Caroline Uhler (MIT)&lt;/p&gt;
&lt;p&gt;We consider the problem of estimating causal DAG models from a mix of observational and interventional data, when the intervention targets are partially or completely unknown. This …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Permutation-Based Causal Structure Learning with Unknown Intervention Targets&lt;/p&gt;
&lt;p&gt;Chandler Squires (Massachusetts Institute of Technology)*; Yuhao Wang (University of Cambridge); Caroline Uhler (MIT)&lt;/p&gt;
&lt;p&gt;We consider the problem of estimating causal DAG models from a mix of observational and interventional data, when the intervention targets are partially or completely unknown. This problem is highly relevant for example in genomics, since gene knockout technologies are known to have off-target effects. We characterize the interventional Markov equivalence class of DAGs that can be identified from interventional data with unknown intervention targets. In addition, we propose a provably consistent algorithm for learning the interventional Markov equivalence class from such data. The proposed algorithm greedily searches over the space of permutations to minimize a novel score function. The algorithm is nonparametric, which is particularly important for applications to genomics, where the relationships between variables are often non-linear and the distribution non-Gaussian. We demonstrate the performance of our algorithm on synthetic and biological datasets. Links to an implementation of our algorithm and to a reproducible code base for our experiments can be found at &lt;a class="reference external" href="https://uhlerlab.github.io/causaldag/utigsp"&gt;https://uhlerlab.github.io/causaldag/utigsp&lt;/a&gt;.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>PoRB-Nets: Poisson Process Radial Basis Function Networks</title><link href="https://pyvideo.org/uai-2020/porb-nets-poisson-process-radial-basis-function-networks.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Beau Coker</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/porb-nets-poisson-process-radial-basis-function-networks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;PoRB-Nets: Poisson Process Radial Basis Function Networks&lt;/p&gt;
&lt;p&gt;Beau Coker (Harvard University)*; Melanie Fernandez Pradier (Harvard University)&lt;/p&gt;
&lt;p&gt;Bayesian neural networks (BNNs) are flexible function priors well-suited to situations in which data are scarce and uncertainty must be quantified. Yet, common weight priors are able to encode little functional knowledge and …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;PoRB-Nets: Poisson Process Radial Basis Function Networks&lt;/p&gt;
&lt;p&gt;Beau Coker (Harvard University)*; Melanie Fernandez Pradier (Harvard University)&lt;/p&gt;
&lt;p&gt;Bayesian neural networks (BNNs) are flexible function priors well-suited to situations in which data are scarce and uncertainty must be quantified. Yet, common weight priors are able to encode little functional knowledge and can behave in undesirable ways. We present a novel prior over radial basis function networks (RBFNs) that allows for independent specification of functional amplitude variance and lengthscale (i.e., smoothness), where the inverse lengthscale corresponds to the concentration of radial basis functions. When the lengthscale is uniform over the input space, we prove consistency and approximate variance stationarity. This is in contrast to common BNN priors, which are highly nonstationary. When the input dependence of the lengthscale is unknown, we show how it can be inferred. We compare this model's behavior to standard BNNs and Gaussian processes using synthetic and real examples.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Prediction Intervals: Split Normal Mixture from Quality-Driven Deep Ensembles</title><link href="https://pyvideo.org/uai-2020/prediction-intervals-split-normal-mixture-from-quality-driven-deep-ensembles.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Tárik Saleh Salem</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/prediction-intervals-split-normal-mixture-from-quality-driven-deep-ensembles.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Prediction Intervals: Split Normal Mixture from Quality-Driven Deep Ensembles&lt;/p&gt;
&lt;p&gt;Tárik Saleh Salem (NTNU)*; Helge Langseth (Norwegian University of Science and Technology); Heri Ramampiaro (Norwegian University of Science and Technology (NTNU))&lt;/p&gt;
&lt;p&gt;Prediction intervals are a machine- and human-interpretable way to represent predictive uncertainty in a regression analysis. In this paper …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Prediction Intervals: Split Normal Mixture from Quality-Driven Deep Ensembles&lt;/p&gt;
&lt;p&gt;Tárik Saleh Salem (NTNU)*; Helge Langseth (Norwegian University of Science and Technology); Heri Ramampiaro (Norwegian University of Science and Technology (NTNU))&lt;/p&gt;
&lt;p&gt;Prediction intervals are a machine- and human-interpretable way to represent predictive uncertainty in a regression analysis. In this paper, we present a method for generating prediction intervals along with point estimates from an ensemble of neural networks. We propose a multi-objective loss function fusing quality measures related to prediction intervals and point estimates, and a penalty function, which enforces semantic integrity of the results and stabilizes the training process of the neural networks. The ensembled prediction intervals are aggregated as a split normal mixture accounting for possible multimodality and asymmetricity of the posterior predictive distribution, and resulting in prediction intervals that capture aleatoric and epistemic uncertainty. Our results show that both our quality-driven loss function and our aggregation method contribute to well-calibrated prediction intervals and point estimates. &amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Probabilistic Safety for Bayesian Neural Networks</title><link href="https://pyvideo.org/uai-2020/probabilistic-safety-for-bayesian-neural-networks.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Matthew Wicker</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/probabilistic-safety-for-bayesian-neural-networks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Probabilistic Safety for Bayesian Neural Networks&lt;/p&gt;
&lt;p&gt;Matthew Wicker (University of Oxford)*; Luca Laurenti (University of Oxford); Andrea Patane (University of Oxford); Marta Kwiatkowska (Oxford University)&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;We study probabilistic safety for Bayesian Neural Networks (BNNs)&lt;/dt&gt;
&lt;dd&gt;under adversarial input perturbations. Given a compact set of input points, $T subseteq mathbb{R …&lt;/dd&gt;&lt;/dl&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Probabilistic Safety for Bayesian Neural Networks&lt;/p&gt;
&lt;p&gt;Matthew Wicker (University of Oxford)*; Luca Laurenti (University of Oxford); Andrea Patane (University of Oxford); Marta Kwiatkowska (Oxford University)&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;We study probabilistic safety for Bayesian Neural Networks (BNNs)&lt;/dt&gt;
&lt;dd&gt;under adversarial input perturbations. Given a compact set of input points, $T subseteq mathbb{R}^m$, we study the probability w.r.t. the BNN posterior that all the points in $T$ are mapped to the same region $S$ in the output space. In particular, this can be used to evaluate the probability that a network sampled from the BNN is vulnerable to adversarial attacks. We rely on relaxation techniques from non-convex optimization to develop a method for computing a lower bound   on probabilistic safety for BNNs, deriving explicit procedures for the case of interval and linear function propagation techniques. We apply our methods to BNNs trained on a regression task, airborne collision avoidance, and MNIST, empirically showing that our approach allows one to certify probabilistic safety of BNNs with millions of parameters.&amp;quot;&lt;/dd&gt;
&lt;/dl&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Provably Efficient Third-Person Imitation from Offline Observation</title><link href="https://pyvideo.org/uai-2020/provably-efficient-third-person-imitation-from-offline-observation.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Aaron Zweig</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/provably-efficient-third-person-imitation-from-offline-observation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Provably Efficient Third-Person Imitation from Offline Observation&lt;/p&gt;
&lt;p&gt;Aaron Zweig (New York University)*; Joan Bruna (Courant Institute of Mathematical Sciences, NYU, USA)&lt;/p&gt;
&lt;p&gt;Domain adaptation in imitation learning represents an essential step towards improving generalizability.  However, even in the restricted setting of third-person imitation where transfer is between isomorphic Markov Decision …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Provably Efficient Third-Person Imitation from Offline Observation&lt;/p&gt;
&lt;p&gt;Aaron Zweig (New York University)*; Joan Bruna (Courant Institute of Mathematical Sciences, NYU, USA)&lt;/p&gt;
&lt;p&gt;Domain adaptation in imitation learning represents an essential step towards improving generalizability.  However, even in the restricted setting of third-person imitation where transfer is between isomorphic Markov Decision Processes, there are no strong guarantees on the performance of transferred policies.  We present problem-dependent, statistical learning guarantees for third-person imitation from observation in an offline setting, and a lower bound on performance in the online setting.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Randomized Exploration for Non-Stationary Stochastic Linear Bandits</title><link href="https://pyvideo.org/uai-2020/randomized-exploration-for-non-stationary-stochastic-linear-bandits.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Baekjin Kim</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/randomized-exploration-for-non-stationary-stochastic-linear-bandits.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Randomized Exploration for Non-Stationary Stochastic Linear Bandits&lt;/p&gt;
&lt;p&gt;Baekjin Kim (University of Michigan)*; Ambuj Tewari (University of Michigan)&lt;/p&gt;
&lt;p&gt;We investigate two perturbation approaches to overcome conservatism that optimism based algorithms chronically suffer from in practice. The first approach replaces optimism with a simple randomization when using confidence sets. The second …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Randomized Exploration for Non-Stationary Stochastic Linear Bandits&lt;/p&gt;
&lt;p&gt;Baekjin Kim (University of Michigan)*; Ambuj Tewari (University of Michigan)&lt;/p&gt;
&lt;p&gt;We investigate two perturbation approaches to overcome conservatism that optimism based algorithms chronically suffer from in practice. The first approach replaces optimism with a simple randomization when using confidence sets. The second one adds random perturbations to its current estimate before maximizing the expected reward. For non-stationary linear bandits, where each action is associated with a $d$-dimensional feature and the unknown parameter is time-varying with total variation $B_T$, we propose two randomized algorithms, Discounted Randomized LinUCB (D-RandLinUCB) and Discounted Linear Thompson Sampling (D-LinTS) via the two perturbation approaches. We highlight the statistical optimality versus computational efficiency trade-off between them in that the former asymptotically achieves the optimal dynamic regret $tilde{cO}(d ^{2/3}B_T^{1/3} T^{2/3})$, but the latter is oracle-efficient with an extra logarithmic factor in the number of arms compared to minimax-optimal dynamic regret. In a simulation study, both algorithms show the outstanding performance in tackling conservatism issue that Discounted LinUCB struggles with.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Regret Analysis of Bandit Problems with Causal Background Knowledge</title><link href="https://pyvideo.org/uai-2020/regret-analysis-of-bandit-problems-with-causal-background-knowledge.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Yangyi Lu</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/regret-analysis-of-bandit-problems-with-causal-background-knowledge.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Regret Analysis of Bandit Problems with Causal Background Knowledge&lt;/p&gt;
&lt;p&gt;Yangyi Lu (University of Michigan)*; Amirhossein Meisami (Adobe); Ambuj Tewari (University of Michigan); William Yan (Adobe Systems Incorporated)&lt;/p&gt;
&lt;p&gt;We study how to learn optimal interventions sequentially given causal information represented as a causal graph along with associated conditional distributions. Causal …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Regret Analysis of Bandit Problems with Causal Background Knowledge&lt;/p&gt;
&lt;p&gt;Yangyi Lu (University of Michigan)*; Amirhossein Meisami (Adobe); Ambuj Tewari (University of Michigan); William Yan (Adobe Systems Incorporated)&lt;/p&gt;
&lt;p&gt;We study how to learn optimal interventions sequentially given causal information represented as a causal graph along with associated conditional distributions. Causal modeling is useful in real world problems like online advertisement where complex causal mechanisms underlie the relationship between interventions and outcomes. We propose two algorithms, causal upper confidence bound (C-UCB) and causal Thompson Sampling (C-TS), that enjoy improved cumulative regret bounds compared with algorithms that do not use causal information. We thus resolve an open problem posed by Lattimore et al. (2016). Further, we extend C-UCB and C-TS to the linear bandit setting and propose causal linear UCB (CL-UCB) and causal linear TS (CL-TS) algorithms. These algorithms enjoy a cumulative regret bound that only scales with the feature dimension. Our experiments show the benefit of using causal information. For example, we observe that even with a few hundreds of iterations, the regret of causal algorithms is less than that of standard algorithms by a factor of three. We also show that under certain causal structures, our algorithms scale better than the standard bandit algorithms as the number of interventions increases.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Regret Bounds for Decentralized Learning in Cooperative Multi-Agent Dynamical Systems</title><link href="https://pyvideo.org/uai-2020/regret-bounds-for-decentralized-learning-in-cooperative-multi-agent-dynamical-systems.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Seyed Mohammad Asghari</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/regret-bounds-for-decentralized-learning-in-cooperative-multi-agent-dynamical-systems.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Regret Bounds for Decentralized Learning in Cooperative Multi-Agent Dynamical Systems&lt;/p&gt;
&lt;p&gt;Seyed Mohammad Asghari (University of Southern California)*; Yi Ouyang (Preferred Networks); Ashutosh Nayyar (University of Southern California)&lt;/p&gt;
&lt;p&gt;Regret analysis is challenging in Multi-Agent Reinforcement Learning (MARL) primarily due to the dynamical environments and the decentralized information among agents. We …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Regret Bounds for Decentralized Learning in Cooperative Multi-Agent Dynamical Systems&lt;/p&gt;
&lt;p&gt;Seyed Mohammad Asghari (University of Southern California)*; Yi Ouyang (Preferred Networks); Ashutosh Nayyar (University of Southern California)&lt;/p&gt;
&lt;p&gt;Regret analysis is challenging in Multi-Agent Reinforcement Learning (MARL) primarily due to the dynamical environments and the decentralized information among agents. We attempt to solve this challenge in the context of decentralized learning in multi-agent linear-quadratic (LQ) dynamical systems. We begin with a simple setup consisting of two agents and two dynamically decoupled stochastic linear systems, each system controlled by an agent. The systems are coupled through a quadratic cost function. When both systems' dynamics are unknown and there is no communication among the agents, we show that no learning policy can generate sub-linear in $T$ regret, where $T$ is the time horizon. When only one system's dynamics are unknown and there is one-directional communication from the agent controlling the unknown system to the other agent, we propose a MARL algorithm based on the construction of an auxiliary single-agent LQ problem. The auxiliary single-agent problem in the proposed MARL algorithm serves as an implicit coordination mechanism among the two learning agents. This allows the agents to achieve a regret within $O(sqrt{T})$ of the regret of the auxiliary single-agent problem. Consequently, using existing results for single-agent LQ regret, our algorithm provides a $tilde{O}(sqrt{T})$ regret bound. (Here $tilde{O}(cdot)$ hides constants and logarithmic factors). Our numerical experiments indicate that this bound is matched in practice. From the two-agent problem, we extend our results to multi-agent LQ systems with certain communication patterns which appear in vehicle platoon control.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Relaxed Multivariate Bernoulli Distribution and Its Applications to Deep Generative Models</title><link href="https://pyvideo.org/uai-2020/relaxed-multivariate-bernoulli-distribution-and-its-applications-to-deep-generative-models.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Xi Wang</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/relaxed-multivariate-bernoulli-distribution-and-its-applications-to-deep-generative-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Relaxed Multivariate Bernoulli Distribution and Its Applications to Deep Generative Models&lt;/p&gt;
&lt;p&gt;Xi Wang (East China Normal University)*; Junming Yin (University of Arizona)&lt;/p&gt;
&lt;p&gt;Recent advances in variational auto-encoder (VAE) have demonstrated the possibility of approximating the intractable posterior distribution with a variational distribution parameterized by a neural network. To optimize …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Relaxed Multivariate Bernoulli Distribution and Its Applications to Deep Generative Models&lt;/p&gt;
&lt;p&gt;Xi Wang (East China Normal University)*; Junming Yin (University of Arizona)&lt;/p&gt;
&lt;p&gt;Recent advances in variational auto-encoder (VAE) have demonstrated the possibility of approximating the intractable posterior distribution with a variational distribution parameterized by a neural network. To optimize the variational objective of VAE, the reparameterization trick is commonly applied to obtain a low-variance estimator of the gradient. The main idea of the trick is to express the variational distribution as a differentiable function of parameters and a random variable with a fixed distribution. To extend the reparameterization trick to inference involving discrete latent variables, a common approach is to use a continuous relaxation of the categorical distribution as the approximate posterior. However, when applying continuous relaxation to the multivariate cases, multiple variables are typically assumed to be independent, making it suboptimal in applications where modeling dependency is crucial to the overall performance. In this work, we propose a multivariate generalization of the Relaxed Bernoulli distribution, which can be reparameterized and can capture the correlation between variables via a Gaussian copula.  We demonstrate its effectiveness in two tasks: density estimation with Bernoulli VAE and semi-supervised multi-label classification.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Risk Bounds for Low Cost Bipartite Ranking</title><link href="https://pyvideo.org/uai-2020/risk-bounds-for-low-cost-bipartite-ranking.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>San Gultekin</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/risk-bounds-for-low-cost-bipartite-ranking.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Risk Bounds for Low Cost Bipartite Ranking&lt;/p&gt;
&lt;p&gt;San Gultekin (Columbia University)*; John Paisley (Columbia University)&lt;/p&gt;
&lt;p&gt;Bipartite ranking is an important supervised learning problem; however, unlike regression or classification, it has a quadratic dependence on the number of samples. To circumvent the prohibitive sample cost, many recent work focus on …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Risk Bounds for Low Cost Bipartite Ranking&lt;/p&gt;
&lt;p&gt;San Gultekin (Columbia University)*; John Paisley (Columbia University)&lt;/p&gt;
&lt;p&gt;Bipartite ranking is an important supervised learning problem; however, unlike regression or classification, it has a quadratic dependence on the number of samples. To circumvent the prohibitive sample cost, many recent work focus on stochastic gradient-based methods. In this paper we consider an alternative approach, which leverages the structure of the widely-adopted pairwise squared loss, to obtain a stochastic and low cost algorithm that does not require stochastic gradients or learning rates. Using a novel uniform risk bound---based on matrix and vector concentration inequalities---we show that the sample size required for competitive performance against the all-pairs batch algorithm does not have a quadratic dependence. Generalization bounds for both the batch and low cost stochastic algorithms are presented. Experimental results show significant speed gain against the batch algorithm, as well as competitive performance against state-of-the-art bipartite ranking algorithms on real datasets.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Robust Collective Classification against Structural Attacks</title><link href="https://pyvideo.org/uai-2020/robust-collective-classification-against-structural-attacks.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Kai Zhou</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/robust-collective-classification-against-structural-attacks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Robust Collective Classification against Structural Attacks&lt;/p&gt;
&lt;p&gt;Kai Zhou (Washington University in St. Louis)*; Yevgeniy Vorobeychik (Washington University in St. Louis)&lt;/p&gt;
&lt;p&gt;Collective learning methods exploit relations among data points to enhance classification performance. However, such relations, represented as edges in the underlying graphical model, expose an extra attack surface to …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Robust Collective Classification against Structural Attacks&lt;/p&gt;
&lt;p&gt;Kai Zhou (Washington University in St. Louis)*; Yevgeniy Vorobeychik (Washington University in St. Louis)&lt;/p&gt;
&lt;p&gt;Collective learning methods exploit relations among data points to enhance classification performance. However, such relations, represented as edges in the underlying graphical model, expose an extra attack surface to the adversaries. We study adversarial robustness of an important class of such graphical models, Associative Markov Networks (AMN), to structural attacks, where an attacker can modify the graph structure at test time. We formulate the task of learning a robust AMN classifier as a bi-level program, where the inner problem is a challenging non- linear integer program that computes optimal structural changes to the AMN. To address this technical challenge, we first relax the attacker problem, and then use duality to obtain a convex quadratic upper bound for the robust AMN problem. We then prove a bound on the quality of the resulting approximately optimal solutions, and experimentally demonstrate the e&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Robust $k$-means++</title><link href="https://pyvideo.org/uai-2020/robust-k-means.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Amit Deshpande</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/robust-k-means.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Robust k-means++&lt;/p&gt;
&lt;p&gt;Amit Deshpande (Microsoft Research); Praneeth Kacham (Carnegie Mellon University); Rameshwar Pratap (Chennai Mathematical Institute (CMI))*&lt;/p&gt;
&lt;p&gt;A good seeding or initialization of cluster centers for the $k$-means method is important from both theoretical and practical standpoints. The k-means objective is inherently non-robust and sensitive to outliers. A …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Robust k-means++&lt;/p&gt;
&lt;p&gt;Amit Deshpande (Microsoft Research); Praneeth Kacham (Carnegie Mellon University); Rameshwar Pratap (Chennai Mathematical Institute (CMI))*&lt;/p&gt;
&lt;p&gt;A good seeding or initialization of cluster centers for the $k$-means method is important from both theoretical and practical standpoints. The k-means objective is inherently non-robust and sensitive to outliers. A popular seeding such as the k-means++ cite{AV2007} that is more likely to pick outliers in the worst case may compound this drawback, thereby affecting the quality of clustering on noisy data.&lt;/p&gt;
&lt;p&gt;For any, we show that using a mixture of  and uniform sampling, we can pick  candidate centers with the following guarantee: they contain some k centers that give approximation to the optimal robust $k$-means solution while discarding at most delta  more points than the outliers discarded by the optimal solution. That is, if the optimal solution discards its farthest beta  points as outliers, our solution discards  its points as outliers. The constant factor in our approximation does not  depend on delta.  This is an improvement over previous results for means with outliers based on LP relaxation and rounding cite{Charikar} and local search cite. The sized subset can be found in time. Our emph robust k-means++ is also easily amenable to scalable, faster, parallel implementations of $k$-means++ cite{Bahmani}. Our empirical results show a comparison of the above emph{robust} variant of $k$-means++ with the usual $k$-means++, uniform random seeding, threshold $k$-means++~cite{tkmeanspp} and local search on real world and synthetic data.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Robust Spatial-Temporal Incident Prediction</title><link href="https://pyvideo.org/uai-2020/robust-spatial-temporal-incident-prediction.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Ayan Mukhopadhyay</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/robust-spatial-temporal-incident-prediction.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Robust Spatial-Temporal Incident Prediction&lt;/p&gt;
&lt;p&gt;Ayan Mukhopadhyay (Stanford University)*; Kai Wang (Harvard University); Andrew Perrault (Harvard University); Mykel Kochenderfer (Stanford University); Milind Tambe (Harvard University); Yevgeniy Vorobeychik (Washington University in St. Louis)&lt;/p&gt;
&lt;p&gt;Spatio-temporal incident prediction is a central issue in law enforcement, with applications in fighting crimes like poaching, human …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Robust Spatial-Temporal Incident Prediction&lt;/p&gt;
&lt;p&gt;Ayan Mukhopadhyay (Stanford University)*; Kai Wang (Harvard University); Andrew Perrault (Harvard University); Mykel Kochenderfer (Stanford University); Milind Tambe (Harvard University); Yevgeniy Vorobeychik (Washington University in St. Louis)&lt;/p&gt;
&lt;p&gt;Spatio-temporal incident prediction is a central issue in law enforcement, with applications in fighting crimes like poaching, human trafficking, illegal fishing, burglaries and smuggling. However, state of the art approaches fail to account for  evasion in response to predictive models, a common form of which is spatial shift in incident occurrence. We present a general approach for incident forecasting that is robust to spatial shifts. We propose two techniques for solving the resulting robust optimization problem: first, a constraint generation method guaranteed to yield an optimal solution, and second, a more scalable gradient-based approach. We then apply these techniques to both discrete-time and continuous-time robust incident forecasting. We evaluate our algorithms on two different real-world datasets, demonstrating that our approach is significantly more robust than conventional methods.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Scalable and Flexible Clustering of Grouped Data via Parallel and Distributed Sampling</title><link href="https://pyvideo.org/uai-2020/scalable-and-flexible-clustering-of-grouped-data-via-parallel-and-distributed-sampling.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Or Dinari</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/scalable-and-flexible-clustering-of-grouped-data-via-parallel-and-distributed-sampling.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Scalable and Flexible Clustering of Grouped Data via Parallel and Distributed Sampling in Versatile Hierarchical Dirichlet ProcessesㅇㅇOr Dinari (Ben Gurion University)*; Oren Freifeld (Ben-Gurion University)ㅇㅇAdaptive clustering of grouped data is often done via the Hierarchical Dirichlet Process Mixture Model (HDPMM). That approach, however, is limited in its flexibility …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Scalable and Flexible Clustering of Grouped Data via Parallel and Distributed Sampling in Versatile Hierarchical Dirichlet ProcessesㅇㅇOr Dinari (Ben Gurion University)*; Oren Freifeld (Ben-Gurion University)ㅇㅇAdaptive clustering of grouped data is often done via the Hierarchical Dirichlet Process Mixture Model (HDPMM). That approach, however, is limited in its flexibility and usually does not scale well. As a remedy, we propose another, but closely related, hierarchical Bayesian nonparametric framework. Our main contributions are as follows. 1) a new model, called the Versatile HDPMM (vHDPMM), with two possible settings: full and reduced. While the latter is akin to the HDPMM's setting, the former supports not only global features (as HDPMM does) but also local ones. 2) An effective mechanism for detecting global features.  3) A  new sampler that addresses the challenges posed by the vHDPMM and, in the reduced setting, scales better than HDPMM samplers. 4)  An efficient, distributed, and easily-modifiable implementation that offers more flexibility (even in the reduced setting) than publicly-available HDPMM implementations. Finally, we show the utility of the approach in applications such as image cosegmentation, visual topic modeling, and clustering with missing data.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Selling Data at an Auction under Privacy Constraints</title><link href="https://pyvideo.org/uai-2020/selling-data-at-an-auction-under-privacy-constraints.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Mengxiao Zhang</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/selling-data-at-an-auction-under-privacy-constraints.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Selling Data at an Auction under Privacy Constraintsㅇ
ㅇMengxiao Zhang (The University of Auckland)*; Fernando Beltran (The University of Auckland); Jiamou Liu (University of Auckland)ㅇㅇPrivate data query combines mechanism design with privacy protection to produce aggregated statistics from privately-owned data records. The problem arises in a data marketplace …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Selling Data at an Auction under Privacy Constraintsㅇ
ㅇMengxiao Zhang (The University of Auckland)*; Fernando Beltran (The University of Auckland); Jiamou Liu (University of Auckland)ㅇㅇPrivate data query combines mechanism design with privacy protection to produce aggregated statistics from privately-owned data records. The problem arises in a data marketplace where data owners have personalised privacy requirements and private data valuations. We focus on the case when the data owners are single-minded, i.e., they are willing to release their data only if the data broker guarantees to meet their announced privacy requirements. For a data broker who wants to purchase data from such data owners, we propose the SingleMindedQuery (SMQ) mechanism, which uses a reverse auction to select data owners and determine compensations. SMQ satisfies interim incentive compatibility, individual rationality, and budget feasibility. Moreover, it uses purchased privacy expectation maximisation as a principle to produce accurate outputs for commonly-used queries such as counting, median and linear predictor. The effectiveness of our method is empirically validated by a series of experiments.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Semi-bandit Optimization in the Dispersed Setting</title><link href="https://pyvideo.org/uai-2020/semi-bandit-optimization-in-the-dispersed-setting.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Travis Dick</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/semi-bandit-optimization-in-the-dispersed-setting.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Semi-bandit Optimization in the Dispersed SettingㅇㅇTravis Dick (University of Pennsylvania)*; Wesley Pegden (Carnegie Mellon University); Maria-Florina Balcan (Carnegie Mellon University)ㅇㅇThe goal of data-driven algorithm design is to obtain high-performing algorithms for specific application domains using machine learning and data. Across many fields in AI, science, and engineering, practitioners …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Semi-bandit Optimization in the Dispersed SettingㅇㅇTravis Dick (University of Pennsylvania)*; Wesley Pegden (Carnegie Mellon University); Maria-Florina Balcan (Carnegie Mellon University)ㅇㅇThe goal of data-driven algorithm design is to obtain high-performing algorithms for specific application domains using machine learning and data. Across many fields in AI, science, and engineering, practitioners will often fix a family of parameterized algorithms and then optimize those parameters to obtain good performance on example instances from the application domain.  In the online setting, we must choose algorithm parameters for each instance as they arrive, and our goal is to be competitive with the best fixed algorithm in hindsight.&lt;/p&gt;
&lt;p&gt;There are two major challenges in online data-driven algorithm design. First, it can be computationally expensive to evaluate the loss functions that map algorithm parameters to performance, which often require the learner to run a combinatorial algorithm to measure its performance. Second, the losses can be extremely volatile and have sharp discontinuities. However, we show that in many applications, evaluating the loss function for one algorithm choice can sometimes reveal the loss for a range of similar algorithms, essentially for free. We develop online optimization algorithms capable of using this kind of extra information by working in the semi-bandit feedback setting. Our algorithms achieve regret bounds that are essentially as good as algorithms under full-information feedback and are significantly more computationally efficient. We apply our semi-bandit results to obtain the first provable guarantees for data-driven algorithm design for linkage-based clustering and we improve the best regret bounds for designing greedy knapsack algorithms.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Semi-supervised learning, causality, and the conditional cluster assumption</title><link href="https://pyvideo.org/uai-2020/semi-supervised-learning-causality-and-the-conditional-cluster-assumption.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Julius von Kügelgen</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/semi-supervised-learning-causality-and-the-conditional-cluster-assumption.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Semi-supervised learning, causality, and the conditional cluster assumptionㅇㅇJulius von Kügelgen (MPI for Intelligent Systems, Tübingen &amp;amp; University of Cambridge); Alexander Mey (Delft University of Technology); Marco Loog (Delft University of Technology &amp;amp; University of Copenhagen); Bernhard Schölkopf (MPI for Intelligent Systems, Tübingen)ㅇㅇWhile the success of semi-supervised learning (SSL) is still …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Semi-supervised learning, causality, and the conditional cluster assumptionㅇㅇJulius von Kügelgen (MPI for Intelligent Systems, Tübingen &amp;amp; University of Cambridge); Alexander Mey (Delft University of Technology); Marco Loog (Delft University of Technology &amp;amp; University of Copenhagen); Bernhard Schölkopf (MPI for Intelligent Systems, Tübingen)ㅇㅇWhile the success of semi-supervised learning (SSL) is still not fully understood, Sch ̈olkopf et al. (2012) have established a link to the principle of independent causal mechanisms. They conclude that SSL should be impossible when predicting a target variable from its causes, but possible when predicting it from its effects. Since both these cases are restrictive, we extend their work by considering classification using cause and effect features at the same time, such as predicting a disease from both risk factors and symptoms. While standard SSL exploits information contained in the marginal distribution of all inputs (to improve the estimate of the conditional distribution of the target given in-puts), we argue that in our more general setting we should use information in the conditional distribution of effect features given causal features. We explore how this insight generalises the previous understanding, and how it relates to and can be exploited algorithmically for SSL.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Semi-Supervised Learning: the Case When Unlabeled Data is Equally Useful</title><link href="https://pyvideo.org/uai-2020/semi-supervised-learning-the-case-when-unlabeled-data-is-equally-useful.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Jingge Zhu</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/semi-supervised-learning-the-case-when-unlabeled-data-is-equally-useful.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Semi-Supervised Learning: the Case When Unlabeled Data is Equally UsefulㅇㅇJingge Zhu (University of Melbourne)ㅇㅇSemi-supervised learning algorithms attempt to take advantage of relatively inexpensive unlabeled data to improve learning performance. In this work, we consider statistical models where the data distributions can be characterized by continuous parameters. We show …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Semi-Supervised Learning: the Case When Unlabeled Data is Equally UsefulㅇㅇJingge Zhu (University of Melbourne)ㅇㅇSemi-supervised learning algorithms attempt to take advantage of relatively inexpensive unlabeled data to improve learning performance. In this work, we consider statistical models where the data distributions can be characterized by continuous parameters. We show that under certain conditions on the distribution, unlabeled data is equally useful as labeled date in terms of learning rate. Specifically, let $n, m$ be the number of labeled and unlabeled data, respectively. It is shown that the learning rate of semi-supervised learning scales as  and scales as  whereas the learning rate of supervised learning scales as $O(1/n)$.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Sensor Placement for Spatial Gaussian Processes with Integral Observations</title><link href="https://pyvideo.org/uai-2020/sensor-placement-for-spatial-gaussian-processes-with-integral-observations.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Krista Longi</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/sensor-placement-for-spatial-gaussian-processes-with-integral-observations.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Sensor Placement for Spatial Gaussian Processes with Integral Observations&lt;/p&gt;
&lt;p&gt;Krista Longi (Univeristy of Helsinki)*; Chang Rajani (University of Helsinki); Tom Sillanpää (University of Helsinki); Joni Mäkinen (University of Helsinki); Timo Rauhala (Altum Technologies); Ari Salmi (University of Helsinki); Edward Haeggström (University of Helsinki); Arto Klami (University of Helsinki)&lt;/p&gt;
&lt;p&gt;Gaussian …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Sensor Placement for Spatial Gaussian Processes with Integral Observations&lt;/p&gt;
&lt;p&gt;Krista Longi (Univeristy of Helsinki)*; Chang Rajani (University of Helsinki); Tom Sillanpää (University of Helsinki); Joni Mäkinen (University of Helsinki); Timo Rauhala (Altum Technologies); Ari Salmi (University of Helsinki); Edward Haeggström (University of Helsinki); Arto Klami (University of Helsinki)&lt;/p&gt;
&lt;p&gt;Gaussian processes (GP) are a natural tool for estimating unknown functions, typically based on a collection of point-wise observations. Interestingly, the GP formalism can be used also with observations that are integrals of the unknown function along some known trajectories, which makes GPs a promising technique for inverse problems in a wide range of physical sensing problems. However, in many real world applications collecting data is laborious and time consuming. We provide tools for optimizing sensor locations for GPs using integral observations, extending both model-based and geometric strategies for GP sensor placement.
We demonstrate the techniques in ultrasonic detection of fouling in closed pipes.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Skewness Ranking Optimization for Personalized Recommendation</title><link href="https://pyvideo.org/uai-2020/skewness-ranking-optimization-for-personalized-recommendation.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Yu-Neng Chuang</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/skewness-ranking-optimization-for-personalized-recommendation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Skewness Ranking Optimization for Personalized Recommendation&lt;/p&gt;
&lt;p&gt;Yu-Neng Chuang (National Chengchi University); Chih-Ming Chen (National Chengchi University); Chuan-Ju Wang (Academia Sinica)*; Ming-Feng Tsai (National Chengchi University)&lt;/p&gt;
&lt;p&gt;In this paper, we propose a novel optimization criterion that leverages features of the skew normal distribution to better model the problem of personalized …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Skewness Ranking Optimization for Personalized Recommendation&lt;/p&gt;
&lt;p&gt;Yu-Neng Chuang (National Chengchi University); Chih-Ming Chen (National Chengchi University); Chuan-Ju Wang (Academia Sinica)*; Ming-Feng Tsai (National Chengchi University)&lt;/p&gt;
&lt;p&gt;In this paper, we propose a novel optimization criterion that leverages features of the skew normal distribution to better model the problem of personalized recommendation. Specifically, the developed criterion borrows the concept and the flexibility of the skew normal distribution, based on which three hyperparameters are attached to the optimization criterion. Furthermore, from a theoretical point of view, we not only establish the relation between the maximization of the proposed criterion and the shape parameter in the skew normal distribution, but also provide the analogies and asymptotic analysis of the proposed criterion to maximization of the area under the ROC curve. Experimental results conducted on a range of large-scale real-world datasets show that our model significantly outperforms the state of the art and yields consistently best performance on all tested datasets.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Slice Sampling for General Completely Random Measures</title><link href="https://pyvideo.org/uai-2020/slice-sampling-for-general-completely-random-measures.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Peiyuan Zhu</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/slice-sampling-for-general-completely-random-measures.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Slice Sampling for General Completely Random Measures&lt;/p&gt;
&lt;p&gt;Peiyuan Zhu (The University of British Columbia Department of Statistics)*; Alexandre Bouchard-Cote (University of British Columbia); Trevor Campbell (UBC)&lt;/p&gt;
&lt;p&gt;Completely random measures provide a principled approach to creating flexible unsupervised models, where the number of latent features is infinite and the number …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Slice Sampling for General Completely Random Measures&lt;/p&gt;
&lt;p&gt;Peiyuan Zhu (The University of British Columbia Department of Statistics)*; Alexandre Bouchard-Cote (University of British Columbia); Trevor Campbell (UBC)&lt;/p&gt;
&lt;p&gt;Completely random measures provide a principled approach to creating flexible unsupervised models, where the number of latent features is infinite and the number of features that influence the data grows  with the size of the  data set.  Due to the infinity the latent features, posterior inference requires either marginalization---resulting in dependence structures that prevent efficient computation via parallelization and conjugacy---or finite  truncation, which arbitrarily limits the flexibility of the model.  In this paper we present a novel Markov chain Monte Carlo algorithm for posterior inference that adaptively sets the truncation level using auxiliary slice variables, enabling efficient, parallelized computation without sacrificing flexibility.  In contrast to past work that achieved this on a model-by-model basis, we provide a general recipe that is applicable to the broad class of completely random measure-based priors.  The efficacy of the proposed algorithm is evaluated on several popular nonparametric models, demonstrating a higher effective sample size per second compared to algorithms using marginalization as well as a higher predictive performance compared to models employing fixed truncations.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Spectral Methods for Ranking with Scarce Data</title><link href="https://pyvideo.org/uai-2020/spectral-methods-for-ranking-with-scarce-data.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Lalit Jain</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/spectral-methods-for-ranking-with-scarce-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Spectral Methods for Ranking with Scarce Data&lt;/p&gt;
&lt;p&gt;Lalit Jain (University of Washington)*; Anna Gilbert (University of Michigan); Umang Varma (University of Michigan)&lt;/p&gt;
&lt;p&gt;Given  a  number  of  pairwise  preferences of items, a common task is to rank all the items.Examples include pairwise movie ratings, New Yorker cartoon caption contests …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Spectral Methods for Ranking with Scarce Data&lt;/p&gt;
&lt;p&gt;Lalit Jain (University of Washington)*; Anna Gilbert (University of Michigan); Umang Varma (University of Michigan)&lt;/p&gt;
&lt;p&gt;Given  a  number  of  pairwise  preferences of items, a common task is to rank all the items.Examples include pairwise movie ratings, New Yorker cartoon caption contests, and many other consumer preferences tasks.  What these settings have in common is two-fold:  a scarcity of data (it may be costly to get comparisons for all the pairs of items) and additional feature information about the items (e.g., movie genre,director,  and cast).   In this paper we modify a popular and well studied method, RankCentrality for rank aggregation to account for few comparisons and that incorporates additional feature information. This method returns meaningful rankings even under scarce comparisons.Using diffusion based methods, we incorporate feature information that outperforms state-of-the-art methods in practice.  We also provide improved sample complexity for RankCentrality in a variety of sampling schemes.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry><entry><title>Stable Policy Optimization via Off-Policy Divergence Regularization</title><link href="https://pyvideo.org/uai-2020/stable-policy-optimization-via-off-policy-divergence-regularization.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Ahmed Touati</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/stable-policy-optimization-via-off-policy-divergence-regularization.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Stable Policy Optimization via Off-Policy Divergence Regularization&lt;/p&gt;
&lt;p&gt;Ahmed Touati (MILA)*; Amy Zhang (McGill, FAIR); Joelle Pineau (McGill / Facebook); Pascal Vincent (Facebook FAIR &amp;amp; MILA Université de Montréal)&lt;/p&gt;
&lt;p&gt;Trust Region Policy Optimization (TRPO) and Proximal Policy Optimization (PPO) are among the most successful policy gradient approaches in deep reinforcement learning (RL …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Stable Policy Optimization via Off-Policy Divergence Regularization&lt;/p&gt;
&lt;p&gt;Ahmed Touati (MILA)*; Amy Zhang (McGill, FAIR); Joelle Pineau (McGill / Facebook); Pascal Vincent (Facebook FAIR &amp;amp; MILA Université de Montréal)&lt;/p&gt;
&lt;p&gt;Trust Region Policy Optimization (TRPO) and Proximal Policy Optimization (PPO) are among the most successful policy gradient approaches in deep reinforcement learning (RL). While these methods achieve state-of-the-art performance across a wide range of challenging tasks, there is room for improvement in the stabilization of the policy learning and how the off-policy data are used. In this paper we revisit the theoretical foundations of these algorithms and propose a new algorithm which stabilizes the policy improvement through a proximity term that constrains the discounted state-action visitation distribution induced by consecutive policies to be close to one another. This proximity term, expressed in terms of the divergence between the visitation distributions, is learned in an off-policy and adversarial manner. We empirically show that our proposed method can have a beneficial effect on stability and improve final performance in benchmark high-dimensional control tasks.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry></feed>