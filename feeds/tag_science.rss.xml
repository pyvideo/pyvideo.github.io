<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 26 Oct 2018 00:00:00 +0000</lastBuildDate><item><title>Satellite data is for everyone: insights into modern remote sensing research with open data and Python</title><link>https://pyvideo.org/pycon-de-2018/satellite-data-is-for-everyone-insights-into-modern-remote-sensing-research-with-open-data-and-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The largest earth observation programme Copernicus
(&lt;a class="reference external" href="http://copernicus.eu"&gt;http://copernicus.eu&lt;/a&gt;) makes it possible to perform terrestrial
observations providing data for all kinds of purposes. One important
objective is to monitor the land-use and land-cover changes with the
Sentinel-2 satellite mission. These satellites measure the sun
reflectance on the earth surface with multispectral cameras (13 channels
between 440 nm to 2190 nm). Machine learning techniques like
convolutional neural networks (CNN) are able to learn the link between
the satellite image (spectrum) and the ground truth (land use class). In
this talk, we give an overview about the state-of-the-art land-use
classification with CNNs based on an open dataset.&lt;/p&gt;
&lt;p&gt;The EuroSAT benchmark dataset (&lt;a class="reference external" href="http://madm.dfki.de/downloads"&gt;http://madm.dfki.de/downloads&lt;/a&gt;) is freely
provided by German Research Center for Artificial Intelligence (DFKI).
It consists of 27.000 image patches for ten different land use/cover
classes, e.g. industrial and residential areas, different crop and
vegetation types and forests. All samples have 64 by 64 pixel dimension
and include either only the RGB images or all 13 bands.&lt;/p&gt;
&lt;p&gt;We will use different out-of-box CNNs for the Keras deep learning
library (&lt;a class="reference external" href="https://keras.io/"&gt;https://keras.io/&lt;/a&gt;). All networks are either included in Keras
itself or are available from Github repositories. We will show the
process of transfer learning for the RGB datasets. Furthermore, the
minimal changes required to apply commonly used CNNs to multispectral
data are demonstrated. Thus, the interested audience will be able to
perform their own classification of remote sensing data within a very
short time. Results of different network structures are visually
compared. Especially the differences of transfer learning and learning
from scratch are demonstrated. This also includes the amount of
necessary training epochs, progress of training and validation error and
visual comparison of the results of the trained networks.&lt;/p&gt;
&lt;p&gt;Finally, we give a quick overview about the current research topics
including recurrent neural networks for spatio-temporal land-use
classification and further applications of multi- and hyperspectral
data, e.g. for the estimation of water parameters and soil
characteristics. Additionally, we provide links to the code and dataset
used in this talk.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Felix M. Riese</dc:creator><pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-26:pycon-de-2018/satellite-data-is-for-everyone-insights-into-modern-remote-sensing-research-with-open-data-and-python.html</guid><category>Artificial Intelligence</category><category>Computer Vision</category><category>Deep Learning &amp; Artificial Intelligence</category><category>Data Science</category><category>Machine Learning</category><category>Science</category></item><item><title>Big Data Systems Performance: The Little Shop of Horrors</title><link>https://pyvideo.org/pycon-de-2018/big-data-systems-performance-the-little-shop-of-horrors.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The confusion around terms such as like NoSQL, Big Data, Data Science,
Spark, SQL, and Data Lakes often creates more fog than clarity. However,
clarity about the underlying technologies is crucial to designing the
best technical solution in any field relying on huge amounts of data
including data science, machine learning, but also more traditional
analytical systems such as data integration, data warehousing,
reporting, and OLAP.&lt;/p&gt;
&lt;p&gt;In my presentation, I will show that often at least three dimensions are
cluttered and confused in discussions when it comes to data management:
First, buzzwords (labels &amp;amp; terms like &amp;quot;big data&amp;quot;, &amp;quot;AI&amp;quot;, &amp;quot;data lake&amp;quot;);
second, data design patterns (principles &amp;amp; best practices like:
selection push-down, materialization, indexing); and Third, software
platforms (concrete implementations &amp;amp; frameworks like: Python, DBMS,
Spark, and NoSQL-systems).&lt;/p&gt;
&lt;p&gt;Only by keeping these three dimensions apart, it is possible to create
technically-sound architectures in the field of big data analytics.&lt;/p&gt;
&lt;p&gt;I will show concrete examples, which through a simple redesign and wise
choice of the right tools and technologies, run thereby up to 1000 times
faster. This in turn triggers tremendous savings in terms of development
time, hardware costs, and maintenance effort.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jens Dittrich</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/big-data-systems-performance-the-little-shop-of-horrors.html</guid><category>Algorithms</category><category>Big Data</category><category>Data Science</category><category>Infrastructure</category><category>Parallel Programming</category><category>Programming</category><category>Python</category><category>Science</category></item><item><title>Driving simulation and data analysis of magnetic nanostructures through Jupyter Notebook</title><link>https://pyvideo.org/pycon-de-2018/driving-simulation-and-data-analysis-of-magnetic-nanostructures-through-jupyter-notebook.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We present ongoing work from a project that makes a particular computer
simulation (implemented in C++ and Tk/Tcl) accessible through a Python
interface, and through the Jupyter Notebook. The talk describes the
motivation and current status of the project.&lt;/p&gt;
&lt;p&gt;In more detail, the computer simulation in question is the Object
Oriented Micromagnetic Modelling Framework
(&lt;a class="reference external" href="http://math.nist.gov/oommf/"&gt;OOMMF&lt;/a&gt;) which is likely the most
widely used micromagnetic simulation package. It can be driven through a
graphical (Tk) user interface or through a configuration file that
defines a simulation run.&lt;/p&gt;
&lt;p&gt;In this talk, we first show a Python interface to OOMMF that allows the
driving of OOMMF simulations from a Python program or interpreter
prompt. This way we embed a widely used scientific code from 1990s in a
general purpose programming language
[&lt;a class="reference external" href="https://doi.org/10.1063/1.4977225"&gt;1&lt;/a&gt;] and enable the full use of
the ecosystem of scientific libraries available for Python. For example,
design optimisation, specialised post-processing, and the creation of
figures can all be carried out using a single script; making the work
more easily reproducible.&lt;/p&gt;
&lt;p&gt;Second, we integrate the Python interface to OOMMF into a Jupyter
notebook, so that all existing benefits of using Jupyter are inherited
for the use in computational micromagnetics, which is the reason we
named our code Jupyter- OOMMF (&lt;a class="reference external" href="http://joommf.github.io/"&gt;JOOMMF&lt;/a&gt;). A
&lt;a class="reference external" href="https://tryjoommf.soton.ac.uk/"&gt;JupyterHub installation&lt;/a&gt; of the tool
reduces barriers in uptake, and all the code is &lt;a class="reference external" href="https://github.com/joommf"&gt;on
github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We discuss the benefits of driving computer simulation and data analysis
through Jupyter Notebooks.&lt;/p&gt;
&lt;p&gt;This project is a part of the Jupyter-OOMMF (JOOMMF) activity in the
&lt;a class="reference external" href="http://opendreamkit.org/"&gt;OpenDreamKit&lt;/a&gt; project and we acknowledge
financial support from Horizon 2020 European Research Infrastructures
project (676541). The work is also supported by the EPSRC CDT in Next
Generation Computational Modelling EP/L015382/1, and the EPSRC grants
EP/M022668/1 and EP/N032128/1.&lt;/p&gt;
&lt;p&gt;For additional context: micromagnetic modelling is a key research method
in academia and industry to support development of high-capacity
magnetic storage devices that are cheap, fast, and reliable, and to
enable research into future alternative storage and processing
technologies such as spintronics. The OOMMF modelling package has been
used in &lt;a class="reference external" href="https://math.nist.gov/oommf/oommf_cites.html"&gt;over 2500
publications&lt;/a&gt; since
1999.&lt;/p&gt;
&lt;p&gt;[1] Beg, M., Pepper, R. A., and Fangohr, H. User interfaces for
computational science: A domain specific language for OOMMF embedded in
Python. AIP Advances 7, 056025 (2017), &lt;a class="reference external" href="https://doi.org/10.1063/1.4977225"&gt;https://doi.org/10.1063/1.4977225&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Hans Fangohr</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/driving-simulation-and-data-analysis-of-magnetic-nanostructures-through-jupyter-notebook.html</guid><category>Data Science</category><category>Jupyter</category><category>Programming</category><category>Python</category><category>Science</category></item><item><title>How to teach space invaders to your computer</title><link>https://pyvideo.org/pycon-de-2018/how-to-teach-space-invaders-to-your-computer.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;First things first: playing good old Atari games might be cool but why
should I write a program for doing it? Well teaching a computer to play
a game means teaching it to develop strategies and use foresight
planning to solve a certain problem. The tools you gather while solving
i.e. space invaders are the same you may use to solve any problem which
requires a sequential set of decisions in order to find an optimal
solution to some problem, like i.e. controlling a robot that collects
garbage. Furthermore, there is a lot of scientific research on
reinforcement learning that focuses on solving Atari games which makes
it a good starting point, as large amounts of publications and open
source code already exists.&lt;/p&gt;
&lt;p&gt;What to expect from this talk? At first there will be a very short
introduction to reinforcement learning theory, just the very basics,
common applications and some references for further reading. Next points
are, how to run Atari games from inside python for a learning task (with
OpenAI's gym), and where to find an algorithm for the actual learning
problem. Finally it will be shown how to build it all together in a
jupyter notebook and let the algorithm play the game. Et voilà that's
your computer beating you in space invaders.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">David Wölfle</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/how-to-teach-space-invaders-to-your-computer.html</guid><category>Deep Learning &amp; Artificial Intelligence</category><category>Jupyter</category><category>Python</category><category>Science</category></item><item><title>Reproducibility, and Selection Bias in Machine Learning</title><link>https://pyvideo.org/pycon-de-2018/reproducibility-and-selection-bias-in-machine-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Reproducibility&lt;/em&gt; - the ability to recompute results — and
&lt;em&gt;replicability&lt;/em&gt; — the chances other experimenters will achieve a
consistent result[1]- are among the main important beliefs of the
&lt;em&gt;scientific method&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Surprisingly, these two aspects are often underestimated or not even
considered when setting up scientific experimental pipelines. In this,
one of the main threat to replicability is the &lt;em&gt;selection bias&lt;/em&gt; , that
is the error in choosing the individuals or groups to take part in a
study. Selection bias may come in different flavours: the selection of
the population of samples in the dataset ( &lt;em&gt;sample bias&lt;/em&gt; ); the
selection of features used by the learning models, particularly sensible
in case of high dimensionality; the selection of hyper parameter best
performing on specific dataset(s). If not properly considered, the
selection bias may strongly affect the validity of derived conclusions,
as well as the reliability of the learning model.&lt;/p&gt;
&lt;p&gt;In this talk I will provide a solid introduction to the topics of
reproducibility and selection bias, with examples taken from the
biomedical research, in which reliability is paramount.&lt;/p&gt;
&lt;p&gt;From a more technological perspective, to date the scientific Python
ecosystem still misses tools to consolidate the experimental pipelines
in in research, that can be used together with Machine and Deep learning
frameworks (e.g. &lt;tt class="docutils literal"&gt;sklearn&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;keras&lt;/tt&gt;). In this talk, I will
present &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;reproducible-lern&lt;/span&gt;&lt;/tt&gt;, a new Python frameworks for reproducible
research to be used for machine and deep learning.&lt;/p&gt;
&lt;p&gt;During the talk, the main features of the framework will be presented,
along with several examples, technical insights and implementation
choices to be discussed with the audience.&lt;/p&gt;
&lt;p&gt;The talk is intended for &lt;em&gt;intermediate&lt;/em&gt; PyData researchers and
practitioners. Basic prior knowledge of the main Machine Learning
concepts is assumed for the first part of the talk. On the other hand,
good proficiency with the Python language and with scientific python
libraries (e.g. &lt;tt class="docutils literal"&gt;numpy&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;sklearn&lt;/tt&gt;) are required for the second
part.&lt;/p&gt;
&lt;p&gt;-- &lt;a class="reference external" href="http://www.pnas.org/content/112/6/1645.full"&gt;1&lt;/a&gt; &lt;em&gt;Reproducible
research can still be wrong: Adopting a prevention approach&lt;/em&gt; by Jeffrey
T. Leek, and Roger D. Peng&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.cancer.gov/publications/dictionaries/cancer-terms?CdrID=44087"&gt;2&lt;/a&gt;
Dictionary of Cancer Terms -&amp;gt; &amp;quot;selection bias&amp;quot;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Valerio Maggio</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/reproducibility-and-selection-bias-in-machine-learning.html</guid><category>Algorithms</category><category>Machine Learning</category><category>Science</category></item><item><title>Satellite Image Segmentation Photovoltaic Potential Estimation</title><link>https://pyvideo.org/pycon-de-2018/satellite-image-segmentation-photovoltaic-potential-estimation.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The used technologies are python based and include: MongoDB tensorflow
Flask google.cloud python API&lt;/p&gt;
&lt;p&gt;A dataset of labelled satellite images is created. Several networks are
trained and tested on this dataset. The network is deployed on a
production server.&lt;/p&gt;
&lt;p&gt;The results of the classification/segmentaion are used to feed python
based photovotlaic simulation libaries. The output is displayed and the
results (the potential) evaluated.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Johannes Oos</dc:creator><pubDate>Thu, 25 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-25:pycon-de-2018/satellite-image-segmentation-photovoltaic-potential-estimation.html</guid><category>Artificial Intelligence</category><category>Computer Vision</category><category>Deep Learning &amp; Artificial Intelligence</category><category>Machine Learning</category><category>Science</category></item><item><title>A Day Has Only 24±1 Hours: import pytz</title><link>https://pyvideo.org/pycon-de-2018/a-day-has-only-24-1-hours-import-pytz.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;On the last Sunday of October “we get one more hour of sleep” but may
spend much more time debugging code dealing with the timezones, daylight
saving time shifts and datetime stuff in general.&lt;/p&gt;
&lt;p&gt;We'll look at a few pitfalls you may encounter when working with
datetimes in Python. We'll discover the &lt;tt class="docutils literal"&gt;pytz&lt;/tt&gt; module and explain why
&lt;tt class="docutils literal"&gt;pytz.all_timezones&lt;/tt&gt; contains over 500 individual timezones. We'll
also find the reason why &lt;tt class="docutils literal"&gt;pytz&lt;/tt&gt; is not part of the standard Python,
why it gets updated so often and why even that won't solve all your
problems.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Miroslav Šedivý</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/a-day-has-only-24-1-hours-import-pytz.html</guid><category>Data Science</category><category>Science</category></item><item><title>Binder - lowering the bar to sharing interactive software</title><link>https://pyvideo.org/pycon-de-2018/binder-lowering-the-bar-to-sharing-interactive-software.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Binder project drastically lowers the bar to sharing and re-using
software. As a user wanting to try out someone else’s work I only have
to click a single link. As the author preparing a binder-ready project
is much easier than having to support many different platforms and for
many projects involves little additional work.&lt;/p&gt;
&lt;p&gt;In this talk I will introduce the audience to the concepts and ideas
behind the Binder project. I will showcase examples from the community
to illustrate use-cases and show off the power of Binder.&lt;/p&gt;
&lt;p&gt;Three pieces of software power Binder:
&lt;a class="reference external" href="http://repo2docker.readthedocs.io/en/latest/"&gt;repo2docker&lt;/a&gt;,
&lt;a class="reference external" href="https://binderhub.readthedocs.io/en/latest/"&gt;BinderHub&lt;/a&gt; and
&lt;a class="reference external" href="http://jupyterhub.readthedocs.io/en/stable/"&gt;JupyterHub&lt;/a&gt;. Using an
example repository I will go through the steps required to make a
repository binder- ready and what happens when a user launches it. At
each step I will illustrate the role that each of the three software
components play and how they interact.&lt;/p&gt;
&lt;p&gt;Binder is a project created by its community. I will present pathways
for getting involved with the community.&lt;/p&gt;
&lt;p&gt;To wrap up I will highlight plans for future developments and features
of Binder.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tim Head</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/binder-lowering-the-bar-to-sharing-interactive-software.html</guid><category>Community</category><category>Data Science</category><category>DevOps</category><category>Jupyter</category><category>Science</category><category>Web</category></item><item><title>Introduction and practical experience about Quantum Computing using the Python libraries from IBM and Google</title><link>https://pyvideo.org/pycon-de-2018/introduction-and-practical-experience-about-quantum-computing-using-the-python-libraries-from-ibm-and-google.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As publicly announced in early 2018, Daimler AG has started cooperations
with IBM and Google on Quantum Computing. When doing concrete
experiments with the Quantum Computing cloud based offerings, two
different Python libraries provided by IBM and Google are used. They are
named QISKIT in the case of IBM and CIRQ in the case of Google. The
experiments with both libraries are handled using appropriate Jupyter
Notebooks. This talk gives a brief introduction on Quantum Computing,
specifically on Quantum Computers based on transmon-based QBits. This is
followed by an introduction of the both Python libraries that are used.
Then some details about the Jupyter notebooks that are used are given.
The talk will finish with some demos and an overview about the most
important practical experiences with both Quantum Computing offerings.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dr. Andreas Riegg</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/introduction-and-practical-experience-about-quantum-computing-using-the-python-libraries-from-ibm-and-google.html</guid><category>Jupyter</category><category>Programming</category><category>Python</category><category>Science</category></item><item><title>Pyccel, a Fortran static compiler for scientific High-Performance Computing</title><link>https://pyvideo.org/pycon-de-2018/pyccel-a-fortran-static-compiler-for-scientific-high-performance-computing.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Pyccel&lt;/em&gt; is a new &lt;strong&gt;static compiler&lt;/strong&gt; for Python that uses &lt;strong&gt;Fortran&lt;/strong&gt;
as backend language while enabling High-Performance Computing &lt;strong&gt;HPC&lt;/strong&gt;
capabilities.&lt;/p&gt;
&lt;p&gt;Fortran is a computer language for scientific programming that is
tailored for efficient run-time execution on a wide variety of
processors. Even if the &lt;em&gt;2003&lt;/em&gt; and &lt;em&gt;2008&lt;/em&gt; standards added major
improvements like &lt;em&gt;OOP, Coarrays, Submodules, do concurrent&lt;/em&gt; , etc ...
they are not covered by all available compilers. Moreover, the Fortran
developer still suffers from the lack of &lt;strong&gt;meta-programming&lt;/strong&gt; compared
to &lt;strong&gt;C++&lt;/strong&gt; ones. Therefore, it is more and more difficult for applied
mathematicians and computational physicists to write applications at the
&lt;em&gt;state of art&lt;/em&gt; (targeting CPUs, GPUs, MICs) while implementing
complicated algorithms or numerical schemes.&lt;/p&gt;
&lt;p&gt;Pyccel can be used in two cases:&lt;/p&gt;
&lt;p&gt;In order to achieve the second point, we developed an internal DSL for
&lt;em&gt;types&lt;/em&gt; and &lt;em&gt;macros&lt;/em&gt;. The later is used to map sentences based on
&lt;em&gt;mpi4py&lt;/em&gt; , &lt;em&gt;scipy.linalg.blas or lapack&lt;/em&gt; onto the appropriate calls in
Fortran. Moreover, two parsers, for &lt;em&gt;OpenMP&lt;/em&gt; and &lt;em&gt;OpenACC&lt;/em&gt; , were added
too, allowing for explicit parallelism through the use of pragmas.&lt;/p&gt;
&lt;p&gt;Last but not least, Pyccel is an extension of &lt;strong&gt;Sympy&lt;/strong&gt;. Actually, it
converts a Python code to symbolic expressions/trees, from a Full Syntax
Tree ( &lt;em&gt;RedBaron&lt;/em&gt; ), then annotates the new AST using types or different
settings provided by the user.&lt;/p&gt;
&lt;p&gt;In this talk, after a brief description of Pyccel, I will show different
applications including Finite Elements (1d, 2d, 3d), Semi-Lagrangian
schemes (4d), Kronecker linear solvers, diagnostics for 5D kinetic
simulations and Machine Learning for Partial Differential Equations.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dr. Ing. Ratnani Ahmed</dc:creator><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-10-24:pycon-de-2018/pyccel-a-fortran-static-compiler-for-scientific-high-performance-computing.html</guid><category>Artificial Intelligence</category><category>Algorithms</category><category>Astronomy</category><category>Parallel Programming</category><category>Programming</category><category>Python</category><category>Science</category></item><item><title>Theoretical physics with sympy</title><link>https://pyvideo.org/pycon-de-2017/theoretical-physics-with-sympy.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Florian Thöle&lt;/strong&gt; (&amp;#64;florian_thl)&lt;/p&gt;
&lt;p&gt;PhD student in Computational Materials Science. Enthusiastic about teaching. Instructor for Software Carpentry.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this talk, I will introduce the basics of sympy. Using a simple model system in magnetism, we'll play around with simplifications, then do a bit of numerical optimization and in the end make psychedelic-looking figures.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I will introduce the basic functionalities of the sympy package to do symbolic computing, with a special focus on vector and matrix operations. Then, I'll briefly explain a real-world model from the description of 2D layered magnetic materials and use sympy to deal with the resulting expressions. We'll evaluate those expressions to visualize the results of the model and obtain a numerical estimate of a transition point.&lt;/p&gt;
&lt;p&gt;The aim of this talk is to give a light-hearted introduction into the world of symbolic computing to someone who has more fun working with computers than pen and paper.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Florian Thole</dc:creator><pubDate>Wed, 25 Oct 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-10-25:pycon-de-2017/theoretical-physics-with-sympy.html</guid><category>physics</category><category>science</category><category>sympy</category></item><item><title>Dev Ops meets Data Science Taking models from prototype to production with Docker</title><link>https://pyvideo.org/pydata-dc-2016/dev-ops-meets-data-science-taking-models-from-prototype-to-production-with-docker.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;We present the evolution of a model to a production API that can scale to large e-commerce needs. On the journey we discuss metrics of success and how to use the Kubernetes cluster manager and associated tools for deploy. In addition to the use of these tools we highlight how to make use of the cluster management system for further testing and experimentation with your models.&lt;/p&gt;
&lt;p&gt;The chasm between data science and dev ops is often wide and impenetrable, but the two fields have more in common than meets the eye. Every data scientist will be able to lean in and help their career by investing in a basic understanding the basic principles of dev ops. In this talk I present the notions of service level indicators, objectives, and agreements. I cover the rigorous monitoring and testing of services. Finally we demonstrate how to build a basic data science workflow and push to production level APIs with Docker and Kubernetes.&lt;/p&gt;
&lt;p&gt;Kubernetes is an opinionated container cluster manager with an easy to use, robust interface. It can be use on very small and very large clusters. Docker is a container system that allows one to build code in an isolated environment. Paired with a container manager such as Kubernetes we are able to manage millions of instances as needed for a production deployment. These tools are two of many different options but are considered among the best open source solutions available.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andy Terrel</dc:creator><pubDate>Sun, 09 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-09:pydata-dc-2016/dev-ops-meets-data-science-taking-models-from-prototype-to-production-with-docker.html</guid><category>Data</category><category>data science</category><category>docker</category><category>models</category><category>science</category></item><item><title>Keynote: How Open Data Science Opens the World of Innovation</title><link>https://pyvideo.org/pydata-dc-2016/keynote-how-open-data-science-opens-the-world-of-innovation.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Innovation today appears to be instantaneous in large part due to open source technology. Open Data Science is no exception. Python, a pillar in the Open Data Science bedrock, is well positioned to harvest innovation in software and with Anaconda, it’s also well positioned to capitalize on the latest hardware innovations. Anaconda and Intel are blazing a path for the Python community to take advantage of cognitive computing, including machine learning and deep learning.&lt;/p&gt;
&lt;p&gt;In this keynote, Peter and Robert will talk about how Open Data Science––a connected ecosystem of data, analytics and compute––streamlines the path to high performance and innovation to achieve breakthrough results.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Robert Cohn</dc:creator><pubDate>Sat, 08 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-08:pydata-dc-2016/keynote-how-open-data-science-opens-the-world-of-innovation.html</guid><category>Data</category><category>data science</category><category>science</category></item><item><title>Scaling up to Big Data Devops for Data Science</title><link>https://pyvideo.org/pydata-dc-2016/scaling-up-to-big-data-devops-for-data-science.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Scaling up R/Python from a single machine to a cluster environment can be tricky. While there are many tools available that make the launching of a cluster relatively easy, they are not focused or optimized to the specific use case of analytics but mostly on operations. Come and learn about devops tips and tricks to optimize your transition into the big data world as a data scientist.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marck Vaisman</dc:creator><pubDate>Sat, 08 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-10-08:pydata-dc-2016/scaling-up-to-big-data-devops-for-data-science.html</guid><category>big data</category><category>Data</category><category>data science</category><category>devops</category><category>scaling</category><category>science</category></item><item><title>When Worlds Collide: Productionalizing a Data Science Model</title><link>https://pyvideo.org/pydata-chicago-2016/when-worlds-collide-productionalizing-a-data-science-model.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;On our first data science project at Shiftgig, the data science and engineering teams had to build software that was production-ready while maintaining the flexibility of a data science sandbox. Although these seem like irreconcilable goals, they forced us to improve inter-team communication and ultimately helped create a great product. We’ll walk through our process and the lessons we learned.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tudor Radoaca</dc:creator><pubDate>Sun, 28 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-28:pydata-chicago-2016/when-worlds-collide-productionalizing-a-data-science-model.html</guid><category>Data</category><category>data science</category><category>model</category><category>science</category></item><item><title>Keynote: Using Data Science for Social Good: Examples, Opportunities, and Challenges</title><link>https://pyvideo.org/pydata-chicago-2016/keynote-using-data-science-for-social-good-examples-opportunities-and-challenges.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Rayid Ghani</dc:creator><pubDate>Sat, 27 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-27:pydata-chicago-2016/keynote-using-data-science-for-social-good-examples-opportunities-and-challenges.html</guid><category>Data</category><category>data science</category><category>science</category></item><item><title>Workshop Panel with Guido van Rossum</title><link>https://pyvideo.org/pydata/workshop-panel-with-guido-van-rossum.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;In this presentation from the 2012 PyData Workshop hosted at Google on
March 2-3, Guido van Rossum, author of the Python programming language,
engages in an open discussion on the intersection of the evolution of
Python and the growth of the scientific community. Panelists include
Fernando Perez, Travis Oliphant, and David Cournapeau.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guido Van Rossum</dc:creator><pubDate>Fri, 02 Mar 2012 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2012-03-02:pydata/workshop-panel-with-guido-van-rossum.html</guid><category>science</category><category>scientific</category></item><item><title>High-performance computing on gamer PCs</title><link>https://pyvideo.org/europython-2011/high-performance-computing-on-gamer-pcs.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Yann Le Du - 20 June 2011 in &amp;quot;Track Lasagne&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In Electron Paramagnetic Resonance Imaging, we are faced with a
deconvolution problem that has a strong impact on the image actually
reconstructed. Faced with the need of mapping the distribution of
organic matter in Terrestrial and Martian rock samples for applications
in exobiology, we needed to see how to extract a maximum amount of
information from our data: our approach uses reservoir computing
artificial neural networks coupled to a particle swarm algorithm that
evolves the reservoirs’ weights.&lt;/p&gt;
&lt;p&gt;The code runs on the Hybrid Processing Units for Science (HPU4Science)
cluster located at the Laboratoire de Chimie de la Matière Condensée de
Paris (LCMCP). The cluster is composed of a central data storage machine
and a heterogeneous ensemble of 6 decentralized nodes. Each node is
equipped with a Core2 Quad or i7 CPU and 3-7 NVIDIA Graphical Processing
Units (GPUs) including the GF110 series. Each of the 28 GPUs
independently explores a different parameter space sphere of the same
problem. Our application shows a sustained real performance of 15.6
TFLOPS. The HPU4Science cluster cost
&lt;span class="formula"&gt;36, 090&lt;i&gt;resulting&lt;/i&gt;&lt;i&gt;in&lt;/i&gt;&lt;i&gt;a&lt;/i&gt;432.3&lt;i&gt;MFLOPS&lt;/i&gt; ⁄ &lt;/span&gt; cost performance.&lt;/p&gt;
&lt;p&gt;That talk is meant to demonstrate on a practical case how consumer grade
computer hardware coupled to a very popular computer language can be
used to tackle a difficult yet very elementary scientific problem: how
do you go from formulating the problem, to choosing the right hardware
and software, and all the way to programming the algorithms using the
appropriate development tools and methodologies (notably Literate
Programming). On the math side, the talk requires a basic understanding
of matrix algebra and of the discretization process involved when
computing integrals.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yann Le Du</dc:creator><pubDate>Thu, 21 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-21:europython-2011/high-performance-computing-on-gamer-pcs.html</guid><category>image</category><category>mapping</category><category>nvidia</category><category>performance</category><category>processing</category><category>science</category><category>scientific</category></item><item><title>MiG - A Complete Grid Middleware (mostly) in Python</title><link>https://pyvideo.org/europython-2011/mig-a-complete-grid-middleware-mostly-in-pyth.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Jonas Bardino - 22 June 2011 in &amp;quot;Track Tagliatelle &amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Grid computing was all the buzz in the beginning of the millennium and
still has serious attention in different forms although many of the
original grand promises were never delivered. The general level of
ambitions have instead slowly but steadily degraded to those of the
latest buzz word, Cloud.&lt;/p&gt;
&lt;p&gt;We as a project have proven that most of the original promises &lt;em&gt;can&lt;/em&gt;
actually be delivered and we have done so using Python almost solely as
the implementation language. The choice of Python provided us with a
stable and versatile base for quickly getting this far and it
significantly eases extending and maintaining our middleware in the
future. MiG is currently about 50000 lines of source code but it still
offers more features than competing grid systems with millions of lines
of code.&lt;/p&gt;
&lt;p&gt;Apart from introducing the open source MiG middleware and summarizing
how we got here, this talk will outline some of the core technologies
used to reach that goal and underline why it can make a lot of sense to
choose Python for complex HPC projects like MiG, too. Talk keywords
include Network Programming, Open Source Python projects, Science and
Math and Web-based Systems. There's no special intended audience, but a
certain level of Python knowledge and experience may be an advantage.
Please refer to &lt;a class="reference external" href="http://code.google.com/p/migrid/"&gt;http://code.google.com/p/migrid/&lt;/a&gt; for further MiG
information.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jonas Bardino</dc:creator><pubDate>Thu, 21 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-21:europython-2011/mig-a-complete-grid-middleware-mostly-in-pyth.html</guid><category>forms</category><category>hpc</category><category>network</category><category>science</category></item><item><title>Source code processing with Python</title><link>https://pyvideo.org/europython-2011/source-code-processing-with-python.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Kay Schluehr - 24 June 2011 in &amp;quot;Track Lasagne&amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Folklore says that having a problem and trying to solve it with regular
expressions gives you two problems. However not applying regular
expressions to advanced textual search'n replace doesn't solve your
problem either. One step above you have large portions of recursively
structured text aka &amp;quot;source code&amp;quot; and using context free grammars and
tools supporting them gives you two problems but not using them also
doesn't solve your original problem. Maybe you get uneasy at that point
because what I say implies parsers and computing science and what not
and you still wake up in the night believing that you have to learn
automata theory but you are lucky it was just a nightmare. Otherwise you
are laughing about the little diatribe against regexps and use them
without much deliberation, verifying your SQL input, mining source code
and do all the other things they are not made for.&lt;/p&gt;
&lt;p&gt;In my talk I'm addressing daily use of grammars outside of the scope of
compiler implementation or natural language processing. My talk covers:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Search &amp;amp; Replace using grammars&lt;/li&gt;
&lt;li&gt;CodeTemplates for source code transformation&lt;/li&gt;
&lt;li&gt;Generative grammars for expression generation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'm touching this from the lightweight, &amp;quot;pythonic&amp;quot; angle and you might
wonder why not everyone uses those techniques already for decades in
their daily work. I can't answer this, I wonder about this too.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kay Schluehr</dc:creator><pubDate>Wed, 13 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-13:europython-2011/source-code-processing-with-python.html</guid><category>processing</category><category>science</category></item><item><title>Advanced Pickling with Stackless Python and sPickle</title><link>https://pyvideo.org/europython-2011/advanced-pickling-with-stackless-python-and-spick.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;[EuroPython 2011] Anselm Kruis - 24 June 2011 in &amp;quot;Track Tagliatelle &amp;quot;&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Stackless Python supports pickling of a wider range of types than
conventional C-Python, including stack frames and code objects. On this
basis it is possible to extend further the pickle.Pickler class in order
to serialise classes, modules, packages up to certain limits. The
&lt;a class="reference external" href="http://pypi.python.org/pypi/sPickle"&gt;sPickle package&lt;/a&gt; provides such
an extended Pickler. The code was developed as part of a commercial
project and recently released as free software by science + computing
ag. Currently it requires Stackless Python 2.7.&lt;/p&gt;
&lt;p&gt;In my presentation, I'll first demonstrate some applications of the
sPickle package including serialisation of modules and executing parts
of a program on a remote computer using RPyC and Paramiko.&lt;/p&gt;
&lt;p&gt;In the second part of my speech, I'll give some insight in the internal
operations of sPickle and the lessons learned during its development.
Extending the Pickler showed to be like opening a can of worms. You have
take care of many odds and ends to get it right. I'll point out some
weak points in the implementation of the conventional pickling code and
I'll also show the limits of the current sPickle implementation.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Anselm Kruis</dc:creator><pubDate>Thu, 07 Jul 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-07-07:europython-2011/advanced-pickling-with-stackless-python-and-spick.html</guid><category>packages</category><category>pickling</category><category>science</category><category>stackless</category></item><item><title>PyConAU 2010: Using Python in a scientific real-time data collection network</title><link>https://pyvideo.org/pycon-au-2010/pyconau-2010--using-python-in-a-scientific-real-t.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Using Python in a scientific real-time data collection network&lt;/p&gt;
&lt;p&gt;Presented by Dr. Paul Dyson (Bureau of Meteorology)&lt;/p&gt;
&lt;p&gt;Python is being increasingly used within the Solar and Terrestrial
Radiation Network at the Bureau of Meteorology. This Network consists of
ten ground stations across Australasia that track the sun, measuring the
irradiance of the sun and sky. This talk will outline the work of the
Network, the changes resulting from the introduction of Python in 2005,
and advantages and some difficulties of using Python.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dr. Paul Dyson</dc:creator><pubDate>Sat, 26 Jun 2010 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2010-06-26:pycon-au-2010/pyconau-2010--using-python-in-a-scientific-real-t.html</guid><category>casestudy</category><category>pyconau</category><category>pyconau2010</category><category>science</category></item><item><title>Teaching Python to the young and impressionable</title><link>https://pyvideo.org/pycon-au-2011/teaching-python-to-the-young-and-impressionable.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;We present two outreach programmes run by Sydney University for high
school students: the National Computer Science School
(&lt;a class="reference external" href="http://www.ncss.edu.au"&gt;http://www.ncss.edu.au&lt;/a&gt;) and the Girls' Programming Network
(&lt;a class="reference external" href="http://sydney.edu.au/it/gpn"&gt;http://sydney.edu.au/it/gpn&lt;/a&gt;). For the past four years we have been
teaching Python to students in grades 9-12, and based on this experience
we will discuss why Python is a good first language and the parts of it
which are still difficult for students to grasp.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Georgina Wilcox</dc:creator><pubDate>Mon, 22 Aug 2011 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2011-08-22:pycon-au-2011/teaching-python-to-the-young-and-impressionable.html</guid><category>network</category><category>outreach</category><category>science</category><category>teaching</category></item><item><title>What's New in Python for Science and Engineering</title><link>https://pyvideo.org/pycon-au-2012/whats-new-in-python-for-science-and-engineering.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;This is a tutorial about using Python for scientific and engineering
purposes, focusing on the latest and best tools available in 2012. It
will walk you through exploring a variety of interesting domains and
problems using the latest&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This is a presentation about the latest and most exciting tools in
Python for scientific and engineering applications in 2012. It will walk
you through what's now possible with tools like the IPython Notebook,
the Pandas toolkit for data analysis, and IPython integration with
SymPy, R, and Cython. It will then give you an update on the status of
Python 3 ports of major packages. It will show why Python is an
outstanding tool for science and engineering work, and getting better.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Edward Schofield</dc:creator><pubDate>Tue, 21 Aug 2012 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2012-08-21:pycon-au-2012/whats-new-in-python-for-science-and-engineering.html</guid><category>science</category></item></channel></rss>