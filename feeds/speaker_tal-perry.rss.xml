<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 30 Jun 2017 00:00:00 +0000</lastBuildDate><item><title>Lightning Talks - Part 1</title><link>https://pyvideo.org/pydata-meetups/lightning-talks-part-1.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="7%" /&gt;
&lt;col width="27%" /&gt;
&lt;col width="66%" /&gt;
&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;00:00&lt;/td&gt;
&lt;td&gt;Uri Goren&lt;/td&gt;
&lt;td&gt;Basic Bayesian statistics for churn analysis&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;08:49&lt;/td&gt;
&lt;td&gt;Ohad Zadok&lt;/td&gt;
&lt;td&gt;Visualization of Neural networks&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;14:56&lt;/td&gt;
&lt;td&gt;Tal perry&lt;/td&gt;
&lt;td&gt;Recurrent neural networks in 10 minutes or less&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;26:00&lt;/td&gt;
&lt;td&gt;Nathaniel Shimoni&lt;/td&gt;
&lt;td&gt;Model validation methods (Kaggle)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;35:20&lt;/td&gt;
&lt;td&gt;Raphael Cohen&lt;/td&gt;
&lt;td&gt;Wow, that's awesome! Detecting emotion in call&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Uri Goren</dc:creator><pubDate>Thu, 16 Feb 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-02-16:pydata-meetups/lightning-talks-part-1.html</guid><category>lightning talks</category></item><item><title>A word is worth a thousand pictures: Convolutional methods for text</title><link>https://pyvideo.org/pydata-berlin-2017/a-word-is-worth-a-thousand-pictures-convolutional-methods-for-text.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Link to slides: &lt;a class="reference external" href="https://www.slideshare.net/secret/2a5Xz9Sgc3D5GU"&gt;https://www.slideshare.net/secret/2a5Xz9Sgc3D5GU&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Description
Those folks in computer vision keep publishing amazing ideas about you to apply convolutions to images. What about those of us who work with text? Can't we enjoy convolutions as well? In this talk I'll review some convolutional architectures that worked great for images and were adapted to text and confront the hardest parts of getting them to work in Tensorflow .&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The go to architecture for deep learning on sequences such as text is the RNN and particularly LSTM variants. While remarkably effective, RNNs are painfully slow due their sequential nature. Convolutions allow us to process a whole sequence in parallel greatly reducing the time required to train and infer. One of the most important advances in convolutional architectures has been the use of gating to concur the vanishing gradient problem thus allowing arbitrarily deep networks to be trained efficiently.&lt;/p&gt;
&lt;p&gt;In this talk we'll review the key innovations in the DenseNet architecture and show how to adapt it to text. We'll go over &amp;quot;deconvolution&amp;quot; operators and dilated convolutions as means of handling long range dependencies. Finally we'll look at convolutions applied to [translation] (&lt;a class="reference external" href="https://arxiv.org/abs/1610.10099"&gt;https://arxiv.org/abs/1610.10099&lt;/a&gt;) at the character level.&lt;/p&gt;
&lt;p&gt;The goal of this talk is to demonstrate the practical advantages and relative ease with which these methods can be applied, as such we will focus on the ideas and implementations (in tensorflow) more than on the math.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tal Perry</dc:creator><pubDate>Fri, 30 Jun 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-06-30:pydata-berlin-2017/a-word-is-worth-a-thousand-pictures-convolutional-methods-for-text.html</guid></item></channel></rss>