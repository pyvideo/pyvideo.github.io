<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_dean-langsam.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-12-12T00:00:00+00:00</updated><entry><title>Disease Modeling with Scipy and PyMC</title><link href="https://pyvideo.org/pydata-warsaw-2019/disease-modeling-with-scipy-and-pymc.html" rel="alternate"></link><published>2019-12-12T00:00:00+00:00</published><updated>2019-12-12T00:00:00+00:00</updated><author><name>Dean Langsam</name></author><id>tag:pyvideo.org,2019-12-12:pydata-warsaw-2019/disease-modeling-with-scipy-and-pymc.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Programs which aim eradicate disease must rely on interpretable models.
These models quickly become hard to solve, not to mention train on
missing parameters. Scipy and PyMC come to our rescue for the heavy
lifting.&lt;/p&gt;
&lt;p&gt;In 2018, Israel has seen the biggest outbreak of measles since the
introduction of a vaccine in the late 1960s. Nowadays, vaccine policies
are not only decided by laboratory tests. Those tests are complemented
by a plethora of computational epidemiology simulations predicting the
effects of various vaccination policies on the entire population. A
population-level policy to eradicate disease must rely on Interpretable
models. These models quickly become hard to solve, not to mention train
on missing parameters. Using Scipy as a solver, and PyMC for Bayesian
inference we are able to learn parameter distributions for missing
natural parameters, such as the disease's &amp;quot;strength&amp;quot; or
&amp;quot;infectiousness&amp;quot;. We can then use the underlying distributions for these
parameters in order to simulate possible outcomes for future policies.&lt;/p&gt;
</summary></entry><entry><title>Disease Modeling with Scipy and PyMC - Dean Langsam - PyCon Israel 2019</title><link href="https://pyvideo.org/pycon-israel-2019/disease-modeling-with-scipy-and-pymc-dean-langsam-pycon-israel-2019.html" rel="alternate"></link><published>2019-06-04T00:00:00+00:00</published><updated>2019-06-04T00:00:00+00:00</updated><author><name>Dean Langsam</name></author><id>tag:pyvideo.org,2019-06-04:pycon-israel-2019/disease-modeling-with-scipy-and-pymc-dean-langsam-pycon-israel-2019.html</id><summary type="html"></summary></entry><entry><title>Anomaly Detection using Neural Networks</title><link href="https://pyvideo.org/pycon-israel-2018/anomaly-detection-using-neural-networks.html" rel="alternate"></link><published>2018-06-05T00:00:00+00:00</published><updated>2018-06-05T00:00:00+00:00</updated><author><name>Dean Langsam</name></author><id>tag:pyvideo.org,2018-06-05:pycon-israel-2018/anomaly-detection-using-neural-networks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;BlueVine is a leading provider of funding for small and medium sized businesses with a primary focus on speed, simplicity and transparency. Models that make decisions in real-time are a critical part of that effort and must be strictly monitored. Consequently, it is the responsibility of every data scientist at BlueVine to both develop and maintain a high level of performance for every model they own. Maintaining code is a hard task in itself and it is discussed a lot among software developers: code needs to run without errors, and more importantly - must run as expected. In data science, the notion of whatâ€™s expected becomes quite complex and sometimes not well-defined, due to the statistical nature of the problems. Without anomaly detection, it is possible for critical decisions to be made based on unexpected changes in the data or simply incorrect calculations. Therefore, it is critical to be able to detect such anomalies quickly while getting a concise message as to what is their nature. This quickly becomes a challenging task when keeping the human factor in mind - too many false positive may cause the user to become alert prone, thus rendering them useless, while a low detection rate may affect the integrity of our data. We leverage our historical data and some of the most advanced techniques in the field to classify anomalies against normal behaviour. We use Keras to train a neural network that predicts expected values in a time series using a series of previous timestamps. We also add auxiliary information for a rich multi-input prediction. If there were clear labels for anomalous data, a classifier could then be employed. This is not our case, and we need to find another strategy. We start with a trivial approach, comparing the difference between the prediction and the actual values. This method proved problematic as they would yield too many false positives and as robust thresholds would be hard to set manually for hundreds of time series. Therefore we used other methods for detection such as accumulating repeating anomalies that indicate continuous bursts and bayesian inference to detect shift in value distributions. Detecting changes in the behaviour of our data lets us quickly adapt and react. We can fix errors, change our ETL methods or retrain our models in a proactive manner.&lt;/p&gt;
</summary></entry></feed>