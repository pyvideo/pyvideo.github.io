<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Enzo Ferrante</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_enzo-ferrante.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2022-07-11T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Keynote: Fairness of Machine Learning in Medical Image Analysis</title><link href="https://pyvideo.org/scipy-2022/keynote-fairness-of-machine-learning-in-medical-image-analysis.html" rel="alternate"></link><published>2022-07-11T00:00:00+00:00</published><updated>2022-07-11T00:00:00+00:00</updated><author><name>Enzo Ferrante</name></author><id>tag:pyvideo.org,2022-07-11:/scipy-2022/keynote-fairness-of-machine-learning-in-medical-image-analysis.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Medical institutions around the world are adopting machine learning (ML) systems to assist in analyzing health data; at the same time, the research community of fairness in ML has shown that these systems can be biased, resulting in disparate performance for specific subpopulations. In this talk, we will discuss â€¦&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Medical institutions around the world are adopting machine learning (ML) systems to assist in analyzing health data; at the same time, the research community of fairness in ML has shown that these systems can be biased, resulting in disparate performance for specific subpopulations. In this talk, we will discuss the relationship between bias, ML and health systems, addressing the specific case of gender bias in X-ray classifiers for computer-assisted diagnosis.&lt;/p&gt;
</content><category term="SciPy 2022"></category><category term="Keynote"></category></entry></feed>