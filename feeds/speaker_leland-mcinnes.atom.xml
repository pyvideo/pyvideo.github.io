<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_leland-mcinnes.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-12-04T00:00:00+00:00</updated><entry><title>Learning Topology: Topological Techniques for Unsupervised Learning</title><link href="https://pyvideo.org/pydata-la-2019/learning-topology-topological-techniques-for-unsupervised-learning.html" rel="alternate"></link><published>2019-12-04T00:00:00+00:00</published><updated>2019-12-04T00:00:00+00:00</updated><author><name>Leland McInnes</name></author><id>tag:pyvideo.org,2019-12-04:pydata-la-2019/learning-topology-topological-techniques-for-unsupervised-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Many topics in unsupervised learning can be viewed as dealing with the
relative geometry of data. In mathematics, topology and homotopy theory
are the fields that deal with similar kinds of questions. Using ideas,
techniques, and language from topology can prove fruitful for
unsupervised learning. This talk will introduce you to the ideas and
intuitions for this, and provide meaningful examples.&lt;/p&gt;
&lt;p&gt;Many topics in unsupervised learning can be viewed as dealing with the
relative geometry of data. In mathematics, topology and homotopy theory
are the fields that deal with similar kinds of questions. Using ideas,
techniques, and language from topology can prove fruitful for
unsupervised learning. This talk will look at how topological approaches
can be brought to bear upon unsupervised learning problems as diverse as
dimension reduction, clustering, anomaly detection, word embedding, and
metric learning. Through the lens and language of topology and category
theory we can draw common threads through all these topics, pointing the
way toward new approaches to these problems. By focusing on broad ideas
and intuitions, and working with example uses, you don't need a
background in topology to understand the approach. I hope to convince
you that topological approaches offer a rich and growing field of
research for unsupervised learning.&lt;/p&gt;
</summary></entry><entry><title>A Bluffer's Guide to Dimension Reduction</title><link href="https://pyvideo.org/pydata-new-york-city-2018/a-bluffers-guide-to-dimension-reduction.html" rel="alternate"></link><published>2018-08-17T00:00:00+00:00</published><updated>2018-08-17T00:00:00+00:00</updated><author><name>Leland McInnes</name></author><id>tag:pyvideo.org,2018-08-17:pydata-new-york-city-2018/a-bluffers-guide-to-dimension-reduction.html</id><summary type="html"></summary></entry><entry><title>UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction</title><link href="https://pyvideo.org/scipy-2018/umap-uniform-manifold-approximation-and-projection-for-dimension-reduction.html" rel="alternate"></link><published>2018-07-12T00:00:00+00:00</published><updated>2018-07-12T00:00:00+00:00</updated><author><name>Leland McInnes</name></author><id>tag:pyvideo.org,2018-07-12:scipy-2018/umap-uniform-manifold-approximation-and-projection-for-dimension-reduction.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will present a new approach to dimension reduction called
UMAP. UMAP is grounded in manifold learning and topology, making an
effort to preserve the topological structure of the data. The resulting
algorithm can provide both 2D visualisations of data of comparable
quality to t-SNE, and general purpose dimension reduction. UMAP has been
implemented as a (scikit-learn compatible) python library that can
perform efficient dimension reduction, scaling out to much larger
datasets than t-SNE or other comparable algorithms (see
&lt;a class="reference external" href="http://github.com/lmcinnes/umap).Presenter(s"&gt;http://github.com/lmcinnes/umap).Presenter(s&lt;/a&gt;): Speaker: Leland McInnes,
Tutte Institute for Mathematics and Computing&lt;/p&gt;
</summary></entry><entry><title>Clustering: A Guide for the Perplexed</title><link href="https://pyvideo.org/pydata-dc-2016/clustering-a-guide-for-the-perplexed.html" rel="alternate"></link><published>2016-10-08T00:00:00+00:00</published><updated>2016-10-08T00:00:00+00:00</updated><author><name>Leland McInnes</name></author><id>tag:pyvideo.org,2016-10-08:pydata-dc-2016/clustering-a-guide-for-the-perplexed.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Finding clusters is a powerful tool for understanding and exploring data. While the task sounds easy, it can be surprisingly difficult to do it well. Most standard clustering algorithms can, and do, provide very poor clustering results in many cases. We discuss how to do clustering correctly.&lt;/p&gt;
&lt;p&gt;Finding clusters is a powerful tool for understanding and exploring data. While the task sounds easy, it can be surprisingly difficult to it well. Most standard clustering algorithms can, and do, provide very poor clustering results in many cases. Our intuitions for what a cluster is are not as clear as we would like, and can easily be lead astray. We will attempt to find a definition of clustering that makes sense for most cases, and introduce an algorithm for finding such clusters, along with a high performance python implementation of the algorithm, building up more intuition for what clustering really means as we go.&lt;/p&gt;
</summary></entry><entry><title>High Quality, High Performance Clustering with HDBSCAN</title><link href="https://pyvideo.org/scipy-2016/high-quality-high-performance-clustering-with-hdbscan-scipy-2016-leland-mcinnes.html" rel="alternate"></link><published>2016-07-14T00:00:00+00:00</published><updated>2016-07-14T00:00:00+00:00</updated><author><name>Leland McInnes</name></author><id>tag:pyvideo.org,2016-07-14:scipy-2016/high-quality-high-performance-clustering-with-hdbscan-scipy-2016-leland-mcinnes.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Data clustering is a powerful tool for data analysis. It can be particularly useful in exploratory data analysis for helping to summarize and give intuition about a dataset. Despite it's power clustering is used for this task far less frequently than it could be. A plethora of options for clustering algorithms exist, and we will provide a survey of some of the more popular options, discussing their strengths and weaknesses, particularly with regard to exploratory data analysis. Our focus, however, is on a relatively new algorithm that appears to be the best equipped to meet the needs of exploratory data analysis: HDBSCAN* has the strengths of density based algorithms, has a small robust set of parameters, and with suitable implementation can be made highly scalable to large datasets. We will discuss how the algorithm works, taking a few different perspectives, and explain the techniques used for a high performance implementation. Finally we'll discuss ways to extend the algorithm, drawing on ideas from topological data analysis.&lt;/p&gt;
</summary><category term="SciPy 2016"></category></entry></feed>