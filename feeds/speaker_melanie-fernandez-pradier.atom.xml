<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Melanie Fernandez Pradier</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_melanie-fernandez-pradier.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-08-03T00:00:00+00:00</updated><subtitle></subtitle><entry><title>PoRB-Nets: Poisson Process Radial Basis Function Networks</title><link href="https://pyvideo.org/uai-2020/porb-nets-poisson-process-radial-basis-function-networks.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Beau Coker</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/porb-nets-poisson-process-radial-basis-function-networks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;PoRB-Nets: Poisson Process Radial Basis Function Networks&lt;/p&gt;
&lt;p&gt;Beau Coker (Harvard University)*; Melanie Fernandez Pradier (Harvard University)&lt;/p&gt;
&lt;p&gt;Bayesian neural networks (BNNs) are flexible function priors well-suited to situations in which data are scarce and uncertainty must be quantified. Yet, common weight priors are able to encode little functional knowledge and â€¦&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;PoRB-Nets: Poisson Process Radial Basis Function Networks&lt;/p&gt;
&lt;p&gt;Beau Coker (Harvard University)*; Melanie Fernandez Pradier (Harvard University)&lt;/p&gt;
&lt;p&gt;Bayesian neural networks (BNNs) are flexible function priors well-suited to situations in which data are scarce and uncertainty must be quantified. Yet, common weight priors are able to encode little functional knowledge and can behave in undesirable ways. We present a novel prior over radial basis function networks (RBFNs) that allows for independent specification of functional amplitude variance and lengthscale (i.e., smoothness), where the inverse lengthscale corresponds to the concentration of radial basis functions. When the lengthscale is uniform over the input space, we prove consistency and approximate variance stationarity. This is in contrast to common BNN priors, which are highly nonstationary. When the input dependence of the lengthscale is unknown, we show how it can be inferred. We compare this model's behavior to standard BNNs and Gaussian processes using synthetic and real examples.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry></feed>