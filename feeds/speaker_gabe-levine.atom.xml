<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_gabe-levine.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-10-04T00:00:00+00:00</updated><entry><title>You Don't Need Neural Nets - How Simpler Algorithms Can Solve Your Problems With Less Headache</title><link href="https://pyvideo.org/pygotham-2019/you-dont-need-neural-nets-how-simpler-algorithms-can-solve-your-problems-with-less-headache.html" rel="alternate"></link><published>2019-10-04T00:00:00+00:00</published><updated>2019-10-04T00:00:00+00:00</updated><author><name>Gabe Levine</name></author><id>tag:pyvideo.org,2019-10-04:pygotham-2019/you-dont-need-neural-nets-how-simpler-algorithms-can-solve-your-problems-with-less-headache.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;You’ve heard a lot about Neural Networks (or “A.I.” as your company’s
marketing team likes to call it), and how they are solution to all of your
problems. Unfortunately, they’re also finicky and complex. And for most
problems that most people deal with, they’re not necessarily much better
than easier-to-use algorithms such as Gradient Boosted Trees (GBTs). We will
explain (briefly) what GBTs are, compare neural networks vs. GBTs on some
benchmark problems, demonstrate where Neural Nets are necessary
(images/sound/text), and share some tips for making GBTs working even on
those cases.&lt;/p&gt;
&lt;p&gt;This talk is meant for people with a cursory knowledge of machine learning,
but who aren’t necessarily experts.&lt;/p&gt;
</summary></entry><entry><title>Machine Music: Exploring Machine Learning By Generating Music Or How To Teach A Computer To Rock Out</title><link href="https://pyvideo.org/pygotham-2017/machine-music-exploring-machine-learning-by-generating-music-or-how-to-teach-a-computer-to-rock-out.html" rel="alternate"></link><published>2017-10-07T00:00:00+00:00</published><updated>2017-10-07T00:00:00+00:00</updated><author><name>Gabe Levine</name></author><id>tag:pyvideo.org,2017-10-07:pygotham-2017/machine-music-exploring-machine-learning-by-generating-music-or-how-to-teach-a-computer-to-rock-out.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will go through the ups and downs of a machine learning    beginner trying to create a Recurrent Neural Network (RNN) to implement    a music generating algorithm. We will build off of Gabe’s PyGotham 2016    talk (The Sounds Of Data: &lt;a class="reference external" href="https://www.youtube.com/watch?v=vb9c_WFMYeI"&gt;https://www.youtube.com/watch?v=vb9c_WFMYeI&lt;/a&gt;)    and will attempt to implement an RNN based on Alex Graves’ GeneratingSequences With Recurrent Neural Networks    (&lt;a class="reference external" href="https://arxiv.org/pdf/1308.0850.pdf"&gt;https://arxiv.org/pdf/1308.0850.pdf&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Gabe Levine is a &lt;a class="reference external" href="http://pitchfork.com/reviews/albums/12049-migration/"&gt;musician&lt;/a&gt;    turned &lt;a class="reference external" href="https://github.com/gabelev"&gt;software engineer&lt;/a&gt;, and Jonathan Arfa is a &lt;a class="reference external" href="https://github.com/jarfa"&gt;Statistics and     Machine Learning enthusiast&lt;/a&gt;&lt;/p&gt;
</summary></entry></feed>