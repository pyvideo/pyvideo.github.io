<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 08 Apr 2017 00:00:00 +0000</lastBuildDate><item><title>Diagnosing Machine Learning Models</title><link>https://pyvideo.org/pydata-amsterdam-2017/diagnosing-machine-learning-models.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2017&lt;/p&gt;
&lt;p&gt;A Machine Learning Models is never perfect. If it completely fails, it must be fixed, if it performs well, we want to improve it.
In this talk, several techniques to diagnose the source of errors a model makes will be presented.&lt;/p&gt;
&lt;p&gt;Your model performs worse than a random model. What do you do? Your model has 99.9% ROC AUC, should you just celebrate? Every time you add a new feature the interpretation of the model's parameters changes completely. What 's wrong? Your model has 75% ROC AUC. Should you add more data? More features? Use a more complex model? You are out of new features, no matter what you do, the model performance is the same? What is happening?&lt;/p&gt;
&lt;p&gt;Many of these questions appear once and again when working with Machine Learning,, answering them takes time and has a huge impact on the final outcome of a Machine Learning project. Understanding the current condition of a model is the key to decide what to do next.&lt;/p&gt;
&lt;p&gt;In this talk I will describe several techniques to diagnose algorithms and models, some of them are: Bias and Variance Decomposition Calibration Curves Response Distribution Chart Residual Plots etc.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lucas Javier Bernardi</dc:creator><pubDate>Sat, 08 Apr 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-04-08:pydata-amsterdam-2017/diagnosing-machine-learning-models.html</guid></item></channel></rss>