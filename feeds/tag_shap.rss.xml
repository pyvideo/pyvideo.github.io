<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Thu, 31 Oct 2019 00:00:00 +0000</lastBuildDate><item><title>Making sense of ML Black Box: Interpreting ML Models Using SHAP</title><link>https://pyvideo.org/pycon-se-2019/making-sense-of-ml-black-box-interpreting-ml-models-using-shap.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Extracting insights from a complex machine learning model is not easy hence for many people machine learning models are in a sense black box. This is a problem especially in high stake sectors like banking and healthcare. In this talk we will discuss how we can increase transparency, auditability, and stability of the model using valuable insights we can get from SHAP and explain reasoning behind individual predictions and how this can be aggregated into powerful model-level insights. We will also see the code to calculate SHAP values.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ravi Singh</dc:creator><pubDate>Thu, 31 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-31:pycon-se-2019/making-sense-of-ml-black-box-interpreting-ml-models-using-shap.html</guid><category>machine learning</category><category>SHAP</category></item></channel></rss>