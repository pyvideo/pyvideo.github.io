<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Dana Racah</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_dana-racah.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2022-06-03T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Can Unsupevised ML Be Overfitted?</title><link href="https://pyvideo.org/pycon-italia-2022/can-unsupevised-ml-be-overfitted.html" rel="alternate"></link><published>2022-06-03T00:00:00+00:00</published><updated>2022-06-03T00:00:00+00:00</updated><author><name>Dana Racah</name></author><id>tag:pyvideo.org,2022-06-03:/pycon-italia-2022/can-unsupevised-ml-be-overfitted.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Can Unsupevised ML Be Overfitted? - PyCon Italia 2022&lt;/p&gt;
&lt;p&gt;Overfitting is a widely discussed pitfall in ML. In ML 101 class, we are
taught how to identify and mitigate it in a Supervised ML setting. But
wait, how about the Unsupervised setting? Can we overfit there as well?
In my …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Can Unsupevised ML Be Overfitted? - PyCon Italia 2022&lt;/p&gt;
&lt;p&gt;Overfitting is a widely discussed pitfall in ML. In ML 101 class, we are
taught how to identify and mitigate it in a Supervised ML setting. But
wait, how about the Unsupervised setting? Can we overfit there as well?
In my talk, I will show that we sure can, and we will discuss what to do
about it. Throughout my career as a data scientist, I had the
opportunity to work on many diverse Machine Learning (ML) projects. Some
of my favourite projects deal with an unsupervised learning setting. At
first glance, an unsupervised model may seem simpler to execute, and
with less potential for pitfalls along the way. For example, it does not
require to split the data into training, test and validation datasets,
and on the face of it, there is no risk of overfitting: we just run our
ML model on the dataset, and voila!&lt;/p&gt;
&lt;p&gt;Subsequently however, from my experience, when the model is deployed to
production, we often measure poor performance. How can this be? In this
talk, I will present how, if we are not careful enough, unsupervised ML
models can be overfitted. I will demonstrate overfitting on a clustering
problem, by simulating a clustering model selection. We will run several
clustering models on the learning set and select the best model. Then,
we will see that it may be overfitted. But don’t worry! We will also
discuss some ways to mitigate the overfitting peril in an unsupervised
setting. I will provide a toolset to help you identify and avoid this
situation, and will show how each mitigation impacts our simulation
results.&lt;/p&gt;
&lt;p&gt;Speaker: Dana Racah&lt;/p&gt;
</content><category term="PyCon Italia 2022"></category><category term="machine learning"></category></entry></feed>