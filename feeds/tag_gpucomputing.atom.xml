<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_gpucomputing.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-12-07T00:00:00+00:00</updated><entry><title>Speeding up Machine Learning tasks using GPUs in Python</title><link href="https://pyvideo.org/pydata-austin-2019/speeding-up-machine-learning-tasks-using-gpus-in-python.html" rel="alternate"></link><published>2019-12-07T00:00:00+00:00</published><updated>2019-12-07T00:00:00+00:00</updated><author><name>Saloni Jain</name></author><id>tag:pyvideo.org,2019-12-07:pydata-austin-2019/speeding-up-machine-learning-tasks-using-gpus-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;GPUs are typically used to accelerate deep learning models, but they haven't been widely deployed for traditional machine learning. This talk will cover cuML's GPU based implementation of Decision Trees and Random Forest algorithms, aimed to provide 10x-50x speedup and a new library called Forest Inference Library (FIL), which allows GPU accelerated inference of different pretrained forest models&lt;/p&gt;
</summary><category term="GPU"></category><category term="GPUComputing"></category><category term="machine learning"></category></entry><entry><title>Deep Learning for brain MRI segmentation: Big Data, AI and HPC meet together</title><link href="https://pyvideo.org/pycon-italia-2019/deep-learning-for-brain-mri-segmentation-big-data-ai-and-hpc-meet-together.html" rel="alternate"></link><published>2019-05-05T00:00:00+00:00</published><updated>2019-05-05T00:00:00+00:00</updated><author><name>Giuseppe Di Bernardo</name></author><id>tag:pyvideo.org,2019-05-05:pycon-italia-2019/deep-learning-for-brain-mri-segmentation-big-data-ai-and-hpc-meet-together.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;With ever-increasing advancements in technology, neuroscientists are
able to collect data in greater volumes and with finer resolution. There
has been a growing interest in leveraging this vast volume of data
across levels of analysis, measurement techniques, and experimental
paradigms to gain more insight into brain function. At multiple stages
and levels of neuroscience investigation, ML holds great promise as an
addition to the arsenal of analysis tools for discovering how the brain
works. As quantitative analysis of brain MRI is routine for many
neurological diseases and conditions, deep learning-based segmentation
approaches for brain Magnetic Resonance Imaging (MRI) are gaining
interest due to their self-learning and generalisation ability over
large amounts of data. On the other hand, High Performance Computing
(HPC) and AI will increasingly intertwine as we transition to an
exascale future using new computing, storage, and communications
technologies. In this talk I will walk you through fundamentals of
generating high- performance deep-learning models in TensorFlow platform
using Python on large computing system (e.g NVIDIA® Tesla® GPUs powered
by Tensor Cores), in order to infer and segment thousands of cell
centroids out of the brain objects of interest. From a more
technological perspective, although astonishing results have been
achieved concerning the distribution of training large convolutional
neural networks on big data, to date the Python scientific ecosystem is
still missing tools for an optimised and, above all, distributed
inference of deep learning models. In this talk I will show you how a
tiling-based inferencing approach could be a good solution to remedy the
problem. The talk is intended for intermediate PyData researchers and
practitioners. Basic to intermediate level experience in image
recognition/object detection deep learning applications is assumed.
Overall, a good proficiency with the Python language and with scientific
python libraries (e.g. numpy, TensorFlow, Keras) are required for the
entire talk.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1794"&gt;https://python.it/feedback-1794&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Sunday 5 May&lt;/strong&gt; at 11:00 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="GPUComputing"></category><category term="parallelization"></category><category term="bio-informatics"></category><category term="Machine Learning"></category><category term="ComputerVision"></category><category term="optimization"></category><category term="data-analysis"></category><category term="Artificial Intelligence"></category></entry><entry><title>GPU-accelerated data analysis in Python: a study case in Material Sciences</title><link href="https://pyvideo.org/pycon-italia-2018/gpu-accelerated-data-analysis-in-python-a-study-case-in-material-sciences.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Giuseppe Di Bernardo</name></author><id>tag:pyvideo.org,2018-04-21:pycon-italia-2018/gpu-accelerated-data-analysis-in-python-a-study-case-in-material-sciences.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Max Planck Computing and Data Facility is engaged in the development
and optimization of algorithms and applications for high performance
computing as well as for data-intensive projects. As programming
language in data science, Python is now used at MPCDF in the scientific
area of “atom probe crystallography” (APT): a Fourier analysis in 3D
space can be simulated in order to reveal composition and
crystallographic structure at the atomic scale of billions APT
experimental data sets.&lt;/p&gt;
&lt;p&gt;The Python data ecosystem has proved to be well suited to this, as it
has grown beyond the confines of single machines to embrace scalability.
The talk aims to describe our approach to scaling across multiple GPUs,
and the role of visualization methods too.&lt;/p&gt;
&lt;p&gt;Our data workflow analysis relies on the GPU-accelerated Python software
package PyNX, an open source library which provides fast parallel
computation scattering. The code takes advantage of the high throughput
of GPUs, using the pyCUDA library.&lt;/p&gt;
&lt;p&gt;Exploratory data analysis, high productivity and rapid prototyping with
high performance are enabled through Jupyter Notebooks and Python
packages e.g., pandas, matplotlib/plotly. In production stage,
interactive visualization is realized by using standard scientific tool,
e.g. Paraview, an open-source 3D visualization program which requires
Python modules to generate visualization components within VTK files.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 14:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="GPUComputing"></category><category term="visualization"></category><category term="mathematical-modelling"></category><category term="image-processing"></category><category term="bigdata"></category><category term="matplotlib"></category><category term="analytics"></category><category term="data-visualization"></category><category term="data-analysis"></category><category term="Data Mining"></category><category term="scientific-computing"></category><category term="physics"></category><category term="python3"></category></entry></feed>