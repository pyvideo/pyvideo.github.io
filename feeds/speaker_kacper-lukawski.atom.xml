<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Kacper Łukawski</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_kacper-lukawski.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2024-07-08T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Deconstructing the text embedding models</title><link href="https://pyvideo.org/europython-2024/deconstructing-the-text-embedding-models.html" rel="alternate"></link><published>2024-07-08T00:00:00+00:00</published><updated>2024-07-08T00:00:00+00:00</updated><author><name>Kacper Łukawski</name></author><id>tag:pyvideo.org,2024-07-08:/europython-2024/deconstructing-the-text-embedding-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[EuroPython 2024 — North Hall on 2024-07-10]&lt;/p&gt;
&lt;p&gt;Deconstructing the text embedding models by Kacper Łukawski&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://ep2024.europython.eu/session/deconstructing-the-text-embedding-models"&gt;https://ep2024.europython.eu/session/deconstructing-the-text-embedding-models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Selecting the optimal text embedding model is often guided by benchmarks such as the Massive Text Embedding Benchmark (MTEB). While choosing the best model from the leaderboard is a …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[EuroPython 2024 — North Hall on 2024-07-10]&lt;/p&gt;
&lt;p&gt;Deconstructing the text embedding models by Kacper Łukawski&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://ep2024.europython.eu/session/deconstructing-the-text-embedding-models"&gt;https://ep2024.europython.eu/session/deconstructing-the-text-embedding-models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Selecting the optimal text embedding model is often guided by benchmarks such as the Massive Text Embedding Benchmark (MTEB). While choosing the best model from the leaderboard is a common practice, it may not always align perfectly with the unique characteristics of your specific dataset. This approach overlooks a crucial yet frequently underestimated element - the tokenizer.&lt;/p&gt;
&lt;p&gt;We will delve deep into the tokenizer's fundamental role, shedding light on its operations and introducing straightforward techniques to assess whether a particular model is suited to your data based solely on its tokenizer. We will explore the significance of the tokenizer in the fine-tuning process of embedding models and discuss strategic approaches to optimize its effectiveness.&lt;/p&gt;
&lt;p&gt;---&lt;/p&gt;
&lt;p&gt;This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License: &lt;a class="reference external" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;https://creativecommons.org/licenses/by-nc-sa/4.0/&lt;/a&gt;&lt;/p&gt;
</content><category term="EuroPython 2024"></category></entry></feed>