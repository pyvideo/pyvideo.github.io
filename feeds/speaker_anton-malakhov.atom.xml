<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_anton-malakhov.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-07-12T00:00:00+00:00</updated><entry><title>Addressing Multithreading and Multiprocessing in Transparent and Pythonic Methods</title><link href="https://pyvideo.org/scipy-2018/addressing-multithreading-and-multiprocessing-in-transparent-and-pythonic-methods.html" rel="alternate"></link><published>2018-07-12T00:00:00+00:00</published><updated>2018-07-12T00:00:00+00:00</updated><author><name>David Liu</name></author><id>tag:pyvideo.org,2018-07-12:scipy-2018/addressing-multithreading-and-multiprocessing-in-transparent-and-pythonic-methods.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;With the increase in computing power, harnessing and controlling one’s
code out of the single threaded realm becomes an ever-increasing
problem, coupled with the desire to stay in the Python layer. With the
recent tools and frameworks that have been published, escaping the GIL
cleanly is much easier than before, and can allow one’s Python code to
effectively utilize multi-core and many core architectures in the most
Pythonic ways possible. In this talk, learn about how to utilize static
multiprocessing for process pinning, and effectively balancing thread
pools with a monkey-patched import of threading modules.Presenter(s):
Speaker: David Liu, Intel Speaker: Anton Malakhov, Intel Corporation&lt;/p&gt;
</summary></entry><entry><title>Composable Multiprocessing and Multithreading for Numeric Libraries</title><link href="https://pyvideo.org/scipy-2017/composable-multiprocessing-and-multithreading-for-numeric-libraries.html" rel="alternate"></link><published>2017-07-14T00:00:00+00:00</published><updated>2017-07-14T00:00:00+00:00</updated><author><name>Anton Malakhov</name></author><id>tag:pyvideo.org,2017-07-14:scipy-2017/composable-multiprocessing-and-multithreading-for-numeric-libraries.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Among numeric communities Python is popular because of its easy to use number crunching modules like Numpy, Scipy, Tensor Flow, Theano, Dask, and Numba – to name but a few. These modules often use parallel processing in order to exploit all of the resources of multi-core processors efficiently. However, when used together in the same application, or in an application which exposes parallelism itself, these Python modules can interfere with each other by requesting too many worker threads. That leads to inefficiency or even causes failure of the code due to resource exhaustion. Last year, the Intel® Threading Building Blocks (Intel® TBB) module for Python introduced a new approach to tackle these issues. However, It is limited to a single process and packages which can switch to using the Intel® TBB library for multi-threading (e.g. Numpy, Dask, Joblib, and Numba). In this work, we address both limitations in the existing approach by introducing a way to compose parallelism implemented with OpenMP* runtime and to support multiprocessing coordination for both Intel® TBB and OpenMP threading runtimes.&lt;/p&gt;
</summary></entry><entry><title>Composable Multi Threading for Python Libraries</title><link href="https://pyvideo.org/scipy-2016/composable-multi-threading-for-python-libraries-scipy-2016-anton-malakhov.html" rel="alternate"></link><published>2016-07-14T00:00:00+00:00</published><updated>2016-07-14T00:00:00+00:00</updated><author><name>Anton Malakhov</name></author><id>tag:pyvideo.org,2016-07-14:scipy-2016/composable-multi-threading-for-python-libraries-scipy-2016-anton-malakhov.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Multi-processing parallelism in Python might be unacceptable due to cache-inefficiency and memory overhead. On the other hand, multi-threaded parallelism with Python suffers from the GIL but when it comes to numeric computations, most of the time is spent in native codes where the GIL can easily be released. This is why modules such as Dask and Numba use multi-threading to greatly speed up the computations. But being used together in a nested way, e.g. when a Dask task calls Numba's threaded ufunc, it leads to the situation where there are more active software threads than available hardware resources. This situation is called over-subscription and it leads to inefficient execution due to frequent context switches, thread migration, broken cache-efficiency, and finally to a load imbalance when some threads finished their work but others are stuck along with the overall progress.&lt;/p&gt;
&lt;p&gt;Another example is Numpy/Scipy when they are accelerated using Intel Math Kernels Library (MKL) like the ones shipped as part of Intel Distribution for Python. MKL is usually threaded using OpenMP which is known for not easily co-existing even with itself. In particular, OpenMP threads keep spin-waiting after the work is done -- which is usually necessary to reduce work distribution overhead for the next possible parallel region. But it plays badly with another thread pool because while OpenMP worker threads keep consuming CPU time in spin-waiting, the other parallel work like Numba's ufunc cannot start until OpenMP threads stop spinning or are preempted by the OS.&lt;/p&gt;
&lt;p&gt;And the worst case is also connected to usage of OpenMP when a program starts multiple parallel tasks and each of these tasks ends up executing an OpenMP parallel region. This is quadratic over-subscription which ruins multi-threaded performance.&lt;/p&gt;
&lt;p&gt;Our approach to solve these co-existence problems is to share one thread pool among all the necessary modules and native libraries so that one task scheduler will take care of this composability issue. Intel Threading Building Blocks (TBB) library works as such a task scheduler in our solution. TBB is a wide-spread and recognized C++ library for enabling multi-core parallelism. It was designed for composability, nested parallelism support, and avoidance of over-subscription from its early days. Thus we implemented a Python module which integrates TBB with Python, it is already available as part of Intel Distribution for Python and on Intel channel for conda users. I will show how to enable it for Numpy/Scipy, Dask, Numba, Joblib, and other threaded modules and demonstrate the performance benefits it brings.&lt;/p&gt;
</summary><category term="SciPy 2016"></category></entry></feed>