<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Rollin Thomas</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_rollin-thomas.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2021-07-12T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Optimizing Python Based Spectroscopic Data Processing on NERSC Supercomputers</title><link href="https://pyvideo.org/scipy-2019/optimizing-python-based-spectroscopic-data-processing-on-nersc-supercomputers.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Stephen Bailey</name></author><id>tag:pyvideo.org,2019-07-11:/scipy-2019/optimizing-python-based-spectroscopic-data-processing-on-nersc-supercomputers.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk is a case study that describes how a Python image processing pipeline was optimized for increased throughput of 5-7x on a high-performance system. The workflow of using profiling tools to find candidate kernels for optimization and the techniques for speeding up these kernels will be described. The …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk is a case study that describes how a Python image processing pipeline was optimized for increased throughput of 5-7x on a high-performance system. The workflow of using profiling tools to find candidate kernels for optimization and the techniques for speeding up these kernels will be described. The most successful method used to obtain speedup was just-in-time compiling using Numba; several successful examples will be provided. Parallelization strategies using MPI and Dask will be compared, and preliminary considerations for moving the code to GPUs will be discussed.&lt;/p&gt;
</content><category term="SciPy 2019"></category></entry><entry><title>Interactive Supercomputing with Jupyter at NERSC</title><link href="https://pyvideo.org/scipy-2020/interactive-supercomputing-with-jupyter-at-nersc.html" rel="alternate"></link><published>2020-07-06T00:00:00+00:00</published><updated>2020-07-06T00:00:00+00:00</updated><author><name>Rollin Thomas</name></author><id>tag:pyvideo.org,2020-07-06:/scipy-2020/interactive-supercomputing-with-jupyter-at-nersc.html</id><content type="html"></content><category term="SciPy 2020"></category></entry><entry><title>Monitoring Scientific Python Usage on a Supercomputer</title><link href="https://pyvideo.org/scipy-2021/monitoring-scientific-python-usage-on-a-supercomputer.html" rel="alternate"></link><published>2021-07-12T00:00:00+00:00</published><updated>2021-07-12T00:00:00+00:00</updated><author><name>Rollin Thomas</name></author><id>tag:pyvideo.org,2021-07-12:/scipy-2021/monitoring-scientific-python-usage-on-a-supercomputer.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In 2020, 35% of users at the National Energy Research Scientific Computing Center (NERSC) used Python on the Cori supercomputer. How do we know? We developed a simple, minimally invasive monitoring framework that leverages standard Python features to capture Python imports and other job data. The data are analyzed …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In 2020, 35% of users at the National Energy Research Scientific Computing Center (NERSC) used Python on the Cori supercomputer. How do we know? We developed a simple, minimally invasive monitoring framework that leverages standard Python features to capture Python imports and other job data. The data are analyzed with GPU-enabled Python libraries (Dask + cuDF) in a Jupyter notebook, and results are summarized in a Voila dashboard. After detailing our methodology, we provide a high-level tour of some of the data we’ve gathered over the past year. We conclude by outlining future work and potential broader applications.&lt;/p&gt;
</content><category term="SciPy 2021"></category></entry></feed>