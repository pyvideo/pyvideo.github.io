<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Hamid Shojanazeri</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_hamid-shojanazeri.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2023-10-16T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Lightning Talk: Exploring PiPPY, Tensor Parallel and Torchserve for Large Model Inference</title><link href="https://pyvideo.org/pytorch-conference-2023/lightning-talk-exploring-pippy-tensor-parallel-and-torchserve-for-large-model-inference.html" rel="alternate"></link><published>2023-10-16T00:00:00+00:00</published><updated>2023-10-16T00:00:00+00:00</updated><author><name>Hamid Shojanazeri</name></author><id>tag:pyvideo.org,2023-10-16:/pytorch-conference-2023/lightning-talk-exploring-pippy-tensor-parallel-and-torchserve-for-large-model-inference.html</id><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Here, we talk about large model inference with Torchserve, using PiPPy, Tensor Parallel, challenges of distributed inference and available solutions. Discuss the features that Torchserve provide today for serving LLMs in production today.&lt;/p&gt;
</content><category term="PyTorch Conference 2023"></category><category term="Lightning Talk"></category></entry></feed>