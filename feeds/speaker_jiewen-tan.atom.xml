<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Jiewen Tan</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_jiewen-tan.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2023-10-16T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Lightning Talk: Large-Scale Distributed Training with Dynamo and Triton</title><link href="https://pyvideo.org/pytorch-conference-2023/lightning-talk-large-scale-distributed-training-with-dynamo-and-triton.html" rel="alternate"></link><published>2023-10-16T00:00:00+00:00</published><updated>2023-10-16T00:00:00+00:00</updated><author><name>Yeounoh Chung</name></author><id>tag:pyvideo.org,2023-10-16:/pytorch-conference-2023/lightning-talk-large-scale-distributed-training-with-dynamo-and-triton.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we cover PyTorch/XLA distributed API in relation with Torch.Dynamo. Specifically, we discuss the new PyTorch/XLA SPMD API for automatic parallelization and our latest LLaMA2 training results. PyTorch/XLA SPMD makes it simple for PyTorch developers to distribute their ML workloads (e.g., training â€¦&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we cover PyTorch/XLA distributed API in relation with Torch.Dynamo. Specifically, we discuss the new PyTorch/XLA SPMD API for automatic parallelization and our latest LLaMA2 training results. PyTorch/XLA SPMD makes it simple for PyTorch developers to distribute their ML workloads (e.g., training &amp;amp; inference with Dynamo) with easy-to-use API, and uses XLA GSPMD, high-performance automatic parallelization system. Under the hood, it transforms the user single-device program into a partitioned one. We will share how we enabled advanced 2D sharding strategies for LLaMA2 using PyTorch/XLA SPMD.&lt;/p&gt;
</content><category term="PyTorch Conference 2023"></category><category term="Lightning Talk"></category></entry></feed>