<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - reinforcement learning</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 17 Apr 2023 00:00:00 +0000</lastBuildDate><item><title>(Alpha) Zero to Elo</title><link>https://pyvideo.org/pycon-italia-2018/alpha-zero-to-elo.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Reinforcement learning is a sequential decision making framework that
has received a lot of attention given incredible results from DeepMind,
DQN and AlphaGo. More recently DeepMind delivered a more general AI game
player call AlphaZero, which learns by self-play.&lt;/p&gt;
&lt;p&gt;During this session we will introduce you the key ideas behind
AlphaZero:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Reinforcement Learning and Value function&lt;/li&gt;
&lt;li&gt;MonteCarlo Tree Search&lt;/li&gt;
&lt;li&gt;Self-play&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will explore how they contribute to beat greatest Go player of our
time, in Python.&lt;/p&gt;
&lt;p&gt;Agenda:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Introduction to AI in games&lt;/li&gt;
&lt;li&gt;What AlphaZero is made of? (Boring theory)&lt;/li&gt;
&lt;li&gt;How to build your own AlphaZero? (Cool code)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;in __on &lt;strong&gt;domenica 22 aprile&lt;/strong&gt; at 15:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Simone Totaro</dc:creator><pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-22:/pycon-italia-2018/alpha-zero-to-elo.html</guid><category>PyCon Italia 2018</category><category>Deep-Learning</category><category>reinforcement-learning</category><category>datascience</category></item><item><title>Improving Machine Learning from Human Feedback</title><link>https://pyvideo.org/pydata-berlin-2023/improving-machine-learning-from-human-feedback.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Large generative models rely upon massive data sets that are collected automatically. For example, GPT-3 was trained with data from &amp;quot;Common Crawl&amp;quot; and &amp;quot;Web Text&amp;quot;, among other sources. As the saying goes — bigger isn't always better. While powerful, these data sets (and the models that they create) often come at a cost, bringing their &amp;quot;internet-scale biases&amp;quot; along with their &amp;quot;internet-trained models.&amp;quot; While powerful, these models beg the question — is unsupervised learning the best future for machine learning?&lt;/p&gt;
&lt;p&gt;ML researchers have developed new model-tuning techniques to address the known biases within existing models and improve their performance (as measured by response preference, truthfulness, toxicity, and result generalization). All of this at a fraction of the initial training cost. In this talk, we will explore these techniques, known as Reinforcement Learning from Human Feedback (RLHF), and how open-source machine learning tools like PyTorch and Label Studio can be used to tune off-the-shelf models using direct human feedback.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Erin Mikail Staples</dc:creator><pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-04-17:/pydata-berlin-2023/improving-machine-learning-from-human-feedback.html</guid><category>PyData Berlin 2023</category><category>reinforcement learning</category><category>human feedback</category><category>pytorch</category><category>label studio</category></item><item><title>Aprendizaje por refuerzo con OpenAI Gym</title><link>https://pyvideo.org/pydata-cordoba-2019/aprendizaje-por-refuerzo-con-openai-gym.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Esta charla ofrece una introducción a aprendizaje por refuerzo y cómo podemos experimentar con estos algoritmos usando la librería OpenAI Gym.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Ana Laura Diedrichs</dc:creator><pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-09-27:/pydata-cordoba-2019/aprendizaje-por-refuerzo-con-openai-gym.html</guid><category>PyData Córdoba 2019</category><category>artificial intelligence</category><category>openai gym</category><category>reinforcement learning</category></item><item><title>Inteligencia Artificial para Principiantes</title><link>https://pyvideo.org/riiaa-2021/inteligencia-artificial-para-principiantes.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Benjamín Sánchez Léngelin</dc:creator><pubDate>Wed, 25 Aug 2021 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2021-08-25:/riiaa-2021/inteligencia-artificial-para-principiantes.html</guid><category>RIIAA 2021</category><category>Artificial Intelligence</category><category>Data Science</category><category>Machine Learning</category><category>Reinforcement Learning</category></item><item><title>Relaciones de equivalencia y métricas de estados para procesos de decisión Markovianos.</title><link>https://pyvideo.org/riiaa-2021/relaciones-de-equivalencia-y-metricas-de-estados-para-procesos-de-decision-markovianos.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Este taller presenta la teoría de relaciones de equivalencia y métricas de estado para procesos de decisión Markovianos (MDPs). En años recientes se ha popularizado como una técnica teórica y empírica para el aprendizaje por refuerzo. El enfoque principal será matemático, pero utilizaremos collaboratory notebooks para poder tener un mejor entendimiento de las diferentes teorías y sus aplicaciones al aprendizaje por refuerzo.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Pablo Castro</dc:creator><pubDate>Wed, 25 Aug 2021 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2021-08-25:/riiaa-2021/relaciones-de-equivalencia-y-metricas-de-estados-para-procesos-de-decision-markovianos.html</guid><category>RIIAA 2021</category><category>Artificial Intelligence</category><category>Reinforcement Learning</category></item></channel></rss>