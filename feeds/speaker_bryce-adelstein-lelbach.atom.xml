<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Bryce Adelstein Lelbach</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_bryce-adelstein-lelbach.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2025-05-17T00:00:00+00:00</updated><subtitle></subtitle><entry><title>GPU Programming in Pure Python</title><link href="https://pyvideo.org/pycon-us-2025/gpu-programming-in-pure-python.html" rel="alternate"></link><published>2025-05-17T00:00:00+00:00</published><updated>2025-05-17T00:00:00+00:00</updated><author><name>Bryce Adelstein Lelbach</name></author><id>tag:pyvideo.org,2025-05-17:/pycon-us-2025/gpu-programming-in-pure-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;GPU programming can be scary but doesn’t need to be. With the CUDA Core Libraries and CUDA Python object model, you have a friendly interface to get you started with GPU acceleration.&lt;/p&gt;
&lt;p&gt;In this example-driven talk, we'll begin with a general discussion of the CUDA model and how …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;GPU programming can be scary but doesn’t need to be. With the CUDA Core Libraries and CUDA Python object model, you have a friendly interface to get you started with GPU acceleration.&lt;/p&gt;
&lt;p&gt;In this example-driven talk, we'll begin with a general discussion of the CUDA model and how to manage accelerator devices in Python with cuda.core. Next, we'll teach you how to launch work and manage memory. Then, you'll learn how to use parallel algorithms with cuda.parallel, write your own kernels that leverage cooperative algorithms with cuda.cooperative, and integrate seamlessly with accelerated libraries such as cuDNN and cuBLAS.&lt;/p&gt;
&lt;p&gt;We'll look at a variety of parallel examples, from counting words, to implementing softmax, to a full blown machine learning demo.&lt;/p&gt;
&lt;p&gt;By the time the talk is over, you'll be ready to start accelerating your Python code with GPUs!&lt;/p&gt;
</content><category term="PyCon US 2025"></category></entry></feed>