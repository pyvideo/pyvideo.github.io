<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_celia-cintas.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-07-13T00:00:00+00:00</updated><entry><title>Raiders of the Pottery GAN: Using 3D Generative Adversarial Networks for Data Augmentation in Archaeological Studies</title><link href="https://pyvideo.org/scipy-2019/raiders-of-the-pottery-gan-using-3d-generative-adversarial-networks-for-data-augmentation-in-archaeological-studies.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Celia Cintas</name></author><id>tag:pyvideo.org,2019-07-13:scipy-2019/raiders-of-the-pottery-gan-using-3d-generative-adversarial-networks-for-data-augmentation-in-archaeological-studies.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Reassembly of 3D fragmented objects from a collection of hundreds of randomly mixed fragments is a problem that arises in several applied disciplines, such as archaeology, failure analysis, paleontology, etc. In this talk we will walk through the pipeline of 3D data generation in archaeological studies, from pre-processing of images, moving from 2D to 3D space, and finally the training and evaluation of generative adversarial networks in Python for 3D meshes corresponding to Iberian vessels. We will report several python libraries (scikit-image, pytorch, visdom, etc.) and how they are used in this particular pipeline. The main goal of augmenting our dataset in 3D is to perform fragment part identification and vessel reconstruction.&lt;/p&gt;
</summary></entry><entry><title>Introduction to Deep Learning with Python - The force awakens</title><link href="https://pyvideo.org/pycon-uk-2017/introduction-to-deep-learning-with-python-the-force-awakens.html" rel="alternate"></link><published>2017-10-28T14:30:00+01:00</published><updated>2017-10-28T14:30:00+01:00</updated><author><name>Celia Cintas</name></author><id>tag:pyvideo.org,2017-10-28:pycon-uk-2017/introduction-to-deep-learning-with-python-the-force-awakens.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk we will give a gentle introduction to Deep Learning using Python with the help of Lasagne, Numpy, Pandas and OpenCV having fun with Star Wars miniature ships in the process. We will walk through the pipeline, starting from data acquisition, preparation, construction of ConvNets, training and assessment, in order to classify different types of ships! Deep Learning allows computational models that are composed of multiple processing layers to learn representation of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Particularly, Convolutional Neural Networks (ConvNets) represent the state of art of several computer vision problems, given its outstanding classification performance in large volumes of images. ConvNets great performance is based on four fundamental ideas. Local connections, shared weights, pooling and the use of multiple layers. For this talk we will have miniatures ships in the room so participants can record their own videos, and use it as data source for their own classifiers! During the talk we will show how to classify k-wing, lambda shuttle and millennium falcon miniatures.&lt;/p&gt;
</summary></entry><entry><title>Introducción a programación paralela con PyOpenCL</title><link href="https://pyvideo.org/pycon-ar-2016/introduccion-a-programacion-paralela-con-pyopencl.html" rel="alternate"></link><published>2016-11-25T00:00:00+00:00</published><updated>2016-11-25T00:00:00+00:00</updated><author><name>Celia Cintas</name></author><id>tag:pyvideo.org,2016-11-25:pycon-ar-2016/introduccion-a-programacion-paralela-con-pyopencl.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyconAR 2016 - Bahía Blanca&lt;/p&gt;
&lt;p&gt;Introducción a programación paralela con PyOpenCL por Celia Cintas&lt;/p&gt;
&lt;p&gt;Audience level: Principiante&lt;/p&gt;
&lt;p&gt;Descripción&lt;/p&gt;
&lt;p&gt;Se mostrará cómo crear soluciones paralelas e independientes al hardware (CPUs, DSP, FPGAs y GPUs) utilizando PyOpenCL. Veremos una breve introducción a conceptos básicos: arquitecturas, tipos de memoria y modelos de ejecución. Luego implementaremos el pipeline básico de una aplicación con PyOpenCL y resolveremos problemas desde simples operaciones con matrices hasta proc. de imágenes.&lt;/p&gt;
&lt;p&gt;Resumen&lt;/p&gt;
&lt;p&gt;OpenCL es un estándar abierto y libre para la programación paralela de propósito general sobre CPU, GPU entre otros. OpenCL nos permite desarrollar código rápido y eficiente para una serie de aplicaciones con diferentes comportamientos: control intensivo (búsqueda y clasificación), volúmenes de datos (procesamiento de imágenes, simulación y modelado, y la minería de datos), cálculo intensivo (métodos iterativos, métodos numéricos y modelamiento financiero). OpenCL abstrae el código de cuestiones específicas del hardware, permitiendo que nuestros programas se ejecuten sobre una gran variedad de dispositivos. PyOpenCL es un entorno de programación Python, que reduce la cantidad de código C a solo la implementación de los kernels, dejando el resto de nuestro código (la parte de host) en Python, sin renunciar a la eficiencia ni la velocidad y manteniendo la independencia del hardware.&lt;/p&gt;
&lt;p&gt;Estructura de la charla&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Qué es programación paralela?&lt;/li&gt;
&lt;li&gt;Qué es OpenCL? Cuales son sus componentes?&lt;/li&gt;
&lt;li&gt;Arquitectura abstracta de OpenCL&lt;/li&gt;
&lt;li&gt;Tipos de memoria en OpenCL&lt;/li&gt;
&lt;li&gt;Modelo de ejecución OpenCL&lt;/li&gt;
&lt;li&gt;Introducción a PyOpenCL (hands-on código en ipynb)&lt;/li&gt;
&lt;li&gt;Plataforma, Contextos, Colas, Kernel y programas.&lt;/li&gt;
&lt;li&gt;Buffers&lt;/li&gt;
&lt;li&gt;Ejemplos de operaciones de matrices, procesamiento de imágenes y fractales.&lt;/li&gt;
&lt;/ul&gt;
</summary></entry><entry><title>Lightning Talks 20/05/2016</title><link href="https://pyvideo.org/scipyla-2016/lightning-talks-20052016.html" rel="alternate"></link><published>2016-06-24T00:00:00+00:00</published><updated>2016-06-24T00:00:00+00:00</updated><author><name>Nestor Cubas Wendt</name></author><id>tag:pyvideo.org,2016-06-24:scipyla-2016/lightning-talks-20052016.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;ol class="arabic simple"&gt;
&lt;li&gt;Molecular Dynamics in Ecotoxicology - Nestor Cubas Wendt&lt;/li&gt;
&lt;li&gt;⁠⁠⁠Bioinformatics applied to RNA sequencing - Daniella Helena Hock&lt;/li&gt;
&lt;li&gt;PyLadies São Paulo - Tania Patricia Simões Yamaki&lt;/li&gt;
&lt;li&gt;Introduction to High Performance Scientific Computing with PyOpenCL - Celia Cintas&lt;/li&gt;
&lt;li&gt;IPython-Unittest - João Felipe Pimentel&lt;/li&gt;
&lt;li&gt;Literate Programming, Pweave - Melissa Mendonça&lt;/li&gt;
&lt;li&gt;Comunidade SciPy América Latina - Ivan Ogasawara&lt;/li&gt;
&lt;li&gt;5 Coisas para ler 1 para fazer - Raniere Silva&lt;/li&gt;
&lt;/ol&gt;
</summary><category term="lightning talks"></category></entry><entry><title>3D sensors and Python: A space odyssey</title><link href="https://pyvideo.org/europython-2014/3d-sensors-and-python-a-space-odyssey.html" rel="alternate"></link><published>2014-07-23T00:00:00+00:00</published><updated>2014-07-23T00:00:00+00:00</updated><author><name>Celia Cintas</name></author><id>tag:pyvideo.org,2014-07-23:europython-2014/3d-sensors-and-python-a-space-odyssey.html</id><summary type="html">&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;This talk will show how to build a simple open source based NUI (Natural
User Interface) game with 3D Sensors, incorporating PyOpenNI with PyGame
and WebGL. OpenNI allows you operate several 3D sensors, enabling
hardware independent game development (supported 3D sensors are
Microsoft Kinect, PrimeSense Carmine or Asus XTion). It also runs on
Linux, Mac OS X and Windows.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will start with a brief introduction to 3D Sensors and OpenNI.
Then we’ll surf into PyOpenNI, features such as the skeleton, hand and
gesture tracking, RGB and depth video. Every topic will be presented
with practical demos. The talk will end with a demo integrating WebGL
(THREE.JS), 3D sensors, Flask and ZMQ to produce a simple fully open
source based NUI game.&lt;/p&gt;
&lt;p&gt;Some simple demos of PyOpenNI and PyGame can be found at
&lt;a class="reference external" href="https://www.youtube.com/watch?v=wI2ktioiPY8"&gt;1&lt;/a&gt; and
&lt;a class="reference external" href="http://youtu.be/3e8jibGUQ2Q"&gt;2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Attendees will not only learn about game related technologies but also
about innovative ways of doing domotics, cinema &amp;amp; art, Interactive
visualization, scientific research, educations, etc.&lt;/p&gt;
&lt;p&gt;3D Sensors will be available for testing during the event - you can get
yours for about 80 to 140 Euros (depending on the brand). Slides and
demo code will be available at Github.&lt;/p&gt;
&lt;p&gt;Talk structure:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Introduction: hardware and OpenNI goodies and a tale of PCL (5’)&lt;/li&gt;
&lt;li&gt;Hands On PyOpenNI&lt;ul&gt;
&lt;li&gt;Normal and Depth camera - basics concepts and small demo (5’)&lt;/li&gt;
&lt;li&gt;Skeleton - basics concepts and small demo. (5’)&lt;/li&gt;
&lt;li&gt;Hand &amp;amp; gesture - basics concepts and small demo. (5’)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Final Demo&lt;ul&gt;
&lt;li&gt;What we’re going to use? Flask, ZMQ, THREE.JS, PyOpenNI. (6’)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Q&amp;amp;A. (4’)&lt;/li&gt;
&lt;/ul&gt;
</summary></entry></feed>