<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Peter Dayan</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_peter-dayan.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-08-03T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Static and Dynamic Values of Computation in MCTS</title><link href="https://pyvideo.org/uai-2020/static-and-dynamic-values-of-computation-in-mcts.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Eren Sezener</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/static-and-dynamic-values-of-computation-in-mcts.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Static and Dynamic Values of Computation in MCTS&lt;/p&gt;
&lt;p&gt;Eren Sezener (DeepMind)*; Peter Dayan (Max Planck Institute for Biological Cybernetics)&lt;/p&gt;
&lt;p&gt;Monte-Carlo Tree Search (MCTS) is one of the most-widely used methods
for planning, and has powered many recent advances in artificial
intelligence. In MCTS, one typically performs computations
(i.e â€¦&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Static and Dynamic Values of Computation in MCTS&lt;/p&gt;
&lt;p&gt;Eren Sezener (DeepMind)*; Peter Dayan (Max Planck Institute for Biological Cybernetics)&lt;/p&gt;
&lt;p&gt;Monte-Carlo Tree Search (MCTS) is one of the most-widely used methods
for planning, and has powered many recent advances in artificial
intelligence. In MCTS, one typically performs computations
(i.e., simulations) to collect statistics about the possible future
consequences of actions, and then chooses accordingly. Many
popular MCTS methods such as UCT and its variants decide which
computations to perform by trading-off exploration and exploitation. In
this work, we take a more direct approach, and explicitly quantify the
value of a computation based on its expected impact on the quality of
the action eventually chosen. Our approach goes beyond the emph{myopic}
limitations of existing computation-value-based methods in two senses:
(I) we are able to account for the impact of non-immediate (ie, future)
computations (II) on non-immediate actions. We show that policies that
greedily optimize computation values are optimal under certain
assumptions and obtain results that are competitive with the
state-of-the-art.&lt;/p&gt;
</content><category term="UAI 2020"></category></entry></feed>