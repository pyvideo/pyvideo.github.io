<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_cuda.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-05-04T00:00:00+00:00</updated><entry><title>CUDA in your Python: Effective Parallel Programming on the GPU</title><link href="https://pyvideo.org/pytexas-2019/cuda-in-your-python-effective-parallel-programming-on-the-gpu.html" rel="alternate"></link><published>2019-04-13T00:00:00+00:00</published><updated>2019-04-13T00:00:00+00:00</updated><author><name>William Horton</name></author><id>tag:pyvideo.org,2019-04-13:pytexas-2019/cuda-in-your-python-effective-parallel-programming-on-the-gpu.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;It’s 2019, and Moore’s Law is dead. CPU performance is plateauing, but GPUs provide a chance for continued hardware performance gains, if you can structure your programs to make good use of them. In this talk you will learn how to speed up your Python programs using Nvidia’s CUDA platform.&lt;/p&gt;
</summary><category term="GPU"></category><category term="cuda"></category></entry><entry><title>Basta problemi con tensorflow usando Docker &amp; Nvidia Docker</title><link href="https://pyvideo.org/pycon-italia-2019/basta-problemi-con-tensorflow-usando-docker-nvidia-docker.html" rel="alternate"></link><published>2019-05-04T00:00:00+00:00</published><updated>2019-05-04T00:00:00+00:00</updated><author><name>Nicola Landro</name></author><id>tag:pyvideo.org,2019-05-04:pycon-italia-2019/basta-problemi-con-tensorflow-usando-docker-nvidia-docker.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Di sicuro vi sarà capitato che condividendo o effettuando un progetto
tensorflow questo non funzioni correttamente. Soprattutto non riesco a
far scalare la mia app perchè non ho abbastanza macchine con GPU e
eseguire lo scale su macchine con solo CPU è costoso per poi ottenere
scarsi benefici. La soluzione è utilizzare Docker e Nvidia Docker.
Vedremo perchè Docker è migliore di una macchina virtuale e come
cambiano le prestazioni rispetto ad andare direttamente sulla macchina.
Vedremo trucchi su come strutturare dei docker-compose file senza
duplicazione per poter sviluppare agilmente sia con GPU che senza, poter
effettuare un deploy con tranquillità e poter scalare facilmente anche
senza GPU. Slide Link: &amp;lt;&lt;a class="reference external" href="https://www.slideshare.net/NicolaLandro/basta"&gt;https://www.slideshare.net/NicolaLandro/basta&lt;/a&gt;-
problemicontensorflowusandodockernvidiadocker&amp;gt;&lt;/p&gt;
&lt;p&gt;Feedback form: &lt;a class="reference external" href="https://python.it/feedback-1528"&gt;https://python.it/feedback-1528&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Saturday 4 May&lt;/strong&gt; at 10:45 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="OSX"></category><category term="windows"></category><category term="devops"></category><category term="Machine Learning"></category><category term="GNU/Linux"></category><category term="cuda"></category><category term="tensorflow"></category><category term="docker"></category></entry></feed>