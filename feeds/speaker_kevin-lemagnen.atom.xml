<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_kevin-lemagnen.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-07-13T00:00:00+00:00</updated><entry><title>Adv. Software Testing for Data Scientists</title><link href="https://pyvideo.org/pydata-london-2019/adv-software-testing-for-data-scientists.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Raoul-Gabriel Urma</name></author><id>tag:pyvideo.org,2019-07-13:pydata-london-2019/adv-software-testing-for-data-scientists.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The journey to deploy a model to production starts with testing it rigorously, including its code implementation. In this tutorial, you will learn about state of the art software testing approach. You will learn how to write unit tests with enhanced diagnostics, leverage validation tools from numpy, pandas, scikit-learn, apply test doubles and generate test cases using property-based testing.&lt;/p&gt;
</summary></entry><entry><title>Maintainable code in data science</title><link href="https://pyvideo.org/pydata-london-2019/maintainable-code-in-data-science.html" rel="alternate"></link><published>2019-07-13T00:00:00+00:00</published><updated>2019-07-13T00:00:00+00:00</updated><author><name>Kevin Lemagnen</name></author><id>tag:pyvideo.org,2019-07-13:pydata-london-2019/maintainable-code-in-data-science.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Notebooks are great, they allow to explore your data and prototype models quickly. But they make it hard to follow good software practices. In this tutorial, we will go through a case study.We will see how to refactor our code as a testable and maintainable Python package with entry-points to tune, train and test our model so it can easily be integrated to a CI/CD flow.&lt;/p&gt;
</summary></entry><entry><title>Open the Black Box: an Introduction to Model Interpretability in Python</title><link href="https://pyvideo.org/pycon-us-2019/open-the-black-box-an-introduction-to-model-interpretability-in-python.html" rel="alternate"></link><published>2019-05-02T13:20:00+00:00</published><updated>2019-05-02T13:20:00+00:00</updated><author><name>Kevin Lemagnen</name></author><id>tag:pyvideo.org,2019-05-02:pycon-us-2019/open-the-black-box-an-introduction-to-model-interpretability-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;What's the use of sophisticated machine learning models if you can't
interpret them?&lt;/p&gt;
&lt;p&gt;In fact, many industries including finance and healthcare require clear
explanations of why a decision is made. This tutorial covers recent
model interpretability techniques that are essentials in your data
scientist toolbox: Eli5, LIME (Local Interpretable Model-Agnostic
Explanations) and SHAP (SHapley Additive exPlanations).&lt;/p&gt;
&lt;p&gt;You will learn how to apply these techniques in Python on real-world
data science problems in order to debug your models and explain their
decisions.&lt;/p&gt;
&lt;p&gt;You will also learn the conceptual background behind these techniques so
you can better understand when they are appropriate.&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Open the Black Box: an Introduction to Model Interpretability with LIME and SHAP</title><link href="https://pyvideo.org/pydata-new-york-city-2018/open-the-black-box-an-introduction-to-model-interpretability-with-lime-and-shap.html" rel="alternate"></link><published>2018-08-17T00:00:00+00:00</published><updated>2018-08-17T00:00:00+00:00</updated><author><name>Kevin Lemagnen</name></author><id>tag:pyvideo.org,2018-08-17:pydata-new-york-city-2018/open-the-black-box-an-introduction-to-model-interpretability-with-lime-and-shap.html</id><summary type="html"></summary></entry><entry><title>Walking the Random Forest and boosting the trees</title><link href="https://pyvideo.org/europython-2018/walking-the-random-forest-and-boosting-the-trees.html" rel="alternate"></link><published>2018-07-27T00:00:00+00:00</published><updated>2018-07-27T00:00:00+00:00</updated><author><name>Kevin Lemagnen</name></author><id>tag:pyvideo.org,2018-07-27:europython-2018/walking-the-random-forest-and-boosting-the-trees.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deep Learning is all the rage, but ensemble models are still in the
game. With libraries such as the recent and performant LightGBM, the
Kaggle superstar XGboost or the classic Random Forest from scikit-learn,
ensembles models are a must-have in a data scientist’s toolbox. They’ve
been proven to provide good performance on a wide range of problems, and
are usually simpler to tune and interpret. This talk focuses on two of
the most popular tree-based ensemble models. You will learn about Random
Forest and Gradient Boosting, relying respectively on bagging and
boosting. This talk will attempt to build a bridge between the theory of
ensemble models and their implementation in Python.&lt;/p&gt;
&lt;p&gt;Notebook:
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;https://github.com/klemag/europython2018_walking_the_random_forest&lt;/span&gt;&lt;/tt&gt;&lt;/p&gt;
</summary></entry></feed>