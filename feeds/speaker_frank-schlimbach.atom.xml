<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_frank-schlimbach.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-05-03T00:00:00+00:00</updated><entry><title>High Performance and Scalability Made Easy For Data-Analytics/Machine-Learning Codes</title><link href="https://pyvideo.org/pycon-italia-2019/high-performance-and-scalability-made-easy-for-data-analyticsmachine-learning-codes.html" rel="alternate"></link><published>2019-05-03T00:00:00+00:00</published><updated>2019-05-03T00:00:00+00:00</updated><author><name>Frank Schlimbach</name></author><id>tag:pyvideo.org,2019-05-03:pycon-italia-2019/high-performance-and-scalability-made-easy-for-data-analyticsmachine-learning-codes.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Is your data-analysis code running for too long with Scikit-Learn,
Numpy, Scipy and/or Pandas? Does your data-set blow your memory? Are
spark/dask/… not giving you the scalability and/or ease-of-use your
need?&lt;/p&gt;
&lt;p&gt;Intel implemented optimizations in Numpy, Scikit-Learn, Scipy and Pandas
which achieve up to orders of magnitude better performance for many
functionalities compared to standard implementations. The optimized
packages are drop-in replacements which do not require any code changes
and allow processing more data in less time.&lt;/p&gt;
&lt;p&gt;Moreover, two new tools allow you to easily bring your full data
analytics pipeline to unprecedented scales: daal4py and HPAT. Daal4py is
a convenient Python API to Intel® DAAL (Intel® Data Analytics
Acceleration Library). While its interface is scikit-learn-like, its
MPI-based engine under the hood allows scaling machine learning
algorithms to bare-metal cluster performance with only little code
changes. HPAT (High Performance Analytics Toolkit) scales analytics
codes using Pandas/Python to bare-metal cluster performance. It
automatically compiles a subset of Python (Pandas/Numpy/Daal4py) to
efficient parallel binaries with MPI, also requiring only minimal code
changes. With these tools your code can be orders of magnitude faster
than alternatives like Apache Spark - without the pain of dealing
directly with lower-level languages and/or tools like C and/or message
passing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1805"&gt;https://python.it/feedback-1805&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 15:45 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary></entry></feed>