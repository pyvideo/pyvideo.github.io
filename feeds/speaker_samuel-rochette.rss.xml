<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 04 Nov 2019 00:00:00 +0000</lastBuildDate><item><title>Quantifying uncertainty in machine learning models</title><link>https://pyvideo.org/pydata-new-york-city-2019/quantifying-uncertainty-in-machine-learning-models.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Many models give a lot more information during the inference process that we usually know. We will begin with an intrinsic estimation of all the distribution with random forest algorithm. Then we will extend those 'prediction intervals' to almost every regression models thanks to the quantile loss. Eventually we will discuss about probability calibration to measure uncertainty in classification.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Samuel Rochette</dc:creator><pubDate>Mon, 04 Nov 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-11-04:pydata-new-york-city-2019/quantifying-uncertainty-in-machine-learning-models.html</guid></item></channel></rss>