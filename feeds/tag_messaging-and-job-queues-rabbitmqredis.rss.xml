<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Messaging and Job Queues (RabbitMQ/Redis/...)</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Thu, 23 Jul 2020 00:00:00 +0000</lastBuildDate><item><title>Advanced Infrastructure Management in Kubernetes using Python</title><link>https://pyvideo.org/europython-2020/advanced-infrastructure-management-in-kubernetes-using-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Automate managing complex applications in a cloud native way using Operators written in Python&lt;/p&gt;
&lt;p&gt;Many of us are using Kubernetes in production. A Kubernetes Operator is a way to automate packaging, deploying, and managing of a Kubernetes Application. It is a software alternative to a human operator who has deep knowledge of how to set up, deploy, and manage a particular piece of infrastructure and what to do if it isn’t behaving correctly. Let’s see how we can automate all of this while staying in the Python ecosystem.&lt;/p&gt;
&lt;p&gt;It will be helpful to know some basic concepts of Kubernetes(Deployments, Services, Pods, Configmap etc.) and Celery(docs.celeryproject.org) to get the most out of this talk.&lt;/p&gt;
&lt;p&gt;Talk is divided into four phases.&lt;/p&gt;
&lt;p&gt;Phase I - Problems and Opportunities
We're going to see some simple examples/problems where a lot of manual effort is involved so as to connect audience to the problem.
We're going to discuss problems with configuration management, database cluster setup and introduce the focus problem of the talk which is around automating the setup of a Celery cluster.&lt;/p&gt;
&lt;p&gt;Phase II - Incrementally Approaching the Solution
We're going to incrementally approach the automation each of the manual steps involved in running a Celery cluster in Production. We're going to discuss the extension capabilities in Kubernetes using CRDs and Custom Controllers which are going to help us manage our Celery cluster automagically.&lt;/p&gt;
&lt;p&gt;Phase III - Celery Operator in action
We're going to see the code of custom controller and the whole operator in action. We create the newly defined celery resource and see how the operator works on bringing up the worker and flower deployments and handles autoscaling based on queue length.&lt;/p&gt;
&lt;p&gt;Phase IV - Conclusion and Q&amp;amp;A
We're going to talk about different use-cases and what is world doing with Operators. We'll discuss the next steps for the Celery operator and some resources to help build operators. We'll end the talk with a Q&amp;amp;A.&lt;/p&gt;
&lt;p&gt;Slides for the talk are available on - &lt;a class="reference external" href="https://bit.ly/europython20-ppt"&gt;https://bit.ly/europython20-ppt&lt;/a&gt;
Celery Operator POC I built for this talk is open source - &lt;a class="reference external" href="https://github.com/brainbreaker/Celery-Kubernetes-Operator"&gt;https://github.com/brainbreaker/Celery-Kubernetes-Operator&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Gautam Prajapati</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/advanced-infrastructure-management-in-kubernetes-using-python.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>DevOps general</category><category>Distributed Systems</category><category>Infrastructure</category><category>Messaging and Job Queues (RabbitMQ/Redis/...)</category><category>python</category></item><item><title>IoTPy: Python + Streams + Agents for Streaming Applications</title><link>https://pyvideo.org/europython-2020/iotpy-python-streams-agents-for-streaming-applications.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Ingest and analyze streams of data generated by sensors, social media an other sources.&lt;/p&gt;
&lt;p&gt;Sensors, social media, news feeds, webcams and other sources generate streams of data which are analyzed to control actuators, generate alerts, and feed displays. These applications process streams on onboard computers, such as the Raspberry Pi, connected directly to sensors, and send summarized information to the cloud for further processing. These applications have two characteristics: (1) Concurrency: The applications are concurrent using multiple threads to connect to sensors and actuators, shared memory across multiple processes on multicore machines and message passing for distributed systems spanning multiple computers. (2) Data Analysis: The applications use programs from a variety of libraries including those for signal processing, machine learning and natural language processing.&lt;/p&gt;
&lt;p&gt;Developers of streaming applications can use open-source software to deal with both characteristics. Concurrency: multiprocessing.Array can be used to construct shared-memory multiprocessing Python programs in multicore computers, and frameworks such as APMQ and Kafka can be used to build distributed applications. Data Analysis: A vast collection of open-source Python libraries can be used to analyze data in streams. Developers of streaming applications encounter an impedance mismatch between the software libraries that address these two characteristics. The next paragraph describes the mismatch and how IoTPy addresses it.&lt;/p&gt;
&lt;p&gt;Programs in most software libraries apply a function to data, get results, and terminate execution. By contrast, streaming applications are perpetual processes that analyze endless streams of data. IoTPy helps developers: (1) build non-terminating streaming applications by harnessing conventional terminating programs from Python’s huge base of libraries and (2) create multithreaded, multicore and distributed Python applications by simply connecting streams to each other.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.AssembleSoftware.com"&gt;https://www.AssembleSoftware.com&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kanianthra Chandy</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/iotpy-python-streams-agents-for-streaming-applications.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>Distributed Systems</category><category>Internet of Things (IoT)</category><category>Messaging and Job Queues (RabbitMQ/Redis/...)</category><category>Scientific Libraries (Numpy/Pandas/SciKit/...)</category><category>Sensors</category></item></channel></rss>