<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Wed, 14 Sep 2016 00:00:00 +0000</lastBuildDate><item><title>Scalable Data Science with Spark and R</title><link>https://pyvideo.org/pydata-carolinas-2016/scalable-data-science-with-spark-and-r.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Processing large datasets in R have been limited by the amount of
memory in the local system. To overcome the native R limitation,
several cluster computing alternatives have recently emerged including
Apache Spark. In this session, we will discuss the architecture of
Spark and introduce the SparkR library. We will work through examples
of the API and discuss additional resources to learn more.&lt;/p&gt;
&lt;p&gt;In this tutorial, we will focus on SparkR. The outline of the tutorial
is as follows: - Introduction to cluster computing with Spark -
Getting started with SparkR - Deep dive into SparkR DataFrame API -
Additional resources&lt;/p&gt;
&lt;p&gt;In preparation for this tutorial please install.packages(&amp;quot;SparkR&amp;quot;) in
your system.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Zeydy Ortiz</dc:creator><pubDate>Wed, 14 Sep 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-09-14:pydata-carolinas-2016/scalable-data-science-with-spark-and-r.html</guid></item></channel></rss>