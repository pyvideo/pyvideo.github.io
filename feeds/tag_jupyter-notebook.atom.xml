<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_jupyter-notebook.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-05-10T00:00:00+00:00</updated><entry><title>STEAM Workshops using Jupyter Notebooks, JupyterHub, and Binder</title><link href="https://pyvideo.org/pycon-us-2018/steam-workshops-using-jupyter-notebooks-jupyterhub-and-binder.html" rel="alternate"></link><published>2018-05-10T00:00:00+00:00</published><updated>2018-05-10T00:00:00+00:00</updated><author><name>Carol Willing</name></author><id>tag:pyvideo.org,2018-05-10:pycon-us-2018/steam-workshops-using-jupyter-notebooks-jupyterhub-and-binder.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Middle School and High School students can learn by doing. Jupyter Notebooks and the rich Python ecosystem with libraries on a variety of topics can engage many learners of the sciences and humanities. Interactive content, using Jupyter Widgets and visualization libraries, put the student in charge of manipulating content and extending their learning. Giving students engaging content in familiar subjects encourages them to develop and use computational skills to build upon their interests.&lt;/p&gt;
&lt;p&gt;One difficulty of teaching workshops is access to computers and the ability to install software on those systems. This talk will demonstrate how a workshop organizer or teacher can deploy JupyterHub easily for a class using the Zero to JupyterHub Guide, Kubernetes, and Cloud Services. Even if students only have access to smartphones, tablets, or shared computers, a workshop can be held using Binder which allows a notebook environment to be served at the click of a button to any modern web browser.&lt;/p&gt;
</summary><category term="jupyter notebook"></category><category term="jupyterhub"></category><category term="binder"></category></entry><entry><title>Jupyter notebooks and collaboration</title><link href="https://pyvideo.org/pycon-uk-2017/jupyter-notebooks-and-collaboration.html" rel="alternate"></link><published>2017-10-28T10:30:00+01:00</published><updated>2017-10-28T10:30:00+01:00</updated><author><name>Scott Stevenson</name></author><id>tag:pyvideo.org,2017-10-28:pycon-uk-2017/jupyter-notebooks-and-collaboration.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Git has seen widespread adoption to become the de facto standard for sharing and collaborating on code, and the same is true of Jupyter notebooks as the environment for doing data science. However, herein lies a problem: Git was designed to version plain text files containing source code, and not for storing structured data such as the JSON source of Jupyter notebooks and binary data such as embedded images.&lt;/p&gt;
&lt;p&gt;Without extra tooling and processes, this makes following best practices - such as making small, self-contained patches on topic branches and submitting them for code review - difficult, and the output messy. In this talk, I'll demonstrate the tools and practices that make working in data science more collaborative, more productive, and more fun.&lt;/p&gt;
&lt;p&gt;I'll show you how to use built-in Git features, such as incremental staging of changed files, to avoid introducing noise from changed cell counts, before moving on to show how simple tooling can allow us to automatically clear output cells from notebooks before committing new changes to Git, avoiding adding binary data to our repository.&lt;/p&gt;
&lt;p&gt;Finally, I'll introduce the nbdime tools from the Jupyter project: a set of tools for diffing and merging Jupyter notebooks. I'll demonstrate how to install them, and how to integrate them to Git to finally achieve great integration between Jupyter notebooks and version control for collaborative data science.&lt;/p&gt;
</summary><category term="jupyter notebook"></category><category term="nbdime"></category></entry><entry><title>Scientific Python Tools for Non-Scientific Uses</title><link href="https://pyvideo.org/pyconweb-2017/scientific-python-tools-for-non-scientific-uses.html" rel="alternate"></link><published>2017-05-27T00:00:00+00:00</published><updated>2017-05-27T00:00:00+00:00</updated><author><name>Mike Müller</name></author><id>tag:pyvideo.org,2017-05-27:pyconweb-2017/scientific-python-tools-for-non-scientific-uses.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python is an amazing programming language that is used by many different
communities. Dev-ops, web programmers, sys admins, database programmers
as well as scientists and engineers from many different fields use it daily.
But often members of one sub-community might not be familiar with the
libraries and tools another sub-community uses. Even these libraries are
originally designed for total different purposes, they can be useful for
unintended usages.&lt;/p&gt;
&lt;p&gt;This talk introduces two very use popular scientific Python tools, the Jupyter
Notebook for fast, exploratory Python programming and pandas, the amazingly
useful data analyses library. Both libraries could be called killer apps in
their fields. Come and see what they can offer and how they can simplify your
daily web-programming tasks.&lt;/p&gt;
</summary><category term="jupyter notebook"></category></entry><entry><title>Interactive 3D Visualization in Jupyter Notebooks</title><link href="https://pyvideo.org/euroscipy-2017/interactive-3d-visualization-in-jupyter-notebooks.html" rel="alternate"></link><published>2017-08-31T00:00:00+00:00</published><updated>2017-08-31T00:00:00+00:00</updated><author><name>Vidar Tonaas Fauske</name></author><id>tag:pyvideo.org,2017-08-31:euroscipy-2017/interactive-3d-visualization-in-jupyter-notebooks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Interactive 3D visualization of data is a crucial part of the analysis toolbox for many subfields of computational science and engineering, ranging from fluid dynamics to biology, mathematics, cosmology, and more. With the widespread availability of WebGL in browsers, it is now possible to include GPU accelerated 3D graphics directly in Jupyter Notebooks (www.jupyter.org). As part of the OpenDreamKit project (www.opendreamkit.org), we are working to improve the state of 3D visualization in Notebooks.&lt;/p&gt;
&lt;p&gt;In the last couple of years a number of visualization projects have started to explore this area, including established projects such as VTK, Paraview and MayaVi, as well as newer, smaller projects such as ipyvolume, pythreejs, k3d-jupyter, SciviJS, and unray, the latter three being initiatives from the OpenDreamKit project.&lt;/p&gt;
&lt;p&gt;In this talk we will present the current state of 3D visualization in Jupyter Notebooks and our contributions, including our work to lessen fragmentation and double-work in the field.&lt;/p&gt;
</summary><category term="jupyter notebook"></category></entry><entry><title>Adding interactivity by extending Jupyter Notebook</title><link href="https://pyvideo.org/pycon-israel-2017/adding-interactivity-by-extending-jupyter-notebook.html" rel="alternate"></link><published>2017-06-13T00:00:00+00:00</published><updated>2017-06-13T00:00:00+00:00</updated><author><name>Beni Cherniavsky-Paskin</name></author><id>tag:pyvideo.org,2017-06-13:pycon-israel-2017/adding-interactivity-by-extending-jupyter-notebook.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter (formerly IPython) Notebook is a &amp;quot;better REPL&amp;quot; that can be easily extended. I'll demonstrate how writing new backends is a productive way to expose existing tools (e.g. Ansible) in a more interactive way.&lt;/p&gt;
</summary><category term="jupyter notebook"></category></entry><entry><title>Data Science &amp; Data Visualization in Python. How to harness power of Python for social good?</title><link href="https://pyvideo.org/pydata-berlin-2017/data-science-data-visualization-in-python-how-to-harness-power-of-python-for-social-good.html" rel="alternate"></link><published>2017-06-30T00:00:00+00:00</published><updated>2017-06-30T00:00:00+00:00</updated><author><name>Radovan Kavicky</name></author><id>tag:pyvideo.org,2017-06-30:pydata-berlin-2017/data-science-data-visualization-in-python-how-to-harness-power-of-python-for-social-good.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python as an Open Data Science tool offers many libraries for data visualization and I will show you how to use and combine the best. I strongly believe that power of data is not only in the information &amp;amp; insight that data can provide us, Data is and can be really beautiful and can not only transform our perception but also the world that we all live in.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In my talk I will primarily focus on answering/offer the answer to these questions:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Why we need data science and why more and more people should be really interested in analyzing data and data visualization? (motivation)&lt;/li&gt;
&lt;li&gt;What is data science and how to start doing it in Python? (introduction of procedures, tools, most popular IDE-s for Python, etc.)&lt;/li&gt;
&lt;li&gt;What tools for data analysis and data visualization Python offers? (in each stage of analysis the best libraries will be shown for the specific purpose; as for data visualization we will focus particularly on Bokeh, Seaborn, Plotly and use of Jupyter Notebook and Plotly)&lt;/li&gt;
&lt;li&gt;How to 'unlock' the insight hidden in data through Python and how to use it to transform not only public administration or business, but ultimately the transformation of the whole society and economy towards the insight &amp;amp; knowledge based? (potential of data science)&lt;/li&gt;
&lt;li&gt;Open Data, Open Government Partnership, Open Public Administration &amp;amp; all the advantages of Open Data Science &amp;amp; Python. Data-Driven Approach. Everywhere. Now. (the end of talk +vision)&lt;/li&gt;
&lt;/ul&gt;
</summary><category term="python"></category><category term="data-science"></category><category term="data-visualization"></category><category term="analytics"></category><category term="PyData"></category><category term="PyDataBLN"></category><category term="PyDataBerlin"></category><category term="PyDataBA"></category><category term="PyDataBratislava"></category><category term="talk"></category><category term="Data"></category><category term="Bokeh"></category><category term="Social Good"></category><category term="datascience"></category><category term="jupyter"></category><category term="open science"></category><category term="open data science"></category><category term="DataVisualization"></category><category term="data-analysis"></category><category term="analysis"></category><category term="matplotlib"></category><category term="numpy"></category><category term="data wrangling"></category><category term="jupyter notebook"></category><category term="pandas"></category><category term="machine learning"></category><category term="deep learning"></category><category term="Open Data"></category><category term="Citizen Data Science"></category></entry><entry><title>Prototyping Interactive Dashboards with Jupyter Notebooks</title><link href="https://pyvideo.org/pydata-barcelona-2017/prototyping-interactive-dashboards-with-jupyter-notebooks.html" rel="alternate"></link><published>2017-05-21T12:45:00+02:00</published><updated>2017-05-21T12:45:00+02:00</updated><author><name>Camilo Cardona</name></author><id>tag:pyvideo.org,2017-05-21:pydata-barcelona-2017/prototyping-interactive-dashboards-with-jupyter-notebooks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, I describe my experience in using jupyter-dashboards, ipywidgets and other libraries to build basic prototypes of data exploration dashboards for datasets related to Internet traffic and packet-switching networks. We’ll go over various examples on how to build and use the widgets to navigate the data, visualize analysis, and evaluate optimization changes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As python programmers, we often use jupyter notebooks as a platform for reproducible data analysis and publication of results. The jupyter ecosystem is still under-utilized for projects that require interactions from non-coder users, such as explorative dashboards or Business intelligence applications. There are other specialised options for these UI/UX interfaces, but integrating them into the analysis pipeline (e.g. Jupyter) is often rather hard. Preferably, we would be able to prototype these interactive applications without leaving our environment.&lt;/p&gt;
&lt;p&gt;Jupyter-dashboards, ipywidgets, and other typical pydata libraries provide jupyter with the capabilities to create flexible, and rather powerful interactive elements. This toolset can be used in small projects to create the final facing interface for a limited number of end users. For bigger projects, a more robust UI/UX is normally required to support larger number of simultaneous users. However, the jupyter-dashboard/ipywidgets toolset can still be useful in these cases as an end-to-end prototyping platform, allowing us to get feedback from users at early stages of the project, thus helping us better steer our development.&lt;/p&gt;
&lt;p&gt;In this talk, I share experiences of using this toolset for different use cases related to analysis of Internet traffic and network engineering. I’ll go over examples of how to build widgets to explore the Internet traffic and other network data, while highlighting some of its characteristics. Furthermore, I’ll describe some optimisations performed by network engineers on their traffic, such as load balancing, and how the tools can be used to evaluate them.&lt;/p&gt;
</summary><category term="jupyter notebook"></category></entry><entry><title>Extending Jupyter with Google Cloud Storage file system backend</title><link href="https://pyvideo.org/pydata-barcelona-2017/extending-jupyter-with-google-cloud-storage-file-system-backend.html" rel="alternate"></link><published>2017-05-20T15:45:00+02:00</published><updated>2017-05-20T15:45:00+02:00</updated><author><name>Egor Bulychev</name></author><id>tag:pyvideo.org,2017-05-20:pydata-barcelona-2017/extending-jupyter-with-google-cloud-storage-file-system-backend.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter has a modular architecture which allows extending it in numerous ways. This talk presents src-d/jgscm, Google Cloud Storage Jupyter file system backend which provides the ability to work with notebooks and other files directly in Google Cloud Storage. The described approach can be used for writing similar backends, e.g. for Amazon Cloud.&lt;/p&gt;
&lt;p&gt;See more here : &lt;a class="reference external" href="https://egorbu.github.io/pydata_2017_barcelona/index.html"&gt;https://egorbu.github.io/pydata_2017_barcelona/index.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;src-d/jgscm is a Jupyter file system backend for Google Cloud Storage. It allows to work with notebooks and other files directly in Google Cloud Storage. It's codebase is rather small and simple thanks to Jupyter's modular architecture. We start from the very basics, revise how Google Cloud Storage works and how Jupyter deals with the virtual file system and end up with the complete production-tested backend implementation. The described ideas are rather versatile and can be re-used to create backends for similar cloud storage systems, e.g. Amazon.&lt;/p&gt;
</summary><category term="jupyter notebook"></category></entry><entry><title>Running jupyter notebook remotely in a docker swarm cluster</title><link href="https://pyvideo.org/pydata-barcelona-2017/running-jupyter-notebook-remotely-in-a-docker-swarm-cluster.html" rel="alternate"></link><published>2017-05-20T15:00:00+02:00</published><updated>2017-05-20T15:00:00+02:00</updated><author><name>Jordi Deu-Pons</name></author><id>tag:pyvideo.org,2017-05-20:pydata-barcelona-2017/running-jupyter-notebook-remotely-in-a-docker-swarm-cluster.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The current version of Jupyter Notebook computes the document state at the browser side, this is a problem if you run long jobs in a remote notebook from a laptop. If you close the browser you lose all the output of the current running cell. I will explain how we solved this problem in our lab. This solution it also allows a &amp;quot;walkie-talkie&amp;quot; like real-time collaboration.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The solution is based on running a docker container with a browser and a VNC server. All the remote access to the notebooks is done using Apache Guacamole a clientless remote desktop gateway. Everything is running on a dynamic docker swarm cluster of 20 nodes. As a lateral effect, this solution it also allows a real-time collaboration between users in a way that multiple users can access at the same time the same desktop (but they have to fight for the mouse and the keyboard).&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/jordeu/pytalks/tree/master/20170520_pydata_jupyter_in_a_docker_cluster"&gt;https://github.com/jordeu/pytalks/tree/master/20170520_pydata_jupyter_in_a_docker_cluster&lt;/a&gt;&lt;/p&gt;
</summary><category term="jupyter notebook"></category><category term="docker"></category><category term="swarm"></category></entry><entry><title>bqplot Seamless Interactive Visualizations in the Jupyter Notebook</title><link href="https://pyvideo.org/scipy-2017/bqplot-seamless-interactive-visualizations-in-the-jupyter-notebook.html" rel="alternate"></link><published>2017-07-17T00:00:00+00:00</published><updated>2017-07-17T00:00:00+00:00</updated><author><name>Dhruv Madeka</name></author><id>tag:pyvideo.org,2017-07-17:scipy-2017/bqplot-seamless-interactive-visualizations-in-the-jupyter-notebook.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;bqplot is a Python plotting library based on d3.js that offers its functionality directly in the Jupyter Notebook, including selections, interactions, and arbitrary css customizations. In bqplot, every element of a chart is an interactive ipython widget that can be bound to a python function, which serves as the callback when an interaction takes place. The bidirectional communication between Python and JavaScript is a feature of bqplot that makes the python code aware of any interactions the user has with the visualization. This allows the rapid generation of full fledged web applications directly in the Notebook with just a few lines of Python code. We will also review some of bqplot's many new and innovative visualizations and interactions - including the MarketMap and the FastIntervalSelector and demonstrate concrete applications that leverage them to enhance a Data Science or Machine Learning workflow.     The talk will also cover bqplot's seamless integration with the native Jupyter widgets - including layout and styling of web applications, as well as the integration with other widget libraries such as ipyleaflet or ipyvolume. We will also demonstrate the simple way to export bqplot charts as stand alone web applications through the embedding mechanism of the ipywidgets library.&lt;/p&gt;
&lt;p&gt;Finally, we will highlight bqplot as the first plotting library to have complete integration with the new JupyterLab IDE by demonstrating dashboarding, resizing and custom integrations.&lt;/p&gt;
</summary><category term="bqplot"></category><category term="jupyter notebook"></category></entry><entry><title>Deploying Interactive Jupyter Dashboards for Visualizing Hundreds of Millions of Datapoints, in 30 Lines of Python</title><link href="https://pyvideo.org/scipy-2017/deploying-interactive-jupyter-dashboards-for-visualizing-hundreds-of-millions-of-datapoints-in-30-lines-of-python.html" rel="alternate"></link><published>2017-07-17T00:00:00+00:00</published><updated>2017-07-17T00:00:00+00:00</updated><author><name>Philipp Rudiger</name></author><id>tag:pyvideo.org,2017-07-17:scipy-2017/deploying-interactive-jupyter-dashboards-for-visualizing-hundreds-of-millions-of-datapoints-in-30-lines-of-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;It can be difficult to assemble the right set of packages from the Python scientific software ecosystem to solve complex problems. This presentation will show step by step how to make and deploy a concise, fast, and fully reproducible recipe for interactive visualization of millions or billions of datapoints using very few lines of Python in a Jupyter notebook using a combination of the HoloViews, Datashader, Dask, Bokeh and paramNB libraries and deployed as a Jupyter Dashboard.&lt;/p&gt;
</summary><category term="jupyter notebook"></category></entry><entry><title>nbgrader - A Tool for Creating and Grading Assignments in the Jupyter Notebook</title><link href="https://pyvideo.org/scipy-2017/nbgrader-a-tool-for-creating-and-grading-assignments-in-the-jupyter-notebook.html" rel="alternate"></link><published>2017-07-17T00:00:00+00:00</published><updated>2017-07-17T00:00:00+00:00</updated><author><name>Jessica Hamrick</name></author><id>tag:pyvideo.org,2017-07-17:scipy-2017/nbgrader-a-tool-for-creating-and-grading-assignments-in-the-jupyter-notebook.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As usage of the Jupyter notebook in scientific computing becomes increasingly ubiquitous, so too does its presence in classrooms. In this talk, I will describe &lt;em&gt;nbgrader&lt;/em&gt;, a tool developed by and for instructors to create and grade rich, interactive assignments in the notebook. On its own, nbgrader provides functionality for creating assignments and then for both automatic and manual grading of submissions. When combined with JupyterHub, it supports the full grading pipeline: creating assignments, releasing them to students, collecting submissions, grading, and generating personalized feedback. To demonstrate the use of nbgrader, I will walk the audience through the basics of the tool, and then outline two example workflows: one using standalone nbgrader, and one using nbgrader with JupyterHub. In doing so, I will illustrate to instructors how they can create their own assignments in the notebook using nbgrader.&lt;/p&gt;
</summary><category term="jupyter notebook"></category><category term="nbgrader"></category></entry><entry><title>The Jupyter Interactive Widget Ecosystem</title><link href="https://pyvideo.org/scipy-2017/the-jupyter-interactive-widget-ecosystem.html" rel="alternate"></link><published>2017-07-11T00:00:00+00:00</published><updated>2017-07-11T00:00:00+00:00</updated><author><name>Matt Craig</name></author><id>tag:pyvideo.org,2017-07-11:scipy-2017/the-jupyter-interactive-widget-ecosystem.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter widgets are powerful tools for building user interfaces with graphical controls such as sliders and text boxes inside a Jupyter notebook. Interactive widgets can also be rendered in Sphinx documentation, nbviewer, and static web pages. Jupyter widgets are more than a collection of controls, they also are a framework that makes it easy to build custom GUI controls. Examples of custom widget packages include libraries for interactive 2-D charting (bqplot), 3-D graphics (pythreejs, ipyvolume), mapping (ipyleaflet), and more.&lt;/p&gt;
</summary><category term="jupyter notebook"></category><category term="jupyter widgets"></category></entry><entry><title>Making your code faster: Cython and parallel processing in the Jupyter Notebook</title><link href="https://pyvideo.org/pydata-dc-2016/making-your-code-faster-cython-and-parallel-processing-in-the-jupyter-notebook.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Gustavo Patino</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/making-your-code-faster-cython-and-parallel-processing-in-the-jupyter-notebook.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData DC 2016&lt;/p&gt;
&lt;p&gt;Github: &lt;a class="reference external" href="https://github.com/gapatino/Making-Your-Code-Faster-Cython-and-parallel-processing-in-the-Jupyter-Notebook"&gt;https://github.com/gapatino/Making-Your-Code-Faster-Cython-and-parallel-processing-in-the-Jupyter-Notebook&lt;/a&gt;
Slides: &lt;a class="reference external" href="http://www.slideshare.net/PyData/making-your-code-faster-cython-and-parallel-processing-in-the-jupyter-notebook"&gt;http://www.slideshare.net/PyData/making-your-code-faster-cython-and-parallel-processing-in-the-jupyter-notebook&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As the complexity and scope of applications grow, it is very common to run into slow performance issues. In Python, it is possible to improve the speed of execution with the use of parallel processing and the Cython compiler. The Jupyter Notebook makes the implementation of both of them a relatively simple task, which will be the focus of this session.&lt;/p&gt;
</summary><category term="code"></category><category term="Cython"></category><category term="jupyter"></category><category term="jupyter notebook"></category><category term="notebook"></category><category term="parallel"></category><category term="processing"></category></entry><entry><title>Popping Kernels: An Exploration of Kernel Development for Jupyter Notebooks</title><link href="https://pyvideo.org/pydata-chicago-2016/popping-kernels-an-exploration-of-kernel-development-for-jupyter-notebooks.html" rel="alternate"></link><published>2016-08-26T00:00:00+00:00</published><updated>2016-08-26T00:00:00+00:00</updated><author><name>Safia Abdalla</name></author><id>tag:pyvideo.org,2016-08-26:pydata-chicago-2016/popping-kernels-an-exploration-of-kernel-development-for-jupyter-notebooks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Chicago 2016&lt;/p&gt;
&lt;p&gt;This talk will give individuals with no kernel experience and some Python experience, a brief introduction to the concepts they need to understand in order to develop kernels. This talk will also be useful to individuals who are looking for fun projects that will allow them to strengthen their skills in a particular programming language.&lt;/p&gt;
</summary><category term="development"></category><category term="jupyter"></category><category term="jupyter notebook"></category></entry><entry><title>Setting up Python for machine learning: scikit-learn and IPython Notebook</title><link href="https://pyvideo.org/data-school/scikit-learn-02-machine-learning-setup.html" rel="alternate"></link><published>2015-04-15T00:00:00+00:00</published><updated>2015-04-15T00:00:00+00:00</updated><author><name>Kevin Markham</name></author><id>tag:pyvideo.org,2015-04-15:data-school/scikit-learn-02-machine-learning-setup.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Want to get started with machine learning in Python? I'll discuss the pros and cons of the scikit-learn library, show how to install my preferred Python distribution, and demonstrate the basic functionality of the IPython Notebook. If you don't yet know any Python, I'll also provide four recommended resources for learning Python.&lt;/p&gt;
&lt;p&gt;This is the second video in the series, &lt;a class="reference external" href="http://www.dataschool.io/machine-learning-with-scikit-learn/"&gt;Introduction to machine learning with scikit-learn&lt;/a&gt;. The notebook and resources shown in the video are available on &lt;a class="reference external" href="https://github.com/justmarkham/scikit-learn-videos"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</summary><category term="machine learning"></category><category term="data science"></category><category term="scikit-learn"></category><category term="tutorial"></category><category term="Data School"></category><category term="IPython notebook"></category><category term="Jupyter notebook"></category></entry><entry><title>Jupyter: Notebooks in Multiple Languages for Data Science</title><link href="https://pyvideo.org/pydata-amsterdam-2016/jupyter-notebooks-in-multiple-languages-for-data-science.html" rel="alternate"></link><published>2016-03-26T00:00:00+00:00</published><updated>2016-03-26T00:00:00+00:00</updated><author><name>Thomas Kluyver</name></author><id>tag:pyvideo.org,2016-03-26:pydata-amsterdam-2016/jupyter-notebooks-in-multiple-languages-for-data-science.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2016&lt;/p&gt;
&lt;p&gt;We'll talk about how the Jupyter Notebook has evolved from a Python specific tool to a general data science tool that supports many different languages, and about our own experiences in supporting a wide variety of languages for data science. We'll also demonstrate some of the new features and ideas being developed in and around the project.&lt;/p&gt;
&lt;p&gt;Jupyter notebooks have become an invaluable tool for all kinds of data science. Originally developed as part of the IPython project, notebooks have evolved from a Python specific tool to support many programming languages; more than 50 different execution kernels have now been published. For all of these languages, notebooks are a way to record and describe a data science workflow, and then share it, publicly or privately, allowing the recipients to easily modify and execute the code.&lt;/p&gt;
&lt;p&gt;We’ll describe the architectural changes and decisions involved in the transition to supporting multiple languages, as well as our own experience in supporting data science languages ranging from C++ to R to Bash. You’ll also get a high-level understanding of how to create a new kernel, if a language you’re excited about is not yet supported.&lt;/p&gt;
&lt;p&gt;We’ll also highlight some of the current development work taking place in and around Jupyter, including redesigned UI, mechanisms for collaboration on notebooks, ways to share live, executable notebooks online, and projects that reuse the Jupyter machinery in different user interfaces.&lt;/p&gt;
&lt;p&gt;Slides available here: &lt;a class="reference external" href="https://docs.google.com/presentation/d/1PHnnkKYgjq1lcSDaVyhZP0Fs7qC70iA07b2Jv0uisUE/edit?usp=sharing"&gt;https://docs.google.com/presentation/d/1PHnnkKYgjq1lcSDaVyhZP0Fs7qC70iA07b2Jv0uisUE/edit?usp=sharing&lt;/a&gt;&lt;/p&gt;
</summary><category term="jupyter notebook"></category></entry><entry><title>Store and manage data effortlessly with HDF5</title><link href="https://pyvideo.org/pydata-amsterdam-2016/store-and-manage-data-effortlessly-with-hdf5.html" rel="alternate"></link><published>2016-03-26T00:00:00+00:00</published><updated>2016-03-26T00:00:00+00:00</updated><author><name>Margaret Mahan</name></author><id>tag:pyvideo.org,2016-03-26:pydata-amsterdam-2016/store-and-manage-data-effortlessly-with-hdf5.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2016&lt;/p&gt;
&lt;p&gt;Description&lt;/p&gt;
&lt;p&gt;Are you looking for accessible, compressed, organized data? HDF5 might be the solution you’re looking for. HDF5 works like a file system within a file, designed for flexible and efficient storage and I/O for high volume, complex data. Come learn from a Pyentist how to leverage HDF5, get started with h5py, and see a real-world example of a processing pipeline utilizing HDF5.&lt;/p&gt;
&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;Are you&lt;/p&gt;
&lt;p&gt;a Pyentist1?
frequently ‘grep’-ing?
drowning in ASCII files?
extending filenames for each processing step?
looking for accessible, compressed, organized data?
If you answered yes to any of these questions, then HDF5 might be the solution you’re looking for. HDF5 is entirely open source and supported by a variety of programming languages and tools, including Python (h5py). HDF5 not only supports large, complex, heterogeneous data but is self-describing and supports data slicing. In this talk, you’ll learn about embracing HDF5 from a Pyentist.&lt;/p&gt;
&lt;p&gt;This talk is aimed at data scientists who have large, numerical datasets that need to be managed and stored but also accessed and processed efficiently. Basic knowledge of NumPy and UNIX will be useful for attendees but not required. Attendees will learn how to get started with h5py, as well as how to leverage HDF5 in order to attain accessible, compressed, and organized data.&lt;/p&gt;
&lt;p&gt;HDF5 stands for Hierarchical Data Format, version 5. It is a file format, library, and data model for storing and managing data. More simply, HDF5 can be described as a file system within a file. An HDF5 file contains two kinds of objects, namely, datasets and groups. Datasets work like NumPy arrays while groups work like dictionaries that hold datasets and other groups. In addition, objects can have attributes, or metadata. HDF5 is designed for flexible and efficient storage and I/O for high volume, complex data. Data scientists will find HDF5 to be invaluable for managing, manipulating, and storing their data.&lt;/p&gt;
&lt;p&gt;Part of this talk will demonstrate how to get started with HDF5. In this demo, attendees will learn how to: create and handle HDF5 files using h5py, manage and manipulate datasets, work with groups, and make use of attributes. A real-world example of a processing pipeline of brain recordings, utilizing HDF5 for storing and managing data at each processing step, will be presented. Attendees will have access to an IPython notebook to follow along during the demo and explore examples. After this talk, attendees will be able to begin using HDF5 to effortlessly store and manage their data.&lt;/p&gt;
</summary><category term="hdf5"></category><category term="h5py"></category><category term="jupyter notebook"></category></entry><entry><title>Diffing and Merging Jupyter Notebooks with nbdime</title><link href="https://pyvideo.org/scipy-2016/diffing-and-merging-jupyter-notebooks-with-nbdime-scipy-2016-min-ragan-kelley.html" rel="alternate"></link><published>2016-07-15T00:00:00+00:00</published><updated>2016-07-15T00:00:00+00:00</updated><author><name>Min Ragan Kelley</name></author><id>tag:pyvideo.org,2016-07-15:scipy-2016/diffing-and-merging-jupyter-notebooks-with-nbdime-scipy-2016-min-ragan-kelley.html</id><summary type="html"></summary><category term="SciPy 2016"></category><category term="jupyter"></category><category term="jupyter notebook"></category></entry><entry><title>JupyterLab: Building Blocks for Interactive Computing</title><link href="https://pyvideo.org/scipy-2016/jupyterlab-building-blocks-for-interactive-computing-scipy-2016-brian-granger.html" rel="alternate"></link><published>2016-07-15T00:00:00+00:00</published><updated>2016-07-15T00:00:00+00:00</updated><author><name>Brian Granger</name></author><id>tag:pyvideo.org,2016-07-15:scipy-2016/jupyterlab-building-blocks-for-interactive-computing-scipy-2016-brian-granger.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Project Jupyter provides building blocks for interactive and exploratory computing. These building blocks make science and data science reproducible across over 40 programming language (Python, Julia, R, etc.). Central to the project is the Jupyter Notebook, a web-based interactive computing platform that allows users to author data- and code-driven narratives - computational narratives - that combine live code, equations, narrative text, visualizations, interactive dashboards and other media.&lt;/p&gt;
&lt;p&gt;While the Jupyter Notebook has proved to be an incredibly productive way of working with code and data interactively, it is helpful to decompose notebooks into more primitive building blocks: kernels for code execution, input areas for typing code, markdown cells for composing narrative content, output areas for showing results, terminals, etc. The fundamental idea of JupyterLab is to offer a user interface that allows users to assemble these building blocks in different ways to support interactive workflows that include, but go far beyond, Jupyter Notebooks.&lt;/p&gt;
&lt;p&gt;JupyterLab accomplishes this by providing a modular and extensible user interface that exposes these building blocks in the context of a powerful work space. Users can arrange multiple notebooks, text editors, terminals, output areas, etc. on a single page with multiple panels, tabs, splitters, and collapsible sidebars with a file browser, command palette and integrated help system. The codebase and UI of JupyterLab is based on a flexible plugin system that makes it easy to extend with new components.&lt;/p&gt;
&lt;p&gt;In this talk, we will demonstrate the JupyterLab interface, its codebase, and describe how it fits within the overall roadmap of the project.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="jupyter"></category><category term="jupyterlab"></category><category term="jupyter notebook"></category></entry><entry><title>Keynote: Project Jupyter</title><link href="https://pyvideo.org/scipy-2016/keynote-project-jupyter-scipy-2016-brian-granger.html" rel="alternate"></link><published>2016-07-15T00:00:00+00:00</published><updated>2016-07-15T00:00:00+00:00</updated><author><name>Brian Granger</name></author><id>tag:pyvideo.org,2016-07-15:scipy-2016/keynote-project-jupyter-scipy-2016-brian-granger.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Brian Granger is an Associate Professor of Physics at Cal Poly State University in San Luis Obispo, CA. He has a background in theoretical physics, with a Ph.D from the University of Colorado. His current research interests include quantum computing, parallel and distributed computing and interactive computing environments for scientific computing and data science. He is a leader of the IPython project, co-founder of Project Jupyter and is an active contributor to a number of other open source projects focused on data science in Python. He is a board member of the NumFocus Foundation and a fellow at Cal Poly’s Center for Innovation and Entrepreneurship. He is &amp;#64;ellisonbg on Twitter and GitHub.&lt;/p&gt;
&lt;p&gt;Announcement of Altair, Altair is a declarative statistical visualization library for Python. Altair is developed by Brian Granger and Jake Vanderplas in close collaboration with the UW Interactive Data Lab.&lt;/p&gt;
&lt;p&gt;With Altair, you can spend more time understanding your data and its meaning. Altair's API is simple, friendly and consistent and built on top of the powerful Vega-Lite JSON specification. This elegant simplicity produces beautiful and effective visualizations with a minimal amount of code.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="altair"></category><category term="jupyter"></category><category term="jupyter notebook"></category></entry><entry><title>Labs in the Wild: Teaching Signal Processing Using Wearables &amp; Jupyter Notebooks</title><link href="https://pyvideo.org/scipy-2016/labs-in-the-wild-teaching-signal-processing-using-wearables-jupyter-notebooks-scipy-2016.html" rel="alternate"></link><published>2016-07-15T00:00:00+00:00</published><updated>2016-07-15T00:00:00+00:00</updated><author><name>Demba Ba</name></author><id>tag:pyvideo.org,2016-07-15:scipy-2016/labs-in-the-wild-teaching-signal-processing-using-wearables-jupyter-notebooks-scipy-2016.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter notebooks and the Python ecosystem provide a unique opportunity for interactive, web-based, teaching of content that has not traditionally leveraged scientific computing resources. We discuss the design and implementation of a new biological signal processing course at Harvard, ES155, which fuses Wearable technology and cloud-based analysis of data. ES155 bridges the gap that has traditionally existed between Electrical Engineering and Computer Science education, in a framework that we term “Labs in the Wild”. In the process of designing the course, we have had to solve the problem of serving Jupyter notebooks on the cloud reliably using AWS EC2 instances. This is a challenging problem because a successful approach must be scalable, cost-effective, reliable, and address the privacy concerns associated with cloud-based technologies. We describe our system in this talk, and perform a live demo of how students in our class interact with the system, and give examples of ingenious final projects put together by students. Being cloud-based, our system lowers the barrier of entry for students to begin using Python for scientific computing.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="jupyter notebook"></category><category term="wearable"></category><category term="education"></category></entry><entry><title>How to “Scrape” Together a Great Dataset Using Things You Find on the Internet Using Python &amp; SciP</title><link href="https://pyvideo.org/scipy-2016/how-to-scrape-together-a-great-dataset-using-things-you-find-on-the-internet-using-python-scip.html" rel="alternate"></link><published>2016-07-14T00:00:00+00:00</published><updated>2016-07-14T00:00:00+00:00</updated><author><name>Deborah Hanus</name></author><id>tag:pyvideo.org,2016-07-14:scipy-2016/how-to-scrape-together-a-great-dataset-using-things-you-find-on-the-internet-using-python-scip.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Using Jupyter notebooks and scikit-learn, you’ll predict whether a movie is likely to win an Oscar or be a box office hit. I’ll walk through the most important steps of creating an effective dataset using information that you find on the Internet: asking a question your data can answer, writing a web scraper, and answering those questions using nothing but Python libraries and data from the Internet. To illustrate how these steps fit together, I walk through building a dataset from IMDB data and use it to predict &lt;a class="reference external" href="http://oscarpredictor.github.io/"&gt;what makes a winning Oscar movie&lt;/a&gt;. To preview our findings, check out &lt;a class="reference external" href="https://youtu.be/84IZ8Gn6PJ"&gt;this trailer&lt;/a&gt; and the &lt;a class="reference external" href="https://github.com/oscarpredictor/oscar-predictor"&gt;github repository&lt;/a&gt;!&lt;/p&gt;
</summary><category term="scrapping"></category><category term="oscarpredictor"></category><category term="jupyter notebook"></category><category term="scikit-learn"></category></entry><entry><title>JupyterHub as an Interactive Supercomputing Gateway</title><link href="https://pyvideo.org/scipy-2016/jupyterhub-as-an-interactive-supercomputing-gateway-scipy-2016-michael-milligan.html" rel="alternate"></link><published>2016-07-14T00:00:00+00:00</published><updated>2016-07-14T00:00:00+00:00</updated><author><name>Michael Milligan</name></author><id>tag:pyvideo.org,2016-07-14:scipy-2016/jupyterhub-as-an-interactive-supercomputing-gateway-scipy-2016-michael-milligan.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At the Minnesota Supercomputing Institute we are exploring ways to provide the immediacy and flexibility of interactive computing within the batch-scheduled, tightly controlled world of traditional cluster supercomputing. As Jupyter Notebook has gained in popularity, the steps needed to use it within such an environment have proven to be a barrier to entry even as increasingly powerful Python tools have developed to take advantage of large computational resources. JupyterHub to the rescue! Except out of the box, it doesn't know anything about resource types, job submission, and so on. We developed BatchSpawner and friends as a general JupyterHub backend for batch-scheduled environments. In this talk I will walk through how we have deployed JupyterHub to provide a user-friendly gateway to interactive supercomputing.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="hpc"></category><category term="jupyterhub"></category><category term="jupyter"></category><category term="jupyter notebook"></category><category term="supercomputing"></category></entry><entry><title>Reproducible, One Button Workflows with the Jupyter Notebook &amp; Scons</title><link href="https://pyvideo.org/scipy-2016/reproducible-one-button-workflows-with-the-jupyter-notebook-scons-scipy-2016-jessica-hamrick.html" rel="alternate"></link><published>2016-07-14T00:00:00+00:00</published><updated>2016-07-14T00:00:00+00:00</updated><author><name>Jessica Hamrick</name></author><id>tag:pyvideo.org,2016-07-14:scipy-2016/reproducible-one-button-workflows-with-the-jupyter-notebook-scons-scipy-2016-jessica-hamrick.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;What is the best way to develop analysis code in the Jupyter notebook, while managing complex dependencies between analyses? In this talk, I will introduce nbflow, which is a project that integrates a Python-based build system (SCons) with the Jupyter notebook, enabling researchers to easily build sophisticated,
complex analysis pipelines entirely within notebooks while still maintaining a &amp;quot;one-button workflow&amp;quot; in which all analyses can be executed, in the correct order, from a single command. I will show how nbflow can be applied to existing analyses and how it can be used to construct an analysis pipeline stretching the entire way from data cleaning, to computing statistics, to generating figures,
and even to automatically generating LaTeX commands that can be used in publications to format results without the risk of copy-and-paste error.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="jupyter"></category><category term="jupyter notebook"></category><category term="workflow"></category><category term="nbflow"></category></entry><entry><title>Sharing Reproducible Environments with Binder</title><link href="https://pyvideo.org/scipy-2016/sharing-reproducible-environments-with-binder-scipy-2016-andrew-osheroff.html" rel="alternate"></link><published>2016-07-14T00:00:00+00:00</published><updated>2016-07-14T00:00:00+00:00</updated><author><name>Andrew Osheroff</name></author><id>tag:pyvideo.org,2016-07-14:scipy-2016/sharing-reproducible-environments-with-binder-scipy-2016-andrew-osheroff.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Binder (&lt;a class="reference external" href="http://mybinder.org"&gt;http://mybinder.org&lt;/a&gt;) is a service that bundles GitHub repositories with code, Jupyter notebooks, and data into reproducible, executable environments that can be launched instantaneously in the browser with the click of a button. Under the hood, Binder uses simple and flexible dependency specifications to build Docker images on demand, and then launches and schedules them across a public Kubernetes cluster. In this talk, I’ll describe in detail how Binder works, and highlight some exciting use cases. I’ll then describe several future directions for the project, including handling larger datasets, lowering barriers for environment specification, and supporting custom deployments with user-provided computing resources.&lt;/p&gt;
</summary><category term="SciPy 2016"></category><category term="binder"></category><category term="jupyter notebook"></category></entry></feed>