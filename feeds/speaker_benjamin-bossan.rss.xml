<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Benjamin Bossan</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 08 Jul 2024 00:00:00 +0000</lastBuildDate><item><title>Fine-tuning large models on local hardware</title><link>https://pyvideo.org/europython-2024/fine-tuning-large-models-on-local-hardware.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;[EuroPython 2024 â€” Forum Hall on 2024-07-11]&lt;/p&gt;
&lt;p&gt;Fine-tuning large models on local hardware by Benjamin Bossan&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://ep2024.europython.eu/session/fine-tuning-large-models-on-local-hardware"&gt;https://ep2024.europython.eu/session/fine-tuning-large-models-on-local-hardware&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Fine-tuning big neural nets like Large Language Models (LLMs) has traditionally been prohibitive due to high hardware requirements. However, Parameter-Efficient Fine-Tuning (PEFT) and quantization enable the training of large models on modest hardware. Thanks to the PEFT library and the Hugging Face ecosystem, these techniques are now accessible to a broad audience.&lt;/p&gt;
&lt;p&gt;Expect to learn:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;what the challenges are of fine-tuning large models&lt;/li&gt;
&lt;li&gt;what solutions have been proposed and how they work&lt;/li&gt;
&lt;li&gt;practical examples of applying the PEFT library&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;---&lt;/p&gt;
&lt;p&gt;This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License: &lt;a class="reference external" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;https://creativecommons.org/licenses/by-nc-sa/4.0/&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Benjamin Bossan</dc:creator><pubDate>Mon, 08 Jul 2024 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2024-07-08:/europython-2024/fine-tuning-large-models-on-local-hardware.html</guid><category>EuroPython 2024</category></item><item><title>skorch: A scikit-learn compatible neural network library...</title><link>https://pyvideo.org/pydata-berlin-2019/skorch-a-scikit-learn-compatible-neural-network-library.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Speaker: Benjamin Bossan&lt;/p&gt;
&lt;p&gt;Track:PyData
This talk is about the open source package [skorch](https://github.com/skorch-dev/skorch), a wrapper library that allows you to combine the best of sklearn and PyTorch. It covers when it makes sense to use skorch and highlights interesting features.&lt;/p&gt;
&lt;p&gt;Recorded at the PyConDE &amp;amp; PyData Berlin 2019 conference.
&lt;a class="reference external" href="https://pycon.de"&gt;https://pycon.de&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More details at the conference page: &lt;a class="reference external" href="https://de.pycon.org/program/NMXSE7"&gt;https://de.pycon.org/program/NMXSE7&lt;/a&gt;
Twitter:  &lt;a class="reference external" href="https://twitter.com/pydataberlin"&gt;https://twitter.com/pydataberlin&lt;/a&gt;
Twitter:  &lt;a class="reference external" href="https://twitter.com/pyconde"&gt;https://twitter.com/pyconde&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Benjamin Bossan</dc:creator><pubDate>Thu, 10 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-10:/pydata-berlin-2019/skorch-a-scikit-learn-compatible-neural-network-library.html</guid><category>PyData Berlin 2019</category></item></channel></rss>