<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_mike-cunha.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2017-11-27T00:00:00+00:00</updated><entry><title>Addressing Prejudice in Text Data</title><link href="https://pyvideo.org/pydata-new-york-city-2017/addressing-prejudice-in-text-data.html" rel="alternate"></link><published>2017-11-27T00:00:00+00:00</published><updated>2017-11-27T00:00:00+00:00</updated><author><name>Mike Cunha</name></author><id>tag:pyvideo.org,2017-11-27:pydata-new-york-city-2017/addressing-prejudice-in-text-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Bias for and against genders, races, and more exist in popular NLP datasets like GloVe and word2vec. This talk will discuss how to detect and remove prejudice in text datasets and derived word embeddings along with the impacts of ignoring them.&lt;/p&gt;
</summary></entry></feed>