<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_valentin-dalibard.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2017-05-07T00:00:00+00:00</updated><entry><title>Interactively Analyse 100GB of Data using Spark, Amazon EMR and Zeppelin</title><link href="https://pyvideo.org/pydata-london-2017/interactively-analyse-100gb-of-data-using-spark-amazon-emr-and-zeppelin.html" rel="alternate"></link><published>2017-05-07T00:00:00+00:00</published><updated>2017-05-07T00:00:00+00:00</updated><author><name>Raoul-Gabriel Urma</name></author><id>tag:pyvideo.org,2017-05-07:pydata-london-2017/interactively-analyse-100gb-of-data-using-spark-amazon-emr-and-zeppelin.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Filmed at PyData London 2017
www.pydata.org&lt;/p&gt;
&lt;p&gt;Description
In this highly interactive session, you will learn how to leverage Apache Spark, Amazon Elastic Map Reduce (EMR) and Apache Zeppelin to rapidly mine a large real-world data set. You will learn how to apply common Spark patterns to extract insights as well as learn useful performance and monitoring tips.&lt;/p&gt;
&lt;p&gt;Abstract
You may have been hearing a lot of buzz around Big Data, Apache Spark, Amazon Elastic Map Reduce (EMR) and Apache Zeppelin. Whatâ€™s the fuss about, and how can you benefit from these state of the art technologies?&lt;/p&gt;
&lt;p&gt;In this highly interactive session, you will learn how to leverage Spark to rapidly mine a large real-world data set. We will conduct the analysis live entirely using an iPython Notebook to show you how easy it can be to get to grips with these technologies.&lt;/p&gt;
&lt;p&gt;In the first part of the session, we will use a sample of data from the Open Library dataset, and you will learn how to apply common Spark patterns to extract insights and aggregate data. In the second part of the session, you will see how to leverage Spark on Amazon EMR to scale your data processing queries over a cluster of machines and interactively analyse a large data set (100GB) with a Zeppelin Notebook. Along the way you will learn gotchas as well as useful performance and monitoring tips&lt;/p&gt;
</summary></entry></feed>