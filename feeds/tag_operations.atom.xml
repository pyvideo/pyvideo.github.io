<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - operations</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_operations.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2022-06-03T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Automate your tasks with Python and publish with Chat Apps</title><link href="https://pyvideo.org/europython-2020/automate-your-tasks-with-python-and-publish-with-chat-apps.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Anton Chernikov</name></author><id>tag:pyvideo.org,2020-07-23:/europython-2020/automate-your-tasks-with-python-and-publish-with-chat-apps.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;That’s the way to build a Virtual Assistant for your team, the way to boost productivity.&lt;/p&gt;
&lt;p&gt;The technology is to take script written in a high-level language (Python), analyze its inputs/outputs, images or graphs display, other interactions with the user and build connectors to this script from …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;That’s the way to build a Virtual Assistant for your team, the way to boost productivity.&lt;/p&gt;
&lt;p&gt;The technology is to take script written in a high-level language (Python), analyze its inputs/outputs, images or graphs display, other interactions with the user and build connectors to this script from Chat Apps like Slack, Skype, and others. Imagine that you described your skill as a script and gave it to a software robot. And from that moment it is his skill, you and your colleagues can ask him any time to run this skill and give results. As a script author, you don't think about how to connect with different Chat Apps, how to control access, how to monitor that script works fine when colleagues run it, how to save logs, how to balance load if there are too many colleagues running script and so on, our platform does all of this so the author doesn't need to think about what is that software robot, how it works, the platform will understand script by itself. The author just drop script to the platform and tell to the platform which colleagues have the right to run this script.&lt;/p&gt;
&lt;p&gt;For whom?&lt;/p&gt;
&lt;p&gt;For teams who are in charge of Servers, Applications, API's, Data Bases, Analytical reports and other information technology items.&lt;/p&gt;
&lt;p&gt;For tasks like&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;to fetch diagnostic information from multiple data sources into Chat App, gather metrics/logs and analyzing them&lt;/li&gt;
&lt;li&gt;to take an action in case of incident right from a Chat App, rerouting users requests, server rebooting, launching new instances, and many other actions&lt;/li&gt;
&lt;li&gt;to give easy access via Chat App to APIs for team members and other coleagues&lt;/li&gt;
&lt;li&gt;to provide analytical reports by the request from Chat App, reports with graphs, images, tables, files, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;These things are trivial to automate and share, you can do much more with Python, Chat App and smart script sharing platform.&lt;/p&gt;
</content><category term="EuroPython 2020"></category><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Best Practice"></category><category term="Community"></category><category term="Operations"></category><category term="Workforce"></category><category term="python"></category></entry><entry><title>Managing large-scale ML pipelines with MLflow and serverless computing.</title><link href="https://pyvideo.org/pycon-italia-2022/managing-large-scale-ml-pipelines-with-mlflow-and-serverless-computing.html" rel="alternate"></link><published>2022-06-03T00:00:00+00:00</published><updated>2022-06-03T00:00:00+00:00</updated><author><name>ilyas chaoua</name></author><id>tag:pyvideo.org,2022-06-03:/pycon-italia-2022/managing-large-scale-ml-pipelines-with-mlflow-and-serverless-computing.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Managing large-scale Machine Learning pipelines with MLflow and
serverless computing. - PyCon Italia 2022&lt;/p&gt;
&lt;p&gt;MLOps aims to manage the machine learning (ML) lifecycle including
experimentation, reproducibility, deployment, and model registry. Come
to discover how in Vedrai - one of the top AI startups in Europe - we
enhance and maintain ML pipelines …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Managing large-scale Machine Learning pipelines with MLflow and
serverless computing. - PyCon Italia 2022&lt;/p&gt;
&lt;p&gt;MLOps aims to manage the machine learning (ML) lifecycle including
experimentation, reproducibility, deployment, and model registry. Come
to discover how in Vedrai - one of the top AI startups in Europe - we
enhance and maintain ML pipelines models in production reliably and
efficiently using MLOps. Problem:&lt;/p&gt;
&lt;p&gt;One difficulty of employing Machine Learning (ML) within organizations
is managing the model’s lifecycle. Moving from experimenting to
deployment in production environments is operated by different steps:
Preparing and Analysing Data, Training, Deployment, Monitoring, and
Governance of ML models. So, it is crucial to possess a platform to
manage and organize the ML lifecycle.&lt;/p&gt;
&lt;p&gt;Solution:&lt;/p&gt;
&lt;p&gt;In Vedrai, we combined the strength of the MLflow framework and the
resilience of AWS serverless services to manage, deploy, and scale our
ML models in production. MLflow is an open-source framework for tracking
the entire ML lifecycle from training to deployment. Among the
functions, it offers model tracking, packaging, and serving. Whereas,
deploying ML applications is an infrastructure affair that needs to be
scalable with minimum server management, which makes AWS serverless
services a great choice.&lt;/p&gt;
&lt;p&gt;Value:&lt;/p&gt;
&lt;p&gt;MLflow enforces the model’s reproducibility and robustness at the same
time allowing more centralized experimentation. AWS serverless services
allow training and inferencing pipelines to run without provisioning or
managing servers while only paying for the time it takes to run.&lt;/p&gt;
&lt;p&gt;Summary:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;State of the art of MLOps.&lt;/li&gt;
&lt;li&gt;Record and query experiments with MLflow Tracking.&lt;/li&gt;
&lt;li&gt;Package data science code with MLflow Projects.&lt;/li&gt;
&lt;li&gt;Store ML models with MLflow Models Registry.&lt;/li&gt;
&lt;li&gt;Deploy ML models in the AWS environment.&lt;/li&gt;
&lt;li&gt;Future MLOps challenges.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Speaker: ilyas chaoua&lt;/p&gt;
</content><category term="PyCon Italia 2022"></category><category term="architecture"></category><category term="aws"></category><category term="best practice"></category><category term="deep learning"></category><category term="devops"></category><category term="docker"></category><category term="infrastructure"></category><category term="machine learning"></category><category term="open source"></category><category term="operations"></category><category term="packaging"></category><category term="performance"></category><category term="scaling"></category></entry></feed>