<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/event_pycon-de-2018.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-10-26T00:00:00+00:00</updated><entry><title>3D Graphics in Python with Ratcave and Pyglet</title><link href="https://pyvideo.org/pycon-de-2018/3d-graphics-in-python-with-ratcave-and-pyglet.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Nicholas A. Del Grosso</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/3d-graphics-in-python-with-ratcave-and-pyglet.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python has some great graphics packages! in this talk, I'll introduce
the fundamentals of 3D graphics and demonstrate how to load 3D models,
created in Blender3D, into an OpenGL window using Pyglet and the Ratcave
extension.&lt;/p&gt;
</summary><category term="Visualisation"></category></entry><entry><title>Build text classification models ( CBOW and Skip-gram) with FastText in python</title><link href="https://pyvideo.org/pycon-de-2018/build-text-classification-models-cbow-and-skip-gram-with-fasttext-in-python.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Kajal Puri</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/build-text-classification-models-cbow-and-skip-gram-with-fasttext-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;FastText has been open-sourced by Facebook in 2016 and with its release,
it became the fastest and most accurate library in Python for text
classification and word representation. It is to be seen as a substitute
for gensim package's word2vec. It includes the implementation of two
extremely important methodologies in NLP i.e Continuous Bag of Words and
Skip-gram model. Fasttext performs exceptionally well with supervised as
well as unsupervised learning.&lt;/p&gt;
&lt;p&gt;The tutorial will be divided in following four segments :&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Data Science"></category><category term="NLP"></category><category term="Machine Learning"></category></entry><entry><title>Building your own conversational AI with open source tools</title><link href="https://pyvideo.org/pycon-de-2018/building-your-own-conversational-ai-with-open-source-tools.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Justina Petraitytė</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/building-your-own-conversational-ai-with-open-source-tools.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Conversational AI is far from being a solved problem, but you don’t need
to rely on third-party APIs to build great chat and voice apps.&lt;/p&gt;
&lt;p&gt;In this talk we will live-code a useful, engaging conversational AI bot
based entirely on machine learning. We’ll be using Rasa NLU &amp;amp; Rasa Core,
which are open source libraries for building machine learning-based
chatbots and voice assistants. We will teach our system how to hold
multi-turn conversations by creating some initial training data, and
then refine its behaviour by interacting with the system and providing
feedback. We will cover the fundamentals of conversational AI, including
the most important algorithms for intent classification, entity
extraction, and dialogue management.&lt;/p&gt;
&lt;p&gt;What will attendees learn:&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="NLP"></category><category term="Machine Learning"></category><category term="Python"></category></entry><entry><title>Closing Session</title><link href="https://pyvideo.org/pycon-de-2018/closing-session.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Various speakers</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/closing-session.html</id><summary type="html"></summary></entry><entry><title>Concurrency in Python - concepts, frameworks and best practices</title><link href="https://pyvideo.org/pycon-de-2018/concurrency-in-python-concepts-frameworks-and-best-practices.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Stefan Schwarzer</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/concurrency-in-python-concepts-frameworks-and-best-practices.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Have you run in situations where concurrent execution could speed up
your Python code? Are you using a GUI toolkit?&lt;/p&gt;
&lt;p&gt;This talk gives you the background to use concurrency in your code
without shooting yourself in the foot - which is quite easy if you don't
understand how concurrent execution differs from linear execution!&lt;/p&gt;
&lt;p&gt;The presentation starts with explaining some concepts like concurrency,
parallelism, resources, atomic operations, race conditions and
deadlocks.&lt;/p&gt;
&lt;p&gt;Then we discuss the commonly-used approaches to concurrency:
multithreading with the &lt;tt class="docutils literal"&gt;threading&lt;/tt&gt; module, multiprocessing with the
&lt;tt class="docutils literal"&gt;multiprocessing&lt;/tt&gt; module, and event loops (which include the
&lt;tt class="docutils literal"&gt;asyncio&lt;/tt&gt; framework). Each of these approaches has its typical use
cases, which are explained.&lt;/p&gt;
&lt;p&gt;You can implement concurrency on a number of abstraction levels. The
lowest level consists of primitives like locks, events, semaphores and
so on. A higher abstraction level is using queues, typically with worker
threads or processes. Even higher abstraction levels are active objects
(hiding primitives or queues behind an API; this includes &amp;quot;actors&amp;quot; if
you heard of them), the thread and process pools in
&lt;tt class="docutils literal"&gt;concurrent.futures&lt;/tt&gt; and the &lt;tt class="docutils literal"&gt;asyncio&lt;/tt&gt; framework. Finally, you can
&amp;quot;outsource&amp;quot; concurrency by leaving it to a message broker, which is a
distinct process that receives and distributes messages.&lt;/p&gt;
&lt;p&gt;The talk closes with some tips and best practices, mainly:&lt;/p&gt;
</summary><category term="Parallel Programming"></category><category term="Programming"></category><category term="Python"></category></entry><entry><title>Enabling the chip technologies of tomorrow – how Python helps us</title><link href="https://pyvideo.org/pycon-de-2018/enabling-the-chip-technologies-of-tomorrow-how-python-helps-us.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Tim Hoffmann</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/enabling-the-chip-technologies-of-tomorrow-how-python-helps-us.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Carl Zeiss SMT GmbH is the leading manufacturer of lithography optics.
Our optics allow chipmakers to produce smaller, faster and more energy
efficient computer chips. As we move to smaller and smaller structures,
the necessary optics grow more and more complex. Customized simulations
and data analytics by highly qualified technical domain experts are
essential. These people are not experienced software developers.
However, with Python and the right support, we can give them powerful
tools to accomplish their task efficiently.&lt;/p&gt;
&lt;p&gt;Pioneering Python in a larger enterprise can be challenging. At present,
we use Python in selected areas of our product development and
production processes. We'd like to share our challenges and solutions
with using Python in a heterogeneous company environment. In particular,
how can we make Python accessible to non-programmers? How do we ensure
consistent development? How do we embed in the non-Python ecosystem of
the company?&lt;/p&gt;
</summary><category term="Data Science"></category></entry><entry><title>From exploration to deployment - combining PyTorch and TensorFlow for Deep Learning</title><link href="https://pyvideo.org/pycon-de-2018/from-exploration-to-deployment-combining-pytorch-and-tensorflow-for-deep-learning.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Marcel Kurovski</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/from-exploration-to-deployment-combining-pytorch-and-tensorflow-for-deep-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Despite the many deep learning frameworks out in the wild few have
achieved widespread adoption. Two of them are TensorFlow and PyTorch.
Where PyTorch relies on a dynamic computation graph TensorFlow goes for
a static graph. Where TensorFlow shows greater adoption and additional
useful extensions with TensorFlow Serving and TensorBoard, Pytorch
proves useful trough its easy and more pythonic API.&lt;/p&gt;
&lt;p&gt;Data scientists are confronted with explorative challenges, but also
need to be aware of model deployment and production. Do we need to
single out frameworks until we end up with the only one or is there a
case for joint usage of two deep learning frameworks? Can we leverage
the strengths of the frameworks for different tasks along the path from
exploration to production?&lt;/p&gt;
&lt;p&gt;In my talk, I want to present a case combining the benefits of PyTorch
and TensorFlow using the first for explorative and latter for deployment
tasks. Therefore, I will choose a common deep learning challenge and
discuss the strengths and weaknesses of both frameworks along a demo
that brings a model from development into production.&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Data Science"></category><category term="Machine Learning"></category></entry><entry><title>Grammar of Graphics in Python</title><link href="https://pyvideo.org/pycon-de-2018/grammar-of-graphics-in-python.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Malte Harder</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/grammar-of-graphics-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A grammar is, according to Wikipedia, the set of structural rules
governing the composition of clauses, phrases, and words in any given
natural language. A grammar of graphics is then the set of structural
rules governing the composition of visual elements. Transforming data
into visual representations using composition is quite powerful and
allows to create complex visualisations with simple building blocks.&lt;/p&gt;
&lt;p&gt;While the ideas behind the grammar of graphics date back well into the
80s, as a Python developer it is only quite recently that we can make
use of it. Altair, backed by the vega specification, is one of the few
plotting libraries in Python that provide such a declarative and
compositional API.&lt;/p&gt;
&lt;p&gt;In this talk I will give an introduction to the core concepts behind the
grammar of graphics as well as practical examples how to use altair API
in Python to create vega plots.&lt;/p&gt;
</summary><category term="Visualisation"></category></entry><entry><title>Keynote: Learning programming &amp; science with Scientific Python</title><link href="https://pyvideo.org/pycon-de-2018/keynote-learning-programming-science-with-scientific-python.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Emmanuelle Gouillart</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/keynote-learning-programming-science-with-scientific-python.html</id><summary type="html"></summary><category term="keynote"></category></entry><entry><title>Prototyping to tested code</title><link href="https://pyvideo.org/pycon-de-2018/prototyping-to-tested-code.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Christopher Prohm</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/prototyping-to-tested-code.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Jupyter notebooks are a great environment to prototype solutions and
explore their design. Turning these solutions into reusable components
usually requires moving them out of the notebook environment into
external python packages. Often, at this stage, the code is refactored
and test are written.&lt;/p&gt;
&lt;p&gt;In this talk, I will demo
&lt;tt class="docutils literal"&gt;`ipytest&lt;/tt&gt; &amp;lt;&lt;a class="reference external" href="https://github.com/chmp/ipytest"&gt;https://github.com/chmp/ipytest&lt;/a&gt;&amp;gt;`__, a small tool to run
tests inside notebooks. It supports &lt;tt class="docutils literal"&gt;`pytest&lt;/tt&gt; &amp;lt;&lt;a class="reference external" href="http://pytest.org/"&gt;http://pytest.org/&lt;/a&gt;&amp;gt;`__
as well as the standard
&lt;tt class="docutils literal"&gt;`unittest&lt;/tt&gt; &amp;lt;&lt;a class="reference external" href="https://docs.python.org/3/library/unittest.html"&gt;https://docs.python.org/3/library/unittest.html&lt;/a&gt;&amp;gt;`__
framework. It allows to start prototypes in a notebook and to develop
the tests with the code in an highly interactive environment. As the
code grows, it can be transparently moved outside notebooks and
transformed into reusable components. By bringing support for tests to
the notebook environment,
&lt;tt class="docutils literal"&gt;`ipytest&lt;/tt&gt; &amp;lt;&lt;a class="reference external" href="https://github.com/chmp/ipytest"&gt;https://github.com/chmp/ipytest&lt;/a&gt;&amp;gt;`__ bridges the artificial
gap between notebooks and reusable components.&lt;/p&gt;
</summary><category term="Data Science"></category><category term="Machine Learning"></category></entry><entry><title>Python Decorators: Gift or Poison?</title><link href="https://pyvideo.org/pycon-de-2018/python-decorators-gift-or-poison.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Anastasiia Tymoshchuk</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/python-decorators-gift-or-poison.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Why would you ever need to use decorators in Python? Have you ever had
the task when you need to use one function in few places and you really
wanted to avoid of code duplicating? For example to add some logging
into functions or timers, etc. Decorators in Python are super powerful
with these tasks, but at the same time they are super complicated,
sometimes even magical. When I started learning Python, Decorators were
really like a magic: how to use them, how are they working, lots of
questions. The goal is to make the things easier and clear to answer a
question: to use or not to use Decorators in your project.&lt;/p&gt;
</summary><category term="Python"></category></entry><entry><title>Satellite data is for everyone: insights into modern remote sensing research with open data and Python</title><link href="https://pyvideo.org/pycon-de-2018/satellite-data-is-for-everyone-insights-into-modern-remote-sensing-research-with-open-data-and-python.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Felix M. Riese</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/satellite-data-is-for-everyone-insights-into-modern-remote-sensing-research-with-open-data-and-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The largest earth observation programme Copernicus
(&lt;a class="reference external" href="http://copernicus.eu"&gt;http://copernicus.eu&lt;/a&gt;) makes it possible to perform terrestrial
observations providing data for all kinds of purposes. One important
objective is to monitor the land-use and land-cover changes with the
Sentinel-2 satellite mission. These satellites measure the sun
reflectance on the earth surface with multispectral cameras (13 channels
between 440 nm to 2190 nm). Machine learning techniques like
convolutional neural networks (CNN) are able to learn the link between
the satellite image (spectrum) and the ground truth (land use class). In
this talk, we give an overview about the state-of-the-art land-use
classification with CNNs based on an open dataset.&lt;/p&gt;
&lt;p&gt;The EuroSAT benchmark dataset (&lt;a class="reference external" href="http://madm.dfki.de/downloads"&gt;http://madm.dfki.de/downloads&lt;/a&gt;) is freely
provided by German Research Center for Artificial Intelligence (DFKI).
It consists of 27.000 image patches for ten different land use/cover
classes, e.g. industrial and residential areas, different crop and
vegetation types and forests. All samples have 64 by 64 pixel dimension
and include either only the RGB images or all 13 bands.&lt;/p&gt;
&lt;p&gt;We will use different out-of-box CNNs for the Keras deep learning
library (&lt;a class="reference external" href="https://keras.io/"&gt;https://keras.io/&lt;/a&gt;). All networks are either included in Keras
itself or are available from Github repositories. We will show the
process of transfer learning for the RGB datasets. Furthermore, the
minimal changes required to apply commonly used CNNs to multispectral
data are demonstrated. Thus, the interested audience will be able to
perform their own classification of remote sensing data within a very
short time. Results of different network structures are visually
compared. Especially the differences of transfer learning and learning
from scratch are demonstrated. This also includes the amount of
necessary training epochs, progress of training and validation error and
visual comparison of the results of the trained networks.&lt;/p&gt;
&lt;p&gt;Finally, we give a quick overview about the current research topics
including recurrent neural networks for spatio-temporal land-use
classification and further applications of multi- and hyperspectral
data, e.g. for the estimation of water parameters and soil
characteristics. Additionally, we provide links to the code and dataset
used in this talk.&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Computer Vision"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Data Science"></category><category term="Machine Learning"></category><category term="Science"></category></entry><entry><title>Strongly typed datasets in a weakly typed world</title><link href="https://pyvideo.org/pycon-de-2018/strongly-typed-datasets-in-a-weakly-typed-world.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Marco Neumann</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/strongly-typed-datasets-in-a-weakly-typed-world.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We at Blue Yonder use Pandas quite a lot during our daily data science
and engineering work. This choice, together with Python as an underlying
programming language gives us flexibility, a feature-rich interface, and
access to a large community and ecosystem. When it comes to preserving
the data and exchanging it with different software stacks, we rely on
Parquet Datasets / Hive Tables. During the write process, there is a
shift from a rather weakly typed world to a strongly typed one. For
example, Pandas may convert integers to floats for many operations
without asking, but parquet files and the schema information stored
alongside them dictate very precise types. The type situation may get
even more &amp;quot;colorful&amp;quot;, when datasets are written by multiple code
versions or different software solutions over time. This then results in
important questions regarding type compatibility.&lt;/p&gt;
&lt;p&gt;This talk will first represent an overview on types at different layers
(like NumPy, Pandas, Arrow and Parquet) and the transition between this
layers. The second part of the talk will present examples of type
compatibility we have seen and why+how we think they should be handled.
At the end there will be a Q+A, which can be seen as the start of a
potentially longer RFC process to align different software stacks (like
Hive and Dask) to handle types in a similar way.&lt;/p&gt;
</summary><category term="Algorithms"></category><category term="Big Data"></category><category term="Data Science"></category><category term="Parallel Programming"></category></entry><entry><title>Suggestions from Python and Solr</title><link href="https://pyvideo.org/pycon-de-2018/suggestions-from-python-and-solr.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Jonathan Oberländer</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/suggestions-from-python-and-solr.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When a user types a query into the search box of our price comparison
website, we try to figure out what they search, and provide suggestions
as they type along. What product, what brand, from which categories?
Solr provides a SuggestComponent that is a good start, but in a lot of
situations we need fallback strategies: what should we show to a user
searching for just a brand name? Or for a singular offer we can't
actually show them? What alternatives can we dig up? And behind all this
backfill logic lurks that dreaded question: what amount of irrelevant
garbage is worse than the horror vacui of an empty result set?&lt;/p&gt;
</summary><category term="Algorithms"></category></entry><entry><title>Advanced Analytics Today: From Open Source Integration to the Operationalization of the Analytic Lifecycle</title><link href="https://pyvideo.org/pycon-de-2018/advanced-analytics-today-from-open-source-integration-to-the-operationalization-of-the-analytic-lifecycle.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Martin Schütz</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/advanced-analytics-today-from-open-source-integration-to-the-operationalization-of-the-analytic-lifecycle.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The times when a single statistician in companies created analytical
models and put them into production in person as a whole, have long been
a thing of the past. Today, our customers are facing important
challenges: the interaction of SAS data scientists and open source
programmers in solving a technical problem and the orderly and regulated
transfer of analytical models to production. The talk will show how SAS
'analytical platform covers the entire spectrum, from modeling through
different types of users to the direct operationalization of models.&lt;/p&gt;
</summary></entry><entry><title>Beyond Jupyter Notebooks - Building your own Data Science platform with Python &amp; Docker</title><link href="https://pyvideo.org/pycon-de-2018/beyond-jupyter-notebooks-building-your-own-data-science-platform-with-python-docker.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Joshua Görner</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/beyond-jupyter-notebooks-building-your-own-data-science-platform-with-python-docker.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Interactive notebooks like Jupyter have become more and more popular in
the recent past and build the core of many data scientist's workplace.
Being accessed via web browser they allow scientists to easily structure
their work by combining code and documentation.&lt;/p&gt;
&lt;p&gt;Yet notebooks often lead to isolated and disposable analysis artefacts.
Keeping the computation inside those notebooks does not allow for
convenient concurrent model training, model exposure or scheduled model
retraining.&lt;/p&gt;
&lt;p&gt;Those issues can be addressed by taking advantage of recent developments
in the discipline of software engineering. Over the past years
containerization became the technology of choice for crafting and
deploying applications. Building a data science platform that allows for
easy access (via notebooks), flexibility and reproducibility (via
containerization) combines the best of both worlds and addresses Data
Scientist's hidden needs.&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Algorithms"></category><category term="Data Science"></category><category term="DevOps"></category><category term="Infrastructure"></category><category term="Jupyter"></category><category term="Machine Learning"></category><category term="Programming"></category><category term="Python"></category></entry><entry><title>Big Data Systems Performance: The Little Shop of Horrors</title><link href="https://pyvideo.org/pycon-de-2018/big-data-systems-performance-the-little-shop-of-horrors.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Jens Dittrich</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/big-data-systems-performance-the-little-shop-of-horrors.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The confusion around terms such as like NoSQL, Big Data, Data Science,
Spark, SQL, and Data Lakes often creates more fog than clarity. However,
clarity about the underlying technologies is crucial to designing the
best technical solution in any field relying on huge amounts of data
including data science, machine learning, but also more traditional
analytical systems such as data integration, data warehousing,
reporting, and OLAP.&lt;/p&gt;
&lt;p&gt;In my presentation, I will show that often at least three dimensions are
cluttered and confused in discussions when it comes to data management:
First, buzzwords (labels &amp;amp; terms like &amp;quot;big data&amp;quot;, &amp;quot;AI&amp;quot;, &amp;quot;data lake&amp;quot;);
second, data design patterns (principles &amp;amp; best practices like:
selection push-down, materialization, indexing); and Third, software
platforms (concrete implementations &amp;amp; frameworks like: Python, DBMS,
Spark, and NoSQL-systems).&lt;/p&gt;
&lt;p&gt;Only by keeping these three dimensions apart, it is possible to create
technically-sound architectures in the field of big data analytics.&lt;/p&gt;
&lt;p&gt;I will show concrete examples, which through a simple redesign and wise
choice of the right tools and technologies, run thereby up to 1000 times
faster. This in turn triggers tremendous savings in terms of development
time, hardware costs, and maintenance effort.&lt;/p&gt;
</summary><category term="Algorithms"></category><category term="Big Data"></category><category term="Data Science"></category><category term="Infrastructure"></category><category term="Parallel Programming"></category><category term="Programming"></category><category term="Python"></category><category term="Science"></category></entry><entry><title>Bonobo, Airflow and Grafana to visualize your business</title><link href="https://pyvideo.org/pycon-de-2018/bonobo-airflow-and-grafana-to-visualize-your-business.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Romain Dorgueil</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/bonobo-airflow-and-grafana-to-visualize-your-business.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Zero-to-one hands-on introduction to building a business dashboard using
Bonobo ETL, Airflow, and a bit of Grafana (because graphs are cool).
Although the opposite is better, there is no need of prior knowledge
about any of those tools.&lt;/p&gt;
&lt;p&gt;After a short introduction about the tools, we'll go through the
following topics, using the real data of a small SaaS software:&lt;/p&gt;
&lt;p&gt;One can expect to be able to build a similar system at the end of the
talk in a few days (of course, the implementation is only a small part
of this process, data is what really matters).&lt;/p&gt;
&lt;p&gt;«Metrics you watch tend to improve over time»&lt;/p&gt;
</summary><category term="Business &amp; Start-Ups"></category><category term="Data Science"></category><category term="Visualisation"></category><category term="Web"></category></entry><entry><title>Cloud chat bot for lazy people</title><link href="https://pyvideo.org/pycon-de-2018/cloud-chat-bot-for-lazy-people.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Björn Meier</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/cloud-chat-bot-for-lazy-people.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At work we established Slack years ago as our chat application and by
now quite a percentage of communication goes through it. As a result it
got much easier to contact one person or a group simultaneously. And
this is good as we can share our knowledge save each other time. But it
also introduced a category of questions in the chat which only require
simple tedious tasks to get the answer and then post it as a response.
One possibility is to educate and point others to the place where they
can find the answer or what tasks they have to do. The other one is use
a chat bot for this. Both ways have advantages and for the bot it is
that you can import a specific type of response more easily into a
conversation without first gathering the information and copy and paste
it. I am a developer and service operator and one category of questions
which fits this is the category of service health questions, like &amp;quot;Does
service X has a problem right now?&amp;quot;. Hence, I will use a bot to answer
them. First I will show you how you can create a python bot for the
Azure bot service. With it the questioner then can either directly use
the bot to answer his question or you can just create the response for
him without going to the service health monitoring. In this case the
service health information has to be obtained from a Prometheus
monitoring service and then transformed into a chat message.&lt;/p&gt;
</summary><category term="DevOps"></category><category term="Infrastructure"></category></entry><entry><title>Creating an inclusive corporate culture</title><link href="https://pyvideo.org/pycon-de-2018/creating-an-inclusive-corporate-culture.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Yenny Cheung</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/creating-an-inclusive-corporate-culture.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Having a tech career as a minority is challenging. It could mean being
the only one to speak against the popular opinion, or becoming more
visible to get the same level of recognition. What can we do on the
corporate level to make sure everyone feels welcome and retain these
talents? Creating an inclusive corporate culture helps us achieve just
that. This talk shares concrete steps that employees and employers can
take to improve minorities in tech’s sense of belonging and engagement:&lt;/p&gt;
</summary><category term="Business &amp; Start-Ups"></category><category term="Community"></category></entry><entry><title>Data science complexity and solutions in real industrial projects</title><link href="https://pyvideo.org/pycon-de-2018/data-science-complexity-and-solutions-in-real-industrial-projects.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Artur Miller</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/data-science-complexity-and-solutions-in-real-industrial-projects.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As data scientists we usually like to apply fancy machine learning
models to well-groomed datasets. Everyone working on industrial problems
will eventually learn, that this does not reflect reality. The amount of
time spent on modeling is small compared to data gathering, -warehousing
and -cleaning. Even after training and deployment of the model, the work
is not done. Continuous monitoring of the performance and input data is
still necessary.&lt;/p&gt;
&lt;p&gt;In this talk I discuss how important data handling is for successful
data science projects. Each milestone, from finding the business case to
continuously monitoring the performance of the solution, is addressed.
This is exemplary shown on a project, with the goal of improving a
productive system.&lt;/p&gt;
</summary><category term="Algorithms"></category><category term="Big Data"></category><category term="Data Science"></category><category term="Infrastructure"></category><category term="Machine Learning"></category></entry><entry><title>Data Science meets Data Protection: Keeping your data secure while learning from it.</title><link href="https://pyvideo.org/pycon-de-2018/data-science-meets-data-protection-keeping-your-data-secure-while-learning-from-it.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Andreas Dewes</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/data-science-meets-data-protection-keeping-your-data-secure-while-learning-from-it.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We will discuss anonymization and pseudonymization techniques that you
can apply to your data to keep it secure and comply with the law(s)
while still being able to gain useful insights from it.&lt;/p&gt;
&lt;p&gt;We will show concrete Python implementations of various techniques and
use example data sets to show how applying pseudonymization and
anonymization will affect our ability to do machine learning / data
science.&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Business &amp; Start-Ups"></category><category term="Big Data"></category><category term="Data Science"></category></entry><entry><title>Deep Learning with PyTorch for more Fun and Profit (Part II)</title><link href="https://pyvideo.org/pycon-de-2018/deep-learning-with-pytorch-for-more-fun-and-profit-part-ii.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Alexander CS Hendorf</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/deep-learning-with-pytorch-for-more-fun-and-profit-part-ii.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There are all these great blog posts about Deep Learning describing all
that awesome stuff. - Is it all that easy? Let's check! This is part 2
of on ongoing series of adventures in Deep Learning for fun, research
and business.&lt;/p&gt;
&lt;p&gt;We'll look into: style transfer (making a picture look like painting),
speech generation (like Siri or Alexa) and text generation (writing a
story). In this talk I'll describe the whole journey: A fun ride from
the idea to the very end including all the struggles, failures and
successes. Steps, we'll cover:&lt;/p&gt;
</summary></entry><entry><title>Driving simulation and data analysis of magnetic nanostructures through Jupyter Notebook</title><link href="https://pyvideo.org/pycon-de-2018/driving-simulation-and-data-analysis-of-magnetic-nanostructures-through-jupyter-notebook.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Hans Fangohr</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/driving-simulation-and-data-analysis-of-magnetic-nanostructures-through-jupyter-notebook.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We present ongoing work from a project that makes a particular computer
simulation (implemented in C++ and Tk/Tcl) accessible through a Python
interface, and through the Jupyter Notebook. The talk describes the
motivation and current status of the project.&lt;/p&gt;
&lt;p&gt;In more detail, the computer simulation in question is the Object
Oriented Micromagnetic Modelling Framework
(&lt;a class="reference external" href="http://math.nist.gov/oommf/"&gt;OOMMF&lt;/a&gt;) which is likely the most
widely used micromagnetic simulation package. It can be driven through a
graphical (Tk) user interface or through a configuration file that
defines a simulation run.&lt;/p&gt;
&lt;p&gt;In this talk, we first show a Python interface to OOMMF that allows the
driving of OOMMF simulations from a Python program or interpreter
prompt. This way we embed a widely used scientific code from 1990s in a
general purpose programming language
[&lt;a class="reference external" href="https://doi.org/10.1063/1.4977225"&gt;1&lt;/a&gt;] and enable the full use of
the ecosystem of scientific libraries available for Python. For example,
design optimisation, specialised post-processing, and the creation of
figures can all be carried out using a single script; making the work
more easily reproducible.&lt;/p&gt;
&lt;p&gt;Second, we integrate the Python interface to OOMMF into a Jupyter
notebook, so that all existing benefits of using Jupyter are inherited
for the use in computational micromagnetics, which is the reason we
named our code Jupyter- OOMMF (&lt;a class="reference external" href="http://joommf.github.io/"&gt;JOOMMF&lt;/a&gt;). A
&lt;a class="reference external" href="https://tryjoommf.soton.ac.uk/"&gt;JupyterHub installation&lt;/a&gt; of the tool
reduces barriers in uptake, and all the code is &lt;a class="reference external" href="https://github.com/joommf"&gt;on
github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We discuss the benefits of driving computer simulation and data analysis
through Jupyter Notebooks.&lt;/p&gt;
&lt;p&gt;This project is a part of the Jupyter-OOMMF (JOOMMF) activity in the
&lt;a class="reference external" href="http://opendreamkit.org/"&gt;OpenDreamKit&lt;/a&gt; project and we acknowledge
financial support from Horizon 2020 European Research Infrastructures
project (676541). The work is also supported by the EPSRC CDT in Next
Generation Computational Modelling EP/L015382/1, and the EPSRC grants
EP/M022668/1 and EP/N032128/1.&lt;/p&gt;
&lt;p&gt;For additional context: micromagnetic modelling is a key research method
in academia and industry to support development of high-capacity
magnetic storage devices that are cheap, fast, and reliable, and to
enable research into future alternative storage and processing
technologies such as spintronics. The OOMMF modelling package has been
used in &lt;a class="reference external" href="https://math.nist.gov/oommf/oommf_cites.html"&gt;over 2500
publications&lt;/a&gt; since
1999.&lt;/p&gt;
&lt;p&gt;[1] Beg, M., Pepper, R. A., and Fangohr, H. User interfaces for
computational science: A domain specific language for OOMMF embedded in
Python. AIP Advances 7, 056025 (2017), &lt;a class="reference external" href="https://doi.org/10.1063/1.4977225"&gt;https://doi.org/10.1063/1.4977225&lt;/a&gt;&lt;/p&gt;
</summary><category term="Data Science"></category><category term="Jupyter"></category><category term="Programming"></category><category term="Python"></category><category term="Science"></category></entry><entry><title>Fulfilling Apache Arrow's Promises: Pandas on JVM memory without a copy</title><link href="https://pyvideo.org/pycon-de-2018/fulfilling-apache-arrows-promises-pandas-on-jvm-memory-without-a-copy.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Uwe L. Korn</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/fulfilling-apache-arrows-promises-pandas-on-jvm-memory-without-a-copy.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Apache Arrow established a standard for columnar in-memory analytics to
redefine the performance and interoperability of most Big Data
technologies in early 2016. Since then implementations in Java, C++,
Python, Glib, Ruby, Go, JavaScript and Rust have been added. Although
Apache Arrow (&lt;tt class="docutils literal"&gt;pyarrow&lt;/tt&gt;) is already known to many Python/Pandas users
for reading Apache Parquet files, its main benefit is the cross-language
interoperability. With feather and PySpark, you can already benefit from
this in Python and R/Java via the filesystem or network. While they
improve data sharing and remove serialization overhead, data still needs
to be copied as it is passed between processes.&lt;/p&gt;
&lt;p&gt;In the 0.23 release of Pandas, the concept of ExtensionArrays was
introduced. They allow the extension of Pandas DataFrames and Series
with custom, user- defined typed. The most prominent example is
&lt;tt class="docutils literal"&gt;cyberpandas&lt;/tt&gt; which adds an IP dtype that is backed by the appropriate
representation using NumPy arrays. These ExtensionArrays are not limited
to arrays backed by NumPy but can take an arbitrary storage as long as
they fulfill a certain interfaces. Using Apache Arrow we can implement
ExtensionArrays that are of the same dtype as the built-in types of
Pandas but memory management is not tied to Pandas' internal
BlockManager. On the other hand Apache Arrow has a much more wider set
of efficient types that we can also expose as an ExtensionArray. These
types include a native string type as well as a arbitrarily nested types
such as &lt;tt class="docutils literal"&gt;list of …&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;struct of (…, …, …)&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;To show the real-world benefits of this, we take the example of a data
pipeline that pulls data from a relational store, transforms it and then
passes it into a machine learning model. A typical setup nowadays most
likely involves a data lake that is queried with a JVM based query
engine. The machine learning model is then normally implemented in
Python using popular frameworks like CatBoost or Tensorflow.&lt;/p&gt;
&lt;p&gt;While sometimes these query engines provide Python clients, their
performance is normally not optimized for large results sets. In the
case of a machine learning model, we will do some feature
transformations and possibly aggregations with the query engine but feed
as many rows as possible into the model. This will lead then to result
sets that have above a million rows. In contrast to the Python clients,
these engines often come with efficient JDBC drivers that can cope with
result sets of this size but then the conversion from Java objects to
Python objects in the JVM bridge will slow things down again. In our
example, we will show how to use Arrow to retrieve a large result in the
JVM and then pass it on to Python without running into these
bottlenecks.&lt;/p&gt;
</summary><category term="Algorithms"></category><category term="Big Data"></category><category term="Data Science"></category><category term="Parallel Programming"></category></entry><entry><title>How to make your (digital) Communication strong &amp; future ready</title><link href="https://pyvideo.org/pycon-de-2018/how-to-make-your-digital-communication-strong-future-ready.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Simon Daubermann</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/how-to-make-your-digital-communication-strong-future-ready.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Your business is all set up and ready. You want to enter the market with
a new product or service. As digital communication evolves, brands and
companies are constantly facing new challenges. The ways of providing
information and interacting become more and more multi-layered and
complex. A well-defined communicative base can serve as a corrective
that prevents technology from becoming self-serving.&lt;/p&gt;
</summary><category term="Business &amp; Start-Ups"></category><category term="Community"></category></entry><entry><title>How to teach space invaders to your computer</title><link href="https://pyvideo.org/pycon-de-2018/how-to-teach-space-invaders-to-your-computer.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>David Wölfle</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/how-to-teach-space-invaders-to-your-computer.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;First things first: playing good old Atari games might be cool but why
should I write a program for doing it? Well teaching a computer to play
a game means teaching it to develop strategies and use foresight
planning to solve a certain problem. The tools you gather while solving
i.e. space invaders are the same you may use to solve any problem which
requires a sequential set of decisions in order to find an optimal
solution to some problem, like i.e. controlling a robot that collects
garbage. Furthermore, there is a lot of scientific research on
reinforcement learning that focuses on solving Atari games which makes
it a good starting point, as large amounts of publications and open
source code already exists.&lt;/p&gt;
&lt;p&gt;What to expect from this talk? At first there will be a very short
introduction to reinforcement learning theory, just the very basics,
common applications and some references for further reading. Next points
are, how to run Atari games from inside python for a learning task (with
OpenAI's gym), and where to find an algorithm for the actual learning
problem. Finally it will be shown how to build it all together in a
jupyter notebook and let the algorithm play the game. Et voilà that's
your computer beating you in space invaders.&lt;/p&gt;
</summary><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Jupyter"></category><category term="Python"></category><category term="Science"></category></entry><entry><title>Interactive Visualization of Traffic Data using Bokeh</title><link href="https://pyvideo.org/pycon-de-2018/interactive-visualization-of-traffic-data-using-bokeh.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Dr. Patrik Hlobil</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/interactive-visualization-of-traffic-data-using-bokeh.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk covers the creation of highly interactive and dynamic
visualization (as HTML) using Python, that can still be opened with any
modern browser. Using real-world examples we will show our usual
workflow for processing and creating visualizations using Bokeh. The
following topics will be covered:&lt;/p&gt;
</summary><category term="Data Science"></category><category term="Visualisation"></category><category term="Web"></category></entry><entry><title>Introduction to Docker for Pythonistas</title><link href="https://pyvideo.org/pycon-de-2018/introduction-to-docker-for-pythonistas.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Jan Wagner</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/introduction-to-docker-for-pythonistas.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="line-block"&gt;
&lt;div class="line"&gt;My Talk aims to introduce you to Docker and how it works, how you can
use prebuild Images from the Docker-Hub and how you can make your own
Images.&lt;/div&gt;
&lt;div class="line"&gt;In more Detail, the following Points will be covered:&lt;/div&gt;
&lt;/div&gt;
</summary><category term="Big Data"></category><category term="Data Science"></category><category term="DevOps"></category><category term="Jupyter"></category><category term="Machine Learning"></category></entry><entry><title>Keynote: Looking backward, looking forward</title><link href="https://pyvideo.org/pycon-de-2018/keynote-looking-backward-looking-forward.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Wes McKinney</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/keynote-looking-backward-looking-forward.html</id><summary type="html"></summary><category term="keynote"></category></entry><entry><title>Machine Learning as a Service: How to deploy ML Models as APIs without going nuts</title><link href="https://pyvideo.org/pycon-de-2018/machine-learning-as-a-service-how-to-deploy-ml-models-as-apis-without-going-nuts.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Anand Chitipothu</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/machine-learning-as-a-service-how-to-deploy-ml-models-as-apis-without-going-nuts.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Often, the most convenient way to deploy a machine model is an API. It
allows accessing it from various programming environments and also
decouples the development and deployment of the models from its use.&lt;/p&gt;
&lt;p&gt;However, building an good API is hard. It involves many nitty-gritties
and many of them need to repeated everytime an API is built. Also, it is
very important to have a client library so that the API can be easily
accessed. If you every plan to use it from Javascript directly, then you
need to worry about cross-origin-resource-sharing etc. All things add up
and building APIs for machine very tedious.&lt;/p&gt;
&lt;p&gt;In this talk demonstrates how deploying machine learning models an APIs
can be made fun by using right programming abstractions. This presents
couple of opensource libraries
&lt;a class="reference external" href="https://firefly-%20python.readthedocs.io/en/latest/"&gt;firefly&lt;/a&gt; and
&lt;a class="reference external" href="https://rorodata.github.io/rorolite/"&gt;rorolite&lt;/a&gt; which are built for
this very purpose.&lt;/p&gt;
</summary><category term="Machine Learning"></category><category term="Python"></category><category term="Web"></category></entry><entry><title>Measuring the hay in the haystack: quantifying hidden variables using Bayesian Inference</title><link href="https://pyvideo.org/pycon-de-2018/measuring-the-hay-in-the-haystack-quantifying-hidden-variables-using-bayesian-inference.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Omer Yuksel</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/measuring-the-hay-in-the-haystack-quantifying-hidden-variables-using-bayesian-inference.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Technology-driven trading is a field with many challenges, and
performance and availability of the network communication is essential
to the business. To have a good understanding on the performance and
availability, we monitor certain metrics - however not every interesting
metric is readily available to measure. Some of these have to be
inferred from the data we see in production by incorporating our own
knowledge. What complicates this further is that the relationship
between the hidden variables and the output data is not a deterministic
one, as we are often dealing with a stochastic system.&lt;/p&gt;
&lt;p&gt;Bayesian inference is a suitable way to tackle this issue - it allows
encoding our knowledge as a prior distribution of the model parameters.
Here we will go through real-world uses of Bayesian inference at IMC,
using PyMC3 to make an estimate for the hidden metrics in the network
traffic.&lt;/p&gt;
&lt;p&gt;Knowledge: No prior knowledge of PyMC3 is required. Since this is a
short presentation, the talk with approach the problem and the solution
at a high level instead of implementation details.&lt;/p&gt;
</summary><category term="Data Science"></category><category term="Networks"></category></entry><entry><title>Microservices from the trenches: how we delivery fancy sofas across Europe</title><link href="https://pyvideo.org/pycon-de-2018/microservices-from-the-trenches-how-we-delivery-fancy-sofas-across-europe.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Christian Barra</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/microservices-from-the-trenches-how-we-delivery-fancy-sofas-across-europe.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At made.com we use micro-services written in Python to power our entire
backend system and deliver an incredible amount of orders each week.
During this presentation I will explain what are micro-services and
compare them to monolith applications. By analysing what are the
differences between micro- services and monolith applications I will
show why you need them and for which situations they are extremely
useful. I will also talk about what you need on different levels
regarding infrastructure, knowledge and experience to get the most out
of a micro-services architecture. The last part of the presentation is
dedicated to the drawbacks of running a micro-services architecture and
sharing some solutions. I will conclude sharing some useful resources
about micro services and taking some questions.&amp;quot;&lt;/p&gt;
</summary><category term="Data Science"></category><category term="Jupyter"></category></entry><entry><title>Observe all your applications</title><link href="https://pyvideo.org/pycon-de-2018/observe-all-your-applications.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Christoph Heer</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/observe-all-your-applications.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;You just deployed your new version of an application or micro-service;
how do you know everything works as expected? You run your comprehensive
test suite to verify functional correctness for known scenarios and
performance tests before deploying, but does your application really
work at the moment or is it just responding with error messages to all
incoming requests?&lt;/p&gt;
&lt;p&gt;I’m part of the team that runs a huge infrastructure for the SAP HANA
development. This infrastructure is vital for nearly all development &amp;amp;
testing activities of SAP HANA. As this infrastructure is powered by
multiple in-house developed applications, we immediately want to know if
an application starts to fail and we need to be able to quickly diagnose
what caused the failure.&lt;/p&gt;
&lt;p&gt;This talk will give you an overview how we monitor our full stack from
the 2000 physical machines up to the 10,000 parallel running Python
application processes, micro-service instances and batch processing
jobs. It includes a review about the used tools, bad and good examples
of instrumentation in Python code, the resulting visualisation and an
outlook on upcoming improvements.&lt;/p&gt;
</summary><category term="DevOps"></category><category term="Infrastructure"></category><category term="Networks"></category><category term="Programming"></category><category term="Python"></category></entry><entry><title>Processing Geodata using Python</title><link href="https://pyvideo.org/pycon-de-2018/processing-geodata-using-python.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Martin Christen</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/processing-geodata-using-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There is a large amount of Python modules available suitable for spatial
data processing. In this talk, it is shown how to analyze, manipulate
and visualize geospatial data by using open source modules. The
following modules will be introduced:&lt;/p&gt;
</summary><category term="Big Data"></category><category term="Data Science"></category><category term="Jupyter"></category><category term="Python"></category><category term="Visualisation"></category></entry><entry><title>Put your data on a map</title><link href="https://pyvideo.org/pycon-de-2018/put-your-data-on-a-map.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Alex Vykaliuk</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/put-your-data-on-a-map.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When you're working with geo data I found that putting it all on a map
helps a lot to see and understand it. I will go over few of the tools I
use on a day to day basis that allow you to draw a map. It will include
few common scenarios and examples.&lt;/p&gt;
</summary></entry><entry><title>Python Birdies: Codegolfing for better understanding (and fun)</title><link href="https://pyvideo.org/pycon-de-2018/python-birdies-codegolfing-for-better-understanding-and-fun.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Jonathan Oberländer</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/python-birdies-codegolfing-for-better-understanding-and-fun.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Codegolfing means taking a programming task and trying to answer it with
a byte-minimal correct solution. Such an answer often takes shortcuts,
is horribly inefficient, and definitely violates almost 100% of PEP 8.
Like any playful interaction with a subject, it can however improve your
understanding of it, as well as teach you about weird interactions
regarding operator precedence, lexer quirks and more.&lt;/p&gt;
&lt;p&gt;After going over basic definitions, I will take a small number of
well-known or straightforward programming tasks and go through the act
of golfing an answer together step by step.&lt;/p&gt;
</summary><category term="Algorithms"></category></entry><entry><title>Python on the blockchain: Triumphs and tribulations in a crypto startup</title><link href="https://pyvideo.org/pycon-de-2018/python-on-the-blockchain-triumphs-and-tribulations-in-a-crypto-startup.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Danny McDonald</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/python-on-the-blockchain-triumphs-and-tribulations-in-a-crypto-startup.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While many cryptographic components of blockchain protocols can be
extremely complex, blockchain systems themselves are relatively easy to
understand when viewed from a distance. To take the example of Bitcoin,
users store digital currency in hardware or software wallets, and use
private keys to sign and broadcast transactions. Broadcasted
transactions are grouped together into a block through a cryptographic
process known as mining, with miners rewarded through the collection of
transaction fees and the issuance of new coins. The mined block of
transactions is appended to the existing chain, and verified by a global
network of nodes. This process repeats in perpetuity, with each newly
added block adding to the trustedness and security of data stored on the
chain.&lt;/p&gt;
&lt;p&gt;Increased interest in and demand for cryptocurrencies has brought about
a need for places where digital assets can easily be bought, sold or
traded. Our platform, Bitpanda, accomplishes this with a backend written
in Python, and relying heavily on Django and MySQL databases. In our
presentation, we begin by providing a brief overview of how blockchains
work. Following this, we describe the Python architecture that (e.g.)
generates cryptocurrency wallets, builds, signs and sends transactions,
and monitors blockchains for new, relevant data. Key challenges,
solutions and failures encountered during the development of the system,
and growth of our team, are presented.&lt;/p&gt;
&lt;p&gt;Throughout our talk, we also highlight a number of broader social
implications of blockchains, and our work with them. More specifically,
we describe the need for open-innovation based approaches to blockchain
development, the value of open-source within the blockchain community,
and the current lack of critical discourse surrounding the potential
uses of blockchains as mechanisms of surveillance and control.&lt;/p&gt;
</summary><category term="Business &amp; Start-Ups"></category><category term="Community"></category><category term="Django"></category><category term="Infrastructure"></category><category term="Python"></category></entry><entry><title>Python with and without Pants</title><link href="https://pyvideo.org/pycon-de-2018/python-with-and-without-pants.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Stephan Erb</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/python-with-and-without-pants.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;What is the best outfit for comfortable, but highly productive
programming at home? While this is definitely an important question,
this talk will focus on a topic that is slightly more controversial:
monorepos and their build tools. Specifically, the talk will have a
closer look at Pants (&lt;a class="reference external" href="https://www.pantsbuild.org"&gt;https://www.pantsbuild.org&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Pants is a build system for large or rapidly growing code bases. It
supports all stages of a typical build ( bootstrapping, dependency
resolution, compilation, linting, ...) and allows users to organize
their code via targets for binaries, libraries, and tests. For Python
programmers, pants is especially interesting, as it makes the
manipulation and distribution of hermetically sealed Python environments
painless - so called PEXes.&lt;/p&gt;
&lt;p&gt;The talk will motivate Pants and its usage in the context of a large
company- wide monorepo. It will then focus on important Python-centric
features, and shortly explain how those work under the hood. The talk
will conclude with a discussion of usecases for Pants outside of a
monorepo, i.e. for the rest of us.&lt;/p&gt;
</summary><category term="DevOps"></category><category term="Infrastructure"></category></entry><entry><title>PyTorch as a scientific computing library: past, present and future</title><link href="https://pyvideo.org/pycon-de-2018/pytorch-as-a-scientific-computing-library-past-present-and-future.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Adam Paszke</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/pytorch-as-a-scientific-computing-library-past-present-and-future.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python is very well known for its ecosystem of mature scientific
computing packages. Despite that, the rapidly rising popularity of deep
learning resulted in creation of a number of new libraries, including
PyTorch. Although originally they were meant to provide better support
for those domain specific use cases, one can come to a conclusion, that
they can actually have wider applications.&lt;/p&gt;
&lt;p&gt;In this talk, I’ll showcase the main ideas behind PyTorch - a relatively
new library focusing on usability and good integration with other Python
packages. I’ll cover some interesting use cases, ranging from ones more
specific to machine learning, to those more generally applicable in
other scientific computing areas. I’ll also cover some recently added
features, and talk a bit about our future roadmap.&lt;/p&gt;
</summary></entry><entry><title>Reproducibility, and Selection Bias in Machine Learning</title><link href="https://pyvideo.org/pycon-de-2018/reproducibility-and-selection-bias-in-machine-learning.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Valerio Maggio</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/reproducibility-and-selection-bias-in-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Reproducibility&lt;/em&gt; - the ability to recompute results — and
&lt;em&gt;replicability&lt;/em&gt; — the chances other experimenters will achieve a
consistent result[1]- are among the main important beliefs of the
&lt;em&gt;scientific method&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Surprisingly, these two aspects are often underestimated or not even
considered when setting up scientific experimental pipelines. In this,
one of the main threat to replicability is the &lt;em&gt;selection bias&lt;/em&gt; , that
is the error in choosing the individuals or groups to take part in a
study. Selection bias may come in different flavours: the selection of
the population of samples in the dataset ( &lt;em&gt;sample bias&lt;/em&gt; ); the
selection of features used by the learning models, particularly sensible
in case of high dimensionality; the selection of hyper parameter best
performing on specific dataset(s). If not properly considered, the
selection bias may strongly affect the validity of derived conclusions,
as well as the reliability of the learning model.&lt;/p&gt;
&lt;p&gt;In this talk I will provide a solid introduction to the topics of
reproducibility and selection bias, with examples taken from the
biomedical research, in which reliability is paramount.&lt;/p&gt;
&lt;p&gt;From a more technological perspective, to date the scientific Python
ecosystem still misses tools to consolidate the experimental pipelines
in in research, that can be used together with Machine and Deep learning
frameworks (e.g. &lt;tt class="docutils literal"&gt;sklearn&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;keras&lt;/tt&gt;). In this talk, I will
present &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;reproducible-lern&lt;/span&gt;&lt;/tt&gt;, a new Python frameworks for reproducible
research to be used for machine and deep learning.&lt;/p&gt;
&lt;p&gt;During the talk, the main features of the framework will be presented,
along with several examples, technical insights and implementation
choices to be discussed with the audience.&lt;/p&gt;
&lt;p&gt;The talk is intended for &lt;em&gt;intermediate&lt;/em&gt; PyData researchers and
practitioners. Basic prior knowledge of the main Machine Learning
concepts is assumed for the first part of the talk. On the other hand,
good proficiency with the Python language and with scientific python
libraries (e.g. &lt;tt class="docutils literal"&gt;numpy&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;sklearn&lt;/tt&gt;) are required for the second
part.&lt;/p&gt;
&lt;p&gt;-- &lt;a class="reference external" href="http://www.pnas.org/content/112/6/1645.full"&gt;1&lt;/a&gt; &lt;em&gt;Reproducible
research can still be wrong: Adopting a prevention approach&lt;/em&gt; by Jeffrey
T. Leek, and Roger D. Peng&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.cancer.gov/publications/dictionaries/cancer-terms?CdrID=44087"&gt;2&lt;/a&gt;
Dictionary of Cancer Terms -&amp;gt; &amp;quot;selection bias&amp;quot;&lt;/p&gt;
</summary><category term="Algorithms"></category><category term="Machine Learning"></category><category term="Science"></category></entry><entry><title>Satellite Image Segmentation Photovoltaic Potential Estimation</title><link href="https://pyvideo.org/pycon-de-2018/satellite-image-segmentation-photovoltaic-potential-estimation.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Johannes Oos</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/satellite-image-segmentation-photovoltaic-potential-estimation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The used technologies are python based and include: MongoDB tensorflow
Flask google.cloud python API&lt;/p&gt;
&lt;p&gt;A dataset of labelled satellite images is created. Several networks are
trained and tested on this dataset. The network is deployed on a
production server.&lt;/p&gt;
&lt;p&gt;The results of the classification/segmentaion are used to feed python
based photovotlaic simulation libaries. The output is displayed and the
results (the potential) evaluated.&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Computer Vision"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Machine Learning"></category><category term="Science"></category></entry><entry><title>Solving Data Science Problems using a Jupyter Notebook and SAP HANA's in-database Machine Learning Libraries</title><link href="https://pyvideo.org/pycon-de-2018/solving-data-science-problems-using-a-jupyter-notebook-and-sap-hanas-in-database-machine-learning-libraries.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Dr Frank Gottfried</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/solving-data-science-problems-using-a-jupyter-notebook-and-sap-hanas-in-database-machine-learning-libraries.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Companies store their data in databases with highly restricted access
regulations. The latest regulatorily changes enforces the need to work
on the datasets in this controlled environment without created
additional external copies. However Data Scientists prefer to work with
tools they are most familiar like Python, R and Jupyter Notebooks using
to a large amount of open- source packages (numpy, matplotlib, pandas,
..). SAP HANA provides highly optimized in-database machine learning
libraries. In this talk we will present how a Data Scientist can work in
an environment he/she is most familiar with and access the data stored
in SAP HANA using SAP HANA machine learning libraries with a
scikit-learn type interface. Data will remain in the database and will
be exposed as dataframes (similar to Pandas dataframes). We will explain
the software architecture and present a complete end-to-end use case by
using a Jupyter Notebook.&lt;/p&gt;
</summary><category term="Big Data"></category><category term="Data Science"></category><category term="Jupyter"></category><category term="Machine Learning"></category><category term="Visualisation"></category></entry><entry><title>Stretchy - NoSQL Database behind REST API</title><link href="https://pyvideo.org/pycon-de-2018/stretchy-nosql-database-behind-rest-api.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Artur Scholz</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/stretchy-nosql-database-behind-rest-api.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Stretchy is built as a microservice that provides a simple and intuitive
REST API with a NoSQL database as backend. No need for database
migrations or upfront schema design. The basic CRUD (create, read,
update, delete) operations are available for getting data in and out
from the database.&lt;/p&gt;
&lt;p&gt;Stretchy is free and open source software built with Python 3, using
Flask web framework. It currently uses MongoDB as its backend database.
Since it is interfaced through the REST API however, Stretchy is
technology agnostic and developers can create bindings to other
databases, including SQL databases.&lt;/p&gt;
&lt;p&gt;This presentation reviews the reasons for creating Stretchy, its current
applications, an short tutorial on how to use it, and tips on how to
deploy it.&lt;/p&gt;
</summary><category term="Big Data"></category><category term="Data Science"></category><category term="Web"></category></entry><entry><title>What's new in Python 3.7?</title><link href="https://pyvideo.org/pycon-de-2018/whats-new-in-python-37.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Stephane Wirtel</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/whats-new-in-python-37.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Scheduled for release in mid-June after the conference, Python 3.7 is
shaping up to be a feature-packed release! This talk will cover all the
new features of Python 3.7, including the Data Classes and the Context
Variables for the asynchronous programming with asyncio.&lt;/p&gt;
</summary><category term="Community"></category><category term="Django"></category><category term="DevOps"></category></entry><entry><title>Where the heck is my memory?</title><link href="https://pyvideo.org/pycon-de-2018/where-the-heck-is-my-memory.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Florian Jetter</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/where-the-heck-is-my-memory.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Memory management is something the common Python user doesn’t need to
bother with because the gory details of it are hidden deep within the
interpreter itself. The garbage collector takes out the trash and we can
spend our precious time bothering with more important things on our
minds. Living in this encapsulated utopia is nice but sometimes it is
worth it to peak behind the curtains to unleash the full power of your
application. In this talk I want to show you when it is necessary to
face this harsh world and convince you that it is in fact not as scary
as it may seem. Using real life examples, I’m going to show you how to
use the garbage collector and open source tooling to get control over
the memory you might not even know you had at your disposal.&lt;/p&gt;
</summary><category term="Big Data"></category><category term="DevOps"></category><category term="Infrastructure"></category></entry><entry><title>ZODB: The Graph Database for PythonDevelopers</title><link href="https://pyvideo.org/pycon-de-2018/zodb-the-graph-database-for-pythondevelopers.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Christopher Lozinski</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/zodb-the-graph-database-for-pythondevelopers.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;You can see the current version of the slides at
&lt;a class="reference external" href="https://pythonlinks.info/presentations/zodbtalk.pdf"&gt;https://pythonlinks.info/presentations/zodbtalk.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I invite you to first watch the full but slightly earlier version of the
talk at PythonLinks.info/zodb&lt;/p&gt;
&lt;p&gt;And then read the following summary to see what else is being added to
the talk.&lt;/p&gt;
&lt;p&gt;The ZODB is a mature graph database written in Python and optimized in
C. Just subclass off of class Persistent Object and Persistent
Container, and your objects, graphs and applications become persistent.&lt;/p&gt;
&lt;p&gt;The market for Graph Databases has recently exploded, as evidenced by
over $200 Million invested in graph database companies. Most of the
graph databases are written in Java.&lt;/p&gt;
&lt;p&gt;If you are a Python developer, you will find much greater productivity
using a graph database written in Python, than one written in statically
bound Java. You cannot add or remove an attribute to an object at
run-time in a statically typed language. Furthermore, the major Java
databases constrain you to one of several persistent data types.
Persistent Python, supported by the ZODB allows you to make any Python
data structure persistent. Publishing JSON, YAML and Pickles are well
supported. GraphQL is conceptually very close to the ZODB schema
approach.&lt;/p&gt;
&lt;p&gt;Okay, the ZODB is interesting, but is it risky? The ZODB is mature, rock
solid and well supported. The ZODB is quite heavily used in the Plone
world. Just the government of Brazil has over 100 websites using the
ZODB. That includes the President's office, parliament and many other
governmet offices. Recently the ZODB has been reengineered. It now
supports thousands of write transactions per second.&lt;/p&gt;
&lt;p&gt;The major applications of graph databases are fraud detection, social
networks and computer networks. NLP is an interesting application area.&lt;/p&gt;
&lt;p&gt;The talk reviews the basic concepts of traversal and views on objects.&lt;/p&gt;
&lt;p&gt;It is important to understand the basics of how objects are stored on
disk. Objects are pickled. There are multiple ways to store those
pickles. When using File Storage, the objects in a transaction are
appended to he end of the database files. When using relstorage, a
record is created with the object id, the version number, and the
pickle. The talk reviews how objects are distributed across multiple
Python processes. With ZEO the pickles are served across the network.
Connections are encrypted. The talk also discusses how to build
real-time (chat and iOT) applications using the MQTT message broker with
the ZODB.&lt;/p&gt;
&lt;p&gt;Performance, scalability, and number of objects, are all discussed.
Comparisons are made to traditional relational databases.&lt;/p&gt;
&lt;p&gt;The ZODB Demo makes it very easy to start building your own applications
on top of the ZODB. You can start by customizing the TreeLeaf,
TreeBranch and TreeRoot classes and their templates. You get CRUD for
free.&lt;/p&gt;
&lt;p&gt;The demo includes traditional relational CRUD, Create, Read, Update, and
Delete. But it also includes the extended graph CRUD. Rename a Leaf or
Branch. Cut and paste leaves or branches, copy and paste leaves or
branches. View and restore historic versions are demonstrated.&lt;/p&gt;
&lt;p&gt;Of course the real reason to use a graph database is to improve the user
experience. A basic concept in human factors is to limit lists to 7
items. That is why librarians use hierarchy. The Panama Papers
journalists said a graph database was more intuitive. Have you ever
selected your country from a list of 150 countries. Much better to use a
hierarchical list. Have you ever used a Google map with thousands of
pins. Much better to have one page for each city.&lt;/p&gt;
&lt;p&gt;And of course the most important reason for using a graph database is
not what the software does, but how it changes how we humans think about
our problems, and how we make decisions. Graph databases enable a
different approach to distributing applications across the network. They
encourage a different approach to managing the git development process.
They enable a different set of decisions to be made.&lt;/p&gt;
&lt;p&gt;By the end of this talk, readers should have a much better appreciation
for the rich but little known and under appreciated ZODB ecosystem.&lt;/p&gt;
</summary><category term="Web"></category></entry><entry><title>A Day Has Only 24±1 Hours: import pytz</title><link href="https://pyvideo.org/pycon-de-2018/a-day-has-only-24-1-hours-import-pytz.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Miroslav Šedivý</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/a-day-has-only-24-1-hours-import-pytz.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;On the last Sunday of October “we get one more hour of sleep” but may
spend much more time debugging code dealing with the timezones, daylight
saving time shifts and datetime stuff in general.&lt;/p&gt;
&lt;p&gt;We'll look at a few pitfalls you may encounter when working with
datetimes in Python. We'll discover the &lt;tt class="docutils literal"&gt;pytz&lt;/tt&gt; module and explain why
&lt;tt class="docutils literal"&gt;pytz.all_timezones&lt;/tt&gt; contains over 500 individual timezones. We'll
also find the reason why &lt;tt class="docutils literal"&gt;pytz&lt;/tt&gt; is not part of the standard Python,
why it gets updated so often and why even that won't solve all your
problems.&lt;/p&gt;
</summary><category term="Data Science"></category><category term="Science"></category></entry><entry><title>About going Open-Source</title><link href="https://pyvideo.org/pycon-de-2018/about-going-open-source.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Tim Großmann</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/about-going-open-source.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;I will start of talking about why &amp;quot;working for free&amp;quot; became an important
part of the developer culture all around the world and talk about why
companies should try to share as many tools as possible. I'll give some
examples of tools that were open sourced and got immense traction
leading to the projects growing with an intense speed. I'll try to take
away the &amp;quot;fear&amp;quot; of open sourcing tools that cost ten of thousands of
dollars to create. Then I'll describe how my journey with open source
looks like and start talking about how you can get your feet into
contributing to known projects. After that I will close off with some
hints on doing and contributing to open source projects that worked out
great for me. They will also get an impression on what opportunities
will show up if they put some of their time into doing OS.&lt;/p&gt;
&lt;p&gt;The audience can be mixed, but it's way more interesting for people that
are either new to programming or have never worked with open source.&lt;/p&gt;
&lt;p&gt;In a perfect world, some of the listeners would leave the presentation
with the motivation and hard goal to start with OS as soon as possible.&lt;/p&gt;
</summary><category term="Business &amp; Start-Ups"></category></entry><entry><title>Achieving Resilient Code with Integration Tests</title><link href="https://pyvideo.org/pycon-de-2018/achieving-resilient-code-with-integration-tests.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Alexandre Figura</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/achieving-resilient-code-with-integration-tests.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;You are maybe like me: I never learned at school how to write tests. My
teachers gave me at first a broad overview of computer history. Then,
they explained me some basic design patterns. And to finish, I often had
to write more or less basic programs, to validate and demonstrate my
skills. Not the kind of code I would be really proud of today: the
procrastinator monkey living in my head at this time was more thinking
about planning my summer holidays, rather than writing Ninja code!&lt;/p&gt;
&lt;p&gt;And to make things worse, my studies focused on network and system
engineering. Not software architecture. Funny story, because I decided
to become programmer a couple of years later…&lt;/p&gt;
&lt;p&gt;What I realize now is that I don’t have as much time as before to learn.
And in a world driven by business, where time is money, and where
tradeoffs are the rule, there is rarely enough money to write both shiny
new features and a complete test suite.&lt;/p&gt;
&lt;p&gt;People who practice Test-Driven Development know how complicated it can
be to write proper tests. TDD is often discouraging at first: the
learning curve is steep. But this problem also exists in the testing
world in general. Because writing good tests is hard, many beginners get
headaches trying to reach this goal. How to convince project managers to
have more time for writing tests in these conditions…&lt;/p&gt;
&lt;p&gt;But “le jeu en vaut la chandelle” as we say in French (&amp;quot;the juice is
worth the squeeze&amp;quot;). Well tested applications are not only easier to
maintain and extend. They also have in general a better API. That’s what
we will see in this talk, by focusing on how to write integration tests.
Our journey will begin with a presentation of different testing
strategies. We will then jump to the practical part, using Pytest,
interface testing , dependency injections and stubs, amongst many
others. And because we want to add nice buzzwords on our resume after
PyConDE, we will finish this talk by automating the whole with Docker
Compose.&lt;/p&gt;
</summary><category term="Programming"></category><category term="Python"></category></entry><entry><title>Active Learning - Building Semi-supervised Classifiers when Labeled Data is not Available</title><link href="https://pyvideo.org/pycon-de-2018/active-learning-building-semi-supervised-classifiers-when-labeled-data-is-not-available.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Dr. Hendrik Niemeyer</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/active-learning-building-semi-supervised-classifiers-when-labeled-data-is-not-available.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In many situations large datasets are available but unfortunately
labeling is expensive and time consuming. Active Learning is a concept
for building classifiers by letting the algorithm choose the training
data it uses. This achieves greater accuracy than just labeling a random
subset of the available dataset.&lt;/p&gt;
&lt;p&gt;The active learning algorithm selects some unlabeled data instances
which are then labeled by a human annotator. Given this information a
classifier is trained and new instances for the human annotator to label
are selected. This iterative process tries to label as few instances as
possible while achieving high classification accuracy.&lt;/p&gt;
&lt;p&gt;In this talk I will give a general overview of the core concepts and
techniques of active learning like algorithms for selecting the queries
and convergence criteria.&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Algorithms"></category><category term="Data Science"></category><category term="Machine Learning"></category><category term="Python"></category></entry><entry><title>Analyzing Twitter Data</title><link href="https://pyvideo.org/pycon-de-2018/analyzing-twitter-data.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Fabian Gebhart</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/analyzing-twitter-data.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>Announcement: PyData MeetUp Prague</title><link href="https://pyvideo.org/pycon-de-2018/announcement-pydata-meetup-prague.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Jiri Bajer</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/announcement-pydata-meetup-prague.html</id><summary type="html"></summary></entry><entry><title>Binder - lowering the bar to sharing interactive software</title><link href="https://pyvideo.org/pycon-de-2018/binder-lowering-the-bar-to-sharing-interactive-software.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Tim Head</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/binder-lowering-the-bar-to-sharing-interactive-software.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Binder project drastically lowers the bar to sharing and re-using
software. As a user wanting to try out someone else’s work I only have
to click a single link. As the author preparing a binder-ready project
is much easier than having to support many different platforms and for
many projects involves little additional work.&lt;/p&gt;
&lt;p&gt;In this talk I will introduce the audience to the concepts and ideas
behind the Binder project. I will showcase examples from the community
to illustrate use-cases and show off the power of Binder.&lt;/p&gt;
&lt;p&gt;Three pieces of software power Binder:
&lt;a class="reference external" href="http://repo2docker.readthedocs.io/en/latest/"&gt;repo2docker&lt;/a&gt;,
&lt;a class="reference external" href="https://binderhub.readthedocs.io/en/latest/"&gt;BinderHub&lt;/a&gt; and
&lt;a class="reference external" href="http://jupyterhub.readthedocs.io/en/stable/"&gt;JupyterHub&lt;/a&gt;. Using an
example repository I will go through the steps required to make a
repository binder- ready and what happens when a user launches it. At
each step I will illustrate the role that each of the three software
components play and how they interact.&lt;/p&gt;
&lt;p&gt;Binder is a project created by its community. I will present pathways
for getting involved with the community.&lt;/p&gt;
&lt;p&gt;To wrap up I will highlight plans for future developments and features
of Binder.&lt;/p&gt;
</summary><category term="Community"></category><category term="Data Science"></category><category term="DevOps"></category><category term="Jupyter"></category><category term="Science"></category><category term="Web"></category></entry><entry><title>Case Study in Travel Business - Understanding agent connections using NetworkX</title><link href="https://pyvideo.org/pycon-de-2018/case-study-in-travel-business-understanding-agent-connections-using-networkx.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Cheuk Ting Ho</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/case-study-in-travel-business-understanding-agent-connections-using-networkx.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Network analysis is getting more and more attention in Business
Intelligence, people hope to get information out of the structure of an
organization or a communication network. In this talk, we use the hotel
room search requests from travel agents, including online public
website, B2C, B2B and B2B2C, to build a relational network among them.
By using this network as an example, we demonstrate how insights can be
extract by studying network properties.&lt;/p&gt;
&lt;p&gt;In the first half of the talk, we will explain how the network is built
using NetworkX, an open-source python library that is designed for the
creation, manipulation, and study of the structure, dynamics, and
functions of complex networks. When 2 agents are making the same search
at the same time , a link ( or an “edge” in network analysts terms) is
made pointing form the initial searcher to the subsequent searcher.
Using a list of these searches, a directed graph is built. We will also
demonstrate how to pick the biggest connected component out form the
graph. In the second half, with the graphs created, we show how
different functions of NetworkX can be used to study the graphs. By
compare the graph properties of our graph to the other popular network
graphs, we can get the insight of how the network was created. Also by
studying the graphs, we can understand the behavior of the agents and
can even figure out which agents are acting as main hubs in the network.&lt;/p&gt;
&lt;p&gt;This talk is for people who are interested in network analysis and would
like to see how it can be used in a business case. Audiences with any
level of python experience can learn some basic concept of network
analysis work and how it can be applied to provide business insights.&lt;/p&gt;
</summary><category term="Algorithms"></category><category term="Networks"></category><category term="Python"></category></entry><entry><title>Cython to speed up your Python code</title><link href="https://pyvideo.org/pycon-de-2018/cython-to-speed-up-your-python-code.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Stefan Behnel</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/cython-to-speed-up-your-python-code.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;a class="reference external" href="http://cython.org"&gt;Cython&lt;/a&gt; is not only a very fast and comfortable
way to talk to native code and libraries, it is also a widely used tool
for speeding up Python code. The Cython compiler translates Python code
to C or C++ code, and applies many static optimisations that make Python
code run visibly faster than in the interpreter. But even better, it
supports static type annotations that allow direct use of C/C++ data
types and functions, which the compiler uses to convert and optimise the
code into fast, native C. The tight integration of all three languages,
Python, C and C++, makes it possible to freely mix Python features like
generators and comprehensions with C/C++ features like native data
types, pointer arithmetic or manually tuned memory management in the
same code.&lt;/p&gt;
&lt;p&gt;This talk by a core developer introduces the Cython compiler by
interactive code examples, and shows how you can use it to speed up your
real-world Python code. You will learn how you can profile a Python
module and use Cython to compile and optimise it into a fast binary
extension module. All of that, without losing the ability to run it
through common development tools like code checkers or coverage test
tools.&lt;/p&gt;
</summary><category term="Big Data"></category><category term="Infrastructure"></category><category term="Jupyter"></category><category term="Parallel Programming"></category></entry><entry><title>Decrypting SSL With Python/Tshark</title><link href="https://pyvideo.org/pycon-de-2018/decrypting-ssl-with-pythontshark.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Johannes Frank</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/decrypting-ssl-with-pythontshark.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>Developing ecommerce platform with Django Oscar</title><link href="https://pyvideo.org/pycon-de-2018/developing-ecommerce-platform-with-django-oscar.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Alexander Gaevsky</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/developing-ecommerce-platform-with-django-oscar.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Modern technologies has changed the way how we buy and sell in the
Internet nowadays. Thus, we also constantly evolve the way how we build
projects to sell and buy goods using our technologies of choice - Python
and Django. Ease of customization and flexibility made Oscar application
of my choice for building custom ecommerce platforms on top of Django,
allowing to satisfy client requirements without necessity of
implementing solution from scratch, since Oscar have ready-made
applications for basket, checkout, shipping etc, available for the
further tweak and refinement.&lt;/p&gt;
&lt;p&gt;I’ve been using and contributing to Django Oscar since 2015, designed
and supported various ecommerce projects in different fields (food,
accessories, shoes) and sizes during this time. In this talk I’m going
to share some of the experience and conclusions about building complex
ecommerce platform using Django, and eventually, Django Oscar.&lt;/p&gt;
&lt;p&gt;I will go through the next topics:&lt;/p&gt;
</summary><category term="Business &amp; Start-Ups"></category><category term="Code-Review"></category><category term="Django"></category></entry><entry><title>Distributed Hyperparameter search with sklearn and kubernetes</title><link href="https://pyvideo.org/pycon-de-2018/distributed-hyperparameter-search-with-sklearn-and-kubernetes.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Jakob Karalus</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/distributed-hyperparameter-search-with-sklearn-and-kubernetes.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;While sklearn provides a good interface to do hyperparameter search on
large &amp;amp; complex model (pipelines), doing these can take up a lot of
time. The traditional way usually includes one beefy machine and a lot
of waiting. In other cases, people tend to “manually” schedule parameter
ranges between nodes, but that can also be problematic since these won't
talk to each other. Kubernetes itself is currently the most prominent
scheduler and shines at distributing task, but is a pretty complex
system in itself.&lt;/p&gt;
&lt;p&gt;In this talk, I will show how you can harness the scheduling of
kubernetes for distributing hyperparameter search with sklearn onto a
cluster of nodes. This can be achieved quite easily and with just a few
changes to the original code, so the Data Scientist won't be bothered by
complex kubernetes internals.&lt;/p&gt;
</summary><category term="Algorithms"></category><category term="Big Data"></category><category term="Data Science"></category><category term="DevOps"></category><category term="Infrastructure"></category><category term="Machine Learning"></category></entry><entry><title>ESA Summer Of Code In Space &amp; Open Source Cubesat Workshop</title><link href="https://pyvideo.org/pycon-de-2018/esa-summer-of-code-in-space-open-source-cubesat-workshop.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Artur Scholz</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/esa-summer-of-code-in-space-open-source-cubesat-workshop.html</id><summary type="html"></summary></entry><entry><title>Experiences from applying Convolutional Neural Networks for classifying 2D sensor data</title><link href="https://pyvideo.org/pycon-de-2018/experiences-from-applying-convolutional-neural-networks-for-classifying-2d-sensor-data.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Matthias Peussner</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/experiences-from-applying-convolutional-neural-networks-for-classifying-2d-sensor-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When being the first in your company to apply a deep learning algorithm
on your data you often have to overcome several obstacles. One challenge
is to understand your data and to form a training and test dataset.
Another one is to get your algorithms and its performance accepted and
integrated in your existing processing workflow.&lt;/p&gt;
&lt;p&gt;Convolutional Neural Networks have become a standard tool in processing
image data. They have shown to reach human-level classification
performance on some object recognition tasks.&lt;/p&gt;
&lt;p&gt;In this talk I will present my experiences in getting started using a
convolutional neural network for classification of 2D sensor data. I
will point out the importance of understanding your data and give hints
of how to select your train and test datasets according to the
requirements. Furthermore, I will show how to get a feature extractor
out of the classifier and how to visualize it.&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Computer Vision"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Machine Learning"></category></entry><entry><title>From Wittgenstein to TensorFlow: The role of Domain Specific Languages and Language Design in Machine Learning</title><link href="https://pyvideo.org/pycon-de-2018/from-wittgenstein-to-tensorflow-the-role-of-domain-specific-languages-and-language-design-in-machine-learning.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Mattia Ferrini</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/from-wittgenstein-to-tensorflow-the-role-of-domain-specific-languages-and-language-design-in-machine-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;What programming language do you use to develop Machine Learning (ML)
and Artificial Intelligence (AI) systems? This is one of the most
frequently asked question about my work. The short answer: a mix of
Scala, Python and F# The long answer: DSLs are a hot topic and play a
crucial role in many of the tasks Machine Learning (ML) and Artificial
Intelligence (AI) systems need to tackle. Expertise in DSLs is mission
critical in ML and AI systems.&lt;/p&gt;
</summary></entry><entry><title>Generate Company Names With Neural Networks</title><link href="https://pyvideo.org/pycon-de-2018/generate-company-names-with-neural-networks.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Alexander Engelhardt</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/generate-company-names-with-neural-networks.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>GeoPython 2019</title><link href="https://pyvideo.org/pycon-de-2018/geopython-2019.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Martin Christen</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/geopython-2019.html</id><summary type="html"></summary></entry><entry><title>Germany's next topic model</title><link href="https://pyvideo.org/pycon-de-2018/germanys-next-topic-model.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Thomas Mayer</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/germanys-next-topic-model.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Identifying topic models for user generated content like hotel reviews
turns out to be difficult with the standard approach of LDA (Latent
Dirichlet Allocation; Blei et al., 2003). Hotel review texts usually
don't differ as much in the topics that are covered as is typical with
other genres such as Wikipedia or newsgroup articles where there is
commonly only a very small set of topics present in each document.&lt;/p&gt;
&lt;p&gt;To this end, we developed our own approach to topic modeling that is
especially tailored to non-edited texts like hotel reviews. The approach
can be divided into three major steps. First, using the concept of
second-order cooccurrences we define a contextual similarity score that
enables us to identify words that are similar with respect to certain
topics. This score allows us to build up a topic network where nodes are
words and edges the contextual similarity between the words. With the
help of algorithms from graph theory, like the Infomap algorithm
(Rosvall and Bergstrom, 2008), we are able to detect clusters of highly
connected words that can be identified as topics in our review texts. In
a further step, we use these clusters and the respective words to get a
topic similarity score for each word in the network. In other words, we
transform a hard clustering of words into topics into a probability
score of how likely a certain word belongs to a given topic/cluster.&lt;/p&gt;
&lt;p&gt;The presentation is structured as follows:&lt;/p&gt;
&lt;p&gt;References: David M. Blei, Andrew Y. Ng, Michael I. Jordan: Latent
dirichlet allocation. In: Journal of Machine Learning Research, Jg. 3
(2003), S. 993–1022, ISSN 1532-4435 M. Rosvall and C. T. Bergstrom, Maps
of information flow reveal community structure in complex networks, PNAS
105, 1118 (2008) &lt;a class="reference external" href="http://dx.doi.org/10.1073/pnas.0706851105"&gt;http://dx.doi.org/10.1073/pnas.0706851105&lt;/a&gt;,
&lt;a class="reference external" href="http://arxiv.org/abs/0707.0609"&gt;http://arxiv.org/abs/0707.0609&lt;/a&gt;&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Data Science"></category><category term="Networks"></category><category term="NLP"></category><category term="Machine Learning"></category><category term="Visualisation"></category></entry><entry><title>Hacktoberfest And You Can Have Pythin In Your Language</title><link href="https://pyvideo.org/pycon-de-2018/hacktoberfest-and-you-can-have-pythin-in-your-language.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Cheuk Ting Ho</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/hacktoberfest-and-you-can-have-pythin-in-your-language.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>How type annotations make your code better</title><link href="https://pyvideo.org/pycon-de-2018/how-type-annotations-make-your-code-better.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Igor Davydenko</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/how-type-annotations-make-your-code-better.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Type annotations still not received that amount of popularity, that
should. People still finding them hard and sometimes ambiguous to use.
But if you start new project in Python in 2018 you should consider using
type annotations in your code and this short talk describes why.&lt;/p&gt;
&lt;p&gt;I'll go over examples, where type annotations helped my team to create
less complex code, and how using type annotations changing your mind for
projecting &amp;amp; implementing features for your project.&lt;/p&gt;
</summary><category term="Infrastructure"></category><category term="Web"></category></entry><entry><title>HyperLog Log</title><link href="https://pyvideo.org/pycon-de-2018/hyperlog-log.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Robin Roth</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/hyperlog-log.html</id><summary type="html"></summary></entry><entry><title>Introduction and practical experience about Quantum Computing using the Python libraries from IBM and Google</title><link href="https://pyvideo.org/pycon-de-2018/introduction-and-practical-experience-about-quantum-computing-using-the-python-libraries-from-ibm-and-google.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Dr. Andreas Riegg</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/introduction-and-practical-experience-about-quantum-computing-using-the-python-libraries-from-ibm-and-google.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As publicly announced in early 2018, Daimler AG has started cooperations
with IBM and Google on Quantum Computing. When doing concrete
experiments with the Quantum Computing cloud based offerings, two
different Python libraries provided by IBM and Google are used. They are
named QISKIT in the case of IBM and CIRQ in the case of Google. The
experiments with both libraries are handled using appropriate Jupyter
Notebooks. This talk gives a brief introduction on Quantum Computing,
specifically on Quantum Computers based on transmon-based QBits. This is
followed by an introduction of the both Python libraries that are used.
Then some details about the Jupyter notebooks that are used are given.
The talk will finish with some demos and an overview about the most
important practical experiences with both Quantum Computing offerings.&lt;/p&gt;
</summary><category term="Jupyter"></category><category term="Programming"></category><category term="Python"></category><category term="Science"></category></entry><entry><title>IoT using Python on Linux: Lessons Learned</title><link href="https://pyvideo.org/pycon-de-2018/iot-using-python-on-linux-lessons-learned.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Thomas Keppler</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/iot-using-python-on-linux-lessons-learned.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In a distributed sensor network system with a Java based Cloud
application, mobile apps and a proprietary radio protocol accompanying
it we developed an IoT appliance that connects the existing radio
infrastructure to the Cloud service developed in-house.&lt;/p&gt;
&lt;p&gt;Using CPython 3.5 + Debian GNU/Linux 9 on an ARMv7 platform, we
developed the following features:&lt;/p&gt;
&lt;p&gt;Over the course of this project, we learned a lot about Test Driven
Development of Python apps in teams and DevOps in the IoT space. We
would now like to share our experience developing a Python application
for a headless IoT device and the things we would liked to have known
upfront.&lt;/p&gt;
&lt;p&gt;The talk is held both by Matthias Schmidt (Senior Architect at diva-e)
and Thomas Keppler (Software Developer at diva-e).&lt;/p&gt;
</summary><category term="DevOps"></category><category term="Infrastructure"></category><category term="Networks"></category><category term="Programming"></category><category term="Python"></category></entry><entry><title>Jupyter Notebook Best Practices</title><link href="https://pyvideo.org/pycon-de-2018/jupyter-notebook-best-practices.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Simon Tschöke</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/jupyter-notebook-best-practices.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>Keynote: Digital Cultural Techniques</title><link href="https://pyvideo.org/pycon-de-2018/keynote-digital-cultural-techniques.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Peter Weibel</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/keynote-digital-cultural-techniques.html</id><summary type="html"></summary><category term="keynote"></category></entry><entry><title>Let Me Just Explain Gravity</title><link href="https://pyvideo.org/pycon-de-2018/let-me-just-explain-gravity.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Peer Wagner</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/let-me-just-explain-gravity.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>Let Me Take A Quick Look Into The Data</title><link href="https://pyvideo.org/pycon-de-2018/let-me-take-a-quick-look-into-the-data.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Sofia</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/let-me-take-a-quick-look-into-the-data.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>Let's Play Testing</title><link href="https://pyvideo.org/pycon-de-2018/lets-play-testing.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Johannes Lippmann</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/lets-play-testing.html</id><summary type="html"></summary></entry><entry><title>MoinMoin Wiki</title><link href="https://pyvideo.org/pycon-de-2018/moinmoin-wiki.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Thomas Waldmann</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/moinmoin-wiki.html</id><summary type="html"></summary></entry><entry><title>Notebooks As Scripts</title><link href="https://pyvideo.org/pycon-de-2018/notebooks-as-scripts.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Tim Head</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/notebooks-as-scripts.html</id><summary type="html"></summary></entry><entry><title>OCA: The Home Of One Of The Biggest Python OS Projects</title><link href="https://pyvideo.org/pycon-de-2018/oca-the-home-of-one-of-the-biggest-python-os-projects.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Jörg Lorenz</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/oca-the-home-of-one-of-the-biggest-python-os-projects.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>PewPew</title><link href="https://pyvideo.org/pycon-de-2018/pewpew.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Radomir Dopieralski</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/pewpew.html</id><summary type="html"></summary></entry><entry><title>Pizza</title><link href="https://pyvideo.org/pycon-de-2018/pizza.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Christian Barra</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/pizza.html</id><summary type="html"></summary></entry><entry><title>Productionizing your ML code seamlessly</title><link href="https://pyvideo.org/pycon-de-2018/productionizing-your-ml-code-seamlessly.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Lauris Jullien</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/productionizing-your-ml-code-seamlessly.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Data science and Machine Learning are hot topics right now for Software
Engineers and beyond. There are a lot of python tools that allow you to
hack together a notebook to quickly get insight on your data, or train a
model to predict or classify. Or you might have inherited some data
wrangling and modeling {Jupyter/Zeppelin} notebook code from someone
else, like the resident data scientist.&lt;/p&gt;
&lt;p&gt;The code works on test data, when you run the cells in the right order
(skipping cell 22), and you believe that the insight gained from this
work would be a valuable game changer. But now how do you take this
experimental code into production, and keep it up-to-date with a regular
retraining schedule? And what do you need to do after that, to ensure
that it remains reliable and brings value in the long term?&lt;/p&gt;
&lt;p&gt;These will be the questions this talk will answer, focusing on 2 main
themes: What does running an ML model in production involve? How to
improve your development workflow to make the path to production easier?&lt;/p&gt;
&lt;p&gt;This talk will draw examples from real projects at Yelp, like migrating
a pandas/sklearn classification project into production with pyspark,
while aiming to give advice that is not dependent on specific
frameworks, or tools, and is useful for listeners from all backgrounds.&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Data Science"></category><category term="Machine Learning"></category></entry><entry><title>Prophet Fon Time Series: Do You Use It?</title><link href="https://pyvideo.org/pycon-de-2018/prophet-fon-time-series-do-you-use-it.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Gregory Wallace</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/prophet-fon-time-series-do-you-use-it.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>Pyccel, a Fortran static compiler for scientific High-Performance Computing</title><link href="https://pyvideo.org/pycon-de-2018/pyccel-a-fortran-static-compiler-for-scientific-high-performance-computing.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Dr. Ing. Ratnani Ahmed</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/pyccel-a-fortran-static-compiler-for-scientific-high-performance-computing.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Pyccel&lt;/em&gt; is a new &lt;strong&gt;static compiler&lt;/strong&gt; for Python that uses &lt;strong&gt;Fortran&lt;/strong&gt;
as backend language while enabling High-Performance Computing &lt;strong&gt;HPC&lt;/strong&gt;
capabilities.&lt;/p&gt;
&lt;p&gt;Fortran is a computer language for scientific programming that is
tailored for efficient run-time execution on a wide variety of
processors. Even if the &lt;em&gt;2003&lt;/em&gt; and &lt;em&gt;2008&lt;/em&gt; standards added major
improvements like &lt;em&gt;OOP, Coarrays, Submodules, do concurrent&lt;/em&gt; , etc ...
they are not covered by all available compilers. Moreover, the Fortran
developer still suffers from the lack of &lt;strong&gt;meta-programming&lt;/strong&gt; compared
to &lt;strong&gt;C++&lt;/strong&gt; ones. Therefore, it is more and more difficult for applied
mathematicians and computational physicists to write applications at the
&lt;em&gt;state of art&lt;/em&gt; (targeting CPUs, GPUs, MICs) while implementing
complicated algorithms or numerical schemes.&lt;/p&gt;
&lt;p&gt;Pyccel can be used in two cases:&lt;/p&gt;
&lt;p&gt;In order to achieve the second point, we developed an internal DSL for
&lt;em&gt;types&lt;/em&gt; and &lt;em&gt;macros&lt;/em&gt;. The later is used to map sentences based on
&lt;em&gt;mpi4py&lt;/em&gt; , &lt;em&gt;scipy.linalg.blas or lapack&lt;/em&gt; onto the appropriate calls in
Fortran. Moreover, two parsers, for &lt;em&gt;OpenMP&lt;/em&gt; and &lt;em&gt;OpenACC&lt;/em&gt; , were added
too, allowing for explicit parallelism through the use of pragmas.&lt;/p&gt;
&lt;p&gt;Last but not least, Pyccel is an extension of &lt;strong&gt;Sympy&lt;/strong&gt;. Actually, it
converts a Python code to symbolic expressions/trees, from a Full Syntax
Tree ( &lt;em&gt;RedBaron&lt;/em&gt; ), then annotates the new AST using types or different
settings provided by the user.&lt;/p&gt;
&lt;p&gt;In this talk, after a brief description of Pyccel, I will show different
applications including Finite Elements (1d, 2d, 3d), Semi-Lagrangian
schemes (4d), Kronecker linear solvers, diagnostics for 5D kinetic
simulations and Machine Learning for Partial Differential Equations.&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Algorithms"></category><category term="Astronomy"></category><category term="Parallel Programming"></category><category term="Programming"></category><category term="Python"></category><category term="Science"></category></entry><entry><title>PyComic Con</title><link href="https://pyvideo.org/pycon-de-2018/pycomic-con.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Alexander CS Hendorf</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/pycomic-con.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>PyData Frankfurt</title><link href="https://pyvideo.org/pycon-de-2018/pydata-frankfurt.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Alexander Bohn</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/pydata-frankfurt.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>PyLadies - Jessica Greene and PyLadies Berlin</title><link href="https://pyvideo.org/pycon-de-2018/pyladies-jessica-greene-and-pyladies-berlin.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Jessica Greene</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/pyladies-jessica-greene-and-pyladies-berlin.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>PyRant</title><link href="https://pyvideo.org/pycon-de-2018/pyrant.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Valerio Maggio</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/pyrant.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>Python And PostgreSQL</title><link href="https://pyvideo.org/pycon-de-2018/python-and-postgresql.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Stephane Wirtel</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/python-and-postgresql.html</id><summary type="html"></summary></entry><entry><title>Python AWS Dataclasses</title><link href="https://pyvideo.org/pycon-de-2018/python-aws-dataclasses.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Benjamin Weigel</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/python-aws-dataclasses.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>Python Dependency Management</title><link href="https://pyvideo.org/pycon-de-2018/python-dependency-management.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Patrick Muehlbauer</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/python-dependency-management.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;For a long time there were &lt;tt class="docutils literal"&gt;pip&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;virtualenv&lt;/tt&gt; which were used
together with &lt;tt class="docutils literal"&gt;requirements.txt&lt;/tt&gt; files to manage Python dependencies.
Nowadays there are various other tools that help you improve the
workflow.&lt;/p&gt;
&lt;p&gt;We will have a look at popular projects like&lt;/p&gt;
&lt;p&gt;After the talk you will be able to decide for yourself which approach
suits your usecases best and don't have to rely on rants postet on
reddit.&lt;/p&gt;
</summary><category term="Infrastructure"></category></entry><entry><title>Python Is For Everybody</title><link href="https://pyvideo.org/pycon-de-2018/python-is-for-everybody.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Nicholas A. Del Grosso</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/python-is-for-everybody.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>Python Is Slow, Right?</title><link href="https://pyvideo.org/pycon-de-2018/python-is-slow-right.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Stefan Nordhausen</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/python-is-slow-right.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>Python &amp; Javascript = Transcrypt</title><link href="https://pyvideo.org/pycon-de-2018/python-javascript-transcrypt.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Andreas Bunkahle</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/python-javascript-transcrypt.html</id><summary type="html"></summary></entry><entry><title>Python On iOS</title><link href="https://pyvideo.org/pycon-de-2018/python-on-ios.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Ruud Van Der Ham</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/python-on-ios.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>Python VR With RatCAVE</title><link href="https://pyvideo.org/pycon-de-2018/python-vr-with-ratcave.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Nicholas A. Del Grosso</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/python-vr-with-ratcave.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>Repository Line Length Analysis</title><link href="https://pyvideo.org/pycon-de-2018/repository-line-length-analysis.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Peer Wagner</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/repository-line-length-analysis.html</id><summary type="html"></summary><category term="lightning talk"></category></entry><entry><title>reticulate: R interface to Python</title><link href="https://pyvideo.org/pycon-de-2018/reticulate-r-interface-to-python.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Jens Bruno Wittek</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/reticulate-r-interface-to-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python and R are the preferred languages for data science. In 2018,
RStudio introduced its package reticulate and clearly demonstrates that
it favours to join forces. Both languages have strengths and weaknesses.
Tools to combine the strengths will enable easier collaboration in
projects and more possibilities to succeed. Using Python from R gives R
users wider access to functions and makes it easier for Python beginners
to just run scripts and being able to collaborate in Python projects.
The talk will show the possibilities of reticulate: The main part starts
with demonstrating the Python interpreter within R. It will show how to
source Python scripts as well as install and import modules. Then it
will deal with the most important types of Python objects, how they are
represented in R and how to further manipulate them. Thereby, a special
focus is on using Python for data science. In addition, it will be
presented how Conda environments can be created and used from R. A
further application will be the creation of reports with Markdown and
LaTeX where R and Python can be used within one document and share
objects. A last topic is about showing the possibilities for easier
development in RStudio (help regarding Python functions, auto
completion).&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Algorithms"></category><category term="Big Data"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Data Science"></category><category term="NLP"></category><category term="Machine Learning"></category><category term="Visualisation"></category></entry><entry><title>Salabim, Discrete Event Simulation In Python</title><link href="https://pyvideo.org/pycon-de-2018/salabim-discrete-event-simulation-in-python.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Ruud Van Der Ham</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/salabim-discrete-event-simulation-in-python.html</id><summary type="html"></summary></entry><entry><title>Scalable Scientific Computing using Dask</title><link href="https://pyvideo.org/pycon-de-2018/scalable-scientific-computing-using-dask.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Uwe L. Korn</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/scalable-scientific-computing-using-dask.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;</summary><category term="Algorithms"></category><category term="Big Data"></category><category term="Data Science"></category><category term="Parallel Programming"></category><category term="Python"></category></entry><entry><title>Script, Library, or Executable: You can have it all!</title><link href="https://pyvideo.org/pycon-de-2018/script-library-or-executable-you-can-have-it-all.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Luke Lee</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/script-library-or-executable-you-can-have-it-all.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;I will describe one possible way to achieve this using the following
features:&lt;/p&gt;
&lt;p&gt;We want to create a package layout that can support a CLI interface, an
importable library, and a GUI all while sharing as much code as
possible.&lt;/p&gt;
&lt;p&gt;Although text and graphical interfaces are very different we can provide
a consistent API with careful consideration. This way users can easily
use our library or either interface without starting all over again.&lt;/p&gt;
&lt;p&gt;First we will layout a single-file CLI script using argparse similar to
the Unix &lt;tt class="docutils literal"&gt;wc&lt;/tt&gt; tool that takes a text file and outputs the following
information:&lt;/p&gt;
&lt;p&gt;We'll discuss the &lt;tt class="docutils literal"&gt;__name__ == __main__&lt;/tt&gt; Python idiom, separating the
argument parsing from the main function, and why keeping as little as
possible in &lt;tt class="docutils literal"&gt;__main__&lt;/tt&gt; is better for reusability.&lt;/p&gt;
&lt;p&gt;There are several pros and cons to providing others with a single-file
script. It's easy to develop and simple to read, but it requires any
user to have the correct version of Python installed. It's also
difficult for other developers to reuse the code in their own projects
or deploy to PyPI.&lt;/p&gt;
&lt;p&gt;Next we'll take our single-file script and expand it into a basic Python
package using a main folder, &lt;strong&gt;init&lt;/strong&gt;.py, and a cli.py script to expose
the same CLI as before.&lt;/p&gt;
&lt;p&gt;We'll discuss how to restructure the main and parsing functions from
step 1 into an public API defined by the &lt;strong&gt;init&lt;/strong&gt;.py that exposes the
same CLI functionality as a library.&lt;/p&gt;
&lt;p&gt;We won't dive into setup.py at all, but there will be links and a brief
description on the various tools to layout a package such as
cookiecutter and setup.py.&lt;/p&gt;
&lt;p&gt;The &lt;a class="reference external" href="https://github.com/chriskiehl/Gooey"&gt;Gooey&lt;/a&gt; project can easily
expose a CLI as GUI with a few decorators. We'll discuss briefly how to
use Gooey and some of the extra functionality it provides to create more
advanced GUIs.&lt;/p&gt;
&lt;p&gt;We'll also give a simple mental model for how it maps argparse argument
types to GUI widgets.&lt;/p&gt;
&lt;p&gt;Until step 3 all we required of users was a working Python 3
installation. However, adding Gooey requires users to have a working
Python installer, the Gooey library, and wxPython. Typically GUIs are
meant for higher-level users so asking them to install all of this to
benefit from our little app is too much.&lt;/p&gt;
&lt;p&gt;Instead we'll see how we run PyInstaller on our entry script to package
up all our dependencies &lt;strong&gt;including&lt;/strong&gt; Python itself into a simple
executable. We'll briefly discuss the build and dist output folders from
PyInstaller along with the ability to use it to package all sorts of
complicated Python applications using Qt, Numpy, etc.&lt;/p&gt;
&lt;p&gt;End-users in management don't even have to know we used Python!&lt;/p&gt;
</summary><category term="Programming"></category><category term="Python"></category></entry></feed>