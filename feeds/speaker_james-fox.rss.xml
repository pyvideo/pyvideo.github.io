<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - James Fox</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 15 Jul 2024 00:00:00 +0000</lastBuildDate><item><title>Towards Causal Foundations of Safe AI</title><link>https://pyvideo.org/uai-2023/towards-causal-foundations-of-safe-ai.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Towards Causal Foundations of Safe AI&amp;quot;
James Fox, Tom Everitt&lt;/p&gt;
&lt;p&gt;With great power comes great responsibility. Artificial intelligence (AI) is rapidly gaining new capabilities, and is increasingly trusted to make decisions impacting humans in significant ways (from self-driving cars to stock-trading to hiring decisions). To ensure that AI behaves in ethical and robustly beneficial ways, we must identify potential pitfalls and develop effective mitigation strategies. In this tutorial, we will explain how (Pearlian) causality offers a useful formal framework for reasoning about AI risk and describe recent work on this topic. In particular, we’ll cover: causal models of agents and how to discover them; causal definitions of fairness, intent, harm, and incentives; and risks from AI such as misgeneralization and preference manipulation, as well as how mitigation techniques including impact measures, interpretability, and path-specific objectives can help address them.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">James Fox</dc:creator><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-07-31:/uai-2023/towards-causal-foundations-of-safe-ai.html</guid><category>UAI 2023</category><category>tutorial</category></item><item><title>UAI 2024 Oral Session 3: Causality</title><link>https://pyvideo.org/uai-2024/uai-2024-oral-session-3-causality.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Towards Bounding Causal Effects under Markov Equivalence
Alexis Bellot
&lt;a class="reference external" href="https://openreview.net/pdf?id=xY33abx46a"&gt;https://openreview.net/pdf?id=xY33abx46a&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Targeted Reduction of Causal Models
Armin Kekić, Bernhard Schölkopf, Michel Besserve
&lt;a class="reference external" href="https://openreview.net/pdf?id=CFHpI53xmb"&gt;https://openreview.net/pdf?id=CFHpI53xmb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Characterising Interventions in Causal Games
Manuj Mishra, James Fox, Michael J. Wooldridge
&lt;a class="reference external" href="https://openreview.net/pdf?id=MXwg8dYBFd"&gt;https://openreview.net/pdf?id=MXwg8dYBFd&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Causally Abstracted Multi-armed Bandits
Fabio Massimo Zennaro, Nicholas George Bishop, Joel Dyer, Yorgos Felekis, Ani Calinescu, Michael J. Wooldridge, Theodoros Damoulas
&lt;a class="reference external" href="https://openreview.net/pdf?id=Uxrxz4X416"&gt;https://openreview.net/pdf?id=Uxrxz4X416&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexis Bellot</dc:creator><pubDate>Mon, 15 Jul 2024 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2024-07-15:/uai-2024/uai-2024-oral-session-3-causality.html</guid><category>UAI 2024</category></item></channel></rss>