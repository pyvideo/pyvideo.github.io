<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_tobias-sterbak.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-10-11T00:00:00+00:00</updated><entry><title>Tutorial: Managing the end-to-end machine learning lifecycle with MLFlow</title><link href="https://pyvideo.org/pydata-berlin-2019/tutorial-managing-the-end-to-end-machine-learning-lifecycle-with-mlflow.html" rel="alternate"></link><published>2019-10-11T00:00:00+00:00</published><updated>2019-10-11T00:00:00+00:00</updated><author><name>Tobias Sterbak</name></author><id>tag:pyvideo.org,2019-10-11:pydata-berlin-2019/tutorial-managing-the-end-to-end-machine-learning-lifecycle-with-mlflow.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Speaker: Tobias Sterbak&lt;/p&gt;
&lt;p&gt;Track:PyData
Machine learning requires experimenting with datasets, data preparation steps, and algorithms. Deploy models to a production system and retrain it on new data. MLflow is an open source platform for managing the end-to-end machine learning lifecycle.&lt;/p&gt;
&lt;p&gt;Recorded at the PyConDE &amp;amp; PyData Berlin 2019 conference.
&lt;a class="reference external" href="https://pycon.de"&gt;https://pycon.de&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More details at the conference page: &lt;a class="reference external" href="https://de.pycon.org/program/PC38WB"&gt;https://de.pycon.org/program/PC38WB&lt;/a&gt;
Twitter:  &lt;a class="reference external" href="https://twitter.com/pydataberlin"&gt;https://twitter.com/pydataberlin&lt;/a&gt;
Twitter:  &lt;a class="reference external" href="https://twitter.com/pyconde"&gt;https://twitter.com/pyconde&lt;/a&gt;&lt;/p&gt;
</summary></entry><entry><title>“Why Should I Trust You?” - Debugging black-box text classifiers</title><link href="https://pyvideo.org/pydata-amsterdam-2018/why-should-i-trust-you-debugging-black-box-text-classifiers.html" rel="alternate"></link><published>2018-05-26T00:00:00+00:00</published><updated>2018-05-26T00:00:00+00:00</updated><author><name>Tobias Sterbak</name></author><id>tag:pyvideo.org,2018-05-26:pydata-amsterdam-2018/why-should-i-trust-you-debugging-black-box-text-classifiers.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Classifying text is a common use case for machine learning algorithms. But despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction. We will use eli5 and the LIME algorithm to explain text classifiers.&lt;/p&gt;
</summary><category term="eli5"></category><category term="lime"></category></entry></feed>