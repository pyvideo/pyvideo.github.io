<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_shotaro-sano.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-07-11T00:00:00+00:00</updated><entry><title>Optuna: A Define by Run Hyperparameter Optimization Framework</title><link href="https://pyvideo.org/scipy-2019/optuna-a-define-by-run-hyperparameter-optimization-framework.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Takuya Akiba</name></author><id>tag:pyvideo.org,2019-07-11:scipy-2019/optuna-a-define-by-run-hyperparameter-optimization-framework.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, we introduce Optuna, a next-generation hyperparameter optimization framework with new design-criteria: (1) define-by-run API that allows users to concisely construct dynamic, nested, or conditional search spaces, (2) efficient implementation of both sampling and early stopping strategies, and (3) easy-to-setup, versatile architecture that can be deployed for various purposes, ranging from scalable distributed computing to lightweight experiment conducted in a local laptop machine. Our software is available under the MIT license (&lt;a class="reference external" href="https://github.com/pfnet/optuna/"&gt;https://github.com/pfnet/optuna/&lt;/a&gt;)&lt;/p&gt;
</summary></entry><entry><title>Optuna: A Define-by-Run Hyperparameter Optimization Framework</title><link href="https://pyvideo.org/scipy-japan-2019/optuna-a-define-by-run-hyperparameter-optimization-framework.html" rel="alternate"></link><published>2019-04-24T00:00:00+00:00</published><updated>2019-04-24T00:00:00+00:00</updated><author><name>Shotaro Sano</name></author><id>tag:pyvideo.org,2019-04-24:scipy-japan-2019/optuna-a-define-by-run-hyperparameter-optimization-framework.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, we introduce Optuna, a next-generation hyperparameter optimization framework with new design-criteria: (1) define-by-run API that allows users to concisely construct dynamic, nested, or conditional search spaces, (2) efficient implementation of both sampling and early stopping strategies, and (3) easy-to-setup, versatile architecture that can be deployed for various purposes, ranging from scalable distributed computing to lightweight experiment conducted in a local laptop machine. Our software is available under the MIT license (&lt;a class="reference external" href="https://github.com/pfnet/optuna/"&gt;https://github.com/pfnet/optuna/&lt;/a&gt;).&lt;/p&gt;
&lt;div class="section" id="connect-with-us"&gt;
&lt;h4&gt;Connect with us!&lt;/h4&gt;
&lt;p&gt;&lt;a class="reference external" href="https://twitter.com/enthought"&gt;https://twitter.com/enthought&lt;/a&gt;
&lt;a class="reference external" href="https://www.facebook.com/Enthought/"&gt;https://www.facebook.com/Enthought/&lt;/a&gt;
&lt;a class="reference external" href="https://www.linkedin.com/company/enthought"&gt;https://www.linkedin.com/company/enthought&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</summary></entry></feed>