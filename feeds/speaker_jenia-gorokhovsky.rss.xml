<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Tue, 05 Jun 2018 00:00:00 +0000</lastBuildDate><item><title>Deep model serving - scale and ergonomics</title><link>https://pyvideo.org/pycon-israel-2018/deep-model-serving-scale-and-ergonomics.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A serving system for Deep Learning models is a tricky design problem. It's a large scale production system, so we want it to scale well, adapt to changing traffic patterns, and have low latency. It’s also part of the Data Scientist’s core loop - so it should be very flexible, and running an experiment on live traffic should be easy. In this talk, I’ll discuss key design considerations for such a system covering both perspectives. I’ll also describe a system we built at Taboola for serving TensorFlow models. It serves billions of requests per day, spread over dozens of models, and still has pretty good ergonomics,&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jenia Gorokhovsky</dc:creator><pubDate>Tue, 05 Jun 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-06-05:pycon-israel-2018/deep-model-serving-scale-and-ergonomics.html</guid></item></channel></rss>