<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_stephen-helms.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2017-04-08T00:00:00+00:00</updated><entry><title>Finding Needles in a Growing Haystack: An Architecture for Intelligent Reporting at Scale</title><link href="https://pyvideo.org/pydata-amsterdam-2017/finding-needles-in-a-growing-haystack-an-architecture-for-intelligent-reporting-at-scale.html" rel="alternate"></link><published>2017-04-08T00:00:00+00:00</published><updated>2017-04-08T00:00:00+00:00</updated><author><name>Stephen Helms</name></author><id>tag:pyvideo.org,2017-04-08:pydata-amsterdam-2017/finding-needles-in-a-growing-haystack-an-architecture-for-intelligent-reporting-at-scale.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2017&lt;/p&gt;
&lt;p&gt;Finding Needles in a Growing Haystack: An Architecture for Intelligent Reporting at Scale&lt;/p&gt;
&lt;p&gt;As we collect more and more data in the world, one of the major challenges is how to identify, summarize, and present relevant data to users. In this talk, I will present an architecture we have developed at Optiver to automate the identification of important changes in streaming time series data in a scalable way.&lt;/p&gt;
&lt;p&gt;At Optiver, we provide liquidity on markets around the world, performing millions of interactions with financial exchanges each day and generating terabytes of raw data spread across multiple datacenters. Performance is critical in our industry, and every aspect of our business is continually changing in a pursuit of perfection. On the Data team at Optiver, we face the challenge of converting this raw data into a highly aggregated and refined stream of information that people throughout the company can use to make decisions and track our performance.&lt;/p&gt;
&lt;p&gt;Even after refining this raw data, it is still impossible for people to look through every possible subset of the data to identify important changes. The problem also gets worse over time as trading execution times decrease and the number of products we trade expands. On the Data team, we have tried to solve this by developing automated, smart reporting tools that can scale horizontally.&lt;/p&gt;
&lt;p&gt;In this talk, I will discuss the architectural decisions and implementations we have used to build our automated reporting architecture. This includes the use of online (recursive) implementations of Bayesian statistics for estimating metrics and detecting trends and outliers, NoSQL databases for scalable storage and evolving data schemas, parallel execution across a Mesos cluster, and publication of the reports through REST APIs. All implemented in Python of course!&lt;/p&gt;
</summary></entry></feed>