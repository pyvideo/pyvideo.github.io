<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_maciej-kula.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2017-04-09T00:00:00+00:00</updated><entry><title>Neural Networks for Recommender Systems</title><link href="https://pyvideo.org/pydata-amsterdam-2017/neural-networks-for-recommender-systems.html" rel="alternate"></link><published>2017-04-09T00:00:00+00:00</published><updated>2017-04-09T00:00:00+00:00</updated><author><name>Maciej Kula</name></author><id>tag:pyvideo.org,2017-04-09:pydata-amsterdam-2017/neural-networks-for-recommender-systems.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2017&lt;/p&gt;
&lt;p&gt;Neural networks are quickly becoming the tool of choice for recommender systems. In this talk, I'm going to present a number of neural network recommender models: from simple matrix factorization, through learning-to-rank, to recurrent architectures for sequential prediction. All my examples are accompanied by links to implementations to give a starting point for further experimentation.&lt;/p&gt;
&lt;p&gt;The versatility and representational power of artificial neural networks is quickly making them the preferred tool for many machine learning tasks. The same is true of recommender systems: neural networks allow us to quickly iterate over new models and to easily incorporate new user, item, and contextual features. In this talk, I'm going to present a number of useful architectures: from simple matrix factorization in neural network form, through learning-to-rank models, to more complex recurrent architectures for sequential prediction. All my examples are accompanied by links to implementations to provide a starting point for further experimentation.&lt;/p&gt;
</summary></entry><entry><title>Hybrid Recommender Systems in Python</title><link href="https://pyvideo.org/pydata-amsterdam-2016/hybrid-recommender-systems-in-python.html" rel="alternate"></link><published>2016-03-26T00:00:00+00:00</published><updated>2016-03-26T00:00:00+00:00</updated><author><name>Maciej Kula</name></author><id>tag:pyvideo.org,2016-03-26:pydata-amsterdam-2016/hybrid-recommender-systems-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2016&lt;/p&gt;
&lt;p&gt;Systems based on collaborative filtering are the workhorse of recommender systems. They yield great results when abundant data is available. Unfortunately, their performance suffers when encountering new items or new users.&lt;/p&gt;
&lt;p&gt;In this talk, I'm going to talk about hybrid approaches that alleviate this problem, and introduce a mature, high-performance Python recommender package called LightFM.&lt;/p&gt;
&lt;p&gt;Introduction to collaborative filtering.
Works well when data is abundant (MovieLens, Amazon), but poorly when new users and items are common.
Introduce hybrid approaches: metadata embeddings.
This is implemented in LightFM.
LightFM has a couple of tricks up its sleeve: multicore training, training with superior ranking losses.&lt;/p&gt;
&lt;p&gt;Slides available here: &lt;a class="reference external" href="https://speakerdeck.com/maciejkula/hybrid-recommender-systems-at-pydata-amsterdam-2016"&gt;https://speakerdeck.com/maciejkula/hybrid-recommender-systems-at-pydata-amsterdam-2016&lt;/a&gt;&lt;/p&gt;
</summary><category term="lightfm"></category></entry><entry><title>Speeding up search with locality sensitive hashing</title><link href="https://pyvideo.org/europython-2015/speeding-up-search-with-locality-sensitive-hashing.html" rel="alternate"></link><published>2015-08-05T00:00:00+00:00</published><updated>2015-08-05T00:00:00+00:00</updated><author><name>Maciej Kula</name></author><id>tag:pyvideo.org,2015-08-05:europython-2015/speeding-up-search-with-locality-sensitive-hashing.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Maciej Kula - Speeding up search with locality sensitive hashing
[EuroPython 2015]
[24 July 2015]
[Bilbao, Euskadi, Spain]&lt;/p&gt;
&lt;p&gt;Locality sensitive hashing (LSH) is a technique for reducing complex
data down to a simple hash code. If two hash codes are similar than
the original data is similar. Typically, they are used for speeding up
search and other similarity comparisons.&lt;/p&gt;
&lt;p&gt;In this presentation I will discuss two ways of implementing LSH in
python; the first method is completely stateless but only works on
certain forms of data; the second is stateful but does not make any
assumptions about the distribution of the underlying data. I will
conclude the presentation by describing how we apply LSH to search at
Lyst.&lt;/p&gt;
</summary></entry></feed>