<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 21 Oct 2017 00:00:00 +0000</lastBuildDate><item><title>Understanding Customer Intent at Scale in an e-commerce Platform</title><link>https://pyvideo.org/pycon-ireland-2017/understanding-customer-intent-at-scale-in-an-e-commerce-platform.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Zalando is an European Fashion platform with a yearly revenue of ~3.6 Billion Euro. We have more than 20Million active customers and more than 200 Million visits per month. Our tech department has around 1700 people across 3 different countries. Operating in Germany is very interesting from a data protection point of view (specially for products like this) In this talk we present a technical overview of customer intent; a product that assigns a state (exploring, gathering, comparing or deciding) to each customer at any given point in their customer journey in the Zalando shop. We will introduce the problem of customer intent and briefly present our unsupervised approach to solve this model which uses a Hidden Markov Models algorithm. During this talk, we will explain the main challenges we faced on each of the steps when building, and the lessons learned from building this product from an engineering perspective. We will introduce our architecture, the reason behind using PySpark to build our product and how we made extensive use of Apache Zeppelin notebooks and branch-specific deployments in AWS EMR clusters for early experimentation. We will then show how we rewrote parts of the Python HMMLearn library using PySpark to achieve almost linear scalability. Finally, we will explain our use of AWS Data Pipelines to run daily jobs for both feature creation and scoring Zalando customers across 6 different countries, and how we support our product being used by several personalization products in different contexts.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Humberto Corona</dc:creator><pubDate>Sat, 21 Oct 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-10-21:pycon-ireland-2017/understanding-customer-intent-at-scale-in-an-e-commerce-platform.html</guid></item><item><title>Sharing knowledge in the Python ecosystem</title><link>https://pyvideo.org/pycon-ireland-2016/sharing-knowledge-in-the-python-ecosystem.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Data Scientists (or researchers) often do many early-stage prototyping
and run many experiments before finding the optimal solution for the
problem they are trying to solve. However, sometimes, a lot of the
knowledge gained in the process stays with the person. In this proposed
talk, I would like to introduce how to produce, share and ensure the
reproducibility of experiments using jupyter notebooks and github. This
is a series of lessons Iearned while being a research student (where
open-sourcing the code and data used to generate papers is very
important) and more recently, working in a new team in Zalando, where we
have experimented with different ways to share and review the data
science tasks, as well as the knowledge generated from those tasks.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Humberto Corona</dc:creator><pubDate>Sat, 05 Nov 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-11-05:pycon-ireland-2016/sharing-knowledge-in-the-python-ecosystem.html</guid></item></channel></rss>