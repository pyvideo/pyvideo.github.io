<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 03 May 2019 14:35:00 +0000</lastBuildDate><item><title>Everything at Once: Python's Many Concurrency Models</title><link>https://pyvideo.org/pycon-us-2019/everything-at-once-pythons-many-concurrency-models.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python makes it incredibly easy to build programs that do what you want.
But what happens when you want to do what you want, but with more input?
One of the easiest things to do is to make a program concurrent so that
you can get more performance on large data sets. But what's involved
with that?&lt;/p&gt;
&lt;p&gt;Right now, there are any number of ways to do this, and that can be
confusing! How does &lt;tt class="docutils literal"&gt;asyncio&lt;/tt&gt; work? What's the difference between a
thread and a process? And what's this Hadoop thing everyone keeps
talking about?&lt;/p&gt;
&lt;p&gt;In this talk, we'll cover some broad ground of what the different
concurrency models available to you as a Python developer are, the
tradeoffs and advantages of each, and explain how you can select the
right one for your purpose.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jess Shapiro</dc:creator><pubDate>Fri, 03 May 2019 14:35:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-03:pycon-us-2019/everything-at-once-pythons-many-concurrency-models.html</guid><category>talk</category></item></channel></rss>