<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_keras.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-05-05T00:00:00+00:00</updated><entry><title>Let the AI Do the Talk: Adventures with Natural Language Generation</title><link href="https://pyvideo.org/pycon-italia-2019/let-the-ai-do-the-talk-adventures-with-natural-language-generation.html" rel="alternate"></link><published>2019-05-05T00:00:00+00:00</published><updated>2019-05-05T00:00:00+00:00</updated><author><name>Marco Bonzanini</name></author><id>tag:pyvideo.org,2019-05-05:pycon-italia-2019/let-the-ai-do-the-talk-adventures-with-natural-language-generation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Recent advances in Artificial Intelligence have shown how computers can
compete with humans in a variety of mundane tasks, but what happens when
creativity is required?&lt;/p&gt;
&lt;p&gt;This talk introduces the concept of Natural Language Generation, the
task of automatically generating text, for examples articles on a
particular topic, poems that follow a particular style, or speech
transcripts that express some attitude. Specifically, we’ll discuss the
case for Recurrent Neural Networks, a family of algorithms that can be
trained on sequential data, and how they improve on traditional language
models.&lt;/p&gt;
&lt;p&gt;The talk is for beginners, we’ll focus more on the intuitions behind the
algorithms and their practical implications, and less on the
mathematical details. Practical examples with Python will showcase
Keras, a library to quickly prototype deep learning architectures.&lt;/p&gt;
&lt;p&gt;Brief outline:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Introduction to Natural Language Generation&lt;/li&gt;
&lt;li&gt;Language Modelling&lt;/li&gt;
&lt;li&gt;Recurrent Neural Networks and Long Short Term Memory for NLG&lt;/li&gt;
&lt;li&gt;RNN examples with Keras&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Feedback form: &lt;a class="reference external" href="https://python.it/feedback-1574"&gt;https://python.it/feedback-1574&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Sunday 5 May&lt;/strong&gt; at 10:15 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="nlp"></category><category term="Keras"></category><category term="natural-language-processing"></category><category term="pydata"></category></entry><entry><title>Machine Translation with Keras</title><link href="https://pyvideo.org/pycon-ireland-2018/machine-translation-with-keras.html" rel="alternate"></link><published>2018-11-10T00:00:00+00:00</published><updated>2018-11-10T00:00:00+00:00</updated><author><name>Bojan Bozic</name></author><id>tag:pyvideo.org,2018-11-10:pycon-ireland-2018/machine-translation-with-keras.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk I will describe and present ideas for a machine translation prototype implemented in Keras. I will cover Neural Machine Translation, which is an approach to machine translation that uses a large neural network. It departs from phrase-based statistical approaches that use separately engineered subcomponents. E.g. Google uses Google Neural Machine Translation (GNMT) in preference to its previous statistical methods. NMT has highly promising performance for large training data. The common principle is encoding the meaning of input into concept space and performing translation based on encoding which leads to deeper understanding and learning of translation rules, for better translation than SMT. The problem is the tendency towards overfitting to frequent observations and overlooking special cases. With the cause that the translational function is shared, so high- and low-frequency pairs impact each other by adapting shared parameters. Smoothness of translation function makes infrequent pairs seem like noise.&lt;/p&gt;
</summary><category term="keras"></category><category term="machine translation"></category></entry><entry><title>Recent advancements in NLP and Deep Learning: A Quant's Perspective</title><link href="https://pyvideo.org/pycon-italia-2018/recent-advancements-in-nlp-and-deep-learning-a-quants-perspective.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Umit Mert Cakmak</name></author><id>tag:pyvideo.org,2018-04-21:pycon-italia-2018/recent-advancements-in-nlp-and-deep-learning-a-quants-perspective.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There is a gold-rush among hedge-funds for text mining algorithms to
quantify textual data and generate trading signals. Harnessing the power
of alternative data sources became crucial to find novel ways of
enhancing trading strategies.&lt;/p&gt;
&lt;p&gt;With the proliferation of new data sources, natural language data became
one of the most important data sources which could represent the public
sentiment and opinion about market events, which then can be used to
predict financial markets.&lt;/p&gt;
&lt;p&gt;Talk is split into 5 parts;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Who is a quant and how do they use NLP?&lt;/li&gt;
&lt;li&gt;How deep learning has changed NLP?&lt;/li&gt;
&lt;li&gt;Let’s get dirty with word embeddings&lt;/li&gt;
&lt;li&gt;Performant deep learning layer for NLP: The Recurrent Layer&lt;/li&gt;
&lt;li&gt;Using all that to make money&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="who-is-a-quant-and-how-do-they-use-nlp"&gt;
&lt;h4&gt;1. Who is a quant and how do they use NLP?&lt;/h4&gt;
&lt;p&gt;Quants use mathematical and statistical methods to create algorithmic
trading strategies.&lt;/p&gt;
&lt;p&gt;Due to recent advances in available deep learning frameworks and
datasets (time series, text, video etc) together with decreasing cost of
parallelisable hardware, quants are experimenting with various NLP
methods which are applicable to quantitative trading.&lt;/p&gt;
&lt;p&gt;In this section, we will get familiar with the brief history of text
mining work that quants have done so far and recent advancements.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-deep-learning-has-changed-nlp"&gt;
&lt;h4&gt;2. How deep learning has changed NLP?&lt;/h4&gt;
&lt;p&gt;In recent years, data representation and modeling methods are vastly
improved. For example when it comes to textual data, rather than using
high dimensional sparse matrices and suffering from curse of
dimensionality, distributional vectors are more efficient to work with.&lt;/p&gt;
&lt;p&gt;In this section, I will talk about distributional vectors a.k.a. word
embeddings and recent neural network architectures used when building
NLP models.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="lets-get-dirty-with-word-embeddings"&gt;
&lt;h4&gt;3. Let’s get dirty with word embeddings&lt;/h4&gt;
&lt;p&gt;Models such as Word2vec or GloVe helps us create word embeddings from
large unlabeled corpus which represent the relation between words, their
contextual relationships in numerical vector spaces and these
representations not only work for words but also could be used for
phrases and sentences.&lt;/p&gt;
&lt;p&gt;In this section, I will talk about inner workings of these models and
important points when creating domain-specific embeddings (e.g. for
sentiment analysis in financial domain).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="performant-deep-learning-layer-for-nlp-the-recurrent-layer"&gt;
&lt;h4&gt;4. Performant deep learning layer for NLP: The Recurrent Layer&lt;/h4&gt;
&lt;p&gt;Recurrent Neural Networks (RNNs) can capture and hold the information
which was seen before (context), which is important for dealing with
unbounded context in NLP tasks.&lt;/p&gt;
&lt;p&gt;Long Short Term Memory (LSTM) networks, which is a special type of RNN,
can understand the context even if words have long term dependencies,
words which are far back in their sequence.&lt;/p&gt;
&lt;p&gt;In this talk, I will compare LSTMs with other deep learning
architectures and will look at LSTM unit from a technical point of view.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="using-all-that-to-make-money"&gt;
&lt;h4&gt;5. Using all that to make money&lt;/h4&gt;
&lt;p&gt;Financial news, especially if it’s major, can change the sentiment among
investors and affect the related asset price with immediate price
corrections.&lt;/p&gt;
&lt;p&gt;For example, what’s been communicated in quarterly earnings calls might
indicate whether the price of share will drop or increase based on the
language used. If the message of the company is not direct and featuring
complex sounding language, it usually indicates that there’s some shady
stuff going on and if this information extracted right, it’s a valuable
trading signal. For similar reasons, scanning announcements and
financial disclosures for trading signals became a common NLP practice
in investment industry.&lt;/p&gt;
&lt;p&gt;In this section, I will talk about the various data sources that
researchers can use and also explain common NLP workflows and deep
learning practices for quantifying textual data for generating trading
signals.&lt;/p&gt;
&lt;p&gt;I will end with summary with application architecture in case anyone
would like to implement similar systems for their own use.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 14:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</summary><category term="nlp"></category><category term="data-science"></category><category term="Keras"></category><category term="Python"></category><category term="Deep-Learning"></category><category term="machine-learning"></category><category term="spaCy"></category><category term="nltk"></category></entry><entry><title>Deep Learning from zero to hero</title><link href="https://pyvideo.org/pycon-italia-2018/deep-learning-from-zero-to-hero.html" rel="alternate"></link><published>2018-04-20T00:00:00+00:00</published><updated>2018-04-20T00:00:00+00:00</updated><author><name>Gianluca Carucci</name></author><id>tag:pyvideo.org,2018-04-20:pycon-italia-2018/deep-learning-from-zero-to-hero.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Avete sentito parlare di Deep Learning ma credete che la teoria alla
base sia troppo complessa? Non avete una laurea in matematica e
statistica e pensate che il machine learning non faccia per voi? Niente
paura: avrete solo bisogno di una conoscenze di base di Python.&lt;/p&gt;
&lt;p&gt;Conoscete la regola dell’80/20? Con il 20% delle conoscenze potete
raggiungere l’80% dei risultati: in questo talk vi mostrerò in modo
pratico tramite delle demo - alcuni trucchi per costruire dei buoni
modelli predittivi, evitando di perdere (tanto) tempo nella scelta dei
tools e delle librerie necessarie al vostro scopo.&lt;/p&gt;
&lt;p&gt;L’obbiettivo è fornirvi le basi pratiche con cui scegliere un modello di
rete neurale, farne training e ottimizzarlo nel modo più adatto alla
tipologia del problema che dovete affrontare.&lt;/p&gt;
&lt;p&gt;Agenda: - Introduzione al Deep Learning - Un esempio di training senza
scrivere codice - Sviluppare, testare e ottimizzare un modello reale -
Considerazioni finali&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;venerdì 20 aprile&lt;/strong&gt; at 12:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="machine-learning"></category><category term="Keras"></category><category term="Deep-Learning"></category><category term="data-analysis"></category><category term="tensorflow"></category><category term="computer-science"></category><category term="neural network"></category></entry><entry><title>Hands-on introduction to Deep Learning with Keras and Tensorflow</title><link href="https://pyvideo.org/pydata-amsterdam-2018/hands-on-introduction-to-deep-learning-with-keras-and-tensorflow.html" rel="alternate"></link><published>2018-05-26T00:00:00+00:00</published><updated>2018-05-26T00:00:00+00:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:pyvideo.org,2018-05-26:pydata-amsterdam-2018/hands-on-introduction-to-deep-learning-with-keras-and-tensorflow.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deep Learning has already conquered areas such as image recognition, NLP, voice recognition, and is a must-know tool for every Data Practitioner. This tutorial for aspiring Deep Learners will consist of a quick blunt Deep Learning overview followed by a hands-on tutorial that will teach you how to get started using Keras and Tesorflow.&lt;/p&gt;
</summary><category term="deep learning"></category><category term="keras"></category><category term="tensorflow"></category></entry><entry><title>Text Classification with Word Vectors &amp; Recurrent Neural Networks</title><link href="https://pyvideo.org/pycon-ireland-2017/text-classification-with-word-vectors-recurrent-neural-networks.html" rel="alternate"></link><published>2017-10-21T00:00:00+00:00</published><updated>2017-10-21T00:00:00+00:00</updated><author><name>Shane Lynn</name></author><id>tag:pyvideo.org,2017-10-21:pycon-ireland-2017/text-classification-with-word-vectors-recurrent-neural-networks.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Globally, research teams are reporting dramatic improvements in text classification accuracy and text processing by employing deep neural networks. But what are deep nets? Can you harness these techniques in your own projects? How much training data do you need? What are the libraries required? Do you need a super computer? Do these techniques improving accuracy and are they worth the hassle? In this talk, we'll examine some basic neural architectures for text classification, we'll run through how to use the Python Keras library for classification, and speak a little about our experience in using these techniques.&lt;/p&gt;
</summary><category term="keras"></category></entry><entry><title>First steps in deep learning with Keras</title><link href="https://pyvideo.org/pydata-warsaw-group/first-steps-in-deep-learning-with-keras.html" rel="alternate"></link><published>2017-01-12T00:00:00+00:00</published><updated>2017-01-12T00:00:00+00:00</updated><author><name>Piotr Migdał</name></author><id>tag:pyvideo.org,2017-01-12:pydata-warsaw-group/first-steps-in-deep-learning-with-keras.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;#8 PyData Warsaw&lt;/p&gt;
&lt;p&gt;Here are is my Jupyter Notebook on Keras:
&lt;a class="reference external" href="https://gist.github.com/stared/7de2908b9bcba01c39ee3c591875a23c"&gt;https://gist.github.com/stared/7de2908b9bcba01c39ee3c591875a23c&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I hope I inspired some of you to start learning deep learning, or to hone your DL skills! :)&lt;/p&gt;
&lt;p&gt;If you have any questions, I am happy to answer (just drop me an email, contacts here: &lt;a class="reference external" href="http://p.migdal.pl"&gt;http://p.migdal.pl&lt;/a&gt;).&lt;/p&gt;
</summary><category term="keras"></category></entry><entry><title>Machine Learning con Python: previsione in real-time della richiesta di energia elettrica</title><link href="https://pyvideo.org/pycon-italia-2017/machine-learning-con-python-previsione-in-real-time-della-richiesta-di-energia-elettrica.html" rel="alternate"></link><published>2017-04-08T00:00:00+00:00</published><updated>2017-04-08T00:00:00+00:00</updated><author><name>Felice Tuosto</name></author><id>tag:pyvideo.org,2017-04-08:pycon-italia-2017/machine-learning-con-python-previsione-in-real-time-della-richiesta-di-energia-elettrica.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Nel talk si parlerà di come attraverso il linguaggio Python sia
possibile risolvere un problema reale e complesso relativamente alla
trasmissione di energia elettrica. Verrà spiegato il progetto
&lt;strong&gt;RealtimeLoadForecast&lt;/strong&gt; che è stato sviluppato per un importante TSO
(Transmission System Operator). Si tratta di sistema predittivo che
permette di fornire in tempo reale ogni 15 minuti ed entro 5 minuti, le
previsioni delle serie storiche dei consumi di energia elettrica
relativi a circa 500 nodi elettrici.&lt;/p&gt;
&lt;p&gt;Si parlerà dei passi che occorre seguire per ottenere da un semplice
prototipo, un sistema &lt;em&gt;ingegnerizzato&lt;/em&gt; che lavori in tempo reale e di
come sono state utilizzate le librerie di Python per l’acquisizione,
manipolazione e processamento dei dati elettrici ed ambientali.&lt;/p&gt;
&lt;p&gt;Saranno descritte alcune tecniche algoritmiche e di Machine Learning per
ottenere dei modelli predittivi capaci di fornire previsioni accurate ma
con tempi di risposta sfidanti.&lt;/p&gt;
&lt;p&gt;Verrà mostrato un &lt;em&gt;esempio concreto&lt;/em&gt; di implementazione di un algoritmo
predittivo basato sulla libreria Deep Learning &lt;strong&gt;Keras&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Per la comprensione del talk non sono necessari particolari requisiti se
non una conoscenza di base di programmazione in Python e di Machine
Learning.&lt;/p&gt;
</summary><category term="Forecasting"></category><category term="Genetic Algorithms"></category><category term="Keras"></category><category term="Data Mining"></category><category term="programming-paradigms"></category><category term="scikit-learn"></category><category term="bigdata"></category><category term="scalability"></category><category term="Deep-Learning"></category><category term="threading"></category><category term="realtime"></category><category term="Data-Scientist"></category><category term="database"></category><category term="machine-learning"></category><category term="mysql"></category><category term="signal-processing"></category><category term="LoadForecasting"></category><category term="cassandra"></category></entry><entry><title>The unconventional Introduction to Deep Learning</title><link href="https://pyvideo.org/pycon-italia-2017/the-unconventional-introduction-to-deep-learning.html" rel="alternate"></link><published>2017-04-07T00:00:00+00:00</published><updated>2017-04-07T00:00:00+00:00</updated><author><name>Valerio Maggio</name></author><id>tag:pyvideo.org,2017-04-07:pycon-italia-2017/the-unconventional-introduction-to-deep-learning.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;If you are into Deep Learning, sooner or later, it inevitbly happens
that you’re asked at least once to explain what actually means &lt;strong&gt;Deep
Learning&lt;/strong&gt; , and what’s all the fuss about it.&lt;/p&gt;
&lt;p&gt;Indeed, answering this question in a proper way, may vary (and it has
to) depending on the kind of audience you’ve been talking to.&lt;/p&gt;
&lt;p&gt;If you are talking to a machine learning experts, you have to
concentrate on what &lt;em&gt;deep&lt;/em&gt; means, for the multiple learning models you
can come up with. Most importarly, you have to convince them that a deep
learning model would work by far better than a more standard and robust
Random Forest or Support Vector Machine.&lt;/p&gt;
&lt;p&gt;On the other hand, if your audience is made up of engineers, they
[STRIKEOUT:don’t give a damn..] are definitely more interested in how
you implement your Artificial Neural Networks (ANN) rather than
understanding what are the implications of different &lt;em&gt;activations&lt;/em&gt; and
&lt;em&gt;optimizers&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Finally, if your audience is made up of data scientists - who are a good
mixture of the previous two, according to &lt;a class="reference external" href="http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram"&gt;Drew
Conway&lt;/a&gt;
- they are more or less interested in both the two aspects.&lt;/p&gt;
&lt;p&gt;The other way, that is the &lt;em&gt;unconventional way&lt;/em&gt;, to explain what Deep
Learning means, is from the perspective of the computational model it
requires to be properly effective. Therefore, you may want to talk about
ANN in terms of matrix multiplications algorithms, running on a (series
of) GPUs in parallel. And this is &lt;strong&gt;exactly&lt;/strong&gt; the perspecitve I intend
to pursue in this talk.&lt;/p&gt;
&lt;p&gt;This talk is for PyData scientists who are interested in understanding
Deep Learning models from this unconventional perspective, learning what
are the libraries and tools they may leverage for their experiments on
GPUs. Experienced engineers may likely benefit from this talk as well,
learning how they can make their models run fast(er).&lt;/p&gt;
</summary><category term="Keras"></category><category term="rumba"></category><category term="Deep-Learning"></category><category term="machine-learning"></category><category term="Theano"></category><category term="GPU"></category><category term="tensorflow"></category></entry><entry><title>H2O Deep Water with Python early sneek</title><link href="https://pyvideo.org/pydata-dc-2016/h2o-deep-water-with-python-early-sneek.html" rel="alternate"></link><published>2016-10-09T00:00:00+00:00</published><updated>2016-10-09T00:00:00+00:00</updated><author><name>Fabrizio Milo</name></author><id>tag:pyvideo.org,2016-10-09:pydata-dc-2016/h2o-deep-water-with-python-early-sneek.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData 2016&lt;/p&gt;
&lt;p&gt;Python as a language for DeepLearning. Python is emerging as the facto language to specify Deep Learning Networks. In this talk we will explore some of the popular libraries like Tensorflow and Keras to see the semantics used to describe such networks and look a bit more under the hood at what is the python layer actually doing for these well known deep learning libraries.&lt;/p&gt;
</summary><category term="deep learning"></category><category term="tensorflow"></category><category term="keras"></category></entry><entry><title>Deep Learning in Python</title><link href="https://pyvideo.org/pycon-za-2016/deep-learning-in-python.html" rel="alternate"></link><published>2016-10-07T00:00:00+00:00</published><updated>2016-10-07T00:00:00+00:00</updated><author><name>Tobias Brandt</name></author><id>tag:pyvideo.org,2016-10-07:pycon-za-2016/deep-learning-in-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk will give an introduction to Neural Networks and Deep Learning
in Python. We will cover some of the history of Neural Networks and
obstacles that were encountered in the 1990s. This will then lead onto
the developments in 2006 and 2012 that lead to the resurgence of
interest in Neural Networks and the rebranding of the field as Deep
Learning. These developments will be illustrated by means of an extended
example of building a classifier of hand written digits on the MNIST
dataset. We will start with a simple Multi-Layer Perceptron and then
build this up into a Stacked Denoising Autoencoder. All code will be
developed using the Keras framework and TensorFlow and can be run on a
simple laptop.&lt;/p&gt;
</summary><category term="deep learning"></category><category term="keras"></category><category term="tensorflow"></category></entry></feed>