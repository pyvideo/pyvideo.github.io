<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_computer-vision.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-07-11T00:00:00+00:00</updated><entry><title>AI in Contemporary Art</title><link href="https://pyvideo.org/europython-2019/ai-in-contemporary-art.html" rel="alternate"></link><published>2019-07-11T00:00:00+00:00</published><updated>2019-07-11T00:00:00+00:00</updated><author><name>Luba Elliott</name></author><id>tag:pyvideo.org,2019-07-11:europython-2019/ai-in-contemporary-art.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Over the past couple of years, there has been increasing interest in
applying the latest advances in machine learning to creative projects in
art and design. From DeepDream and style transfer to a GAN-generated
painting selling for $430,000 at auction, AI art has moved beyond the
world of research and academia and become a trend in its own right.
Meanwhile, the contemporary art world's fascination with the social
impact of facial recognition, recommendation systems and deep fakes has
encouraged artists to explore AI critically as subject matter. This talk
will give an overview of how artists and technologists are using and
thinking about machine learning, its creative potential and societal
impact.&lt;/p&gt;
</summary><category term="Algorithms"></category><category term="Computer Vision"></category><category term="Deep Learning"></category></entry><entry><title>Image processing with scikit-image and Dash</title><link href="https://pyvideo.org/europython-2019/image-processing-with-scikit-image-and-dash.html" rel="alternate"></link><published>2019-07-10T00:00:00+00:00</published><updated>2019-07-10T00:00:00+00:00</updated><author><name>Emmanuelle Gouillart</name></author><id>tag:pyvideo.org,2019-07-10:europython-2019/image-processing-with-scikit-image-and-dash.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Images are an ubiquitous form of data in various fields of science and&lt;/div&gt;
&lt;div class="line"&gt;industry. Images often need to be transformed and processed, for
example for helping medical diagnosis by extracting regions of
interest or measures, or for building training sets for machine
learning.&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;In this talk, I will present and discuss several tools for automatic
and&lt;/div&gt;
&lt;div class="line"&gt;interactive image processing with Python. I will start by a short&lt;/div&gt;
&lt;div class="line"&gt;introduction to scikit-image (&lt;a class="reference external" href="https://scikit-image.org/"&gt;https://scikit-image.org/&lt;/a&gt;), the
open-source&lt;/div&gt;
&lt;div class="line"&gt;image processing toolkit of the Pydata ecosystem, which aims at&lt;/div&gt;
&lt;div class="line"&gt;processing images from a large class of modalities (2-D, 3-D, etc.)
and&lt;/div&gt;
&lt;div class="line"&gt;strives to have a gentle learning curve with pedagogical example-based&lt;/div&gt;
&lt;div class="line"&gt;documentation. scikit-image provides users with a simple API based on
a large number of functions, which can be used to build pipelines of
image processing workflows.&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;In a second part, I will explain how to use Dash for building
interactive&lt;/div&gt;
&lt;div class="line"&gt;image processing operations. Dash (&lt;a class="reference external" href="https://dash.plot.ly/"&gt;https://dash.plot.ly/&lt;/a&gt;) is an&lt;/div&gt;
&lt;div class="line"&gt;open-source Python web application framework developed by Plotly.
Written on top of Flask, Plotly.js, and React.js, Dash is meant for
building data visualization apps with highly custom user interfaces in
pure Python. The dash-canvas component library of Dash
(&lt;a class="reference external" href="https://dash.plot.ly/canvas"&gt;https://dash.plot.ly/canvas&lt;/a&gt;) is an interactive component for
annotating images with several tools (freehand brush, lines, bounding
boxes, ...). It also provides utility functions for using
user-provided annotations for several image processing tasks such as
segmentation, transformation, measures, etc. The latter functions are
based on libraries such scikit-image and openCV. A gallery of examples
showcases some typical uses of Dash for image processing on&lt;/div&gt;
&lt;div class="line"&gt;&lt;a class="reference external" href="https://dash-canvas.plotly.host/"&gt;https://dash-canvas.plotly.host/&lt;/a&gt;. Also, other components of Dash can
be leveraged easily to build powerful image processing applications,
such as widgets to tune parameters or data tables for inspecting
object&lt;/div&gt;
&lt;div class="line"&gt;properties.&lt;/div&gt;
&lt;/div&gt;
</summary><category term="Computer Vision"></category><category term="Data Science"></category><category term="Image Processing"></category><category term="JavaScript Web Frameworks (AngularJS/ReactJS/...)"></category><category term="Scientific Libraries (Numpy/Pandas/SciKit/...)"></category></entry><entry><title>Multi-modal classification with PyTorch</title><link href="https://pyvideo.org/pycon-italia-2019/multi-modal-classification-with-pytorch.html" rel="alternate"></link><published>2019-05-04T00:00:00+00:00</published><updated>2019-05-04T00:00:00+00:00</updated><author><name>Jennifer Seale</name></author><id>tag:pyvideo.org,2019-05-04:pycon-italia-2019/multi-modal-classification-with-pytorch.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Recent work by Kiela et al. (2018) reveals that image and text
multi-modal classification models far outperform both text- and
image-only models. This talk will review work that extends Kiela et
al.’s (2018) research by determining if accuracy in classification may
be increased by the implementation of transfer learning in language
processing. The performance of the model over a MM-IMDb (Arevalo et al.
2017) dataset is analyzed and compared to the baseline provided by Kiela
et al. (2018).&lt;/p&gt;
&lt;p&gt;The work is implemented with PyTorch and the goal of the talk will be to
review details of the implementation, and performance of the model as
compared to that recorded in Kiela et al. (2018). Attendees of this talk
should have a basic familiarity with neural nets developed in PyTorch
for the purposes of NLP and computer vision.&lt;/p&gt;
&lt;p&gt;References: Arevalo, J., Solorio, T., Montes-y-Gómez, M., &amp;amp; González, F.
A. 2017. Gated multimodal units for information fusion. arXiv preprint
arXiv:1702.01992.&lt;/p&gt;
&lt;p&gt;Kiela, Douwe, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2018.
Efficient large-scale multi-modal classification. arXiv preprint
arXiv:1802.02892.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1754"&gt;https://python.it/feedback-1754&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Saturday 4 May&lt;/strong&gt; at 10:45 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="nlp"></category><category term="mathematical-modelling"></category><category term="computer-vision"></category></entry><entry><title>Building a Fine Grained Image Classification System</title><link href="https://pyvideo.org/pycon-ireland-2018/building-a-fine-grained-image-classification-system.html" rel="alternate"></link><published>2018-11-10T00:00:00+00:00</published><updated>2018-11-10T00:00:00+00:00</updated><author><name>Fergal Walsh</name></author><id>tag:pyvideo.org,2018-11-10:pycon-ireland-2018/building-a-fine-grained-image-classification-system.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At Fieldguide we are developing a digital field guide for all species of flora and fauna across the planet. We are using image recognition technology to enable species identification and to help with the curation of this massive catalogue. In this talk I will describe how we are building an image recognition system with the aim of identifying all known species in the natural world. The system has gone through a number of iterations at this point using a variety of computer vision and machine learning techniques, from nearest neighbour search to classification with fine tuned deep convolutional networks. All of this has been implemented in Python using scikit-learn, Numpy, Caffe and Tensorflow. Aside from the obvious machine learning challenges in designing and training such a system we faced numerous technical challenges while implementing and scaling this system in a cost effective manner. I will discuss these challenges, our solutions and the remaining open problems. While this talk will be relatively high level with few code examples and no math (but lots moths), it will be of most interest to those who have some knowledge of machine learning concepts.&lt;/p&gt;
</summary><category term="image-recognition"></category><category term="Computer Vision"></category><category term="machine learning"></category></entry><entry><title>Satellite data is for everyone: insights into modern remote sensing research with open data and Python</title><link href="https://pyvideo.org/pycon-de-2018/satellite-data-is-for-everyone-insights-into-modern-remote-sensing-research-with-open-data-and-python.html" rel="alternate"></link><published>2018-10-26T00:00:00+00:00</published><updated>2018-10-26T00:00:00+00:00</updated><author><name>Felix M. Riese</name></author><id>tag:pyvideo.org,2018-10-26:pycon-de-2018/satellite-data-is-for-everyone-insights-into-modern-remote-sensing-research-with-open-data-and-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The largest earth observation programme Copernicus
(&lt;a class="reference external" href="http://copernicus.eu"&gt;http://copernicus.eu&lt;/a&gt;) makes it possible to perform terrestrial
observations providing data for all kinds of purposes. One important
objective is to monitor the land-use and land-cover changes with the
Sentinel-2 satellite mission. These satellites measure the sun
reflectance on the earth surface with multispectral cameras (13 channels
between 440 nm to 2190 nm). Machine learning techniques like
convolutional neural networks (CNN) are able to learn the link between
the satellite image (spectrum) and the ground truth (land use class). In
this talk, we give an overview about the state-of-the-art land-use
classification with CNNs based on an open dataset.&lt;/p&gt;
&lt;p&gt;The EuroSAT benchmark dataset (&lt;a class="reference external" href="http://madm.dfki.de/downloads"&gt;http://madm.dfki.de/downloads&lt;/a&gt;) is freely
provided by German Research Center for Artificial Intelligence (DFKI).
It consists of 27.000 image patches for ten different land use/cover
classes, e.g. industrial and residential areas, different crop and
vegetation types and forests. All samples have 64 by 64 pixel dimension
and include either only the RGB images or all 13 bands.&lt;/p&gt;
&lt;p&gt;We will use different out-of-box CNNs for the Keras deep learning
library (&lt;a class="reference external" href="https://keras.io/"&gt;https://keras.io/&lt;/a&gt;). All networks are either included in Keras
itself or are available from Github repositories. We will show the
process of transfer learning for the RGB datasets. Furthermore, the
minimal changes required to apply commonly used CNNs to multispectral
data are demonstrated. Thus, the interested audience will be able to
perform their own classification of remote sensing data within a very
short time. Results of different network structures are visually
compared. Especially the differences of transfer learning and learning
from scratch are demonstrated. This also includes the amount of
necessary training epochs, progress of training and validation error and
visual comparison of the results of the trained networks.&lt;/p&gt;
&lt;p&gt;Finally, we give a quick overview about the current research topics
including recurrent neural networks for spatio-temporal land-use
classification and further applications of multi- and hyperspectral
data, e.g. for the estimation of water parameters and soil
characteristics. Additionally, we provide links to the code and dataset
used in this talk.&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Computer Vision"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Data Science"></category><category term="Machine Learning"></category><category term="Science"></category></entry><entry><title>Satellite Image Segmentation Photovoltaic Potential Estimation</title><link href="https://pyvideo.org/pycon-de-2018/satellite-image-segmentation-photovoltaic-potential-estimation.html" rel="alternate"></link><published>2018-10-25T00:00:00+00:00</published><updated>2018-10-25T00:00:00+00:00</updated><author><name>Johannes Oos</name></author><id>tag:pyvideo.org,2018-10-25:pycon-de-2018/satellite-image-segmentation-photovoltaic-potential-estimation.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The used technologies are python based and include: MongoDB tensorflow
Flask google.cloud python API&lt;/p&gt;
&lt;p&gt;A dataset of labelled satellite images is created. Several networks are
trained and tested on this dataset. The network is deployed on a
production server.&lt;/p&gt;
&lt;p&gt;The results of the classification/segmentaion are used to feed python
based photovotlaic simulation libaries. The output is displayed and the
results (the potential) evaluated.&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Computer Vision"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Machine Learning"></category><category term="Science"></category></entry><entry><title>Experiences from applying Convolutional Neural Networks for classifying 2D sensor data</title><link href="https://pyvideo.org/pycon-de-2018/experiences-from-applying-convolutional-neural-networks-for-classifying-2d-sensor-data.html" rel="alternate"></link><published>2018-10-24T00:00:00+00:00</published><updated>2018-10-24T00:00:00+00:00</updated><author><name>Matthias Peussner</name></author><id>tag:pyvideo.org,2018-10-24:pycon-de-2018/experiences-from-applying-convolutional-neural-networks-for-classifying-2d-sensor-data.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When being the first in your company to apply a deep learning algorithm
on your data you often have to overcome several obstacles. One challenge
is to understand your data and to form a training and test dataset.
Another one is to get your algorithms and its performance accepted and
integrated in your existing processing workflow.&lt;/p&gt;
&lt;p&gt;Convolutional Neural Networks have become a standard tool in processing
image data. They have shown to reach human-level classification
performance on some object recognition tasks.&lt;/p&gt;
&lt;p&gt;In this talk I will present my experiences in getting started using a
convolutional neural network for classification of 2D sensor data. I
will point out the importance of understanding your data and give hints
of how to select your train and test datasets according to the
requirements. Furthermore, I will show how to get a feature extractor
out of the classifier and how to visualize it.&lt;/p&gt;
</summary><category term="Artificial Intelligence"></category><category term="Computer Vision"></category><category term="Deep Learning &amp; Artificial Intelligence"></category><category term="Machine Learning"></category></entry><entry><title>Deep Learning in Computer Vision: state of the art techniques and applications in industry</title><link href="https://pyvideo.org/pycon-italia-2018/deep-learning-in-computer-vision-state-of-the-art-techniques-and-applications-in-industry.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Rocco Michele Lancellotti</name></author><id>tag:pyvideo.org,2018-04-21:pycon-italia-2018/deep-learning-in-computer-vision-state-of-the-art-techniques-and-applications-in-industry.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Audience Level Data Scientists and Data Science Practitioners with basic
to intermediate level experience in image recognition/object detection
deep learning applications, basic Python programming skills.&lt;/p&gt;
&lt;p&gt;Brief Description Deep Learning is revolutionizing both Data Science and
Artificial Intelligence real-world applications. Yet, being the
discipline so young, it’s not straightforward to understand both the
reasoning at its core and its countless use cases. In this talk we will
review the basics of Neural Networks, from the classical CNNs to the
current state of the art, comparing them through real industry
applications and highlighting pros and cons in a business setting.&lt;/p&gt;
&lt;p&gt;Abstract / Summary Deep Learning has been on a hype roll for a few
years. Being such a young discipline makes deep learning interesting,
but also subject to misunderstandings. Every year, brand new
architectures rise, taking over old ones and outperforming state of the
art benchmarks for accuracy. Further, the applications of deep learning
are at the core of some of the most advanced technologies like
autonomous driving, personal assistants, and customer profiling. In such
a context it is not straightforward to grasp what is at the core of deep
learning itself, and what is common to all the architectures, neither to
realize how concrete use cases can be tackled. Using Python, we’ll take
the audience from the simplest neuron, the atom of the deep learning
world, to the most recent architectures. We’ll achieve this using a
simple Convolutional Neural Network as a building block and comparing
that to the latest breakthroughs in image recognition. In doing this
we’ll try to give an answer to the following questions: • Is deep
learning actually useful in a business setting? • What about state of
the art techniques in the Computer Vision field: are we just stacking
more and more convolutional and pooling layers? We will then address
real industry applications (e.g. the insurance sector) using analyzed
techniques. This will include opening some of these so- called black box
models and retraining them, at least partially, on our datasets, or
building a complete brand new network from scratch, tailoring it
according to the application needs and datasets characteristics.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 17:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="image-recognition"></category><category term="transfer-learning"></category><category term="industry applications"></category><category term="deep learning"></category><category term="Deep-Learning"></category><category term="ComputerVision"></category><category term="computer vision"></category><category term="image recognition"></category><category term="transfer learning"></category><category term="industry-applications"></category></entry></feed>