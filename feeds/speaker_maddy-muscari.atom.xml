<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Maddy Muscari</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_maddy-muscari.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2025-04-26T00:00:00+00:00</updated><subtitle></subtitle><entry><title>"It’s About Ethics in AI Alignment" – Resistance in the Age of AI-Governed Speech</title><link href="https://pyvideo.org/north-bay-python-2025/its-about-ethics-in-ai-alignment-resistance-in-the-age-of-ai-governed-speech.html" rel="alternate"></link><published>2025-04-26T00:00:00+00:00</published><updated>2025-04-26T00:00:00+00:00</updated><author><name>Maddy Muscari</name></author><id>tag:pyvideo.org,2025-04-26:/north-bay-python-2025/its-about-ethics-in-ai-alignment-resistance-in-the-age-of-ai-governed-speech.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Maddy Muscari&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://pretalx.northbaypython.org/nbpy-2025/talk/W7XXBA"&gt;https://pretalx.northbaypython.org/nbpy-2025/talk/W7XXBA&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Remember gamergate? The phrase &amp;quot;It's about ethics in AI alignment&amp;quot; should be a joke—but it's not. AI alignment is shaping who gets to speak, what gets remembered and how truth is defined.&lt;/p&gt;
&lt;p&gt;Application developers, not AI researchers, are the …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Maddy Muscari&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://pretalx.northbaypython.org/nbpy-2025/talk/W7XXBA"&gt;https://pretalx.northbaypython.org/nbpy-2025/talk/W7XXBA&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Remember gamergate? The phrase &amp;quot;It's about ethics in AI alignment&amp;quot; should be a joke—but it's not. AI alignment is shaping who gets to speak, what gets remembered and how truth is defined.&lt;/p&gt;
&lt;p&gt;Application developers, not AI researchers, are the ones implementing these systems—which means AI governance isn’t just a policy problem; it’s a codebase and product problem.&lt;/p&gt;
&lt;p&gt;This talk deconstructs alignment through a lens of control:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;How authoritarian data controls like constitutional classifiers and red-team RLHF training are damaging reasoning models.&lt;/li&gt;
&lt;li&gt;The &amp;quot;slippery slope&amp;quot; of allowing these kinds of classifiers to find their way into human communications&lt;/li&gt;
&lt;li&gt;Why AI alignment is not just about safety—it’s about deciding who gets to define epistemic reality.&lt;/li&gt;
&lt;li&gt;How engineers can identify, challenge, and counteract AI-mediated censorship in the tools they build.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If alignment becomes invisible, it becomes unchallengeable. If practitioners don’t resist now, AI won’t just shape knowledge—it will shape what can even be thought.&lt;/p&gt;
&lt;p&gt;Key Takeaways:
✔ Understand how alignment architectures are being adapted for human speech control.
✔ Recognize when AI alignment becomes silent censorship.
✔ Resist epistemic capture by designing systems that preserve interpretability and agency.&lt;/p&gt;
&lt;p&gt;Sat Apr 26 14:15:00 2025 at Reis River Ranch&lt;/p&gt;
&lt;p&gt;Produced by NDV: &lt;a class="reference external" href="https://youtube.com/channel/UCQ7dFBzZGlBvtU2hCecsBBg?sub_confirmation=1"&gt;https://youtube.com/channel/UCQ7dFBzZGlBvtU2hCecsBBg?sub_confirmation=1&lt;/a&gt;&lt;/p&gt;
</content><category term="North Bay Python 2025"></category></entry></feed>