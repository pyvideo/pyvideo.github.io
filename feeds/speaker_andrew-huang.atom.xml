<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Andrew Huang</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_andrew-huang.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2024-05-16T00:00:00+00:00</updated><subtitle></subtitle><entry><title>From RAGs to riches: Build an AI document inquiry web-app</title><link href="https://pyvideo.org/pycon-us-2024/from-rags-to-riches-build-an-ai-document-inquiry-web-app.html" rel="alternate"></link><published>2024-05-16T00:00:00+00:00</published><updated>2024-05-16T00:00:00+00:00</updated><author><name>Pavithra Eswaramoorthy</name></author><id>tag:pyvideo.org,2024-05-16:/pycon-us-2024/from-rags-to-riches-build-an-ai-document-inquiry-web-app.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As we descend from the peak of the hype cycle around Large Language
Models (LLMs), chat-based document interrogation systems have emerged as
a high value practical use case. The ability to ask natural language
questions and get relevant and accurate answers from a large corpus of
documents can fundamentally …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As we descend from the peak of the hype cycle around Large Language
Models (LLMs), chat-based document interrogation systems have emerged as
a high value practical use case. The ability to ask natural language
questions and get relevant and accurate answers from a large corpus of
documents can fundamentally transform organizations and make
institutional knowledge accessible. Foundational LLM models like
OpenAI’s GPT4 provide powerful capabilities, but using them directly to
answer questions about a collection of documents presents
accuracy-related limitations. Retrieval-augmented generation (RAG) is
the leading approach to enhancing the capabilities and usability of
Large Language Models, especially for personal or company-level
chat-based document interrogation systems.&lt;/p&gt;
&lt;p&gt;RAG is a technique to share relevant context and external information
(retrieved from vector storage) to LLMs, thus making them more powerful
and accurate. In this tutorial, we’ll dive into RAG by creating a
personal chat application that accurately answers questions about your
selected documents. We’ll use a new &lt;a class="reference external" href="https://ragna.chat/en/latest/"&gt;OSS project called
Ragna&lt;/a&gt; that provides a friendly Python
and REST API, designed for this particular case. For our example, we’ll
test the effectiveness of different LLMs and vector databases. We'll
then develop a web application that leverages the REST API, built with
&lt;a class="reference external" href="https://panel.holoviz.org"&gt;Panel–a powerful OSS Python application development
framework&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;By the end of this tutorial, you will have an understanding of the
fundamental components that form a RAG model, and practical knowledge of
open source tools that can help you or your organization explore and
build on your own applications. This tutorial is designed to enable
enthusiasts in our community to explore an interesting topic using some
beginner-friendly Python libraries.&lt;/p&gt;
</content><category term="PyCon US 2024"></category></entry></feed>