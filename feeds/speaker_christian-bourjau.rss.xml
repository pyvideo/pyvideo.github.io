<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Christian Bourjau</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 17 Apr 2023 00:00:00 +0000</lastBuildDate><item><title>Making Machine Learning Applications Fast and Simple with ONNX</title><link>https://pyvideo.org/pycon-de-2022/making-machine-learning-applications-fast-and-simple-with-onnx.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Speaker:: Jan-Benedikt Jagusch Christian Bourjau&lt;/p&gt;
&lt;p&gt;Track: General: Production
Taking trained machine learning models from inside a Jupyter notebook and deploying them into a production microservice is painful for two reasons:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Models are not fully self-contained and need to be packaged together with their environment&lt;/li&gt;
&lt;li&gt;Models are optimized for batch processing but slow down for single-row predictions, which could lead to timeouts in a fast-paced online microservice.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this talk, you will learn how to use the Open Neural Network Exchange (ONNX) framework to compile models into fully-self contained computational graphs, which can reduce single-row inference time by up to 99%, while also drastically simplifying model management.&lt;/p&gt;
&lt;p&gt;You will be introduced to the ONNX ecosystem, such as the &lt;cite&gt;sklearn-onnx&lt;/cite&gt; and &lt;cite&gt;onnxmltools&lt;/cite&gt; libraries for converting models into ONNX graphs, and will learn how to write converters for custom estimators and transformers.&lt;/p&gt;
&lt;p&gt;Recorded at the PyConDE &amp;amp; PyData Berlin 2022 conference, April 11-13 2022.
&lt;a class="reference external" href="https://2022.pycon.de"&gt;https://2022.pycon.de&lt;/a&gt;
More details at the conference page: &lt;a class="reference external" href="https://2022.pycon.de/program/BLVRVL"&gt;https://2022.pycon.de/program/BLVRVL&lt;/a&gt;
Twitter: &lt;a class="reference external" href="https://twitter.com/pydataberlin"&gt;https://twitter.com/pydataberlin&lt;/a&gt;
Twitter: &lt;a class="reference external" href="https://twitter.com/pyconde"&gt;https://twitter.com/pyconde&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jan-Benedikt Jagusch</dc:creator><pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2022-05-11:/pycon-de-2022/making-machine-learning-applications-fast-and-simple-with-onnx.html</guid><category>PyCon DE 2022</category><category>PyCon</category><category>PyConDE</category><category>pyconde2022</category><category>pydata</category><category>PyDataBerlin</category><category>pydataberlin2022</category></item><item><title>Rapid model development and stable, high-performance deployments</title><link>https://pyvideo.org/pydata-berlin-2023/rapid-model-development-and-stable-high-performance-deployments.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;At the boundary of model development and MLOps lies the balance between the speed of deploying new models and ensuring operational constraints. These include factors like low latency prediction, the absence of vulnerabilities in dependencies and the need for the model behavior to stay reproducible for years. The longer the list of constraints, the longer it usually takes to take a model from its development environment into production. In this talk, we present how we seemingly managed to square the circle and have both a rapid, highly dynamic model development and yet also a stable and high-performance deployment.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Christian Bourjau</dc:creator><pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-04-17:/pydata-berlin-2023/rapid-model-development-and-stable-high-performance-deployments.html</guid><category>PyData Berlin 2023</category></item></channel></rss>