<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_facundo-calcagno.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-11-02T00:00:00+00:00</updated><entry><title>LSTM Variational AutoEncoders for Network Signal Anomaly Detection</title><link href="https://pyvideo.org/pycon-fr-2019/lstm-variational-autoencoders-for-network-signal-anomaly-detection.html" rel="alternate"></link><published>2019-11-02T00:00:00+00:00</published><updated>2019-11-02T00:00:00+00:00</updated><author><name>Facundo Calcagno</name></author><id>tag:pyvideo.org,2019-11-02:pycon-fr-2019/lstm-variational-autoencoders-for-network-signal-anomaly-detection.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A major French telecom provider has entrusted our team to develop a tool capable of accurately detecting anomalies in their network. This tool is to be deployed in a central surveillance cockpit that monitors the whole network in order to assist analysts in detecting and identifying risks, vulnerabilities and incidents in the network in real time.&lt;/p&gt;
&lt;p&gt;The solution proposedis based on state-of-the-art Deep Learning technology, more specifically, we developed the &amp;quot;Croissant&amp;quot; model, a Bidirectional LSTM Variational Autoencoder (VAE) that monitors the traffic in the network and triggers an alarm when an anomaly is detected. To cope with the large amounts of data, e.g., the number of inbound and outbound bytes of more than 300K devices within the network every 5 minutes, our model was developed to function at scale and using an adapted software and hardware solutions such as DGX stations for training and server equipped with NVIDIA T4s for inference/operations.&lt;/p&gt;
&lt;p&gt;The talk with go deeply into the architecture of the selected model and explaining step by step why it works and how it is going to be implemented.&lt;/p&gt;
</summary></entry><entry><title>Mask R-CNN in Lane Detection</title><link href="https://pyvideo.org/pycon-fr-2018/mask-r-cnn-in-lane-detection.html" rel="alternate"></link><published>2018-10-06T00:00:00+00:00</published><updated>2018-10-06T00:00:00+00:00</updated><author><name>Facundo Calcagno</name></author><id>tag:pyvideo.org,2018-10-06:pycon-fr-2018/mask-r-cnn-in-lane-detection.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The aim of this paper is to introduce to the newcomers the ideas of Deep
Neural Networks started by Yan LeCun and continued by Alex A., NYU,
Google and Facebook teams, make a small panorama of the more common
types of Neural Networks available and explain in detail a new and very
successful architecture called Mask R-CNN that has won recognition all
around the world.&lt;/p&gt;
&lt;p&gt;After this big introduction, we will dive into the resolution of the
problem of Lane Recognition with images taken from inside cars using
CuLanes dataset and its implementation in TensorFlow. We will see how
difficult and problematic this type of images can be due to the
different and possible geometric issues that diverse landscapes have.
Nevertheless, we will show that the technique is applicable to this
specific problem and could be improved to be automatized and implemented
in a self-driving car.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/fmcalcagno/MASK_Lane_Detection"&gt;https://github.com/fmcalcagno/MASK_Lane_Detection&lt;/a&gt; &amp;#64;fmcalcagno&lt;/p&gt;
</summary></entry></feed>