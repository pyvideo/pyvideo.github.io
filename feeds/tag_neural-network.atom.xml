<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/tag_neural-network.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2019-05-05T00:00:00+00:00</updated><entry><title>RedisAI</title><link href="https://pyvideo.org/pycon-italia-2019/redisai.html" rel="alternate"></link><published>2019-05-05T00:00:00+00:00</published><updated>2019-05-05T00:00:00+00:00</updated><author><name>Luca Antiga</name></author><id>tag:pyvideo.org,2019-05-05:pycon-italia-2019/redisai.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Taking deep learning models to production and doing so reliably is one
of the next frontiers of DevOps. With the advent of Redis modules and
the availability of C APIs for the major deep learning frameworks, it is
now possible to turn Redis into a reliable runtime for deep learning
workloads, providing a simple solution for a model serving microservice.
In this talk we will introduce RedisAI, a joint effort by Orobix and
RedisLabs that introduces tensors and graphs as new Redis data types and
allows to execute graphs over tensors using multiple backends (PyTorch,
TensorFlow, and ONNXRuntime), both on the CPU and GPU. The module also
supports scripting with TorchScript, which provides a Python-like tensor
language that can be used to facilitate pre- and post-processing
operations, like input shaping or output ensambling. In addition, thanks
to its support for the ONNX standard, including ONNX-ML, RedisAI is not
strictly limited to deep learning, but it offers support for general
machine learning algorithms. In this talk, we will demonstrate a full,
Python-powered journey from fine tuning a model to a scalable Flask +
RedisAI deployment. Last, we will lay down the roadmap for the future,
like automated batching, sharding, integration with Redis data types
(e.g. streams) and advanced monitoring. The talk will include sample
code, best practices and a live demo.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1756"&gt;https://python.it/feedback-1756&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Sunday 5 May&lt;/strong&gt; at 12:30 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="database"></category><category term="redis"></category><category term="devops"></category><category term="Machine Learning"></category><category term="deployment"></category><category term="neural network"></category></entry><entry><title>AI and algorithmic art</title><link href="https://pyvideo.org/pycon-italia-2019/ai-and-algorithmic-art.html" rel="alternate"></link><published>2019-05-03T00:00:00+00:00</published><updated>2019-05-03T00:00:00+00:00</updated><author><name>Cheuk Ho</name></author><id>tag:pyvideo.org,2019-05-03:pycon-italia-2019/ai-and-algorithmic-art.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Abstract&lt;/p&gt;
&lt;p&gt;Many people think of neural networks as magic boxes, using them as such
is similar to allowing the computer or the machine to have a mind of
their own. Classification and prediction are the best-known applications
of these algorithms. But it has been demonstrated that they can also be
used in multiple creative or artistic ways such as generating pictures,
musical pieces, humour based dialogues or jokes and plays or literary
pieces. Leading to the following question: can these black boxes express
true creativity? A trait commonly associated with humans.&lt;/p&gt;
&lt;p&gt;Description&lt;/p&gt;
&lt;p&gt;Algorithmic Art (or computer generated art) refers to the use of
computer algorithms to create artistic pieces. Algorithmic art has been
around from the early 1960s, when artists used a plotter controlled by a
computer to create some visual artwork pieces. In the 80s when computer
graphics became more accessible, digital fractal artworks dominated to
become the mainstream of algorithmic art. By the end of the 80s, genetic
algorithms had matured enough to have a major influence in the
algorithmic composition of music. At the same time, the artificial
neural networks were used to explore the creation of musical
compositions. Most recently, thanks to the blooming of neural network
frameworks (e.g. tensorflow), availability of GPUs and development in
sophisticated neural network architecture, they play an important part
in academic research and data science business applications. Besides
that, these enhanced resources and frameworks have enabled the neural
networks to make significant contributions in the area of Algorithmic
Arts. Examples of this are the Deep Dream and artistic style transfer
and GANs (generative adversarial network) which can generate highly
deceptive pictures. A specially trained neural network is also capable
of composing music mimicking the style of Beethoven or generating a
modern music piece. In the same way, a neural network can be used to
generate poems or literary pieces in the true style of Shakespeare or
Hamilton. In this talk, we will go through a gallery of art and music
created by algorithms, showcasing what roles computers took in different
algorithmic art forms. From the earliest fractal art to the music and
pictures generated by the state of the art neural networks and GANs.
This talk is suitable for everyone, from the curious general public to
experts in the field of neural networks, both will find this talk
inspiring and amusing.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Slide for this talk:
&lt;a class="reference external" href="https://slides.com/cheukting_ho/ai-and-algorithmic-art/live#/"&gt;https://slides.com/cheukting_ho/ai-and-algorithmic-art/live#/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1778"&gt;https://python.it/feedback-1778&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 11:15 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="art"></category><category term="pydata"></category><category term="AI"></category><category term="Algorithms"></category><category term="algorithmicart"></category><category term="neural network"></category></entry><entry><title>Deep learning: the final frontier for time series analysis and signal processing?</title><link href="https://pyvideo.org/pycon-italia-2019/deep-learning-the-final-frontier-for-time-series-analysis-and-signal-processing.html" rel="alternate"></link><published>2019-05-03T00:00:00+00:00</published><updated>2019-05-03T00:00:00+00:00</updated><author><name>Alexandr Honchar</name></author><id>tag:pyvideo.org,2019-05-03:pycon-italia-2019/deep-learning-the-final-frontier-for-time-series-analysis-and-signal-processing.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Deep neural networks are becoming irreplaceable for analyzing most kinds
of data that humans supposed to exceed in - images, video, sounds,
texts. They can not only predict something based on some input but also
generate new images or sounds. Meanwhile, we are forgetting about
another very important source of data - signals (or time series, which
will be interchangeably here), that gets less hype in public but
benefits a lot from applying deep learning comparing to classical
approaches.&lt;/p&gt;
&lt;p&gt;In this talk, we will review what are sources of time series and what
business goals are we solving while analyzing them, what are “old” tools
for analysis and how deep neural nets overcome them, we will learn the
latest trends and ruin some myths and, moreover, we will see how
generative models can be applied to the signal processing as well.&lt;/p&gt;
&lt;p&gt;After this talk, you’ll be able to boost your current solutions in
signal processing or time series analysis with deep learning. It will be
also interesting for practitioners in other areas, like computer vision
or NLP since we will discuss some concepts that are widely applicable.
Previous experience with time series is not required, but some
theoretical or practical experience with machine learning and/or neural
networks is preferred.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1716"&gt;https://python.it/feedback-1716&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 18:00 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="machine-learning"></category><category term="deep learning"></category><category term="biomedical-data-science"></category><category term="TimeSeries"></category><category term="signal-processing"></category><category term="neural network"></category><category term="finance"></category></entry><entry><title>Python on Mars</title><link href="https://pyvideo.org/europython-2013/python-on-mars.html" rel="alternate"></link><published>2013-07-03T00:00:00+00:00</published><updated>2013-07-03T00:00:00+00:00</updated><author><name>Ezio Melotti</name></author><id>tag:pyvideo.org,2013-07-03:europython-2013/python-on-mars.html</id><summary type="html"></summary><category term="pytango"></category><category term="space suit tango"></category><category term="tango"></category><category term="mars"></category><category term="scientific-computing"></category><category term="neural network"></category><category term="space suit"></category></entry><entry><title>Python su Marte</title><link href="https://pyvideo.org/europython-2013/python-su-marte.html" rel="alternate"></link><published>2013-07-03T00:00:00+00:00</published><updated>2013-07-03T00:00:00+00:00</updated><author><name>Ezio Melotti</name></author><id>tag:pyvideo.org,2013-07-03:europython-2013/python-su-marte.html</id><summary type="html"></summary><category term="tango"></category><category term="scientific-computing"></category><category term="pytango"></category><category term="neural network"></category><category term="tuta spaziale"></category></entry><entry><title>How to make your model happy again</title><link href="https://pyvideo.org/pycon-italia-2018/how-to-make-your-model-happy-again.html" rel="alternate"></link><published>2018-04-21T00:00:00+00:00</published><updated>2018-04-21T00:00:00+00:00</updated><author><name>Alessia Marcolini</name></author><id>tag:pyvideo.org,2018-04-21:pycon-italia-2018/how-to-make-your-model-happy-again.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Nowadays ‘build and run’ a predictive model is a quite easy task, thanks
to frameworks that simplify things and set good defaults for you (i.e.
Keras).&lt;/p&gt;
&lt;p&gt;But how do you &lt;em&gt;effectively&lt;/em&gt; train a model, in order to gain better
performance or to get your results faster? Do you feel frustrated every
time you need to set and then tune the network’s hyperparameters, too?
Don’t worry!&lt;/p&gt;
&lt;p&gt;In this talk I will share some practical tips&amp;amp;tricks (such as Model
Ensembling and learning rate schedulers) and relative examples, derived
from my personal experience or from literature, with the aim to improve
neural networks capabilities and to get the convergence faster.&lt;/p&gt;
&lt;p&gt;This talk is aimed at data scientists or everyone passionate about this
topic who wants to learn more.&lt;/p&gt;
&lt;p&gt;Gently inspired by Practical Deep Learning for Coders Part 1 v2 of
&lt;a class="reference external" href="http://fast.ai"&gt;fast.ai&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;sabato 21 aprile&lt;/strong&gt; at 12:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="Deep-Learning"></category><category term="Data-Scientist"></category><category term="neural network"></category><category term="pydata"></category></entry><entry><title>Deep Learning from zero to hero</title><link href="https://pyvideo.org/pycon-italia-2018/deep-learning-from-zero-to-hero.html" rel="alternate"></link><published>2018-04-20T00:00:00+00:00</published><updated>2018-04-20T00:00:00+00:00</updated><author><name>Gianluca Carucci</name></author><id>tag:pyvideo.org,2018-04-20:pycon-italia-2018/deep-learning-from-zero-to-hero.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Avete sentito parlare di Deep Learning ma credete che la teoria alla
base sia troppo complessa? Non avete una laurea in matematica e
statistica e pensate che il machine learning non faccia per voi? Niente
paura: avrete solo bisogno di una conoscenze di base di Python.&lt;/p&gt;
&lt;p&gt;Conoscete la regola dell’80/20? Con il 20% delle conoscenze potete
raggiungere l’80% dei risultati: in questo talk vi mostrerò in modo
pratico tramite delle demo - alcuni trucchi per costruire dei buoni
modelli predittivi, evitando di perdere (tanto) tempo nella scelta dei
tools e delle librerie necessarie al vostro scopo.&lt;/p&gt;
&lt;p&gt;L’obbiettivo è fornirvi le basi pratiche con cui scegliere un modello di
rete neurale, farne training e ottimizzarlo nel modo più adatto alla
tipologia del problema che dovete affrontare.&lt;/p&gt;
&lt;p&gt;Agenda: - Introduzione al Deep Learning - Un esempio di training senza
scrivere codice - Sviluppare, testare e ottimizzare un modello reale -
Considerazioni finali&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;venerdì 20 aprile&lt;/strong&gt; at 12:30 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</summary><category term="machine-learning"></category><category term="Keras"></category><category term="Deep-Learning"></category><category term="data-analysis"></category><category term="tensorflow"></category><category term="computer-science"></category><category term="neural network"></category></entry><entry><title>A Gentle Introduction to Neural Networks (with Python)</title><link href="https://pyvideo.org/pycon-italia-2017/a-gentle-introduction-to-neural-networks-with-python.html" rel="alternate"></link><published>2017-04-07T00:00:00+00:00</published><updated>2017-04-07T00:00:00+00:00</updated><author><name>Tariq Rashid</name></author><id>tag:pyvideo.org,2017-04-07:pycon-italia-2017/a-gentle-introduction-to-neural-networks-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A gentle introduction to neural networks, and making your own with
Python.&lt;/p&gt;
&lt;p&gt;This session is especially designed to be accessible to everyone,
including anyone with no expertise in mathematics, computer science or
Python.&lt;/p&gt;
&lt;p&gt;From this session you will have an intuitive understanding of what
neural networks are and how they work. If you are more technically
capable, you will see how you could make your own with Python and numpy.&lt;/p&gt;
&lt;p&gt;Part 1 - Ideas:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;the search for AI, hard problems for computers easy for humans&lt;/li&gt;
&lt;li&gt;learning from examples (simple classifier)&lt;/li&gt;
&lt;li&gt;biologically inspired neurons and networks&lt;/li&gt;
&lt;li&gt;training a neural network&lt;/li&gt;
&lt;li&gt;the back propagation breakthrough&lt;/li&gt;
&lt;li&gt;matrix ways of working (good for computers)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Part 2 - Python:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Python is easy, and everywhere&lt;/li&gt;
&lt;li&gt;Python notebooks&lt;/li&gt;
&lt;li&gt;the MNIST data set&lt;/li&gt;
&lt;li&gt;a very simple neural network class&lt;/li&gt;
&lt;li&gt;focus on concise and efficient matrix calculations with numpy&lt;/li&gt;
&lt;li&gt;97.5% accuracy recognising handwritten numbers - with just a few lines of code!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Part 3 - Live Demo! … and Q&amp;amp;A&lt;/p&gt;
</summary><category term="image-processing"></category><category term="numpy"></category><category term="neural network"></category><category term="Artificial Intelligence"></category><category term="Machine Learning"></category></entry></feed>