<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Nathan Day</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 18 Apr 2025 00:00:00 +0000</lastBuildDate><item><title>Maximizing Multimodal: Exploring the search frontier of text-to-image models</title><link>https://pyvideo.org/pydata-virginia-2025/maximizing-multimodal-exploring-the-search-frontier-of-text-to-image-models.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Text-to-Image models, like CLIP, have brought us into a new frontier of visual search. Whether it's searching by circling a section of a photo or powering image generators like Dalle-E the gap between pixels and tokens has never been smaller. This talk discusses how we are improving search and empowering designers with these models at Eezy, a stock art marketplace.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Nathan Day</dc:creator><pubDate>Fri, 18 Apr 2025 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2025-04-18:/pydata-virginia-2025/maximizing-multimodal-exploring-the-search-frontier-of-text-to-image-models.html</guid><category>PyData Virginia 2025</category></item></channel></rss>