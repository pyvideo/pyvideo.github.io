<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Ziniu Li</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_ziniu-li.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2023-07-31T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Provably Efficient Adversarial Imitation Learning with Unknown Transitions</title><link href="https://pyvideo.org/uai-2023/provably-efficient-adversarial-imitation-learning-with-unknown-transitions.html" rel="alternate"></link><published>2023-07-31T00:00:00+00:00</published><updated>2023-07-31T00:00:00+00:00</updated><author><name>Tian Xu</name></author><id>tag:pyvideo.org,2023-07-31:/uai-2023/provably-efficient-adversarial-imitation-learning-with-unknown-transitions.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Provably Efficient Adversarial Imitation Learning with Unknown Transitions&amp;quot;
Tian Xu, Ziniu Li, Yang Yu, Zhi-Quan Luo
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/xu23c.html"&gt;https://proceedings.mlr.press/v216/xu23c.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Imitation learning (IL) has proven to be an effective method for learning good policies from expert demonstrations. Adversarial imitation learning (AIL), a subset of IL â€¦&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Provably Efficient Adversarial Imitation Learning with Unknown Transitions&amp;quot;
Tian Xu, Ziniu Li, Yang Yu, Zhi-Quan Luo
(&lt;a class="reference external" href="https://proceedings.mlr.press/v216/xu23c.html"&gt;https://proceedings.mlr.press/v216/xu23c.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Abstract
Imitation learning (IL) has proven to be an effective method for learning good policies from expert demonstrations. Adversarial imitation learning (AIL), a subset of IL methods, is particularly promising, but its theoretical foundation in the presence of unknown transitions has yet to be fully developed. This paper explores the theoretical underpinnings of AIL in this context, where the stochastic and uncertain nature of environment transitions presents a challenge. We examine the expert sample complexity and interaction complexity required to recover good policies. To this end, we establish a framework connecting reward-free exploration and AIL, and propose an algorithm, MB-TAIL, that achieves the minimax optimal expert sample complexity and interaction complexity. MB-TAIL is the first algorithm to achieve this level of expert sample complexity in the unknown transition setting and improves upon the interaction complexity of the best-known algorithm, OAL. Additionally, we demonstrate the generalization ability of MB-TAIL by extending it to the function approximation setting.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://www.auai.org/uai2023/oral_slides/380-oral-slides.pdf"&gt;https://www.auai.org/uai2023/oral_slides/380-oral-slides.pdf&lt;/a&gt;&lt;/p&gt;
</content><category term="UAI 2023"></category></entry></feed>