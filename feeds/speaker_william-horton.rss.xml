<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - William Horton</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 26 Jul 2025 00:00:00 +0000</lastBuildDate><item><title>A Brief History of Jupyter Notebooks</title><link>https://pyvideo.org/europython-2020/a-brief-history-of-jupyter-notebooks.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The Jupyter Notebook: many Python users love it, many other Python users love to hate it. But where did it come from? How did we come to have a tool that combines code execution, visualization, Markdown, and more? In this talk, we will dive into the development of the Jupyter Notebook and the older ideas that it built upon.&lt;/p&gt;
&lt;p&gt;To start, we will look at tools that popularized the “computational notebook” interface. In 1988, Mathematica introduced this interface to the scientific community. In the 90s, tools like Maple competed with Mathematica to provide the best scientific programming environment. The early 2000s saw the rise in popularity of open-source scientific tools in Python, including IPython, leading to IPython Notebook and then Jupyter.&lt;/p&gt;
&lt;p&gt;Turning to the present, we look at the expanding ecosystem beyond the Notebook. JupyterLab provides a richer programming environment. Voilà and Binder give users better options for sharing their notebooks. And increased language support has led to Jupyter being a tool not only for Julia, Python, and R, but for dozens of other languages.&lt;/p&gt;
&lt;p&gt;Finally: what is still to come? JupyerLab 2.0 promises even greater IDE-like capabilities, while IDEs increase their own Notebook support. Projects like Deepnote and CoCalc promise real-time collaboration on top of the Notebook interface. And the frustrations of working with Git are the source of a growing number of possible solutions. These efforts point us toward what the Jupyter Notebook could become.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">William Horton</dc:creator><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-07-23:/europython-2020/a-brief-history-of-jupyter-notebooks.html</guid><category>EuroPython 2020</category><category>europython</category><category>europython-2020</category><category>europython-online</category><category>Data Science</category><category>Ipython</category><category>Jupyter</category><category>Open-Source</category><category>Scientific Libraries (Numpy/Pandas/SciKit/...)</category></item><item><title>CUDA in your Python: Parallel Programming on the GPU</title><link>https://pyvideo.org/pybay-2019/cuda-in-your-python-parallel-programming-on-the-gpu.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk was presented at PyBay2019 - 4th annual Bay Area Regional Python conference. See pybay.com for more details about PyBay and click SHOW MORE for more information about this talk.&lt;/p&gt;
&lt;p&gt;Description
It’s 2019, and Moore’s Law is dead. CPU performance is plateauing, but GPUs provide a chance for continued hardware performance gains, if you can structure your programs to make good use of them. In this talk you will learn how to speed up your Python programs using Nvidia’s CUDA platform.&lt;/p&gt;
&lt;p&gt;Abstract
CUDA is a platform developed by Nvidia for GPGPU--general purpose computing with GPUs. It backs some of the most popular deep learning libraries, like Tensorflow and Pytorch, but it has broader uses in data analysis, data science, and machine learning.&lt;/p&gt;
&lt;p&gt;There are several ways that you can start taking advantage of CUDA in your Python programs.&lt;/p&gt;
&lt;p&gt;For some common Python libraries, there are drop-in replacements that let you start running computations on the GPU, while still using APIs that you might be familiar with. For example, CuPy provides a Numpy-like API for interacting with multi-dimensional arrays. Another recent project is cuDF by RAPIDS AI, which mimics the pandas interface for dataframes.&lt;/p&gt;
&lt;p&gt;If you want more control over your use of CUDA APIs, you can use the PyCUDA library, which provides bindings for the CUDA API that you can call from your Python code. Compared with drop-in libraries, it gives you the ability to manually allocate memory on the GPU, as well as to write custom CUDA code. However, it comes with some drawbacks, such as having to write your CUDA code as large strings in your Python program, and compiling your CUDA code while running your program, rather than beforehand.&lt;/p&gt;
&lt;p&gt;Finally, for the best performance you can use the Python C/C++ extension interface, the approach taken by deep learning libraries like Pytorch. One of the strengths of Python is the ability to drop down into C/C++, and libraries like Numpy take advantage of this for increased speed. If you use Nvidia’s nvcc compiler for CUDA, you can use the same extension interface to write custom programs in CUDA and then call them from your Python code.&lt;/p&gt;
&lt;p&gt;This talk will explore each of these methods, provide examples to get started, and discuss in more detail the pros and cons of each approach.&lt;/p&gt;
&lt;p&gt;About the speaker
William Horton is a Senior Backend Engineer at Compass, where he works on systems for ingesting, processing, and serving millions of real estate listings. In his spare time, he blogs and speaks about deep learning, contributes to open-source libraries like fastai and pytorch, and competes in computer vision competitions on Kaggle. When he’s not doing tech things, he enjoys powerlifting and singing a cappella.&lt;/p&gt;
&lt;p&gt;Sponsor Acknowledgement
This and other PyBay2019 videos are via the help of our media partner AlphaVoice (&lt;a class="reference external" href="https://www.alphavoice.io/"&gt;https://www.alphavoice.io/&lt;/a&gt;)!&lt;/p&gt;
&lt;p&gt;#pybay #pybay2019 #python #python3 #gdb&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">William Horton</dc:creator><pubDate>Sat, 17 Aug 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-08-17:/pybay-2019/cuda-in-your-python-parallel-programming-on-the-gpu.html</guid><category>PyBay 2019</category></item><item><title>CUDA in Your Python: Effective Parallel Programming on the GPU</title><link>https://pyvideo.org/pycolorado-2019/cuda-in-your-python-effective-parallel-programming-on-the-gpu.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;It’s 2019, and Moore’s Law is dead. CPU performance is plateauing, but GPUs provide a chance for continued hardware performance gains, if you can structure your programs to make good use of them. In this talk you will learn how to speed up your Python programs using Nvidia’s CUDA platform.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">William Horton</dc:creator><pubDate>Sun, 08 Sep 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-09-08:/pycolorado-2019/cuda-in-your-python-effective-parallel-programming-on-the-gpu.html</guid><category>PyColorado 2019</category></item><item><title>CUDA in your Python: Effective Parallel Programming on the GPU</title><link>https://pyvideo.org/pycon-us-2019/cuda-in-your-python-effective-parallel-programming-on-the-gpu.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;It’s 2019, and Moore’s Law is dead. CPU performance is plateauing, but
GPUs provide a chance for continued hardware performance gains, if you
can structure your programs to make good use of them.&lt;/p&gt;
&lt;p&gt;CUDA is a platform developed by Nvidia for GPGPU--general purpose
computing with GPUs. It backs some of the most popular deep learning
libraries, like Tensorflow and Pytorch, but has broader uses in data
analysis, data science, and machine learning.&lt;/p&gt;
&lt;p&gt;There are several ways that you can start taking advantage of CUDA in
your Python programs.&lt;/p&gt;
&lt;p&gt;For some common Python libraries, there are drop-in replacements that
let you start running computations on the GPU while still using familiar
APIs. For example, CuPy provides a NumPy-like API for interacting with
multi-dimensional arrays. Similarly, cuDF is a recent project that
mimics the pandas interface for dataframes.&lt;/p&gt;
&lt;p&gt;If you want more control over your use of CUDA APIs, you can use the
PyCUDA library, which provides bindings for the CUDA API that you can
call from your Python code. Compared with drop-in libraries, it gives
you the ability to manually allocate memory on the GPU, and write custom
CUDA functions (called kernels). However, its drawbacks include writing
your CUDA code as large strings in Python, and compiling your CUDA code
at runtime.&lt;/p&gt;
&lt;p&gt;Finally, for the best performance you can use the Python C/C++ extension
interface, the approach taken by deep learning libraries like Pytorch.
One of the strengths of Python is the ability to drop down into C/C++,
and libraries like NumPy take advantage of this for increased speed. If
you use Nvidia’s nvcc compiler for CUDA, you can use the same extension
interface to write custom CUDA kernels, and then call them from your
Python code.&lt;/p&gt;
&lt;p&gt;This talk will explore each of these methods, provide examples to get
started, and discuss in more detail the pros and cons of each approach.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">William Horton</dc:creator><pubDate>Sat, 04 May 2019 17:10:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-04:/pycon-us-2019/cuda-in-your-python-effective-parallel-programming-on-the-gpu.html</guid><category>PyCon US 2019</category><category>talk</category></item><item><title>You Can Do Deep Learning!</title><link>https://pyvideo.org/pyohio-2018/you-can-do-deep-learning.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;When I started learning web dev, I dove into building my first Rails
app. I didn’t know how it all worked, but after hours of hacking I had a
blogging app running. I imagine many share a similar learning
experience. Similarly, you don’t need a PhD to do deep learning, you can
get started with Python skills and open-source frameworks. It can be fun
and rewarding, and inspire you to dive deeper.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">William Horton</dc:creator><pubDate>Sat, 28 Jul 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-07-28:/pyohio-2018/you-can-do-deep-learning.html</guid><category>PyOhio 2018</category></item><item><title>Demystifying AI Agents with Python Code</title><link>https://pyvideo.org/pyohio-2025/demystifying-ai-agents-with-python-code.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Everyone’s talking about AI Agents! But what are they, and how can you
build them? This talk cuts through the hype. Drawing on a year spent
developing a GenAI platform, I'll show you that creating powerful AI
Agents is within your reach, no advanced degree required.&lt;/p&gt;
&lt;p&gt;We’ll define agents practically: Large Language Models combined with
tools and memory. Moving beyond the abstract definition, I’ll show you
how to build your first agent using the OpenAI Python SDK and
fundamental Python concepts you’re already familiar with: functions,
loops, and conditions. From there, I will demonstrate how you can use
the CrewAI framework to abstract away the boilerplate code, allowing for
simpler setup of multi-agent systems.&lt;/p&gt;
&lt;p&gt;By the end, you won't just understand agents; you'll be equipped and
inspired to build your own, ready to tackle custom tasks by integrating
the APIs that matter to you.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">William Horton</dc:creator><pubDate>Sat, 26 Jul 2025 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2025-07-26:/pyohio-2025/demystifying-ai-agents-with-python-code.html</guid><category>PyOhio 2025</category></item><item><title>CUDA in your Python: Effective Parallel Programming on the GPU</title><link>https://pyvideo.org/pytexas-2019/cuda-in-your-python-effective-parallel-programming-on-the-gpu.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;It’s 2019, and Moore’s Law is dead. CPU performance is plateauing, but GPUs provide a chance for continued hardware performance gains, if you can structure your programs to make good use of them. In this talk you will learn how to speed up your Python programs using Nvidia’s CUDA platform.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">William Horton</dc:creator><pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-04-13:/pytexas-2019/cuda-in-your-python-effective-parallel-programming-on-the-gpu.html</guid><category>PyTexas 2019</category><category>GPU</category><category>cuda</category></item><item><title>What You Can Do With initpy But Probably Shouldnt</title><link>https://pyvideo.org/pytexas-2020/what-you-can-do-with-initpy-but-probably-shouldnt.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;What is __init__.py doing? Why is it in all of my directories? If you’re just starting out learning Python (or even if you’ve been using it for decades), these might be questions you’ve asked before. This talk is all about __init__.py: its history, its usage, and what can go wrong with it.&lt;/p&gt;
&lt;p&gt;Speaker: William Horton
William Horton is a Senior Software Engineer at Compass, where he works on systems for ingesting, processing, and serving millions of real estate listings. In his spare time, he blogs and speaks about deep learning, contributes to open-source Python libraries like fastai and pytorch, and competes in computer vision competitions on Kaggle. When he’s not doing tech things, he enjoys powerlifting and singing a cappella.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">William Horton</dc:creator><pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-10-24:/pytexas-2020/what-you-can-do-with-initpy-but-probably-shouldnt.html</guid><category>PyTexas 2020</category></item><item><title>Demystifying Al Agents with Python Code</title><link>https://pyvideo.org/pytexas-2025/demystifying-al-agents-with-python-code.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Everyone’s talking about AI Agents! But what are they, and how can you build them? In this talk, you will learn about how AI Agents are defined, and their key components, including LLMs, tools, and memory. Moving beyond abstract definitions, I will show you how you can implement AI Agents in Python using the OpenAI Python SDK along with basic Python concepts like functions, while loops, and if statements. From there I will demonstrate how Microsoft’s open-source AutoGen framework abstracts away some of the Python boilerplate for you, allowing for simpler setup when you are working with many agents at once. By the end, you will be empowered to create your own agents that access your own APIs to complete tasks that you define.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">William Horton</dc:creator><pubDate>Sat, 12 Apr 2025 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2025-04-12:/pytexas-2025/demystifying-al-agents-with-python-code.html</guid><category>PyTexas 2025</category></item><item><title>Building Machine Learning Pipelines with Kubeflow</title><link>https://pyvideo.org/scipy-japan-2020/building-machine-learning-pipelines-with-kubeflow.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Kubeflow is a tool for managing machine learning workflows on Kubernetes. In this talk, I will explain how we can use Kubeflow to take on the challenges of machine learning beyond model training, including data preprocessing, model evaluation, and deployment--the steps that together make up a full machine learning pipeline. I will introduce Kubeflow and explain the central concepts of the platform using basic examples. Then I will show how my team is using Kubeflow to tackle real-world problems in the real estate domain.&lt;/p&gt;
&lt;p&gt;Kubeflowは、Kubernetes上で機械学習のワークフローを管理するためのツールです。 本講演では、Kubeflowを使って、データの前処理、モデルの評価、デプロイメントなど、モデル学習の枠を超えた機械学習への挑戦、つまり、機械学習のパイプラインを構成するステップをまとめて解説します。Kubeflowを紹介し、基本的な例を用いてプラットフォームの中心的な概念を説明します。その後、私のチームがどのようにKubeflowを使用して不動産分野の実世界の問題に取り組んでいるかを紹介します。&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">William Horton</dc:creator><pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-10-30:/scipy-japan-2020/building-machine-learning-pipelines-with-kubeflow.html</guid><category>Scipy Japan 2020</category></item></channel></rss>