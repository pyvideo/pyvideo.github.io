<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Tom Everitt</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_tom-everitt.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2023-07-31T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Towards Causal Foundations of Safe AI</title><link href="https://pyvideo.org/uai-2023/towards-causal-foundations-of-safe-ai.html" rel="alternate"></link><published>2023-07-31T00:00:00+00:00</published><updated>2023-07-31T00:00:00+00:00</updated><author><name>James Fox</name></author><id>tag:pyvideo.org,2023-07-31:/uai-2023/towards-causal-foundations-of-safe-ai.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Towards Causal Foundations of Safe AI&amp;quot;
James Fox, Tom Everitt&lt;/p&gt;
&lt;p&gt;With great power comes great responsibility. Artificial intelligence (AI) is rapidly gaining new capabilities, and is increasingly trusted to make decisions impacting humans in significant ways (from self-driving cars to stock-trading to hiring decisions). To ensure that AI behaves …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Towards Causal Foundations of Safe AI&amp;quot;
James Fox, Tom Everitt&lt;/p&gt;
&lt;p&gt;With great power comes great responsibility. Artificial intelligence (AI) is rapidly gaining new capabilities, and is increasingly trusted to make decisions impacting humans in significant ways (from self-driving cars to stock-trading to hiring decisions). To ensure that AI behaves in ethical and robustly beneficial ways, we must identify potential pitfalls and develop effective mitigation strategies. In this tutorial, we will explain how (Pearlian) causality offers a useful formal framework for reasoning about AI risk and describe recent work on this topic. In particular, we’ll cover: causal models of agents and how to discover them; causal definitions of fairness, intent, harm, and incentives; and risks from AI such as misgeneralization and preference manipulation, as well as how mitigation techniques including impact measures, interpretability, and path-specific objectives can help address them.&lt;/p&gt;
</content><category term="UAI 2023"></category><category term="tutorial"></category></entry></feed>