<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Shuguang Cui</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 03 Aug 2020 00:00:00 +0000</lastBuildDate><item><title>An Interpretable and Sample Efficient Deep Kernel for Gaussian Process</title><link>https://pyvideo.org/uai-2020/an-interpretable-and-sample-efficient-deep-kernel-for-gaussian-process.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;An Interpretable and Sample Efficient Deep Kernel for Gaussian Process&lt;/p&gt;
&lt;p&gt;Yijue Dai (The Chinese University of Hong Kong, Shenzhen)*; Tianjian Zhang (The Chinese University of Hong Kong, Shenzhen); Zhidi Lin (The Chinese University of Hong Kong, Shenzhen); Feng Yin (The Chinese University of Hong Kong, Shenzhen); Sergios Theodoridis (National and Kapodistrian University of Athens); Shuguang Cui (The Chinese University of Hong Kong, Shenzhen )&lt;/p&gt;
&lt;p&gt;We propose a novel Gaussian process kernel that takes advantage of a deep neural network (DNN) structure but retains good interpretability. The resulting kernel is capable of addressing four major issues of the previous works of similar art, i.e., the optimality, explainability, model complexity, and sample efficiency. Our kernel design procedure comprises three steps: (1) Derivation of an optimal kernel with a non-stationary dot product structure that minimizes the prediction/test mean-squared-error (MSE); (2) Decomposition of this optimal kernel as a linear combination of shallow DNN subnetworks with the aid of multi-way feature interaction detection; (3) Updating the hyper-parameters of the subnetworks via an alternating rationale until convergence. The designed kernel does not sacrifice interpretability for optimality. On the contrary, each subnetwork explicitly demonstrates the interaction of a set of features in a transformation function, leading to a solid path toward explainable kernel learning. We test the proposed kernel with both synthesized and real-world data sets, and the proposed kernel is superior to its competitors in terms of prediction performance in most cases. Moreover, it tends to maintain the prediction performance and be robust to data over-fitting issue, when reducing the number of samples. &amp;quot;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yijue Dai</dc:creator><pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2020-08-03:/uai-2020/an-interpretable-and-sample-efficient-deep-kernel-for-gaussian-process.html</guid><category>UAI 2020</category></item></channel></rss>