<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - pytorch</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 17 Apr 2023 00:00:00 +0000</lastBuildDate><item><title>Keynote: PyTorch: a framework for fast, dynamic deep learning and scientific computi</title><link>https://pyvideo.org/euroscipy-2017/keynote-pytorch-a-framework-for-fast-dynamic-deep-learning-and-scientific-computi.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this session, you shall be introduced to a new framework for
scientific computing, mainly
aimed at deep learning workloads. The framework consists of an ndarray
library that natively
supports GPU execution, an automatic differentiation engine that is
flexible and fast, and
an optimization package for gradient based optimization methods. We
shall discuss practical
workflows, our features on top of python multiprocessing for efficient
parallel data loaders
and finally we shall briefly look at our upcoming just-in-time Tensor
compiler to fuse
computations and execute them more efficiently.&lt;/p&gt;
&lt;div class="section" id="biographical-sketch"&gt;
&lt;h4&gt;Biographical sketch&lt;/h4&gt;
&lt;p&gt;Soumith Chintala is a Researcher at Facebook AI Research, where he
works on deep learning,
reinforcement learning, generative image models, agents for video
games and large-scale
high-performance deep learning. Prior to joining Facebook in August
2014, he worked at
MuseAmi, where he built deep learning models for music and vision
targeted at mobile
devices. He holds a Masters in CS from NYU, and spent time in Yann
LeCun's NYU lab building
deep learning models for pedestrian detection, natural image OCR,
depth-images among others.&lt;/p&gt;
&lt;p&gt;(Reproduced from &lt;a class="reference external" href="https://research.fb.com/people/chintala-soumith/"&gt;https://research.fb.com/people/chintala-soumith/&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Soumith Chintala</dc:creator><pubDate>Thu, 31 Aug 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-08-31:/euroscipy-2017/keynote-pytorch-a-framework-for-fast-dynamic-deep-learning-and-scientific-computi.html</guid><category>EuroSciPy 2017</category><category>keynote</category><category>pytorch</category></item><item><title>Really Deep Neural Networks with PyTorch</title><link>https://pyvideo.org/pycon-de-2017/really-deep-neural-networks-with-pytorch.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;David Dao&lt;/strong&gt; (&amp;#64;dwddao)&lt;/p&gt;
&lt;p&gt;David is a PhD student at ETH Zurich, working on Deep Reinforcement Learning. Before joining ETH Zurich, he was an autonomous driving researcher at Mercedes-Benz Research in Silicon Valley and a graduate student at the Broad Institute of MIT and Harvard.&lt;/p&gt;
&lt;p&gt;David is a firm believer in open source and is organising Germany's largest deep learning meetup series, and Silicon Valley's self-driving AI series. He is a contributor to popular machine intelligence frameworks such as TensorFlow and PyTorch and speaks chinese with swabian accent.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Modern neural networks have hundreds of layers! How can we train such deep networks? Simply stacking layers on top doesn't work! This talk introduces the deep learning library PyTorch by explaining the exciting math, cool ideas and simple code behind what makes really deep neural networks work.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Modern neural networks consist of hundreds of computation layers! These very deep architectures consistently outperform shallower networks in a variety of tasks. However just simply stacking layers on top of each other won't work because the gradients are either vanishing or exploding during optimisation procedure. This talk explains the exciting math, cool ideas and elegant code that modern neural network architectures such as ResNets, HighwayNets and DenseNets are applying to circumvent the problem using PyTorch. PyTorch is a relatively new deep learning framework that is deeply integrated into Python. Unlike other frameworks such as TensorFlow and Theano, it uses tape-based automatic differentiation to run computation immediately, supports dynamic neural networks and provides a powerful GPU-accelerated Tensor library. The talk concludes with some real-world use-cases for very deep neural networks in chemical-genetic profiling and autonomous driving.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recorded at&lt;/strong&gt; PyCon.DE 2017 Karlsruhe: &lt;a class="reference external" href="https://de.pycon.org/"&gt;https://de.pycon.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video editing&lt;/strong&gt;: Sebastian Neubauer &amp;amp; Andrei Dan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Blender, Avidemux &amp;amp; Sonic Pi&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">David Dao</dc:creator><pubDate>Wed, 25 Oct 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-10-25:/pycon-de-2017/really-deep-neural-networks-with-pytorch.html</guid><category>PyCon DE 2017</category><category>deep learning</category><category>ai</category><category>machine learning</category><category>python</category><category>autonomous-driving</category><category>pytorch</category></item><item><title>Population Anomaly Detection with PyTorch</title><link>https://pyvideo.org/pycon-israel-2017/population-anomaly-detection-with-pytorch.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We introduce a scheme for population anomaly detection based on gaussianization through an adversarial autoencoder. This scheme is applicable to detection of 'soft' anomalies in arbitrarily distributed highly-dimensional data. A soft, or population, anomaly is characterized by a shift in the distribution of the data set, where certain elements appear with higher or lower probability than anticipated. Such anomalies must be detected by considering a large sample set rather than a single sample. Applications include, but not limited to, payment fraud trends, data exfiltration, and system security and health monitoring. We evaluate the scheme on credit card payment and DNS data exfiltration data and obtain both quantitative results and qualitative insights. We discuss our PyTorch implementation of deep gaussianization, and review implementation details, pitfalls, and performance.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">David Tolpin</dc:creator><pubDate>Mon, 12 Jun 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-06-12:/pycon-israel-2017/population-anomaly-detection-with-pytorch.html</guid><category>PyCon Israel 2017</category><category>pytorch</category></item><item><title>PyTorch: a modern scientific computing library for Python</title><link>https://pyvideo.org/pycon-italia-2018/pytorch-a-modern-scientific-computing-library-for-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Python is very well known for its ecosystem of mature scientific
computing packages. They range from low-level providers of generic
functionality like NumPy to very domain specific tools like
scikit-learn. A few years back, machine learning frameworks could be
easily classified into the second category, but this is changing now.
They become increasingly powerful and start to be applied in a whole
variety of settings different than their original purpose. In this talk,
I’ll present a basic tour of PyTorch, a relatively new library that has
already gathered a significant user base. I’ll describe features useful
both in machine learning and other domains, explain how it fits into the
Python landscape, and showcase scenarios where it provides benefits over
existing tools.&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;domenica 22 aprile&lt;/strong&gt; at 09:45 &lt;a class="reference external" href="/p3/schedule/pycon9/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Adam Paszke</dc:creator><pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-04-22:/pycon-italia-2018/pytorch-a-modern-scientific-computing-library-for-python.html</guid><category>PyCon Italia 2018</category><category>deep learning</category><category>Pytorch</category><category>pydata</category></item><item><title>Deep Learning with PyTorch for Fun and Profit (Part III / Italian Edition: Divina Commedia)</title><link>https://pyvideo.org/pycon-italia-2019/deep-learning-with-pytorch-for-fun-and-profit-part-iii-italian-edition-divina-commedia.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;There are all these great articles and blog posts about Deep Learning
describing all that awesome stuff. - Is it all that easy? Let’s check!&lt;/p&gt;
&lt;p&gt;We’ll look into: style transfer (making a picture look like painting),
speech generation (like Siri or Alexa) and text generation (writing a
story). In this talk I’ll describe the whole journey: A fun ride from
the idea to the very end including all the struggles, failures and
successes.&lt;/p&gt;
&lt;p&gt;This is an ongoing talk on how far we can get creating a full &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Radio_drama"&gt;radio
drama (Hörspiel)&lt;/a&gt; with
deep learning and the resources required.&lt;/p&gt;
&lt;p&gt;Steps, we’ll cover:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The data challenge: get the data ready&lt;/li&gt;
&lt;li&gt;Creating a character-level language models with an Recurrent Neural
Network&lt;/li&gt;
&lt;li&gt;Creating a text generator&lt;/li&gt;
&lt;li&gt;Creating artwork&lt;/li&gt;
&lt;li&gt;Synthesising speech&lt;/li&gt;
&lt;li&gt;Making it sound like a real person&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this special PyCon X edition we will also try to recreate text in the
style of Dante’ Divina Commedia.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Feedback form:&lt;/strong&gt; &lt;a class="reference external" href="https://python.it/feedback-1687"&gt;https://python.it/feedback-1687&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;in __on &lt;strong&gt;Friday 3 May&lt;/strong&gt; at 12:00 &lt;a class="reference external" href="/en/sprints/schedule/pycon10/"&gt;**See
schedule**&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexander Hendorf</dc:creator><pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-03:/pycon-italia-2019/deep-learning-with-pytorch-for-fun-and-profit-part-iii-italian-edition-divina-commedia.html</guid><category>PyCon Italia 2019</category><category>deep learning</category><category>Pytorch</category><category>art</category><category>Artificial Intelligence</category><category>nlp</category></item><item><title>Exploring Deep Learning Framework PyTorch</title><link>https://pyvideo.org/pycon-us-2018/exploring-deep-learning-framework-pytorch.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Anyone who is interested in deep learning has gotten their hands dirty playing around with Tensorflow, Google's open source deep learning framework. Tensorflow has its benefits like wide scale adoption, deployment on mobile, and support for distributed computing, but it also has a somewhat challenging learning curve, is difficult to debug, and hard to deploy in production. PyTorch is a new deep learning framework that solves a lot of those problems.&lt;/p&gt;
&lt;p&gt;PyTorch is only in beta, but users are rapidly adopting this modular deep learning framework. PyTorch supports tensor computation and dynamic computation graphs that allow you to change how the network behaves on the fly unlike static graphs that are used in frameworks such as Tensorflow. PyTorch offers modularity which enhances the ability to debug or see within the network and for many, is more intuitive to learn than Tensorflow.&lt;/p&gt;
&lt;p&gt;This talk will objectively look at PyTorch and why it might be the best fit for your deep learning use case and we'll look at use cases that will showcase why you might want consider using Tensorflow instead.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Stephanie Kim</dc:creator><pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-05-11:/pycon-us-2018/exploring-deep-learning-framework-pytorch.html</guid><category>PyCon US 2018</category><category>pytorch</category></item><item><title>Improving Machine Learning from Human Feedback</title><link>https://pyvideo.org/pydata-berlin-2023/improving-machine-learning-from-human-feedback.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Large generative models rely upon massive data sets that are collected automatically. For example, GPT-3 was trained with data from &amp;quot;Common Crawl&amp;quot; and &amp;quot;Web Text&amp;quot;, among other sources. As the saying goes — bigger isn't always better. While powerful, these data sets (and the models that they create) often come at a cost, bringing their &amp;quot;internet-scale biases&amp;quot; along with their &amp;quot;internet-trained models.&amp;quot; While powerful, these models beg the question — is unsupervised learning the best future for machine learning?&lt;/p&gt;
&lt;p&gt;ML researchers have developed new model-tuning techniques to address the known biases within existing models and improve their performance (as measured by response preference, truthfulness, toxicity, and result generalization). All of this at a fraction of the initial training cost. In this talk, we will explore these techniques, known as Reinforcement Learning from Human Feedback (RLHF), and how open-source machine learning tools like PyTorch and Label Studio can be used to tune off-the-shelf models using direct human feedback.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Erin Mikail Staples</dc:creator><pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-04-17:/pydata-berlin-2023/improving-machine-learning-from-human-feedback.html</guid><category>PyData Berlin 2023</category><category>reinforcement learning</category><category>human feedback</category><category>pytorch</category><category>label studio</category></item><item><title>Apex</title><link>https://pyvideo.org/pytorch-conference-2019/apex.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Apex is an open-source PyTorch extension that helps users maximize deep learning training performance on NVIDIA GPUs. Mixed precision utilities in Apex are designed to improve training speed while maintaining the accuracy and stability of training in single precision. Learn more in this talk.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Michael Carilli</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/apex.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>APEX</category><category>Artificial Intelligence</category><category>Deep Learning</category><category>Distributed Training</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>Mixed Precision</category><category>NVIDIA</category><category>NVIDIA GPU</category><category>PyTorch</category><category>PyTorch 1.3</category></item><item><title>Collaborative Natural Language Inference</title><link>https://pyvideo.org/pytorch-conference-2019/collaborative-natural-language-inference.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Get an overview from Professor Sasha Rush of Cornell on the latest research in collaborative natural language inference.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sasha Rush</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/collaborative-natural-language-inference.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>AI Research</category><category>Artificial Intelligence</category><category>Cornell</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>PyTorch</category><category>PyTorch 1.3</category><category>natural language inference</category></item><item><title>CrypTen</title><link>https://pyvideo.org/pytorch-conference-2019/crypten.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Practical applications of ML via cloud-based or machine-learning-as-a-service (MLaaS) platforms pose a range of security and privacy challenges. In particular, users of these platforms may not want or be able to share unencrypted data, which prevents them from taking full advantage of ML tools. CrypTen is a new community-based research platform for taking the field of privacy-preserving ML forward.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Laurens van der Maaten</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/crypten.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>CrypTen</category><category>Facebook</category><category>ML</category><category>MLaaS</category><category>Machine Learning</category><category>Privacy</category><category>Private AI</category><category>PyTorch</category><category>PyTorch 1.3</category></item><item><title>Dataloader Design for PyTorch</title><link>https://pyvideo.org/pytorch-conference-2019/dataloader-design-for-pytorch.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Learn about the PyTorch data loading pipeline and components - the dataset, the sampler, and the dataloader.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tongzhou Wang</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/dataloader-design-for-pytorch.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>AI research</category><category>Artificial Intelligence</category><category>Dataloader Design</category><category>Facebook</category><category>MIT</category><category>ML</category><category>Machine Learning</category><category>Massachusetts Institute of Technology</category><category>PyTorch</category><category>PyTorch 1.3</category><category>PyTorch Datasets</category><category>data loading pipelines</category><category>data sets</category></item><item><title>Detectron2 - Next Gen Object Detection Library</title><link>https://pyvideo.org/pytorch-conference-2019/detectron2-next-gen-object-detection-library.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Object detection and segmentation are used for tasks ranging from autonomous vehicles to content understanding for platform integrity. Learn about Detectron2, an object detection library now implemented in PyTorch. Detectron2 provides support for the latest models and tasks, increased flexibility to aid computer vision research, and improvements in maintainability and scalability to support production use cases.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yuxin Wu</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/detectron2-next-gen-object-detection-library.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Detection library</category><category>Detectron2</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>PyTorch</category><category>PyTorch 1.3</category><category>Segmentation</category><category>computer vision</category><category>computer vision research</category><category>cv</category><category>detectron</category><category>object detection</category></item><item><title>Keynote</title><link>https://pyvideo.org/pytorch-conference-2019/keynote.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyTorch has become a popular open source machine learning framework for cutting edge research, and is increasingly being used in production. Watch Mike Schroepfer, Chief Technology Officer at Facebook, open the keynote at the second annual PyTorch Developer Conference.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mike Schroepfer</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/keynote.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Facebook</category><category>Framework</category><category>Keynote</category><category>ML</category><category>Machine Learning</category><category>Open Source</category><category>PyTorch</category></item><item><title>Linear Algebra in PyTorch</title><link>https://pyvideo.org/pytorch-conference-2019/linear-algebra-in-pytorch.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyTorch 1.2 and 1.3 have added several enhancements for linear algebra in PyTorch, including native batching support, support for gradients, and new semantic naming schemes. Learn more in this session.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Vishwak Srinivasan</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/linear-algebra-in-pytorch.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Facebook</category><category>Linear Algebra in PyTorch</category><category>ML</category><category>Machine Learning</category><category>PyTorch</category><category>PyTorch 1.3</category><category>Semantic naming schemes</category><category>Support for Gradients</category><category>native batching support</category></item><item><title>Panel Discussion</title><link>https://pyvideo.org/pytorch-conference-2019/panel-discussion.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Hear from users and creators in the PyTorch community as they discuss their needs and thoughts around ML tooling, open source ecosystems, and more. This panel is moderated by Soumith Chintala, and includes Lisha Li from Rosebud, Michela Paganini from Facebook, Clément Delangue from HuggingFace, Rachel Thomas from fast.ai, Maria Popova from UNC.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Soumith Chintala</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/panel-discussion.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Facebook</category><category>HuggingFace</category><category>ML</category><category>ML tooling</category><category>Machine Learning</category><category>PyTorch</category><category>PyTorch 1.3</category><category>PyTorch community</category><category>Rosebud</category><category>fast.ai</category><category>open source</category><category>open source ecosystems</category></item><item><title>Privacy Preserving AI</title><link>https://pyvideo.org/pytorch-conference-2019/privacy-preserving-ai.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Learn the basics of secure and private AI techniques, including federated learning and secure multi-party computation. In this talk, Andrew Trask of OpenMined highlights the importance of privacy preserving machine learning, and how to use privacy-focused tools like PySyft.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrew Trask</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/privacy-preserving-ai.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>OpenMined</category><category>Privacy</category><category>Private AI</category><category>PySyft</category><category>PyTorch</category><category>PyTorch 1.3</category><category>private AI techniques</category></item><item><title>PyTorch at Dolby Labs</title><link>https://pyvideo.org/pytorch-conference-2019/pytorch-at-dolby-labs.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Hear how Dolby Labs is using PyTorch to develop deep learning for audio, and learn about the challenges that audio AI presents and the breakthroughs and applications they’ve built at Dolby to push the field forward.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Vivek Kumar</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-at-dolby-labs.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Deep learning audio</category><category>Dolby Labs</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>PyTorch</category><category>PyTorch 1.3</category><category>audio ai</category></item><item><title>PyTorch at Microsoft</title><link>https://pyvideo.org/pytorch-conference-2019/pytorch-at-microsoft.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyTorch is becoming the deep learning tool of choice inside Microsoft. Learn how it’s being used to improve existing features and enable new capabilities in products such as Bing, Outlook, Powerpoint Designer, and more.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Saurabh Tiwary</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-at-microsoft.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Deep Learning tools</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>Microsoft</category><category>PyTorch</category><category>PyTorch 1.3</category></item><item><title>PyTorch at Tesla</title><link>https://pyvideo.org/pytorch-conference-2019/pytorch-at-tesla.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Hear from Andrej Karpathy on how Tesla is using PyTorch to develop full self-driving capabilities for its vehicles, including AutoPilot and Smart Summon.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Andrej Karpathy</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-at-tesla.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Autonomous driving cars</category><category>Autopilot</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>PyTorch</category><category>PyTorch 1.3</category><category>PyTorch at Tesla</category><category>Self-driving cars</category><category>Tesla</category><category>smart Summon</category></item><item><title>PyTorch at Uber</title><link>https://pyvideo.org/pytorch-conference-2019/pytorch-at-uber.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In this talk, Sidney Zhang from Uber talks about how Uber ATG uses PyTorch, and specific features including TorchScript, to develop and deploy cutting-edge deep learning models to power self-driving cars.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sidney Zhang</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-at-uber.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Autonomous driving cars</category><category>Deep Learning Models</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>PyTorch</category><category>PyTorch 1.3</category><category>Self-driving cars</category><category>TorchScript</category><category>Uber</category><category>Uber AGT</category></item><item><title>PyTorch Front-End Features: Named Tensors and Type Promotion</title><link>https://pyvideo.org/pytorch-conference-2019/pytorch-front-end-features-named-tensors-and-type-promotion.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Cornell University’s Sasha Rush has argued that, despite its ubiquity in deep learning, the traditional implementation of tensors has significant shortcomings, such as exposing private dimensions, broadcasting based on absolute position, and keeping type information in documentation. He proposed named tensors as an alternative approach. PyTorch now supports the ability to name tensors, allowing for clearer code with less need for inline comments.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Gregory Chanan</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-front-end-features-named-tensors-and-type-promotion.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Cornell University</category><category>Deep Learning</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>PyTorch</category><category>PyTorch 1.3</category><category>named tensor</category><category>type promotion</category></item><item><title>PyTorch in Robotics</title><link>https://pyvideo.org/pytorch-conference-2019/pytorch-in-robotics.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Learn about the research work at Caltech focused on risk aware machine learning for dynamic robotics control, and how PyTorch is being used to build deep learning systems for projects like the neural lander.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yisong Yue</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-in-robotics.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>AI research</category><category>Artificial Intelligence</category><category>Caltech</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>PyTorch</category><category>PyTorch 1.3</category><category>Robotics</category><category>dynamic robotics control</category></item><item><title>PyTorch Mobile</title><link>https://pyvideo.org/pytorch-conference-2019/pytorch-mobile.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Running ML on edge devices is growing in importance as applications continue to demand lower latency. It is also a foundational element for privacy-preserving techniques such as federated learning. To enable more efficient on-device ML, PyTorch 1.3 now supports an end-to-end workflow from Python to deployment on iOS and Android. Learn more about this early, experimental release.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">David Reiss</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-mobile.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>AI Privacy</category><category>Artificial Intelligence</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>PyTorch</category><category>PyTorch 1.3</category><category>PyTorch Android</category><category>PyTorch Mobile</category><category>PyTorch iOS</category></item><item><title>PyTorch on Google Cloud TPUs</title><link>https://pyvideo.org/pytorch-conference-2019/pytorch-on-google-cloud-tpus.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Google Cloud TPU support in PyTorch is now broadly available. Hear how engineers from Facebook, Google, and Salesforce worked together to enable and pilot Google Cloud TPU support in PyTorch, including experimental support for Cloud TPU Pods.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Vishal Mishra</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-on-google-cloud-tpus.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Cloud TPU Pods</category><category>Facebook</category><category>Google</category><category>Google Cloud</category><category>Google Cloud TPU Support in PyTorch</category><category>ML</category><category>Machine Learning</category><category>PyTorch</category><category>PyTorch 1.3</category><category>Salesforce</category></item><item><title>PyTorch ONNX Export Support</title><link>https://pyvideo.org/pytorch-conference-2019/pytorch-onnx-export-support.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The PyTorch ONNX exporter allows trained models to be easily exported to the ONNX model format. Learn about the latest updates including increased model coverage, improved performance, and support for multiple ONNX opset versions for multiple backends.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lara Haidar</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-onnx-export-support.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>AI Frame works</category><category>Artificial Intelligence</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>Microsoft</category><category>ONNX</category><category>ONNX Exporter</category><category>ONNX Runtime</category><category>PyTorch</category><category>PyTorch 1.3</category></item><item><title>PyTorch Summer Hackathon Winners</title><link>https://pyvideo.org/pytorch-conference-2019/pytorch-summer-hackathon-winners.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The in-person and online Global PyTorch Summer Hackathon brought together researchers and developers around the world to build innovative new projects with PyTorch. Developers submitted creative projects ranging from livestock disease detection to AI-powered financial assistants.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Joe Spisak</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/pytorch-summer-hackathon-winners.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Facebook</category><category>Global PyTorch Summer Hackathon</category><category>Global PyTorch Summer Hackathon 2019</category><category>Hackathon</category><category>ML</category><category>Machine Learning</category><category>PyTorch</category></item><item><title>Quantization</title><link>https://pyvideo.org/pytorch-conference-2019/quantization.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;It’s important to make efficient use of both server-side and on-device compute resources when developing ML applications. To support more efficient deployment on servers and edge devices, PyTorch 1.3 now supports 8-bit model quantization using the familiar eager mode Python API.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dmytro Dzhulgakov</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/quantization.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>Machine learning</category><category>Machine learning applications</category><category>PyTorch</category><category>PyTorch 1.3</category><category>PyTorch API</category><category>PyTorch Quantization</category><category>Quantization</category></item><item><title>Research to Production: PyTorch JIT/TorchScript Updates</title><link>https://pyvideo.org/pytorch-conference-2019/research-to-production-pytorch-jittorchscript-updates.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;TorchScript allows developers to create serializable and optimizable models from PyTorch code. Any TorchScript program can be saved from a Python process and loaded in a process where there is no Python dependency. Using TorchScript and the PyTorch JIT compiler, organizations and businesses have been able to use PyTorch not just for state-of-the-art research, but also to more easily take their trained models to production.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Michael Suo</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/research-to-production-pytorch-jittorchscript-updates.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>AI deployment</category><category>Artificial Intelligence</category><category>Facebook</category><category>JIT Compiler</category><category>ML</category><category>ML deployment</category><category>Machine Learning</category><category>Production AI</category><category>Production ML</category><category>PyTorch</category><category>PyTorch 1.3</category><category>TorchScript</category></item><item><title>Sotabench for Reproducible Research</title><link>https://pyvideo.org/pytorch-conference-2019/sotabench-for-reproducible-research.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Papers with Code recently launched Sotabench, a free and open website created to benchmark and rate the performance of state-of-the-art open source models from GitHub. Learn more about this new resource for reproducible research.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Robert Stojnic</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/sotabench-for-reproducible-research.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>AI research</category><category>Artificial Intelligence</category><category>Facebook</category><category>Github</category><category>ML</category><category>Machine Learning</category><category>Papers with code</category><category>PyTorch</category><category>PyTorch 1.3</category><category>open source</category><category>sotabench</category></item><item><title>Speech Extensions to Fairseq</title><link>https://pyvideo.org/pytorch-conference-2019/speech-extensions-to-fairseq.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Language translation and audio processing are critical components in systems and applications such as search, translation, speech, and assistants. Fairseq, a framework for sequence-to-sequence applications such as language translation, has been extended to include support for end-to-end learning for speech and audio recognition tasks. These extensions enable faster exploration and prototyping of new speech research ideas while offering a clear path to production.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dmytro Okhonko</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/speech-extensions-to-fairseq.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>Audio processing</category><category>Facebook</category><category>Fairseq</category><category>Language Translation</category><category>ML</category><category>Machine Learning</category><category>NLP</category><category>Natural Language Processing</category><category>PyTorch</category><category>PyTorch 1.3</category><category>Speech Extensions to Fairseq</category></item><item><title>StanfordNLP</title><link>https://pyvideo.org/pytorch-conference-2019/stanfordnlp.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;StanfordNLP is a new Python natural language processing analysis package built on PyTorch that’s designed to process many human languages. Learn more about the StanfordNLP library in this talk.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yuhao Zhang</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/stanfordnlp.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Ai Research</category><category>Artificial Intelligence</category><category>Facebook</category><category>ML</category><category>Machine Learning</category><category>PyTorch</category><category>PyTorch 1.3</category><category>Python</category><category>Python libraries</category><category>Python natural language</category><category>Stanford</category><category>StanfordNLP</category><category>StanfordNLP library</category></item><item><title>What's new in PyTorch 1.3</title><link>https://pyvideo.org/pytorch-conference-2019/whats-new-in-pytorch-13.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Get an overview of the latest updates in PyTorch 1.3. This release includes new experimental features and capabilities including the ability to name tensors, seamless model deployment to mobile devices, quantization, and more.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Lin Qiao</dc:creator><pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-16:/pytorch-conference-2019/whats-new-in-pytorch-13.html</guid><category>PyTorch Conference 2019</category><category>AI</category><category>Artificial Intelligence</category><category>CAPTUM</category><category>Detectron2</category><category>Facebook</category><category>Fairseq Extensions</category><category>Introduction to PyTorch</category><category>ML</category><category>Machine Learning</category><category>Named Tensors</category><category>PyTorch</category><category>PyTorch 1.3</category><category>PyTorch Mobile</category><category>PyTorch Overview</category><category>Tensorboard</category><category>TorchScript</category></item></channel></rss>