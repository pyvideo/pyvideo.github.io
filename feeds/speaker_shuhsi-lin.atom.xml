<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Shuhsi Lin</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_shuhsi-lin.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-09-05T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Building Data Pipelines on Apache NiFi with Python</title><link href="https://pyvideo.org/pycon-taiwan-2019/building-data-pipelines-on-apache-nifi-with-python.html" rel="alternate"></link><published>2019-09-21T00:00:00+00:00</published><updated>2019-09-21T00:00:00+00:00</updated><author><name>Shuhsi Lin</name></author><id>tag:pyvideo.org,2019-09-21:/pycon-taiwan-2019/building-data-pipelines-on-apache-nifi-with-python.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Day 2, R0 13:15–14:00&lt;/p&gt;
&lt;p&gt;In today's big data world, the data you need to analyze comes from diverse sources in a variety of different formats. Combining all that data and reconciling it is incredibly difficult. Based on your need, adopting a proper and manageable ETL tool …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Day 2, R0 13:15–14:00&lt;/p&gt;
&lt;p&gt;In today's big data world, the data you need to analyze comes from diverse sources in a variety of different formats. Combining all that data and reconciling it is incredibly difficult. Based on your need, adopting a proper and manageable ETL tool can make data integration easier.&lt;/p&gt;
&lt;p&gt;An open source project, Apache NiFi, is a tool to built to automate and manage the flow of data between systems. You can use NiFi to build streaming data pipelines between different data-related systems, including Apache Kafka and Apache Spark, various RDBS, and so much more!&lt;/p&gt;
&lt;p&gt;In this talk, I will start with introducing a concept of ETL and Apache NiFi, what it can solve, and how to use Python to enable NiFi's ability. Then, a sample demo will help you to understand how to build a streaming data pipeline with NiFi.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://speakerdeck.com/sucitw/building-data-pipelines-on-apache-nifi-with-python"&gt;https://speakerdeck.com/sucitw/building-data-pipelines-on-apache-nifi-with-python&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speaker: Shuhsi Lin&lt;/p&gt;
&lt;p&gt;A data engineer and python programmer. Currently working on various data applications in a manufacturing company.&lt;/p&gt;
&lt;p&gt;Research interests: IoT applications, data streaming processing, data analysis and data visualization.&lt;/p&gt;
</content><category term="PyCon Taiwan 2019"></category></entry><entry><title>Track Machine Learning Applications by MLflow Tracking – PyCon Taiwan 2020</title><link href="https://pyvideo.org/pycon-taiwan-2020/track-machine-learning-applications-by-mlflow-tracking-pycon-taiwan-2020.html" rel="alternate"></link><published>2020-09-05T00:00:00+00:00</published><updated>2020-09-05T00:00:00+00:00</updated><author><name>Shuhsi Lin</name></author><id>tag:pyvideo.org,2020-09-05:/pycon-taiwan-2020/track-machine-learning-applications-by-mlflow-tracking-pycon-taiwan-2020.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Day 1, R1 15:55–16:10&lt;/p&gt;
&lt;p&gt;Productization of machine learning (ML) solutions can be challenging. Therefore, the concept of operationalization on machine learning (MLOps) has emerged in the past few years for effective model lifecycle management. One of the core aspects of MLOps is &amp;quot;monitoring&amp;quot;.&lt;/p&gt;
&lt;p&gt;ML models are …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Day 1, R1 15:55–16:10&lt;/p&gt;
&lt;p&gt;Productization of machine learning (ML) solutions can be challenging. Therefore, the concept of operationalization on machine learning (MLOps) has emerged in the past few years for effective model lifecycle management. One of the core aspects of MLOps is &amp;quot;monitoring&amp;quot;.&lt;/p&gt;
&lt;p&gt;ML models are built by experimenting with a wide range of datasets. However, since the real data continues to change, it is necessary to monitor and to manage model usage, consumption, and results of models.&lt;/p&gt;
&lt;p&gt;MLflow is an open-source framework designed to manage the end-to-end ML lifecycle with different components. In the talk, the basic concepts of MLflow will be introduced. Then, MLflow Tracking will be the main focus. You will know how to track experiments for recording and comparing parameters and results by MLflow Tracking.&lt;/p&gt;
&lt;p&gt;Slides: &lt;a class="reference external" href="https://speakerdeck.com/sucitw/track-machine-learning-applications-by-mlflow-tracking"&gt;https://speakerdeck.com/sucitw/track-machine-learning-applications-by-mlflow-tracking&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Speaker: Shuhsi Lin&lt;/p&gt;
&lt;p&gt;A data engineer and python programmer. Currently working on various data applications in a manufacturing company.&lt;/p&gt;
&lt;p&gt;Research interests: IoT applications, data streaming processing, data analysis and data visualization.&lt;/p&gt;
</content><category term="PyCon Taiwan 2020"></category></entry></feed>