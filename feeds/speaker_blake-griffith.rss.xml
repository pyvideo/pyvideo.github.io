<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 20 Feb 2016 00:00:00 +0000</lastBuildDate><item><title>Using conda for development, continuous integration, and package distribution</title><link>https://pyvideo.org/pycaribbean-2016/conda.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Blake Griffith</dc:creator><pubDate>Sat, 20 Feb 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-02-20:pycaribbean-2016/conda.html</guid><category>conda</category></item><item><title>Going parallel and larger-than-memory with graphs</title><link>https://pyvideo.org/pygotham-2015/going-parallel-and-out-of-core-with-task-scheduli.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Dask is an open source, pure python library that enables parallel
larger-than-memory computation in a novel way. We represent programs as
Directed Acyclic Graphs (DAG) of function calls. These graphs are
executed by dask's schedulers with different optimizations (synchronous,
threaded, parallel, distributed-memory). Dask has modules geared towards
data analysis, which provide a friendly interface to building graps. One
module, dask.array, mimics a subset of NumPy operations. With dask.array
we can work with NumPy like arrays that are larger than RAM and
parallelization comes for free by leveraging the underlying DAG.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Blake Griffith</dc:creator><pubDate>Sun, 16 Aug 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-08-16:pygotham-2015/going-parallel-and-out-of-core-with-task-scheduli.html</guid></item></channel></rss>