<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Yusuf Ozuysal</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_yusuf-ozuysal.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2024-05-16T00:00:00+00:00</updated><subtitle></subtitle><entry><title>The open book of Snowflake's AI research: A look inside our generative AI innovations (Sponsor: Streamlit)</title><link href="https://pyvideo.org/pycon-us-2024/the-open-book-of-snowflakes-ai-research-a-look-inside-our-generative-ai-innovations-sponsor-streamlit.html" rel="alternate"></link><published>2024-05-16T00:00:00+00:00</published><updated>2024-05-16T00:00:00+00:00</updated><author><name>Yusuf Ozuysal</name></author><id>tag:pyvideo.org,2024-05-16:/pycon-us-2024/the-open-book-of-snowflakes-ai-research-a-look-inside-our-generative-ai-innovations-sponsor-streamlit.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As AI becomes more crucial in our daily lives, transparency in AI models
is vital. However, many Large Language Model (LLM) systems keep crucial
information to train large language models at scale proprietary,
contradicting the principles of openness that define the Python
ecosystem.&lt;/p&gt;
&lt;p&gt;This session invites you to explore …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As AI becomes more crucial in our daily lives, transparency in AI models
is vital. However, many Large Language Model (LLM) systems keep crucial
information to train large language models at scale proprietary,
contradicting the principles of openness that define the Python
ecosystem.&lt;/p&gt;
&lt;p&gt;This session invites you to explore how Snowflake's AI research team
implements openness in building and sharing generative AI developments,
prioritizing simplicity and ease-of-use while maintaining efficiency at
scale.&lt;/p&gt;
&lt;p&gt;In this talk, you’ll learn:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;How open tools, practices, datasets, and recipes contribute to and
inform our research&lt;/li&gt;
&lt;li&gt;The recipes we used – including what worked and what didn’t – when
training LLMs&lt;/li&gt;
&lt;li&gt;Developer-first example use cases of prompting, retrieval, and
presentation using the datasets, embeddings, and model trainings we
developed&lt;/li&gt;
&lt;/ul&gt;
</content><category term="PyCon US 2024"></category></entry></feed>