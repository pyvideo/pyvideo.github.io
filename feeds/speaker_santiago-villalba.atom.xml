<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_santiago-villalba.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2015-10-05T00:00:00+00:00</updated><entry><title>Reverse Engineering Animal Vision with Virtual Reality</title><link href="https://pyvideo.org/euroscipy-2015/reverse-engineering-animal-vision-with-virtual-reality.html" rel="alternate"></link><published>2015-10-05T00:00:00+00:00</published><updated>2015-10-05T00:00:00+00:00</updated><author><name>Santiago Villalba</name></author><id>tag:pyvideo.org,2015-10-05:euroscipy-2015/reverse-engineering-animal-vision-with-virtual-reality.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;We present python tools for analyzing large collections of stimulus-response time series. The PyData ecosystem proves proficient at all levels of the data processing pipeline: from collection to discriminative analysis and interpretation. We introduce two new libraries: &amp;quot;whatami&amp;quot;, for easy computation provenance tracking, and &amp;quot;pyopy&amp;quot;, for seamless talking to useful octave/matlab libraries&lt;/p&gt;
</summary></entry></feed>