<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Nicolò Giso</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 26 Jul 2021 00:00:00 +0000</lastBuildDate><item><title>From telemetry data to CSVs with Python, Spark and Azure Databricks</title><link>https://pyvideo.org/europython-2021/from-telemetry-data-to-csvs-with-python-spark-and-azure-databricks.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;From telemetry data to CSVs with Python, Spark and Azure Databricks
[EuroPython 2021 - Talk - 2021-07-28 - Parrot [Data Science]]
[Online]&lt;/p&gt;
&lt;p&gt;By Nicolò Giso&lt;/p&gt;
&lt;p&gt;Tenova is an engineering company working alongside client-partners to design and develop innovative technologies and services that improve their business, creating solutions that help metals and mining companies to reduce costs, save energy, limit environmental impact and improve working conditions for their employees.&lt;/p&gt;
&lt;p&gt;In the context of Industry 4.0, Tenova provides each equipment with a field gateway, named Tenova Edge, to collect telemetry data, perform edge analytics with AI models and send data to the Tenova Platform (hosted on Microsoft Azure) for further elaborations.&lt;/p&gt;
&lt;p&gt;To develop analytics solutions, data scientists and process engineers need the data in a manageable format.&lt;/p&gt;
&lt;p&gt;Furthermore, continuous retraining of AI models is necessary to guarantee high performances and reliable results.&lt;/p&gt;
&lt;p&gt;For all of these reasons, we needed to implement an ETL solution to transform the raw data in formats ready for analysis and retraining. In particular, the key requirement was to convert the JSON Lines files coming from the field in CSV files ready to be used.&lt;/p&gt;
&lt;p&gt;The CSV files have to satisfy the following conditions:
- each file contains the data for a device
- only one file for device per day
- each file has a midnight row containing for each cell the value recorded at midnight or the last value of the previous day (SPOILER: here it’s where the fun happens!)&lt;/p&gt;
&lt;p&gt;For this purpose, we have implemented a series of Databricks Notebooks, run daily by Azure DataFactory, that leveraging Pyspark and Pandas manipulates the raw JsonLines files in nicely formatted CSVs.&lt;/p&gt;
&lt;p&gt;License: This video is licensed under the CC BY-NC-SA 4.0 license: &lt;a class="reference external" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;https://creativecommons.org/licenses/by-nc-sa/4.0/&lt;/a&gt;
Please see our speaker release agreement for details: &lt;a class="reference external" href="https://ep2021.europython.eu/events/speaker-release-agreement/"&gt;https://ep2021.europython.eu/events/speaker-release-agreement/&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Nicolò Giso</dc:creator><pubDate>Mon, 26 Jul 2021 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2021-07-26:/europython-2021/from-telemetry-data-to-csvs-with-python-spark-and-azure-databricks.html</guid><category>EuroPython 2021</category></item></channel></rss>