<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_friederike-schuur.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2017-11-27T00:00:00+00:00</updated><entry><title>Why your relationship is likely to last, or not: Local Interpretable Model-Agnostic Explanations</title><link href="https://pyvideo.org/pydata-new-york-city-2017/why-your-relationship-is-likely-to-last-or-not-local-interpretable-model-agnostic-explanations.html" rel="alternate"></link><published>2017-11-27T00:00:00+00:00</published><updated>2017-11-27T00:00:00+00:00</updated><author><name>Friederike Schuur</name></author><id>tag:pyvideo.org,2017-11-27:pydata-new-york-city-2017/why-your-relationship-is-likely-to-last-or-not-local-interpretable-model-agnostic-explanations.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Complex models (vs. simpler models) capture complex patterns in data and perform at higher accuracy but are less interpretable. Model-agnostic interpretability promises to regain interpretability without sacrificing accuracy. I introduce LIME (Local Interpretable Model-Agnostic Explanations), conceptually and applied to a classification problem: whether couples are likely to stay together, or not.&lt;/p&gt;
</summary></entry></feed>