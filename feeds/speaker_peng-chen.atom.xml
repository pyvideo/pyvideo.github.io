<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Peng Chen</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_peng-chen.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2023-10-16T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Accelerating Explorations in Vision and Multimodal AI Using Pytorch Libraries</title><link href="https://pyvideo.org/pytorch-conference-2023/accelerating-explorations-in-vision-and-multimodal-ai-using-pytorch-libraries.html" rel="alternate"></link><published>2023-10-16T00:00:00+00:00</published><updated>2023-10-16T00:00:00+00:00</updated><author><name>Nicolas Hug</name></author><id>tag:pyvideo.org,2023-10-16:/pytorch-conference-2023/accelerating-explorations-in-vision-and-multimodal-ai-using-pytorch-libraries.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyTorch Libraries provide building blocks (data processing transforms, modeling components, loss functions, etc.) on top of PyTorch as well as examples and tutorials on how to use these building blocks for training SoTA Models. In this talk, we’ll provide insights into ongoing work to accelerate exploration in multimodal …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyTorch Libraries provide building blocks (data processing transforms, modeling components, loss functions, etc.) on top of PyTorch as well as examples and tutorials on how to use these building blocks for training SoTA Models. In this talk, we’ll provide insights into ongoing work to accelerate exploration in multimodal understanding and generative AI using TorchMultimodal. We'll also present TorchVision's new transforms API, with added support for image detection, segmentation, and video tasks.&lt;/p&gt;
</content><category term="PyTorch Conference 2023"></category></entry></feed>