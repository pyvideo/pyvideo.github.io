<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Sat, 13 Jul 2019 00:00:00 +0000</lastBuildDate><item><title>Processing Extremely Large Images: Theory and Practice</title><link>https://pyvideo.org/scipy-2019/processing-extremely-large-images-theory-and-practice.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Images encountered by today's scientist, with the advent of new hardware and methods in areas such as microscopy, synchrotron x-ray imaging, and satellite imaging, are a challenge to process within the common memory constraints and compute capabilities of a single CPU core. Through a resampling example, we provide an overview of the theory and modern practice of processing large images. By the end of this talk, attendees will understand how to develop and apply streaming methods. Furthermore, they will understand how to apply node-based and distributed parallelism to accelerate computation with SciPy tools such as NumPy, Dask, ITK, and the itk-jupyter-widgets.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Deepak Chittajallu</dc:creator><pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-13:scipy-2019/processing-extremely-large-images-theory-and-practice.html</guid></item><item><title>ITK: The Insight Segmentation and Registration Toolkit</title><link>https://pyvideo.org/scipy-2018/itk-the-insight-segmentation-and-registration-toolkit.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The National Library of Medicine Insight Toolkit (ITK) is an
open-source, cross-platform system for processing 2D, 3D, or N-D images.
It provides imaging researchers with an extensive suite of leading-edge
algorithms for registering, segmenting, analyzing, and quantifying
images and related data structures. It is used in thousands of research
and commercial applications, from major labs to individual innovators.
We provide updates on exciting new developments in ITK's Python
packaging, Python interface, and NumPy bridge.Presenter(s): Speaker:
Matthew McCormick, Kitware, Inc. Speaker: Francois Budin, Kitware, Inc.
Speaker: Dženan Zukić, Kitware, Inc. Speaker: Deepak Chittajallu,
Kitware, Inc. Speaker: Beatriz Paniagua, Kitware, Inc. Speaker:
Jean-Christophe Fillion-Robin, Kitware, Inc.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Matthew McCormick</dc:creator><pubDate>Wed, 11 Jul 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-07-11:scipy-2018/itk-the-insight-segmentation-and-registration-toolkit.html</guid></item><item><title>The Sheer Joy of Packaging</title><link>https://pyvideo.org/scipy-2018/the-sheer-joy-of-packaging.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Building packages in Python used to be hard, especially the ones
including compiled extensions. Fortunately, it is getting easier thanks
to efforts in the scientific Python community. However, there are still
a lot of challenges and complexities facing the package builder.There
are at least two major packaging systems (pip/wheel and conda), and lots
of different ways to do work with these systems. This tutorial will
cover packaging from start to finish for both PyPI and conda, including
setup.py, flit, wheels, twine, conda-build, scikit-build, anaconda
cloud, and conda-forge. Particular attention will be paid to critical
details, such as binary compatibility and platform
differences.Presenter(s): Speaker: Michael Sarahan, Anaconda, Inc.
Speaker: Matthew McCormick, Kitware, Inc. Speaker: Jean-Christophe
Fillion-Robin, Kitware, Inc. Speaker: Filipe Fernandes, SECOORA Speaker:
Chris Barker, NOAA Speaker: Matt Craig, Minnesota State University
Moorhead Speaker: Jonathan Helmus, Anaconda, Inc. Speaker: Ray Donnelly,
Anaconda, Inc.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Michael Sarahan</dc:creator><pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-07-10:scipy-2018/the-sheer-joy-of-packaging.html</guid><category>tutorial</category></item><item><title>Docker for Improved Reproducibility of Scientific Python Analyses</title><link>https://pyvideo.org/scipy-2015/docker-for-improved-reproducibility-of-scientific-python-analyses.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Matthew McCormick</dc:creator><pubDate>Fri, 10 Jul 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-07-10:scipy-2015/docker-for-improved-reproducibility-of-scientific-python-analyses.html</guid></item><item><title>Wrapping C and C++ Libraries with CastXML</title><link>https://pyvideo.org/scipy-2015/wrapping-c-and-c-libraries-with-castxml.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brad King</dc:creator><pubDate>Fri, 10 Jul 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-07-10:scipy-2015/wrapping-c-and-c-libraries-with-castxml.html</guid></item><item><title>SimpletITK: Advanced Image Analysis for Python</title><link>https://pyvideo.org/scipy-2014/simpletitk-advanced-image-analysis-for-python.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;SimpleITK brings advanced image analysis capabilities to Python. In
particular, it provides support for 2D/3D and multi-components images
with physical. SimpleITK exposes a large collection of image processing
filters from ITK, including image segmentation and registration.
SimpleITK is freely available as an open source package under the Apache
2.0 License.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;SimpleITK provides scientific image analysis, processing, segmentation
and registration for biomedical, microscopy and other scientific fields
by supporting multi-dimensional images with physical locations [1]. It's
is a layer build upon the Insight Segmentation and Registration Toolkit
(ITK) [2].&lt;/p&gt;
&lt;p&gt;While there are many Python packages to process 2D photographic images,
scientific image analysis adds additional requirements. Images
encountered in these domains often have anisotropic pixel spacing, or
spatial orientations, and calculations are best performed in physical
space as opposed to pixel space.&lt;/p&gt;
&lt;p&gt;SimpleITK brings to Python a plethora of capabilities for performing
image analysis. Although SimpleITK was developed by the biomedical
imaging community, it is also used for generic image processing. It
differentiates from OpenCV in offering 3D images and multi-component
images, and it differentiates from scipy by offering the abstraction of
image classes and their associated data structures. This applies to
images modalities such as CT scans, MRI, fMRI, ultrasound, and in
microscopy modalities such as confocal, SEM, TEM, and traditional bright
and dark field.&lt;/p&gt;
&lt;p&gt;Among the key functionalities supported by SimpleITK are over 260
advanced image filtering and segmentation algorithms as well as access
to scientific image file formats, including specialized formats such as
DICOM, Nifti, NRRD, VTK and other formats that preserve 3D metadata.
Example algorithms include Level Sets Segmentation including
multi-phase, Label Maps, Region Growing, Statistical Classification,
Advanced Thresholding, Geometrical Transformations, Deconvolution,
Anti-Aliasing, Edge Detection, Mathematical Morphology on both labels
and grayscale images and Fourier Analysis [4,5].&lt;/p&gt;
&lt;p&gt;SimpleITK is an open source project with an active community, that
builds upon the large amount of image analysis experience of the ITK
community [3] working in biomedical images analysis since 1999, and that
continues to grow year by year, aggregating state of the art algorithms
.&lt;/p&gt;
&lt;p&gt;SimpleITK development is sponsored by the US National Library of
Medicine.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bradley Lowekamp</dc:creator><pubDate>Mon, 14 Jul 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2014-07-14:scipy-2014/simpletitk-advanced-image-analysis-for-python.html</guid><category>image analysis</category></item><item><title>Reproducible Science: Walking the Walk Part 1</title><link>https://pyvideo.org/scipy-2014/reproducible-science-walking-the-walk-part-1.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;This tutorial will train reproducible research warriors on the practices
and tools that make experimental verification possible with an
end-to-end data analysis workflow. &amp;nbsp;The tutorial will expose attendees
to open science methods during data gathering, storage, analysis up to
publication into a reproducible article. &amp;nbsp;Attendees are expected to have
basic familiarity with scientific Python and Git.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The tutorial will cover four hours with the following topics&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Introduction (10min)&lt;/li&gt;
&lt;li&gt;History of scientific societies and publications&lt;ul&gt;
&lt;li&gt;Leeuwenhoek was the Man !&lt;/li&gt;
&lt;li&gt;The Invisible College&lt;/li&gt;
&lt;li&gt;Nullius in Verba&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Replication of the early microscope experiments by Leeuwenhoek[a][b]&lt;/li&gt;
&lt;li&gt;Image Acquisition (15 min)&lt;ul&gt;
&lt;li&gt;Hands on: Cell camera phone microscope&lt;ul&gt;
&lt;li&gt;With drop of water&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hands on: Each pair acquires images&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data Sharing (45min)&lt;ul&gt;
&lt;li&gt;Image gathering, storage, and sharing (15min)&lt;ul&gt;
&lt;li&gt;GitHub (www.github.com)&lt;/li&gt;
&lt;li&gt;Figshare (www.figshare.com)&lt;/li&gt;
&lt;li&gt;Midas (www.midasplatform.com)&lt;/li&gt;
&lt;li&gt;Hands on: Upload the images&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Metadata Identifiers (15 min)&lt;ul&gt;
&lt;li&gt;Citable&lt;/li&gt;
&lt;li&gt;Machine Readable&lt;/li&gt;
&lt;li&gt;Hands on: Create data citation and machine readable metadata&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hands on: Download data via RESTful API (15min)&lt;ul&gt;
&lt;li&gt;Provenance and&lt;/li&gt;
&lt;li&gt;Python scripts&lt;/li&gt;
&lt;li&gt;Hands on: Download the data via HTTP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Break (10min)&lt;/li&gt;
&lt;li&gt;Local processing (60min)&lt;ul&gt;
&lt;li&gt;Replication Enablement (20min)&lt;ul&gt;
&lt;li&gt;Package versioning&lt;/li&gt;
&lt;li&gt;Virtual Machines&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;Cloud services&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Create a virtualenv&lt;/li&gt;
&lt;li&gt;Run our tutorial package verification script&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Revision Control with Git (20min)&lt;ul&gt;
&lt;li&gt;Keeping track of changes&lt;/li&gt;
&lt;li&gt;Unique hashes&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Forking a repository in GitHub&lt;/li&gt;
&lt;li&gt;Cloning a repository&lt;/li&gt;
&lt;li&gt;Creating a branch&lt;/li&gt;
&lt;li&gt;Making a commit&lt;/li&gt;
&lt;li&gt;Pushing a branch&lt;/li&gt;
&lt;li&gt;Diffing&lt;/li&gt;
&lt;li&gt;Merging&lt;/li&gt;
&lt;li&gt;Pushing again&lt;/li&gt;
&lt;li&gt;Create pull request&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Python scripts (20min)&lt;ul&gt;
&lt;li&gt;Data analysis, particle counting.&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Run scripts on new data&lt;/li&gt;
&lt;li&gt;Generate histogram for the data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Testing (30min)&lt;ul&gt;
&lt;li&gt;Unit testing with known data&lt;/li&gt;
&lt;li&gt;Regression testing with known data&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Run tests&lt;/li&gt;
&lt;li&gt;Add coverage for another method to the unit tests&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Break (10min)&lt;/li&gt;
&lt;li&gt;Publication Tools (30min)&lt;ul&gt;
&lt;li&gt;Article generation&lt;/li&gt;
&lt;li&gt;RST to HTML&lt;/li&gt;
&lt;li&gt;GitHub replication and sharing&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Run dexy to generate the document&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reproducibility Verification (30min)&lt;ul&gt;
&lt;li&gt;Reproducing Works&lt;/li&gt;
&lt;li&gt;Publication of Positive and Negative results&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Create Open Science Framework (OSF) project&lt;/li&gt;
&lt;li&gt;Connect Figshare and Github to OSF project&lt;/li&gt;
&lt;li&gt;Fork or link another group’s project in the OSF to run dexy on
their work&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Infrastructure:&lt;/p&gt;
&lt;p&gt;Attendees will use software installed in their laptops to gather and
process data, then publish and share a reproducible report.&lt;/p&gt;
&lt;p&gt;They will access repositories in GitHub, upload data to a repository and
publish materials necessary to replicate their data analysis.&lt;/p&gt;
&lt;p&gt;We expect that wireless network will be have moderate bandwidth to allow
all attendees to move data, source code and publications between their
laptops and hosting servers.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aashish Chaudhary</dc:creator><pubDate>Wed, 09 Jul 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2014-07-09:scipy-2014/reproducible-science-walking-the-walk-part-1.html</guid><category>open science</category><category>reproducible research</category><category>tutorial</category></item><item><title>Reproducible Science: Walking the Walk Part 2</title><link>https://pyvideo.org/scipy-2014/reproducible-science-walking-the-walk-part-2.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;This tutorial will train reproducible research warriors on the practices
and tools that make experimental verification possible with an
end-to-end data analysis workflow. &amp;nbsp;The tutorial will expose attendees
to open science methods during data gathering, storage, analysis up to
publication into a reproducible article. &amp;nbsp;Attendees are expected to have
basic familiarity with scientific Python and Git.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;The tutorial will cover four hours with the following topics&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Introduction (10min)&lt;/li&gt;
&lt;li&gt;History of scientific societies and publications&lt;ul&gt;
&lt;li&gt;Leeuwenhoek was the Man !&lt;/li&gt;
&lt;li&gt;The Invisible College&lt;/li&gt;
&lt;li&gt;Nullius in Verba&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Replication of the early microscope experiments by Leeuwenhoek[a][b]&lt;/li&gt;
&lt;li&gt;Image Acquisition (15 min)&lt;ul&gt;
&lt;li&gt;Hands on: Cell camera phone microscope&lt;ul&gt;
&lt;li&gt;With drop of water&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hands on: Each pair acquires images&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data Sharing (45min)&lt;ul&gt;
&lt;li&gt;Image gathering, storage, and sharing (15min)&lt;ul&gt;
&lt;li&gt;GitHub (www.github.com)&lt;/li&gt;
&lt;li&gt;Figshare (www.figshare.com)&lt;/li&gt;
&lt;li&gt;Midas (www.midasplatform.com)&lt;/li&gt;
&lt;li&gt;Hands on: Upload the images&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Metadata Identifiers (15 min)&lt;ul&gt;
&lt;li&gt;Citable&lt;/li&gt;
&lt;li&gt;Machine Readable&lt;/li&gt;
&lt;li&gt;Hands on: Create data citation and machine readable metadata&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hands on: Download data via RESTful API (15min)&lt;ul&gt;
&lt;li&gt;Provenance and&lt;/li&gt;
&lt;li&gt;Python scripts&lt;/li&gt;
&lt;li&gt;Hands on: Download the data via HTTP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Break (10min)&lt;/li&gt;
&lt;li&gt;Local processing (60min)&lt;ul&gt;
&lt;li&gt;Replication Enablement (20min)&lt;ul&gt;
&lt;li&gt;Package versioning&lt;/li&gt;
&lt;li&gt;Virtual Machines&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;Cloud services&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Create a virtualenv&lt;/li&gt;
&lt;li&gt;Run our tutorial package verification script&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Revision Control with Git (20min)&lt;ul&gt;
&lt;li&gt;Keeping track of changes&lt;/li&gt;
&lt;li&gt;Unique hashes&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Forking a repository in GitHub&lt;/li&gt;
&lt;li&gt;Cloning a repository&lt;/li&gt;
&lt;li&gt;Creating a branch&lt;/li&gt;
&lt;li&gt;Making a commit&lt;/li&gt;
&lt;li&gt;Pushing a branch&lt;/li&gt;
&lt;li&gt;Diffing&lt;/li&gt;
&lt;li&gt;Merging&lt;/li&gt;
&lt;li&gt;Pushing again&lt;/li&gt;
&lt;li&gt;Create pull request&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Python scripts (20min)&lt;ul&gt;
&lt;li&gt;Data analysis, particle counting.&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Run scripts on new data&lt;/li&gt;
&lt;li&gt;Generate histogram for the data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Testing (30min)&lt;ul&gt;
&lt;li&gt;Unit testing with known data&lt;/li&gt;
&lt;li&gt;Regression testing with known data&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Run tests&lt;/li&gt;
&lt;li&gt;Add coverage for another method to the unit tests&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Break (10min)&lt;/li&gt;
&lt;li&gt;Publication Tools (30min)&lt;ul&gt;
&lt;li&gt;Article generation&lt;/li&gt;
&lt;li&gt;RST to HTML&lt;/li&gt;
&lt;li&gt;GitHub replication and sharing&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Run dexy to generate the document&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reproducibility Verification (30min)&lt;ul&gt;
&lt;li&gt;Reproducing Works&lt;/li&gt;
&lt;li&gt;Publication of Positive and Negative results&lt;/li&gt;
&lt;li&gt;Hands on:&lt;ul&gt;
&lt;li&gt;Create Open Science Framework (OSF) project&lt;/li&gt;
&lt;li&gt;Connect Figshare and Github to OSF project&lt;/li&gt;
&lt;li&gt;Fork or link another group’s project in the OSF to run dexy on
their work&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Infrastructure:&lt;/p&gt;
&lt;p&gt;Attendees will use software installed in their laptops to gather and
process data, then publish and share a reproducible report.&lt;/p&gt;
&lt;p&gt;They will access repositories in GitHub, upload data to a repository and
publish materials necessary to replicate their data analysis.&lt;/p&gt;
&lt;p&gt;We expect that wireless network will be have moderate bandwidth to allow
all attendees to move data, source code and publications between their
laptops and hosting servers.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aashish Chaudhary</dc:creator><pubDate>Wed, 09 Jul 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2014-07-09:scipy-2014/reproducible-science-walking-the-walk-part-2.html</guid><category>open science</category><category>reproducible research</category><category>tutorial</category></item></channel></rss>