<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_obiamaka-agbaneje.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2018-07-26T00:00:00+00:00</updated><entry><title>Building a Naive Bayes Text Classifier with scikit-learn</title><link href="https://pyvideo.org/europython-2018/building-a-naive-bayes-text-classifier-with-scikit-learn.html" rel="alternate"></link><published>2018-07-26T00:00:00+00:00</published><updated>2018-07-26T00:00:00+00:00</updated><author><name>Obiamaka Agbaneje</name></author><id>tag:pyvideo.org,2018-07-26:europython-2018/building-a-naive-bayes-text-classifier-with-scikit-learn.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Machine learning algorithms used in the classification of text are
Support Vector Machines, k Nearest Neighbors but the most popular
algorithm to implement is Naive Bayes because of its simplicity based on
Bayes Theorem.&lt;/p&gt;
&lt;p&gt;The Naive Bayes classifier is able to memorise the relationships between
the training attributes and the outcome and predicts by multiplying the
conditional probabilities of the attributes with the assumption that
they are independent of the outcome. It is popularly used in classifying
data sets that have a large number of features that are sparse or nearly
independent such as text documents.&lt;/p&gt;
&lt;p&gt;In this talk, I will describe how to build a model using the Naive Bayes
algorithm with the scikit-learn library using the spam/ham youtube
comment dataset from the UCI repository. Preprocessing techniques such
as Text normalisation and Feature extraction will be also be discussed.&lt;/p&gt;
</summary></entry></feed>