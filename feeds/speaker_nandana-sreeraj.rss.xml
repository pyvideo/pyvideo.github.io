<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org - Nandana Sreeraj</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Mon, 17 Apr 2023 00:00:00 +0000</lastBuildDate><item><title>Thou Shall Judge But With Fairness: Methods to Ensure an Unbiased Model</title><link>https://pyvideo.org/pycon-de-2023/thou-shall-judge-but-with-fairness-methods-to-ensure-an-unbiased-model.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Is your model prejudicial? Is your model deviating from the predictions it ought to have made? Has your model misunderstood the concept? In the world of artificial intelligence and machine learning, the word &amp;quot;fairness&amp;quot; is particularly common. It is described as having the quality of being impartial or fair. Fairness in ML is essential for contemporary businesses. It helps build consumer confidence and demonstrates to customers that their issues are important. Additionally, it aids in ensuring adherence to guidelines established by authorities. So guaranteeing that the idea of responsible AI is upheld. In this talk, let's explore how certain sensitive features are influencing the model and introducing bias into it. We'll also look at how we can make it better.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Nandana Sreeraj</dc:creator><pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2023-04-17:/pycon-de-2023/thou-shall-judge-but-with-fairness-methods-to-ensure-an-unbiased-model.html</guid><category>PyCon DE 2023</category></item></channel></rss>