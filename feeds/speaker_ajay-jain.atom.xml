<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org - Ajay Jain</title><link href="https://pyvideo.org/" rel="alternate"></link><link href="https://pyvideo.org/feeds/speaker_ajay-jain.atom.xml" rel="self"></link><id>https://pyvideo.org/</id><updated>2020-08-03T00:00:00+00:00</updated><subtitle></subtitle><entry><title>Locally Masked Convolution for Autoregressive Models</title><link href="https://pyvideo.org/uai-2020/locally-masked-convolution-for-autoregressive-models.html" rel="alternate"></link><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><author><name>Ajay Jain</name></author><id>tag:pyvideo.org,2020-08-03:/uai-2020/locally-masked-convolution-for-autoregressive-models.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Locally Masked Convolution for Autoregressive Models&lt;/p&gt;
&lt;p&gt;Ajay Jain (UC Berkeley)*; Pieter Abbeel (UC Berkeley); Deepak Pathak (CMU, FAIR)&lt;/p&gt;
&lt;p&gt;High-dimensional generative models have many applications including image compression, multimedia generation, anomaly detection and data completion. State-of-the-art estimators for natural images are autoregressive, decomposing the joint distribution over pixels into a â€¦&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Locally Masked Convolution for Autoregressive Models&lt;/p&gt;
&lt;p&gt;Ajay Jain (UC Berkeley)*; Pieter Abbeel (UC Berkeley); Deepak Pathak (CMU, FAIR)&lt;/p&gt;
&lt;p&gt;High-dimensional generative models have many applications including image compression, multimedia generation, anomaly detection and data completion. State-of-the-art estimators for natural images are autoregressive, decomposing the joint distribution over pixels into a product of conditionals parameterized by a deep neural network, e.g. a convolutional neural network such as the PixelCNN. However, PixelCNNs only model a single decomposition of the joint, and only a single generation order is efficient. For tasks such as image completion, these models are unable to use much of the observed context. To generate data in arbitrary orders, we introduce LMConv: a simple modification to the standard 2D convolution that allows arbitrary masks to be applied to the weights at each location in the image. Using LMConv, we learn an ensemble of distribution estimators that share parameters but differ in generation order, achieving improved performance on whole-image density estimation (2.89 bpd on unconditional CIFAR10), as well as globally coherent image completions. Code is available at &lt;a class="reference external" href="https://ajayjain.github.io/lmconv"&gt;https://ajayjain.github.io/lmconv&lt;/a&gt;.&amp;quot;&lt;/p&gt;
</content><category term="UAI 2020"></category></entry></feed>