<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Fri, 30 Aug 2019 00:00:00 +0000</lastBuildDate><item><title>Historias de Ciencia, Comunidad, Fracasos y Éxitos</title><link>https://pyvideo.org/pycon-latam-2019/historias-de-ciencia-comunidad-fracasos-y-exitos.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tania Allard</dc:creator><pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-08-30:pycon-latam-2019/historias-de-ciencia-comunidad-fracasos-y-exitos.html</guid><category>keynote</category></item><item><title>Inclusive Leadership: Engaging Contributors in the Long Term</title><link>https://pyvideo.org/scipy-2019/inclusive-leadership-engaging-contributors-in-the-long-term.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;This talk draws on my experience as an open source leader and community builder to provide actionable recommendations to engage with contributors in the long term. This talk will focus on the concept of inclusive leadership and how this can help us with open source sustainability.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tania Allard</dc:creator><pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-07-11:scipy-2019/inclusive-leadership-engaging-contributors-in-the-long-term.html</guid></item><item><title>Building data pipelines in Python: Airflow vs scripts soup</title><link>https://pyvideo.org/pycon-us-2019/building-data-pipelines-in-python-airflow-vs-scripts-soup.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;In data science (in its all its variants) a significant part of an
individual’s time is spent preparing data into a digestible format. In
general, a data science pipeline starts with the acquisition of raw data
which is then manipulated through ETL processes and leads to a series of
analytics. Good data pipelines can be used to automate and schedule
these steps, help with monitoring tasks, and even to dynamically train
models. On top of that, they make the analyses easier to reproduce and
productise.&lt;/p&gt;
&lt;p&gt;In this workshop, you will learn how to migrate from ‘scripts soups’ (a
set of scripts that should be run in a particular order) to robust,
reproducible and easy-to-schedule data pipelines in Airflow. First, we
will learn how to write simple recurrent ETL pipelines. We will then
integrate logging and monitoring capabilities. And we will end using
Airflow along with Jupyter Notebooks and paper mill to produce
reproducible analytics reports.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tania Allard</dc:creator><pubDate>Wed, 01 May 2019 09:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-05-01:pycon-us-2019/building-data-pipelines-in-python-airflow-vs-scripts-soup.html</guid><category>tutorial</category></item><item><title>Jupyter Notebooks: Friends or Foes?</title><link>https://pyvideo.org/pycon-belarus-2019/jupyter-notebooks-friends-or-foes.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tania Allard</dc:creator><pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-02-16:pycon-belarus-2019/jupyter-notebooks-friends-or-foes.html</guid></item></channel></rss>