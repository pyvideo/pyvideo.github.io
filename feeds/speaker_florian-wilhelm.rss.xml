<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>PyVideo.org</title><link>https://pyvideo.org/</link><description></description><lastBuildDate>Thu, 10 Oct 2019 00:00:00 +0000</lastBuildDate><item><title>Are you sure about that?! Uncertainty Quantification in AI</title><link>https://pyvideo.org/pydata-berlin-2019/are-you-sure-about-that-uncertainty-quantification-in-ai.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Speaker: Florian Wilhelm&lt;/p&gt;
&lt;p&gt;Track:PyData
There is a strong need in many AI applications to state the certainty about their predictions. This talk elaborates on different ways to perform uncertainty quantification in deep learning and classical methods.&lt;/p&gt;
&lt;p&gt;Recorded at the PyConDE &amp;amp; PyData Berlin 2019 conference.
&lt;a class="reference external" href="https://pycon.de"&gt;https://pycon.de&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More details at the conference page: &lt;a class="reference external" href="https://de.pycon.org/program/WQMPSW"&gt;https://de.pycon.org/program/WQMPSW&lt;/a&gt;
Twitter:  &lt;a class="reference external" href="https://twitter.com/pydataberlin"&gt;https://twitter.com/pydataberlin&lt;/a&gt;
Twitter:  &lt;a class="reference external" href="https://twitter.com/pyconde"&gt;https://twitter.com/pyconde&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Florian Wilhelm</dc:creator><pubDate>Thu, 10 Oct 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2019-10-10:pydata-berlin-2019/are-you-sure-about-that-uncertainty-quantification-in-ai.html</guid></item><item><title>Bridging the Gap: from Data Science to Production</title><link>https://pyvideo.org/europython-2018/bridging-the-gap-from-data-science-to-production.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;A recent but quite common observation in industry is that although there
is an overall high adoption of data science, many companies struggle to
get it into production. Huge teams of well-payed data scientists often
present one fancy model after the other to their managers but their
proof of concepts never manifest into something business relevant. The
frustration grows on both sides, managers and data scientists.&lt;/p&gt;
&lt;p&gt;In my talk I elaborate on the many reasons why data science to
production is such a hard nut to crack. I start with a taxonomy of data
use cases in order to easier assess technical requirements. Based
thereon, my focus lies on overcoming the two-language-problem which is
Python/R loved by data scientists vs. the enterprise-established
Java/Scala. From my project experiences I present three different
solutions, namely 1) migrating to a single language, 2) reimplementation
and 3) usage of a framework. The advantages and disadvantages of each
approach is presented and general advices based on the introduced
taxonomy is given.&lt;/p&gt;
&lt;p&gt;Additionally, my talk also addresses organisational as well as problems
in quality assurance and deployment. Best practices and further
references are presented on a high-level in order to cover all facets of
data science to production.&lt;/p&gt;
&lt;p&gt;With my talk I hope to convey the message that breakdowns on the road
from data science to production are rather the rule than the exception,
so you are not alone. At the end of my talk, you will have a better
understanding of why your team and you are struggling and what to do
about it.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Florian Wilhelm</dc:creator><pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2018-07-25:europython-2018/bridging-the-gap-from-data-science-to-production.html</guid></item><item><title>“Which car fits my life?” - mobile.de’s approach to recommendations</title><link>https://pyvideo.org/pydata-berlin-2017/which-car-fits-my-life-mobiledes-approach-to-recommendations.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;As Germany’s largest online vehicle marketplace mobile.de uses recommendations at scale to help users find the perfect car. We elaborate on collaborative &amp;amp; content-based filtering as well as a hybrid approach addressing the problem of a fast-changing inventory. We then dive into the technical implementation of the recommendation engine, outlining the various challenges faced and experiences made.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At mobile.de, Germany’s biggest car marketplace, a dedicated team of data engineers and scientists, supported by the IT project house inovex is responsible for creating intelligent data products. Driven by our company slogan “Find the car that fits your life”, we focus on personalised recommendations to address several user needs. Thereby we improve customer experience during browsing as well as finding the perfect offering. In an introduction to recommendation systems, we briefly mention the traditional approaches for recommendation engines, thereby motivating the need for sophisticated approaches. In particular, we explain the different concepts including collaborative and content-based filtering as well as hybrid approaches and general matrix factorisation methods. This is followed by a deep dive into the implementation and architecture at mobile.de that comprises ElasticSearch, Cassandra and Mahout. We explain how Python and Java is used simultaneously to create and serve recommendations.&lt;/p&gt;
&lt;p&gt;By presenting our car-model recommender that suggests similar car models of different brands as a concrete use-case, we reiterate on key-aspects during modelling and implementation. In particular, we present a matrix factorisation library that we used and share our experiences with it. We conclude by a brief demonstration of our results and discuss the improvements we achieved in terms of key performance indicators. Furthermore, we use our use case to exemplify the usage of deep learning for recommendations, comparing it with other traditional approaches and hence providing a brief account of the future of recommendation engines.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Florian Wilhelm</dc:creator><pubDate>Fri, 30 Jun 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-06-30:pydata-berlin-2017/which-car-fits-my-life-mobiledes-approach-to-recommendations.html</guid></item><item><title>Declarative Thinking and Programming</title><link>https://pyvideo.org/europython-2017/declarative-thinking-and-programming.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Declarative Programming is a programming paradigm that focuses on
describing what should be computed in a problem domain without
describing how it should be done.  The talk starts by explaining
differences between a declarative and imperative approach with the
help of examples from everyday life. Having established a clear
notion of declarative programming as well as pointed out some
advantages, we transfer these concepts to programming in general. For
example, the usage of control flow statements like loops
over-determine the order of computation which impedes scalable
execution as well as it often violates the single level of
abstraction principle.&lt;/p&gt;
&lt;p&gt;Following the theoretical part of the talk, some practical examples
are given how declarative programming can be applied easily within
Python. This comprises the advantages and disadvantages of using a
configuration file, e.g. config.yaml, versus a Python configuration
module, e.g. setup.py. Furthermore, the benefits of avoiding
statements of control flow with the help of list and dictionary
comprehensions as well as sets are demonstrated.&lt;/p&gt;
&lt;p&gt;The talk is concluded by a short, high-level excursion to a logistic
programming language, namely PyDatalog in order to build the bridge
between logistic and declarative programming. This is accomplished by
showing how a mathematical crossword can be easily solved with the
help of declarative and logistic programming.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Florian Wilhelm</dc:creator><pubDate>Thu, 13 Jul 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2017-07-13:europython-2017/declarative-thinking-and-programming.html</guid></item><item><title>the idea behind Automatic Relevance Determination and Bayesian Interpolation</title><link>https://pyvideo.org/pydata-amsterdam-2016/the-idea-behind-automatic-relevance-determination-and-bayesian-interpolation.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;PyData Amsterdam 2016&lt;/p&gt;
&lt;p&gt;Even in the era of Big Data there are many real-world problems where the number of input features has about the some order of magnitude than the number of samples. Often many of those input features are irrelevant and thus inferring the relevant ones is an important problem in order to prevent over-fitting. Automatic Relevance Determination solves this problem by applying Bayesian techniques.&lt;/p&gt;
&lt;p&gt;In order to motivate Automatic Relevance Determination (ARD) an intuition for the problem of choosing a complex model that fits the data well vs a simple model that generalizes well is established. Thereby the idea behind Occam's razor is presented as a way of balancing bias and variance. This leads us to the mathematical framework of Bayesian interpolation and model selection to choose between different models based on the data.&lt;/p&gt;
&lt;p&gt;To derive ARD as gently as possible the mathematical basics of a simple linear model are repeated as well as the idea of regularization to prevent over-fitting. Based on that, the Bayesian Ridge Regression (BayesianRidge in Scikit-Learn) is introduced. Generalizing the concept of Bayesian Ridge Regression even more gets us eventually to the the idea behind ARD (ARDRegression in Scikit-Learn).&lt;/p&gt;
&lt;p&gt;With the help of a practical example, we consolidate what has been learnt so far and compare ARD to an ordinary least square model. Now we dive deep into the mathematics of ARD and present the algorithm that solves the minimization problem of ARD. Finally, some details of Scikit-Learn's ARD implementation are discussed.&lt;/p&gt;
&lt;p&gt;Slides available here: &lt;a class="reference external" href="http://www.slideshare.net/FlorianWilhelm2/explaining-the-idea-behind-automatic-relevance-determination-and-bayesian-interpolation-59498957"&gt;http://www.slideshare.net/FlorianWilhelm2/explaining-the-idea-behind-automatic-relevance-determination-and-bayesian-interpolation-59498957&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Florian Wilhelm</dc:creator><pubDate>Sat, 26 Mar 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-03-26:pydata-amsterdam-2016/the-idea-behind-automatic-relevance-determination-and-bayesian-interpolation.html</guid></item><item><title>"It's about time to take your medication!" or how to write a friendly reminder bot ;-)</title><link>https://pyvideo.org/europython-2015/its-about-time-to-take-your-medication-or-how-to-write-a-friendly-reminder-bot-.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Florian Wilhelm - &amp;quot;It's about time to take your medication!&amp;quot; or how to write a friendly reminder bot ;-)
[EuroPython 2015]
[24 July 2015]
[Bilbao, Euskadi, Spain]&lt;/p&gt;
&lt;p&gt;The author  shows how to use the [SleekXMPP][1] library in order to
write a small chatbot that connects to Google Hangouts and reminds you
or someone else to take medication for instance.  The secure and
recommended OAuth2  protocol is used to authorize the bot application
in the [Google Developers Console][2]  in order to access the Google+
Hangouts API. The author will elaborate then on how to use an event-
driven library to write a bot that sends scheduled messages, waits for
a proper reply and repeats the question if need be. Thereby, a primer
on event-driven architectures will be given.&lt;/p&gt;
&lt;p&gt;[1]: &lt;a class="reference external" href="http://sleekxmpp.readthedocs.org/"&gt;http://sleekxmpp.readthedocs.org/&lt;/a&gt;
[2]: &lt;a class="reference external" href="https://console.developers.google.com/"&gt;https://console.developers.google.com/&lt;/a&gt;&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Florian Wilhelm</dc:creator><pubDate>Wed, 05 Aug 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2015-08-05:europython-2015/its-about-time-to-take-your-medication-or-how-to-write-a-friendly-reminder-bot-.html</guid><category>SleekXMPP</category><category>chatbot</category></item><item><title>Handling GPS Data with Python</title><link>https://pyvideo.org/europython-2016/handling-gps-data-with-python.html</link><description>&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Florian Wilhelm - Handling GPS Data with Python
[EuroPython 2016]
[22 July 2016]
[Bilbao, Euskadi, Spain]
(&lt;a class="reference external" href="https://ep2016.europython.eu//conference/talks/handling-gps-data-with-python"&gt;https://ep2016.europython.eu//conference/talks/handling-gps-data-with-python&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;If you have ever happened to need to deal with GPS data in Python you
may have felt a bit lost.  This talk presents libraries starting from
basic reading and writing GPS tracks in the GPS Exchange Format to
adding missing elevation information. Also visualisation of tracks on
OpenStreetmap data with interactive plots in Jupyter notebooks is
covered. Additionally common algorithms for GPS like Douglas-Peucker
and Kalman filter are explained.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;If you have ever happened to need to deal with GPS data in Python you
may have felt a bit lost. There are many libraries at various states
of maturity and scope. Finding a place to start and to actually work
with the GPS data might not be as easy and obvious as you might expect
from other Python domains.
Inspired from my own experiences of dealing with GPS data in Python, I
want to give an overview of some useful libraries. From basic reading
and writing GPS tracks in the GPS Exchange Format with the help of
gpxpy to adding missing elevation information with srtm.py.
Additionally, I will cover mapping and visualising tracks on
OpenStreetmap with mplleaflet that even supports interactive plots in
a Jupyter notebook.
Besides the tooling, I will also demonstrate and explain common
algorithms like Douglas-Peucker to simplify a track and the famous
Kalman filters for smoothing. For both algorithms I will give an
intuition about how they work as well as their basic mathematical
concepts. Especially the Kalman filter that is used for all kinds of
sensor, not only GPS, has the reputation of being hard to understand.
Still, its concept is really easy and quite comprehensible as I will
also demonstrate by presenting an implementation in Python with the
help of Numpy and Scipy. My presentation will make heavy use of the
Jupyter notebook which is a wonderful tool perfectly suited for
experimenting and learning.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Florian Wilhelm</dc:creator><pubDate>Fri, 05 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2016-08-05:europython-2016/handling-gps-data-with-python.html</guid></item><item><title>Extending Scikit-Learn with your own Regressor</title><link>https://pyvideo.org/europython-2014/extending-scikit-learn-with-your-own-regressor.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;We show how to write your own robust linear estimator within the
Scikit-Learn framework using as an example the Theil-Sen estimator known
as &amp;quot;the most popular nonparametric technique for estimating a linear
trend&amp;quot;.&lt;/p&gt;
&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Scikit-Learn (&lt;a class="reference external" href="http://scikit-learn.org/"&gt;http://scikit-learn.org/&lt;/a&gt;) is a well-known and popular
framework for machine learning that is used by Data Scientists all over
the world. We show in a practical way how you can add your own estimator
following the interfaces of Scikit-Learn. First we give a small
introduction to the design of Scikit-Learn and its inner workings. Then
we show how easily Scikit-Learn can be extended by creating an own
estimator. In order to demonstrate this, we extend Scikit-Learn by the
popular and robust Theil-Sen Estimator
(&lt;a class="reference external" href="http://en.wikipedia.org/wiki/Theil%E2%80%93Sen_estimator"&gt;http://en.wikipedia.org/wiki/Theil%E2%80%93Sen_estimator&lt;/a&gt;) that is
currently not in Scikit-Learn. We also motivate this estimator by
outlining some of its superior properties compared to the ordinary least
squares method (LinearRegression in Scikit-Learn).&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Florian Wilhelm</dc:creator><pubDate>Fri, 25 Jul 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2014-07-25:europython-2014/extending-scikit-learn-with-your-own-regressor.html</guid></item><item><title>Handling Big Data with Python</title><link>https://pyvideo.org/pycon-de-2013/handling-big-data-with-python.html</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;p&gt;The talk gives a small introduction of how Blue Yonder applies machine
learning and Predictive Analytics in various fields as well as the
challenges of Big Data. Using the example of Blue Yonder's machine
learning software NeuroBayes, we show the made efforts and hit dead ends
in order to provide a flexible and yet easy to use interface for
NeuroBayes to Data Scientists. Since NeuroBayes is written in FORTRAN
for performance reasons different interface approaches were tried which
lead us eventually to a Python interface. In the talk we elaborate on
the up- and downsides of the different approaches and the various
reasons why Python won the race with an emphasize on the benefits of the
Python ecosystem itself. Also, we discuss performance as well as
scalability issues with Python and how we address them. In detail, we
show the application of Cython to speed up calculations in the Python
interface layer as well as distributed computing in a private cloud
called Stratosphere. Scalability and efficiency is of utmost importance
when data processing is time critical. Our overall goal is to give the
audience an overview how Python fits in the software ecosystem of a
company handling Big Data.&lt;/p&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Florian Wilhelm</dc:creator><pubDate>Thu, 17 Oct 2013 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:pyvideo.org,2013-10-17:pycon-de-2013/handling-big-data-with-python.html</guid></item></channel></rss>